{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    }
   ],
   "source": [
    "print(\"start\")\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir = './'\n",
    "# dataset_id = '007'\n",
    "# dataset_name = 'Blastoma'\n",
    "# raw_folder_path = f'nnUNet_raw/Dataset{dataset_id}_{dataset_name}'\n",
    "# preprocessed_folder_path = f'nnUNet_preprocessed/Dataset{dataset_id}_{dataset_name}'\n",
    "# results_folder_path = f'nnUNet_results/Dataset{dataset_id}_{dataset_name}'\n",
    "\n",
    "# # For Raw folder\n",
    "# base_dir_raw = os.path.join(base_dir, raw_folder_path)\n",
    "# os.makedirs(base_dir_raw, exist_ok=True)\n",
    "\n",
    "# imagesTr_path = os.path.join(base_dir_raw, 'imagesTr')\n",
    "# labelsTr_path = os.path.join(base_dir_raw, 'labelsTr')\n",
    "\n",
    "# os.makedirs(imagesTr_path, exist_ok=True) # for imagesTr folder in raw folder\n",
    "# os.makedirs(labelsTr_path, exist_ok=True) # for labelsTr folder in raw folder\n",
    "# json_file_path = os.path.join(base_dir_raw, 'dataset.json') # json file in raw folder\n",
    "\n",
    "# # For preprocessing folder\n",
    "# base_dir_preprocess = os.path.join(base_dir, preprocessed_folder_path)\n",
    "# os.makedirs(base_dir_preprocess, exist_ok=True)\n",
    "\n",
    "# # For results folder\n",
    "# base_dir_results = os.path.join(base_dir, results_folder_path)\n",
    "# os.makedirs(base_dir_results, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files ['volume_34_0000.nii', 'volume_35_0000.nii', 'volume_36_0000.nii', 'volume_37_0000.nii', 'volume_38_0000.nii', 'volume_39_0000.nii', 'volume_40_0000.nii', 'volume_41_0000.nii']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'src_file_itr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m files_to_copy \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_0000.nii\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m34\u001b[39m,\u001b[38;5;241m42\u001b[39m)]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles\u001b[39m\u001b[38;5;124m\"\u001b[39m,files_to_copy)\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[43msrc_file_itr\u001b[49m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Copy and rename the files\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, file \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(files_to_copy):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'src_file_itr' is not defined"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import nibabel as nib\n",
    "\n",
    "\n",
    "#Source directory to copy train volumes from\n",
    "source_dir_itr = 'D:/Liver Segmentation Meena 2024/Neuroblastoma_2025/volumes'\n",
    "\n",
    "#Destination directory to save train volumes into\n",
    "dest_dir = 'D:/Liver Segmentation Meena 2024/nnUNet_blastoma_2025/nnUNet_raw/Dataset007_Blastoma/imagesTr'\n",
    "\n",
    "# List of specific files to copy\n",
    "files_to_copy = [f'volume_{i}_0000.nii' for i in range(34,42)]\n",
    "print(\"files\",files_to_copy)\n",
    "print(\"src\",src_file_itr)\n",
    "\n",
    "# Copy and rename the files\n",
    "for i, file in enumerate(files_to_copy):\n",
    "    case_id = f'case_{i:03d}'\n",
    "    new_file_name = f'{case_id}_0000.nii.gz'\n",
    "    src_file_itr = os.path.join(source_dir_itr,f'{file}')\n",
    "    dest_file_itr = os.path.join(dest_dir, f'{file}.gz')  # Save as .nii.gz with the original file name\n",
    "\n",
    "    # # Try copying the file\n",
    "    # try:\n",
    "    #     shutil.copy(src_file_itr, dest_file_itr)\n",
    "    #     print(f'Copied {src_file_itr} to {dest_file_itr}')\n",
    "    # except Exception as e:\n",
    "    #     print(f'Failed to copy {src_file_itr} to {dest_file_itr}: {e}')\n",
    "        # Try copying and converting the file\n",
    "    try:\n",
    "        img = nib.load(src_file_itr)\n",
    "        nib.save(img, dest_file_itr)\n",
    "        print(f'Copied and converted {src_file_itr} to {dest_file_itr}')\n",
    "    except Exception as e:\n",
    "        print(f'Failed to copy and convert {src_file_itr} to {dest_file_itr}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 32-33: malformed \\N character escape (3045958319.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    source_dir_itr = 'D:/Liver Segmentation Meena 2024\\Neuroblastoma_2025\\masks'\u001b[0m\n\u001b[1;37m                                                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 32-33: malformed \\N character escape\n"
     ]
    }
   ],
   "source": [
    "source_dir_itr = 'D:/Liver Segmentation Meena 2024\\Neuroblastoma_2025\\masks'\n",
    "\n",
    "#Destination directory to save train volumes into\n",
    "dest_dir = 'D:/Liver Segmentation Meena 2024/nnUNet_blastoma_2025/nnUNet_raw/Dataset007_Blastoma/labelsTr'\n",
    "\n",
    "# List of specific files to copy\n",
    "files_to_copy = [f'volume_{i}.nii' for i in range(34,42)]\n",
    "print(\"files\",files_to_copy)\n",
    "\n",
    "# Copy and rename the files\n",
    "for i, file in enumerate(files_to_copy):\n",
    "    case_id = f'case_{i:03d}'\n",
    "    src_file_itr =  os.path.join(source_dir_itr, f'{file}') \n",
    "    dest_file_itr = os.path.join(dest_dir, f'{file}.gz')  # Save as .nii.gz with the original file name\n",
    "\n",
    "    # # Try copying the file\n",
    "    # try:\n",
    "    #     shutil.copy(src_file_itr, dest_file_itr)\n",
    "    #     print(f'Copied {src_file_itr} to {dest_file_itr}')\n",
    "    # except Exception as e:\n",
    "    #     print(f'Failed to copy {src_file_itr} to {dest_file_itr}: {e}')\n",
    "        # Try copying and converting the file\n",
    "    try:\n",
    "        img = nib.load(src_file_itr)\n",
    "        nib.save(img, dest_file_itr)\n",
    "        print(f'Copied and converted {src_file_itr} to {dest_file_itr}')\n",
    "    except Exception as e:\n",
    "        print(f'Failed to copy and convert {src_file_itr} to {dest_file_itr}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files ['volume_34.nii', 'volume_35.nii', 'volume_36.nii', 'volume_37.nii', 'volume_38.nii', 'volume_39.nii', 'volume_40.nii', 'volume_41.nii']\n",
      "Copied and converted D:/Liver Segmentation Meena 2024/Neuroblastoma_2025/masks\\volume_34.nii to D:/Liver Segmentation Meena 2024/nnUNet_blastoma_2025/nnUNet_raw/Dataset007_Blastoma/labelsTr\\volume_34.nii.gz\n",
      "Copied and converted D:/Liver Segmentation Meena 2024/Neuroblastoma_2025/masks\\volume_35.nii to D:/Liver Segmentation Meena 2024/nnUNet_blastoma_2025/nnUNet_raw/Dataset007_Blastoma/labelsTr\\volume_35.nii.gz\n",
      "Copied and converted D:/Liver Segmentation Meena 2024/Neuroblastoma_2025/masks\\volume_36.nii to D:/Liver Segmentation Meena 2024/nnUNet_blastoma_2025/nnUNet_raw/Dataset007_Blastoma/labelsTr\\volume_36.nii.gz\n",
      "Copied and converted D:/Liver Segmentation Meena 2024/Neuroblastoma_2025/masks\\volume_37.nii to D:/Liver Segmentation Meena 2024/nnUNet_blastoma_2025/nnUNet_raw/Dataset007_Blastoma/labelsTr\\volume_37.nii.gz\n",
      "Copied and converted D:/Liver Segmentation Meena 2024/Neuroblastoma_2025/masks\\volume_38.nii to D:/Liver Segmentation Meena 2024/nnUNet_blastoma_2025/nnUNet_raw/Dataset007_Blastoma/labelsTr\\volume_38.nii.gz\n",
      "Copied and converted D:/Liver Segmentation Meena 2024/Neuroblastoma_2025/masks\\volume_39.nii to D:/Liver Segmentation Meena 2024/nnUNet_blastoma_2025/nnUNet_raw/Dataset007_Blastoma/labelsTr\\volume_39.nii.gz\n",
      "Copied and converted D:/Liver Segmentation Meena 2024/Neuroblastoma_2025/masks\\volume_40.nii to D:/Liver Segmentation Meena 2024/nnUNet_blastoma_2025/nnUNet_raw/Dataset007_Blastoma/labelsTr\\volume_40.nii.gz\n",
      "Copied and converted D:/Liver Segmentation Meena 2024/Neuroblastoma_2025/masks\\volume_41.nii to D:/Liver Segmentation Meena 2024/nnUNet_blastoma_2025/nnUNet_raw/Dataset007_Blastoma/labelsTr\\volume_41.nii.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "\n",
    "# Source directory to copy masks from\n",
    "source_dir_ltr = 'D:/Liver Segmentation Meena 2024/Neuroblastoma_2025/masks'\n",
    "\n",
    "# Destination directory to save masks into\n",
    "dest_dir_ltr = 'D:/Liver Segmentation Meena 2024/nnUNet_blastoma_2025/nnUNet_raw/Dataset007_Blastoma/labelsTr'  # Define labelsTr_path with your destination path\n",
    "\n",
    "# List of specific files to copy\n",
    "files_to_copy = [f'volume_{i}.nii' for i in range(34,42)]\n",
    "print(\"files\",files_to_copy)\n",
    "\n",
    "# Copy and convert the files\n",
    "for file in files_to_copy:\n",
    "    src_file_ltr = os.path.join(source_dir_ltr, file)\n",
    "    dest_file_ltr = os.path.join(dest_dir_ltr, f'{file}.gz')  # Save as .nii.gz with original file name\n",
    "\n",
    "    try:\n",
    "        # Load and save file in .nii.gz format\n",
    "        img = nib.load(src_file_ltr)\n",
    "        nib.save(img, dest_file_ltr)\n",
    "        print(f'Copied and converted {src_file_ltr} to {dest_file_ltr}')\n",
    "    except Exception as e:\n",
    "        print(f'Failed to copy and convert {src_file_ltr} to {dest_file_ltr}: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['nnUNet_preprocessed']= r'D:/Liver Segmentation Meena 2024/nnUNet_blastoma_2025/nnUNet_preprocessed'\n",
    "os.environ['nnUNet_results']= r'D:/Liver Segmentation Meena 2024/nnUNet_blastoma_2025/nnUNet_results'\n",
    "os.environ['nnUNet_raw']= r'D:/Liver Segmentation Meena 2024/nnUNet_blastoma_2025/nnUNet_raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnUNet_raw is not defined and nnU-Net can only be used on data for which preprocessed files are already present on your system. nnU-Net cannot be used for experiment planning and preprocessing like this. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up properly.\n",
      "nnUNet_preprocessed is not defined and nnU-Net can not be used for preprocessing or training. If this is not intended, please read documentation/setting_up_paths.md for information on how to set this up.\n",
      "nnUNet_results is not defined and nnU-Net cannot be used for training or inference. If this is not intended behavior, please read documentation/setting_up_paths.md for information on how to set this up.\n",
      "Fingerprint extraction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\Scripts\\nnUNetv2_plan_and_preprocess.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nnunetv2\\experiment_planning\\plan_and_preprocess_entrypoints.py\", line 180, in plan_and_preprocess_entry\n",
      "    extract_fingerprints(args.d, args.fpe, args.npfp, args.verify_dataset_integrity, args.clean, args.verbose)\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nnunetv2\\experiment_planning\\plan_and_preprocess_api.py\", line 47, in extract_fingerprints\n",
      "    extract_fingerprint_dataset(d, fingerprint_extractor_class, num_processes, check_dataset_integrity, clean,\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nnunetv2\\experiment_planning\\plan_and_preprocess_api.py\", line 26, in extract_fingerprint_dataset\n",
      "    dataset_name = convert_id_to_dataset_name(dataset_id)\n",
      "  File \"C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nnunetv2\\utilities\\dataset_name_id_conversion.py\", line 48, in convert_id_to_dataset_name\n",
      "    raise RuntimeError(f\"Could not find a dataset with the ID {dataset_id}. Make sure the requested dataset ID \"\n",
      "RuntimeError: Could not find a dataset with the ID 7. Make sure the requested dataset ID exists and that nnU-Net knows where raw and preprocessed data are located (see Documentation - Installation). Here are your currently defined folders:\n",
      "nnUNet_preprocessed=None\n",
      "nnUNet_results=None\n",
      "nnUNet_raw=None\n",
      "If something is not right, adapt your environment variables.\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "try:\n",
    "  !nnUNetv2_plan_and_preprocess -d 007 --verify_dataset_integrity\n",
    "except Exception as e:\n",
    "    print(f\"Error during preprocessing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "try:\n",
    "    !nnUNetv2_train 007 3d_fullres 0 -tr nnUNetTrainer\n",
    "except Exception as e:\n",
    "    print(f\"Error during training: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nnunetv2\\training\\nnUNetTrainer\\nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
      "C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2024-11-20 12:32:04.744444: do_dummy_2d_data_aug: False\n",
      "2024-11-20 12:32:04.749445: Using splits from existing split file: D:/Liver Segmentation Meena 2024/nnUNet_blastoma_2025/nnUNet_preprocessed\\Dataset007_Blastoma\\splits_final.json\n",
      "2024-11-20 12:32:04.757446: The split file contains 5 splits.\n",
      "2024-11-20 12:32:04.760447: Desired fold for training: 0\n",
      "2024-11-20 12:32:04.764448: This split has 19 training and 5 validation cases.\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 3d_fullres\n",
      " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [569.5, 512.0, 512.0], 'spacing': [0.625, 0.4882810115814209, 0.4882810115814209], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset007_Blastoma', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.625, 0.4882810115814209, 0.4882810115814209], 'original_median_shape_after_transp': [471, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2609.056396484375, 'mean': 68.07295227050781, 'median': 66.0, 'min': -1028.0, 'percentile_00_5': -59.0, 'percentile_99_5': 248.0, 'std': 47.62541198730469}}} \n",
      "\n",
      "2024-11-20 12:32:27.805769: unpacking dataset...\n",
      "2024-11-20 12:33:18.897957: unpacking done...\n",
      "2024-11-20 12:33:18.913963: Unable to plot network architecture:\n",
      "2024-11-20 12:33:18.917964: No module named 'hiddenlayer'\n",
      "2024-11-20 12:33:18.950476: \n",
      "2024-11-20 12:33:18.956477: Epoch 0\n",
      "2024-11-20 12:33:18.960478: Current learning rate: 0.01\n",
      "2024-11-20 12:35:44.008329: train_loss 0.0719\n",
      "2024-11-20 12:35:44.008329: val_loss 0.0889\n",
      "2024-11-20 12:35:44.018331: Pseudo dice [0.4382]\n",
      "2024-11-20 12:35:44.028330: Epoch time: 145.06 s\n",
      "2024-11-20 12:35:44.028330: Yayy! New best EMA pseudo Dice: 0.4382\n",
      "2024-11-20 12:35:45.278347: \n",
      "2024-11-20 12:35:45.278347: Epoch 1\n",
      "2024-11-20 12:35:45.278347: Current learning rate: 0.00998\n",
      "2024-11-20 12:37:54.735267: train_loss -0.1664\n",
      "2024-11-20 12:37:54.735267: val_loss 0.0508\n",
      "2024-11-20 12:37:54.755268: Pseudo dice [0.5023]\n",
      "2024-11-20 12:37:54.755268: Epoch time: 129.47 s\n",
      "2024-11-20 12:37:54.765267: Yayy! New best EMA pseudo Dice: 0.4446\n",
      "2024-11-20 12:37:55.985587: \n",
      "2024-11-20 12:37:55.985587: Epoch 2\n",
      "2024-11-20 12:37:55.995588: Current learning rate: 0.00996\n",
      "2024-11-20 12:40:05.473966: train_loss -0.223\n",
      "2024-11-20 12:40:05.473966: val_loss 0.0782\n",
      "2024-11-20 12:40:05.483965: Pseudo dice [0.4212]\n",
      "2024-11-20 12:40:05.483965: Epoch time: 129.49 s\n",
      "2024-11-20 12:40:06.483979: \n",
      "2024-11-20 12:40:06.483979: Epoch 3\n",
      "2024-11-20 12:40:06.493979: Current learning rate: 0.00995\n",
      "2024-11-20 12:42:16.083533: train_loss -0.2706\n",
      "2024-11-20 12:42:16.083533: val_loss -0.0168\n",
      "2024-11-20 12:42:16.103534: Pseudo dice [0.5128]\n",
      "2024-11-20 12:42:16.113533: Epoch time: 129.6 s\n",
      "2024-11-20 12:42:16.123535: Yayy! New best EMA pseudo Dice: 0.4493\n",
      "2024-11-20 12:42:17.333550: \n",
      "2024-11-20 12:42:17.333550: Epoch 4\n",
      "2024-11-20 12:42:17.343551: Current learning rate: 0.00993\n",
      "2024-11-20 12:44:26.815079: train_loss -0.2396\n",
      "2024-11-20 12:44:26.815079: val_loss 0.1846\n",
      "2024-11-20 12:44:26.825078: Pseudo dice [0.4597]\n",
      "2024-11-20 12:44:26.825078: Epoch time: 129.48 s\n",
      "2024-11-20 12:44:26.835080: Yayy! New best EMA pseudo Dice: 0.4503\n",
      "2024-11-20 12:44:28.085534: \n",
      "2024-11-20 12:44:28.085534: Epoch 5\n",
      "2024-11-20 12:44:28.085534: Current learning rate: 0.00991\n",
      "2024-11-20 12:46:37.496174: train_loss -0.2583\n",
      "2024-11-20 12:46:37.496174: val_loss 0.0563\n",
      "2024-11-20 12:46:37.506173: Pseudo dice [0.5288]\n",
      "2024-11-20 12:46:37.516173: Epoch time: 129.41 s\n",
      "2024-11-20 12:46:37.516173: Yayy! New best EMA pseudo Dice: 0.4582\n",
      "2024-11-20 12:46:38.716189: \n",
      "2024-11-20 12:46:38.716189: Epoch 6\n",
      "2024-11-20 12:46:38.726190: Current learning rate: 0.00989\n",
      "2024-11-20 12:48:48.124413: train_loss -0.336\n",
      "2024-11-20 12:48:48.124413: val_loss -0.0206\n",
      "2024-11-20 12:48:48.134413: Pseudo dice [0.4873]\n",
      "2024-11-20 12:48:48.144413: Epoch time: 129.41 s\n",
      "2024-11-20 12:48:48.154413: Yayy! New best EMA pseudo Dice: 0.4611\n",
      "2024-11-20 12:48:49.354429: \n",
      "2024-11-20 12:48:49.354429: Epoch 7\n",
      "2024-11-20 12:48:49.364429: Current learning rate: 0.00987\n",
      "2024-11-20 12:50:58.907010: train_loss -0.2753\n",
      "2024-11-20 12:50:58.907010: val_loss 0.1316\n",
      "2024-11-20 12:50:58.917011: Pseudo dice [0.4255]\n",
      "2024-11-20 12:50:58.927010: Epoch time: 129.55 s\n",
      "2024-11-20 12:51:00.087029: \n",
      "2024-11-20 12:51:00.087029: Epoch 8\n",
      "2024-11-20 12:51:00.087029: Current learning rate: 0.00986\n",
      "2024-11-20 12:53:09.548185: train_loss -0.3144\n",
      "2024-11-20 12:53:09.548185: val_loss -0.1316\n",
      "2024-11-20 12:53:09.568186: Pseudo dice [0.5665]\n",
      "2024-11-20 12:53:09.568186: Epoch time: 129.46 s\n",
      "2024-11-20 12:53:09.578187: Yayy! New best EMA pseudo Dice: 0.4684\n",
      "2024-11-20 12:53:10.818503: \n",
      "2024-11-20 12:53:10.818503: Epoch 9\n",
      "2024-11-20 12:53:10.818503: Current learning rate: 0.00984\n",
      "2024-11-20 12:55:20.258254: train_loss -0.3276\n",
      "2024-11-20 12:55:20.258254: val_loss 0.0937\n",
      "2024-11-20 12:55:20.258254: Pseudo dice [0.3968]\n",
      "2024-11-20 12:55:20.268253: Epoch time: 129.43 s\n",
      "2024-11-20 12:55:21.218266: \n",
      "2024-11-20 12:55:21.218266: Epoch 10\n",
      "2024-11-20 12:55:21.218266: Current learning rate: 0.00982\n",
      "2024-11-20 12:57:30.637905: train_loss -0.3387\n",
      "2024-11-20 12:57:30.647906: val_loss 0.0226\n",
      "2024-11-20 12:57:30.647906: Pseudo dice [0.4749]\n",
      "2024-11-20 12:57:30.657907: Epoch time: 129.42 s\n",
      "2024-11-20 12:57:31.617919: \n",
      "2024-11-20 12:57:31.617919: Epoch 11\n",
      "2024-11-20 12:57:31.617919: Current learning rate: 0.0098\n",
      "2024-11-20 12:59:41.146728: train_loss -0.3415\n",
      "2024-11-20 12:59:41.146728: val_loss -0.0614\n",
      "2024-11-20 12:59:41.156728: Pseudo dice [0.5548]\n",
      "2024-11-20 12:59:41.166728: Epoch time: 129.53 s\n",
      "2024-11-20 12:59:41.166728: Yayy! New best EMA pseudo Dice: 0.4718\n",
      "2024-11-20 12:59:42.366744: \n",
      "2024-11-20 12:59:42.376744: Epoch 12\n",
      "2024-11-20 12:59:42.376744: Current learning rate: 0.00978\n",
      "2024-11-20 13:01:51.783924: train_loss -0.3374\n",
      "2024-11-20 13:01:51.783924: val_loss -0.0209\n",
      "2024-11-20 13:01:51.793924: Pseudo dice [0.482]\n",
      "2024-11-20 13:01:51.803925: Epoch time: 129.42 s\n",
      "2024-11-20 13:01:51.803925: Yayy! New best EMA pseudo Dice: 0.4729\n",
      "2024-11-20 13:01:53.013941: \n",
      "2024-11-20 13:01:53.013941: Epoch 13\n",
      "2024-11-20 13:01:53.013941: Current learning rate: 0.00977\n",
      "2024-11-20 13:04:02.464306: train_loss -0.3273\n",
      "2024-11-20 13:04:02.464306: val_loss -0.0314\n",
      "2024-11-20 13:04:02.474305: Pseudo dice [0.5541]\n",
      "2024-11-20 13:04:02.484306: Epoch time: 129.45 s\n",
      "2024-11-20 13:04:02.494306: Yayy! New best EMA pseudo Dice: 0.481\n",
      "2024-11-20 13:04:03.785419: \n",
      "2024-11-20 13:04:03.785419: Epoch 14\n",
      "2024-11-20 13:04:03.795419: Current learning rate: 0.00975\n",
      "2024-11-20 13:06:13.252105: train_loss -0.3724\n",
      "2024-11-20 13:06:13.252105: val_loss -0.0735\n",
      "2024-11-20 13:06:13.262105: Pseudo dice [0.5524]\n",
      "2024-11-20 13:06:13.272105: Epoch time: 129.47 s\n",
      "2024-11-20 13:06:13.272105: Yayy! New best EMA pseudo Dice: 0.4881\n",
      "2024-11-20 13:06:14.672125: \n",
      "2024-11-20 13:06:14.672125: Epoch 15\n",
      "2024-11-20 13:06:14.672125: Current learning rate: 0.00973\n",
      "2024-11-20 13:08:24.360533: train_loss -0.3978\n",
      "2024-11-20 13:08:24.360533: val_loss -0.0937\n",
      "2024-11-20 13:08:24.370534: Pseudo dice [0.5875]\n",
      "2024-11-20 13:08:24.370534: Epoch time: 129.69 s\n",
      "2024-11-20 13:08:24.380534: Yayy! New best EMA pseudo Dice: 0.4981\n",
      "2024-11-20 13:08:25.610850: \n",
      "2024-11-20 13:08:25.610850: Epoch 16\n",
      "2024-11-20 13:08:25.610850: Current learning rate: 0.00971\n",
      "2024-11-20 13:10:35.033830: train_loss -0.3735\n",
      "2024-11-20 13:10:35.033830: val_loss -0.197\n",
      "2024-11-20 13:10:35.043830: Pseudo dice [0.6576]\n",
      "2024-11-20 13:10:35.043830: Epoch time: 129.42 s\n",
      "2024-11-20 13:10:35.053831: Yayy! New best EMA pseudo Dice: 0.514\n",
      "2024-11-20 13:10:36.294153: \n",
      "2024-11-20 13:10:36.304153: Epoch 17\n",
      "2024-11-20 13:10:36.304153: Current learning rate: 0.00969\n",
      "2024-11-20 13:12:45.768536: train_loss -0.3724\n",
      "2024-11-20 13:12:45.768536: val_loss -0.1131\n",
      "2024-11-20 13:12:45.778535: Pseudo dice [0.552]\n",
      "2024-11-20 13:12:45.788535: Epoch time: 129.47 s\n",
      "2024-11-20 13:12:45.788535: Yayy! New best EMA pseudo Dice: 0.5178\n",
      "2024-11-20 13:12:47.128554: \n",
      "2024-11-20 13:12:47.128554: Epoch 18\n",
      "2024-11-20 13:12:47.128554: Current learning rate: 0.00968\n",
      "2024-11-20 13:14:56.542372: train_loss -0.4343\n",
      "2024-11-20 13:14:56.542372: val_loss 0.0492\n",
      "2024-11-20 13:14:56.552373: Pseudo dice [0.5248]\n",
      "2024-11-20 13:14:56.552373: Epoch time: 129.41 s\n",
      "2024-11-20 13:14:56.562373: Yayy! New best EMA pseudo Dice: 0.5185\n",
      "2024-11-20 13:14:57.802776: \n",
      "2024-11-20 13:14:57.802776: Epoch 19\n",
      "2024-11-20 13:14:57.812776: Current learning rate: 0.00966\n",
      "2024-11-20 13:17:07.400063: train_loss -0.4192\n",
      "2024-11-20 13:17:07.400063: val_loss -0.1231\n",
      "2024-11-20 13:17:07.410063: Pseudo dice [0.5563]\n",
      "2024-11-20 13:17:07.410063: Epoch time: 129.6 s\n",
      "2024-11-20 13:17:07.420063: Yayy! New best EMA pseudo Dice: 0.5223\n",
      "2024-11-20 13:17:08.650080: \n",
      "2024-11-20 13:17:08.650080: Epoch 20\n",
      "2024-11-20 13:17:08.650080: Current learning rate: 0.00964\n",
      "2024-11-20 13:19:18.108555: train_loss -0.385\n",
      "2024-11-20 13:19:18.108555: val_loss -0.0337\n",
      "2024-11-20 13:19:18.118555: Pseudo dice [0.5936]\n",
      "2024-11-20 13:19:18.128779: Epoch time: 129.46 s\n",
      "2024-11-20 13:19:18.132814: Yayy! New best EMA pseudo Dice: 0.5294\n",
      "2024-11-20 13:19:19.519590: \n",
      "2024-11-20 13:19:19.519590: Epoch 21\n",
      "2024-11-20 13:19:19.529591: Current learning rate: 0.00962\n",
      "2024-11-20 13:21:28.928235: train_loss -0.4435\n",
      "2024-11-20 13:21:28.928235: val_loss -0.1586\n",
      "2024-11-20 13:21:28.938236: Pseudo dice [0.6549]\n",
      "2024-11-20 13:21:28.938236: Epoch time: 129.41 s\n",
      "2024-11-20 13:21:28.948236: Yayy! New best EMA pseudo Dice: 0.542\n",
      "2024-11-20 13:21:30.138587: \n",
      "2024-11-20 13:21:30.138587: Epoch 22\n",
      "2024-11-20 13:21:30.148587: Current learning rate: 0.0096\n",
      "2024-11-20 13:23:40.254816: train_loss -0.48\n",
      "2024-11-20 13:23:40.254816: val_loss -0.1304\n",
      "2024-11-20 13:23:40.254816: Pseudo dice [0.5974]\n",
      "2024-11-20 13:23:40.264816: Epoch time: 130.12 s\n",
      "2024-11-20 13:23:40.264816: Yayy! New best EMA pseudo Dice: 0.5475\n",
      "2024-11-20 13:23:41.465524: \n",
      "2024-11-20 13:23:41.465524: Epoch 23\n",
      "2024-11-20 13:23:41.465524: Current learning rate: 0.00959\n",
      "2024-11-20 13:25:50.831625: train_loss -0.4687\n",
      "2024-11-20 13:25:50.831625: val_loss -0.157\n",
      "2024-11-20 13:25:50.831625: Pseudo dice [0.6462]\n",
      "2024-11-20 13:25:50.841624: Epoch time: 129.37 s\n",
      "2024-11-20 13:25:50.851625: Yayy! New best EMA pseudo Dice: 0.5574\n",
      "2024-11-20 13:25:52.031641: \n",
      "2024-11-20 13:25:52.031641: Epoch 24\n",
      "2024-11-20 13:25:52.031641: Current learning rate: 0.00957\n",
      "2024-11-20 13:28:01.441612: train_loss -0.4901\n",
      "2024-11-20 13:28:01.441612: val_loss -0.0365\n",
      "2024-11-20 13:28:01.451612: Pseudo dice [0.6042]\n",
      "2024-11-20 13:28:01.461613: Epoch time: 129.41 s\n",
      "2024-11-20 13:28:01.461613: Yayy! New best EMA pseudo Dice: 0.5621\n",
      "2024-11-20 13:28:02.661629: \n",
      "2024-11-20 13:28:02.661629: Epoch 25\n",
      "2024-11-20 13:28:02.661629: Current learning rate: 0.00955\n",
      "2024-11-20 13:30:12.137976: train_loss -0.4881\n",
      "2024-11-20 13:30:12.137976: val_loss -0.1806\n",
      "2024-11-20 13:30:12.137976: Pseudo dice [0.696]\n",
      "2024-11-20 13:30:12.147976: Epoch time: 129.48 s\n",
      "2024-11-20 13:30:12.157977: Yayy! New best EMA pseudo Dice: 0.5755\n",
      "2024-11-20 13:30:13.367993: \n",
      "2024-11-20 13:30:13.367993: Epoch 26\n",
      "2024-11-20 13:30:13.367993: Current learning rate: 0.00953\n",
      "2024-11-20 13:32:22.810275: train_loss -0.509\n",
      "2024-11-20 13:32:22.810275: val_loss -0.3024\n",
      "2024-11-20 13:32:22.820275: Pseudo dice [0.7236]\n",
      "2024-11-20 13:32:22.830275: Epoch time: 129.44 s\n",
      "2024-11-20 13:32:22.830275: Yayy! New best EMA pseudo Dice: 0.5903\n",
      "2024-11-20 13:32:24.040595: \n",
      "2024-11-20 13:32:24.040595: Epoch 27\n",
      "2024-11-20 13:32:24.040595: Current learning rate: 0.00951\n",
      "2024-11-20 13:34:33.493460: train_loss -0.501\n",
      "2024-11-20 13:34:33.493460: val_loss -0.2168\n",
      "2024-11-20 13:34:33.503460: Pseudo dice [0.7104]\n",
      "2024-11-20 13:34:33.503460: Epoch time: 129.46 s\n",
      "2024-11-20 13:34:33.513460: Yayy! New best EMA pseudo Dice: 0.6023\n",
      "2024-11-20 13:34:34.893481: \n",
      "2024-11-20 13:34:34.893481: Epoch 28\n",
      "2024-11-20 13:34:34.893481: Current learning rate: 0.00949\n",
      "2024-11-20 13:36:44.340978: train_loss -0.4864\n",
      "2024-11-20 13:36:44.340978: val_loss -0.2031\n",
      "2024-11-20 13:36:44.357482: Pseudo dice [0.7029]\n",
      "2024-11-20 13:36:44.360986: Epoch time: 129.45 s\n",
      "2024-11-20 13:36:44.370989: Yayy! New best EMA pseudo Dice: 0.6124\n",
      "2024-11-20 13:36:45.591005: \n",
      "2024-11-20 13:36:45.591005: Epoch 29\n",
      "2024-11-20 13:36:45.601005: Current learning rate: 0.00948\n",
      "2024-11-20 13:38:55.115427: train_loss -0.5332\n",
      "2024-11-20 13:38:55.115427: val_loss -0.0552\n",
      "2024-11-20 13:38:55.145429: Pseudo dice [0.6481]\n",
      "2024-11-20 13:38:55.145429: Epoch time: 129.52 s\n",
      "2024-11-20 13:38:55.155429: Yayy! New best EMA pseudo Dice: 0.6159\n",
      "2024-11-20 13:38:56.375975: \n",
      "2024-11-20 13:38:56.375975: Epoch 30\n",
      "2024-11-20 13:38:56.385975: Current learning rate: 0.00946\n",
      "2024-11-20 13:41:05.842085: train_loss -0.5072\n",
      "2024-11-20 13:41:05.842085: val_loss -0.111\n",
      "2024-11-20 13:41:05.852086: Pseudo dice [0.6132]\n",
      "2024-11-20 13:41:05.862086: Epoch time: 129.47 s\n",
      "2024-11-20 13:41:06.842099: \n",
      "2024-11-20 13:41:06.842099: Epoch 31\n",
      "2024-11-20 13:41:06.852099: Current learning rate: 0.00944\n",
      "2024-11-20 13:43:16.273193: train_loss -0.5203\n",
      "2024-11-20 13:43:16.273193: val_loss -0.1175\n",
      "2024-11-20 13:43:16.283194: Pseudo dice [0.6749]\n",
      "2024-11-20 13:43:16.283194: Epoch time: 129.43 s\n",
      "2024-11-20 13:43:16.293194: Yayy! New best EMA pseudo Dice: 0.6216\n",
      "2024-11-20 13:43:17.503210: \n",
      "2024-11-20 13:43:17.503210: Epoch 32\n",
      "2024-11-20 13:43:17.513211: Current learning rate: 0.00942\n",
      "2024-11-20 13:45:26.980241: train_loss -0.4977\n",
      "2024-11-20 13:45:26.980241: val_loss -0.0957\n",
      "2024-11-20 13:45:27.000240: Pseudo dice [0.6432]\n",
      "2024-11-20 13:45:27.000240: Epoch time: 129.48 s\n",
      "2024-11-20 13:45:27.010241: Yayy! New best EMA pseudo Dice: 0.6237\n",
      "2024-11-20 13:45:28.220752: \n",
      "2024-11-20 13:45:28.220752: Epoch 33\n",
      "2024-11-20 13:45:28.230752: Current learning rate: 0.0094\n",
      "2024-11-20 13:47:37.718013: train_loss -0.4991\n",
      "2024-11-20 13:47:37.718013: val_loss -0.0515\n",
      "2024-11-20 13:47:37.718013: Pseudo dice [0.6192]\n",
      "2024-11-20 13:47:37.728013: Epoch time: 129.5 s\n",
      "2024-11-20 13:47:38.708026: \n",
      "2024-11-20 13:47:38.708026: Epoch 34\n",
      "2024-11-20 13:47:38.718027: Current learning rate: 0.00939\n",
      "2024-11-20 13:49:48.207376: train_loss -0.5398\n",
      "2024-11-20 13:49:48.207376: val_loss -0.2272\n",
      "2024-11-20 13:49:48.217377: Pseudo dice [0.7009]\n",
      "2024-11-20 13:49:48.227375: Epoch time: 129.5 s\n",
      "2024-11-20 13:49:48.227375: Yayy! New best EMA pseudo Dice: 0.6311\n",
      "2024-11-20 13:49:49.618859: \n",
      "2024-11-20 13:49:49.618859: Epoch 35\n",
      "2024-11-20 13:49:49.618859: Current learning rate: 0.00937\n",
      "2024-11-20 13:51:59.051472: train_loss -0.509\n",
      "2024-11-20 13:51:59.051472: val_loss -0.1483\n",
      "2024-11-20 13:51:59.061471: Pseudo dice [0.6785]\n",
      "2024-11-20 13:51:59.071473: Epoch time: 129.43 s\n",
      "2024-11-20 13:51:59.071473: Yayy! New best EMA pseudo Dice: 0.6358\n",
      "2024-11-20 13:52:00.311489: \n",
      "2024-11-20 13:52:00.311489: Epoch 36\n",
      "2024-11-20 13:52:00.321489: Current learning rate: 0.00935\n",
      "2024-11-20 13:54:09.757775: train_loss -0.5711\n",
      "2024-11-20 13:54:09.767775: val_loss -0.1758\n",
      "2024-11-20 13:54:09.767775: Pseudo dice [0.6815]\n",
      "2024-11-20 13:54:09.777775: Epoch time: 129.45 s\n",
      "2024-11-20 13:54:09.777775: Yayy! New best EMA pseudo Dice: 0.6404\n",
      "2024-11-20 13:54:11.028092: \n",
      "2024-11-20 13:54:11.028092: Epoch 37\n",
      "2024-11-20 13:54:11.028092: Current learning rate: 0.00933\n",
      "2024-11-20 13:56:20.680362: train_loss -0.4955\n",
      "2024-11-20 13:56:20.680362: val_loss -0.148\n",
      "2024-11-20 13:56:20.690362: Pseudo dice [0.685]\n",
      "2024-11-20 13:56:20.690362: Epoch time: 129.66 s\n",
      "2024-11-20 13:56:20.700362: Yayy! New best EMA pseudo Dice: 0.6448\n",
      "2024-11-20 13:56:21.950686: \n",
      "2024-11-20 13:56:21.950686: Epoch 38\n",
      "2024-11-20 13:56:21.950686: Current learning rate: 0.00931\n",
      "2024-11-20 13:58:31.419264: train_loss -0.5577\n",
      "2024-11-20 13:58:31.419264: val_loss -0.062\n",
      "2024-11-20 13:58:31.429265: Pseudo dice [0.6235]\n",
      "2024-11-20 13:58:31.429265: Epoch time: 129.47 s\n",
      "2024-11-20 13:58:32.439279: \n",
      "2024-11-20 13:58:32.439279: Epoch 39\n",
      "2024-11-20 13:58:32.439279: Current learning rate: 0.0093\n",
      "2024-11-20 14:00:41.909125: train_loss -0.561\n",
      "2024-11-20 14:00:41.909125: val_loss -0.1126\n",
      "2024-11-20 14:00:41.919126: Pseudo dice [0.6089]\n",
      "2024-11-20 14:00:41.919126: Epoch time: 129.47 s\n",
      "2024-11-20 14:00:42.939572: \n",
      "2024-11-20 14:00:42.939572: Epoch 40\n",
      "2024-11-20 14:00:42.949573: Current learning rate: 0.00928\n",
      "2024-11-20 14:02:52.387370: train_loss -0.5248\n",
      "2024-11-20 14:02:52.387370: val_loss -0.0725\n",
      "2024-11-20 14:02:52.397371: Pseudo dice [0.6023]\n",
      "2024-11-20 14:02:52.397371: Epoch time: 129.45 s\n",
      "2024-11-20 14:02:53.577387: \n",
      "2024-11-20 14:02:53.577387: Epoch 41\n",
      "2024-11-20 14:02:53.587387: Current learning rate: 0.00926\n",
      "2024-11-20 14:05:03.168022: train_loss -0.5671\n",
      "2024-11-20 14:05:03.168022: val_loss -0.2863\n",
      "2024-11-20 14:05:03.178022: Pseudo dice [0.7904]\n",
      "2024-11-20 14:05:03.188021: Epoch time: 129.59 s\n",
      "2024-11-20 14:05:03.188021: Yayy! New best EMA pseudo Dice: 0.6511\n",
      "2024-11-20 14:05:04.378038: \n",
      "2024-11-20 14:05:04.378038: Epoch 42\n",
      "2024-11-20 14:05:04.388038: Current learning rate: 0.00924\n",
      "2024-11-20 14:07:13.868066: train_loss -0.5457\n",
      "2024-11-20 14:07:13.868066: val_loss -0.0553\n",
      "2024-11-20 14:07:13.878065: Pseudo dice [0.5769]\n",
      "2024-11-20 14:07:13.888066: Epoch time: 129.49 s\n",
      "2024-11-20 14:07:14.858081: \n",
      "2024-11-20 14:07:14.858081: Epoch 43\n",
      "2024-11-20 14:07:14.858081: Current learning rate: 0.00922\n",
      "2024-11-20 14:09:24.380431: train_loss -0.5776\n",
      "2024-11-20 14:09:24.380431: val_loss -0.1336\n",
      "2024-11-20 14:09:24.390432: Pseudo dice [0.6695]\n",
      "2024-11-20 14:09:24.400432: Epoch time: 129.52 s\n",
      "2024-11-20 14:09:25.370445: \n",
      "2024-11-20 14:09:25.370445: Epoch 44\n",
      "2024-11-20 14:09:25.370445: Current learning rate: 0.0092\n",
      "2024-11-20 14:11:34.854985: train_loss -0.6117\n",
      "2024-11-20 14:11:34.854985: val_loss -0.1766\n",
      "2024-11-20 14:11:34.864986: Pseudo dice [0.7398]\n",
      "2024-11-20 14:11:34.874986: Epoch time: 129.48 s\n",
      "2024-11-20 14:11:34.874986: Yayy! New best EMA pseudo Dice: 0.6556\n",
      "2024-11-20 14:11:36.075002: \n",
      "2024-11-20 14:11:36.075002: Epoch 45\n",
      "2024-11-20 14:11:36.085002: Current learning rate: 0.00919\n",
      "2024-11-20 14:13:45.658248: train_loss -0.5932\n",
      "2024-11-20 14:13:45.658248: val_loss -0.184\n",
      "2024-11-20 14:13:45.668248: Pseudo dice [0.6938]\n",
      "2024-11-20 14:13:45.678248: Epoch time: 129.58 s\n",
      "2024-11-20 14:13:45.678248: Yayy! New best EMA pseudo Dice: 0.6594\n",
      "2024-11-20 14:13:46.888574: \n",
      "2024-11-20 14:13:46.888574: Epoch 46\n",
      "2024-11-20 14:13:46.898573: Current learning rate: 0.00917\n",
      "2024-11-20 14:15:56.392763: train_loss -0.609\n",
      "2024-11-20 14:15:56.392763: val_loss -0.1722\n",
      "2024-11-20 14:15:56.401900: Pseudo dice [0.6912]\n",
      "2024-11-20 14:15:56.408992: Epoch time: 129.5 s\n",
      "2024-11-20 14:15:56.414073: Yayy! New best EMA pseudo Dice: 0.6626\n",
      "2024-11-20 14:15:57.629504: \n",
      "2024-11-20 14:15:57.629504: Epoch 47\n",
      "2024-11-20 14:15:57.629504: Current learning rate: 0.00915\n",
      "2024-11-20 14:18:07.134729: train_loss -0.5971\n",
      "2024-11-20 14:18:07.134729: val_loss -0.1392\n",
      "2024-11-20 14:18:07.144731: Pseudo dice [0.6888]\n",
      "2024-11-20 14:18:07.154731: Epoch time: 129.51 s\n",
      "2024-11-20 14:18:07.154731: Yayy! New best EMA pseudo Dice: 0.6652\n",
      "2024-11-20 14:18:08.505776: \n",
      "2024-11-20 14:18:08.505776: Epoch 48\n",
      "2024-11-20 14:18:08.515777: Current learning rate: 0.00913\n",
      "2024-11-20 14:20:17.994166: train_loss -0.5587\n",
      "2024-11-20 14:20:17.994166: val_loss -0.1335\n",
      "2024-11-20 14:20:18.004167: Pseudo dice [0.6001]\n",
      "2024-11-20 14:20:18.004167: Epoch time: 129.49 s\n",
      "2024-11-20 14:20:18.985166: \n",
      "2024-11-20 14:20:18.985166: Epoch 49\n",
      "2024-11-20 14:20:18.985166: Current learning rate: 0.00911\n",
      "2024-11-20 14:22:28.800308: train_loss -0.6036\n",
      "2024-11-20 14:22:28.800308: val_loss -0.1883\n",
      "2024-11-20 14:22:28.810308: Pseudo dice [0.7217]\n",
      "2024-11-20 14:22:28.820309: Epoch time: 129.83 s\n",
      "2024-11-20 14:22:30.030657: \n",
      "2024-11-20 14:22:30.030657: Epoch 50\n",
      "2024-11-20 14:22:30.040658: Current learning rate: 0.0091\n",
      "2024-11-20 14:24:39.520052: train_loss -0.616\n",
      "2024-11-20 14:24:39.520052: val_loss -0.1971\n",
      "2024-11-20 14:24:39.540053: Pseudo dice [0.6961]\n",
      "2024-11-20 14:24:39.540053: Epoch time: 129.49 s\n",
      "2024-11-20 14:24:39.550054: Yayy! New best EMA pseudo Dice: 0.6681\n",
      "2024-11-20 14:24:40.750377: \n",
      "2024-11-20 14:24:40.750377: Epoch 51\n",
      "2024-11-20 14:24:40.750377: Current learning rate: 0.00908\n",
      "2024-11-20 14:26:50.282683: train_loss -0.5704\n",
      "2024-11-20 14:26:50.282683: val_loss -0.1579\n",
      "2024-11-20 14:26:50.292684: Pseudo dice [0.693]\n",
      "2024-11-20 14:26:50.292684: Epoch time: 129.54 s\n",
      "2024-11-20 14:26:50.302684: Yayy! New best EMA pseudo Dice: 0.6706\n",
      "2024-11-20 14:26:51.533020: \n",
      "2024-11-20 14:26:51.533020: Epoch 52\n",
      "2024-11-20 14:26:51.543020: Current learning rate: 0.00906\n",
      "2024-11-20 14:29:01.144907: train_loss -0.5689\n",
      "2024-11-20 14:29:01.144907: val_loss -0.1647\n",
      "2024-11-20 14:29:01.154907: Pseudo dice [0.6791]\n",
      "2024-11-20 14:29:01.164907: Epoch time: 129.61 s\n",
      "2024-11-20 14:29:01.174908: Yayy! New best EMA pseudo Dice: 0.6715\n",
      "2024-11-20 14:29:02.395230: \n",
      "2024-11-20 14:29:02.395230: Epoch 53\n",
      "2024-11-20 14:29:02.395230: Current learning rate: 0.00904\n",
      "2024-11-20 14:31:11.894732: train_loss -0.5467\n",
      "2024-11-20 14:31:11.894732: val_loss -0.2844\n",
      "2024-11-20 14:31:11.904732: Pseudo dice [0.7615]\n",
      "2024-11-20 14:31:11.904732: Epoch time: 129.5 s\n",
      "2024-11-20 14:31:11.914732: Yayy! New best EMA pseudo Dice: 0.6805\n",
      "2024-11-20 14:31:13.124748: \n",
      "2024-11-20 14:31:13.124748: Epoch 54\n",
      "2024-11-20 14:31:13.124748: Current learning rate: 0.00902\n",
      "2024-11-20 14:33:22.582975: train_loss -0.6039\n",
      "2024-11-20 14:33:22.582975: val_loss -0.1346\n",
      "2024-11-20 14:33:22.592975: Pseudo dice [0.6657]\n",
      "2024-11-20 14:33:22.592975: Epoch time: 129.46 s\n",
      "2024-11-20 14:33:23.743306: \n",
      "2024-11-20 14:33:23.743306: Epoch 55\n",
      "2024-11-20 14:33:23.753306: Current learning rate: 0.009\n",
      "2024-11-20 14:35:33.235582: train_loss -0.6314\n",
      "2024-11-20 14:35:33.235582: val_loss -0.278\n",
      "2024-11-20 14:35:33.245582: Pseudo dice [0.7335]\n",
      "2024-11-20 14:35:33.245582: Epoch time: 129.49 s\n",
      "2024-11-20 14:35:33.255583: Yayy! New best EMA pseudo Dice: 0.6844\n",
      "2024-11-20 14:35:34.475907: \n",
      "2024-11-20 14:35:34.475907: Epoch 56\n",
      "2024-11-20 14:35:34.475907: Current learning rate: 0.00899\n",
      "2024-11-20 14:37:44.040980: train_loss -0.5656\n",
      "2024-11-20 14:37:44.040980: val_loss -0.2804\n",
      "2024-11-20 14:37:44.040980: Pseudo dice [0.7302]\n",
      "2024-11-20 14:37:44.050981: Epoch time: 129.57 s\n",
      "2024-11-20 14:37:44.050981: Yayy! New best EMA pseudo Dice: 0.689\n",
      "2024-11-20 14:37:45.281302: \n",
      "2024-11-20 14:37:45.281302: Epoch 57\n",
      "2024-11-20 14:37:45.281302: Current learning rate: 0.00897\n",
      "2024-11-20 14:39:54.738783: train_loss -0.6401\n",
      "2024-11-20 14:39:54.738783: val_loss -0.0342\n",
      "2024-11-20 14:39:54.748784: Pseudo dice [0.6458]\n",
      "2024-11-20 14:39:54.758783: Epoch time: 129.46 s\n",
      "2024-11-20 14:39:55.728797: \n",
      "2024-11-20 14:39:55.728797: Epoch 58\n",
      "2024-11-20 14:39:55.728797: Current learning rate: 0.00895\n",
      "2024-11-20 14:42:05.166291: train_loss -0.6172\n",
      "2024-11-20 14:42:05.166291: val_loss -0.104\n",
      "2024-11-20 14:42:05.176293: Pseudo dice [0.6962]\n",
      "2024-11-20 14:42:05.176293: Epoch time: 129.45 s\n",
      "2024-11-20 14:42:06.176612: \n",
      "2024-11-20 14:42:06.176612: Epoch 59\n",
      "2024-11-20 14:42:06.176612: Current learning rate: 0.00893\n",
      "2024-11-20 14:44:15.599161: train_loss -0.5793\n",
      "2024-11-20 14:44:15.599161: val_loss -0.2939\n",
      "2024-11-20 14:44:15.609162: Pseudo dice [0.764]\n",
      "2024-11-20 14:44:15.619161: Epoch time: 129.42 s\n",
      "2024-11-20 14:44:15.629162: Yayy! New best EMA pseudo Dice: 0.6937\n",
      "2024-11-20 14:44:16.859178: \n",
      "2024-11-20 14:44:16.859178: Epoch 60\n",
      "2024-11-20 14:44:16.859178: Current learning rate: 0.00891\n",
      "2024-11-20 14:46:26.338882: train_loss -0.594\n",
      "2024-11-20 14:46:26.338882: val_loss -0.3035\n",
      "2024-11-20 14:46:26.348882: Pseudo dice [0.7992]\n",
      "2024-11-20 14:46:26.348882: Epoch time: 129.48 s\n",
      "2024-11-20 14:46:26.358883: Yayy! New best EMA pseudo Dice: 0.7042\n",
      "2024-11-20 14:46:27.589703: \n",
      "2024-11-20 14:46:27.589703: Epoch 61\n",
      "2024-11-20 14:46:27.599704: Current learning rate: 0.00889\n",
      "2024-11-20 14:48:36.998802: train_loss -0.6022\n",
      "2024-11-20 14:48:36.998802: val_loss -0.1166\n",
      "2024-11-20 14:48:37.008802: Pseudo dice [0.6203]\n",
      "2024-11-20 14:48:37.008802: Epoch time: 129.41 s\n",
      "2024-11-20 14:48:38.159689: \n",
      "2024-11-20 14:48:38.159689: Epoch 62\n",
      "2024-11-20 14:48:38.169689: Current learning rate: 0.00888\n",
      "2024-11-20 14:50:47.529098: train_loss -0.6147\n",
      "2024-11-20 14:50:47.529098: val_loss -0.2824\n",
      "2024-11-20 14:50:47.539099: Pseudo dice [0.7229]\n",
      "2024-11-20 14:50:47.549098: Epoch time: 129.37 s\n",
      "2024-11-20 14:50:48.530157: \n",
      "2024-11-20 14:50:48.530157: Epoch 63\n",
      "2024-11-20 14:50:48.540158: Current learning rate: 0.00886\n",
      "2024-11-20 14:52:57.917597: train_loss -0.6448\n",
      "2024-11-20 14:52:57.917597: val_loss -0.2114\n",
      "2024-11-20 14:52:57.927598: Pseudo dice [0.7039]\n",
      "2024-11-20 14:52:57.937598: Epoch time: 129.39 s\n",
      "2024-11-20 14:52:58.917611: \n",
      "2024-11-20 14:52:58.917611: Epoch 64\n",
      "2024-11-20 14:52:58.927611: Current learning rate: 0.00884\n",
      "2024-11-20 14:55:08.426577: train_loss -0.6114\n",
      "2024-11-20 14:55:08.426577: val_loss -0.1414\n",
      "2024-11-20 14:55:08.436579: Pseudo dice [0.6504]\n",
      "2024-11-20 14:55:08.446580: Epoch time: 129.51 s\n",
      "2024-11-20 14:55:09.446592: \n",
      "2024-11-20 14:55:09.446592: Epoch 65\n",
      "2024-11-20 14:55:09.446592: Current learning rate: 0.00882\n",
      "2024-11-20 14:57:18.833986: train_loss -0.6145\n",
      "2024-11-20 14:57:18.833986: val_loss -0.2501\n",
      "2024-11-20 14:57:18.843986: Pseudo dice [0.7069]\n",
      "2024-11-20 14:57:18.853987: Epoch time: 129.39 s\n",
      "2024-11-20 14:57:19.844001: \n",
      "2024-11-20 14:57:19.844001: Epoch 66\n",
      "2024-11-20 14:57:19.844001: Current learning rate: 0.0088\n",
      "2024-11-20 14:59:29.280954: train_loss -0.6202\n",
      "2024-11-20 14:59:29.280954: val_loss 0.4905\n",
      "2024-11-20 14:59:29.290953: Pseudo dice [0.2119]\n",
      "2024-11-20 14:59:29.300955: Epoch time: 129.45 s\n",
      "2024-11-20 14:59:30.270967: \n",
      "2024-11-20 14:59:30.270967: Epoch 67\n",
      "2024-11-20 14:59:30.280968: Current learning rate: 0.00879\n",
      "2024-11-20 15:01:39.710062: train_loss -0.6215\n",
      "2024-11-20 15:01:39.710062: val_loss -0.0339\n",
      "2024-11-20 15:01:39.720063: Pseudo dice [0.6096]\n",
      "2024-11-20 15:01:39.730063: Epoch time: 129.44 s\n",
      "2024-11-20 15:01:40.720388: \n",
      "2024-11-20 15:01:40.720388: Epoch 68\n",
      "2024-11-20 15:01:40.720388: Current learning rate: 0.00877\n",
      "2024-11-20 15:03:50.320049: train_loss -0.6151\n",
      "2024-11-20 15:03:50.320049: val_loss -0.3531\n",
      "2024-11-20 15:03:50.330050: Pseudo dice [0.7889]\n",
      "2024-11-20 15:03:50.340049: Epoch time: 129.6 s\n",
      "2024-11-20 15:03:51.500399: \n",
      "2024-11-20 15:03:51.500399: Epoch 69\n",
      "2024-11-20 15:03:51.500399: Current learning rate: 0.00875\n",
      "2024-11-20 15:06:00.921179: train_loss -0.6134\n",
      "2024-11-20 15:06:00.921179: val_loss 0.0104\n",
      "2024-11-20 15:06:00.921179: Pseudo dice [0.6269]\n",
      "2024-11-20 15:06:00.931179: Epoch time: 129.42 s\n",
      "2024-11-20 15:06:01.922078: \n",
      "2024-11-20 15:06:01.922078: Epoch 70\n",
      "2024-11-20 15:06:01.922078: Current learning rate: 0.00873\n",
      "2024-11-20 15:08:11.349794: train_loss -0.5907\n",
      "2024-11-20 15:08:11.349794: val_loss -0.2978\n",
      "2024-11-20 15:08:11.359795: Pseudo dice [0.7742]\n",
      "2024-11-20 15:08:11.359795: Epoch time: 129.43 s\n",
      "2024-11-20 15:08:12.349807: \n",
      "2024-11-20 15:08:12.349807: Epoch 71\n",
      "2024-11-20 15:08:12.359807: Current learning rate: 0.00871\n",
      "2024-11-20 15:10:21.780528: train_loss -0.6016\n",
      "2024-11-20 15:10:21.780528: val_loss -0.269\n",
      "2024-11-20 15:10:21.790529: Pseudo dice [0.7453]\n",
      "2024-11-20 15:10:21.800528: Epoch time: 129.43 s\n",
      "2024-11-20 15:10:22.790542: \n",
      "2024-11-20 15:10:22.790542: Epoch 72\n",
      "2024-11-20 15:10:22.790542: Current learning rate: 0.00869\n",
      "2024-11-20 15:12:32.320731: train_loss -0.6211\n",
      "2024-11-20 15:12:32.320731: val_loss -0.014\n",
      "2024-11-20 15:12:32.340732: Pseudo dice [0.6401]\n",
      "2024-11-20 15:12:32.340732: Epoch time: 129.53 s\n",
      "2024-11-20 15:12:33.340492: \n",
      "2024-11-20 15:12:33.340492: Epoch 73\n",
      "2024-11-20 15:12:33.345577: Current learning rate: 0.00868\n",
      "2024-11-20 15:14:42.753459: train_loss -0.6293\n",
      "2024-11-20 15:14:42.753459: val_loss -0.0341\n",
      "2024-11-20 15:14:42.763459: Pseudo dice [0.6377]\n",
      "2024-11-20 15:14:42.763459: Epoch time: 129.41 s\n",
      "2024-11-20 15:14:43.763472: \n",
      "2024-11-20 15:14:43.763472: Epoch 74\n",
      "2024-11-20 15:14:43.763472: Current learning rate: 0.00866\n",
      "2024-11-20 15:16:53.231959: train_loss -0.6322\n",
      "2024-11-20 15:16:53.231959: val_loss -0.1564\n",
      "2024-11-20 15:16:53.241959: Pseudo dice [0.647]\n",
      "2024-11-20 15:16:53.241959: Epoch time: 129.47 s\n",
      "2024-11-20 15:16:54.241974: \n",
      "2024-11-20 15:16:54.241974: Epoch 75\n",
      "2024-11-20 15:16:54.241974: Current learning rate: 0.00864\n",
      "2024-11-20 15:19:03.708491: train_loss -0.6342\n",
      "2024-11-20 15:19:03.708491: val_loss -0.2705\n",
      "2024-11-20 15:19:03.718491: Pseudo dice [0.6834]\n",
      "2024-11-20 15:19:03.718491: Epoch time: 129.47 s\n",
      "2024-11-20 15:19:04.888507: \n",
      "2024-11-20 15:19:04.888507: Epoch 76\n",
      "2024-11-20 15:19:04.898507: Current learning rate: 0.00862\n",
      "2024-11-20 15:21:14.466600: train_loss -0.6333\n",
      "2024-11-20 15:21:14.466600: val_loss 0.0934\n",
      "2024-11-20 15:21:14.486600: Pseudo dice [0.5132]\n",
      "2024-11-20 15:21:14.486600: Epoch time: 129.58 s\n",
      "2024-11-20 15:21:15.486908: \n",
      "2024-11-20 15:21:15.486908: Epoch 77\n",
      "2024-11-20 15:21:15.486908: Current learning rate: 0.0086\n",
      "2024-11-20 15:23:25.064543: train_loss -0.6618\n",
      "2024-11-20 15:23:25.064543: val_loss -0.2691\n",
      "2024-11-20 15:23:25.074544: Pseudo dice [0.7675]\n",
      "2024-11-20 15:23:25.074544: Epoch time: 129.58 s\n",
      "2024-11-20 15:23:26.084558: \n",
      "2024-11-20 15:23:26.084558: Epoch 78\n",
      "2024-11-20 15:23:26.084558: Current learning rate: 0.00858\n",
      "2024-11-20 15:25:35.529482: train_loss -0.6576\n",
      "2024-11-20 15:25:35.529482: val_loss -0.1638\n",
      "2024-11-20 15:25:35.539482: Pseudo dice [0.7022]\n",
      "2024-11-20 15:25:35.539482: Epoch time: 129.44 s\n",
      "2024-11-20 15:25:36.569496: \n",
      "2024-11-20 15:25:36.569496: Epoch 79\n",
      "2024-11-20 15:25:36.569496: Current learning rate: 0.00857\n",
      "2024-11-20 15:27:46.129696: train_loss -0.677\n",
      "2024-11-20 15:27:46.129696: val_loss -0.4696\n",
      "2024-11-20 15:27:46.159696: Pseudo dice [0.7988]\n",
      "2024-11-20 15:27:46.159696: Epoch time: 129.56 s\n",
      "2024-11-20 15:27:47.189711: \n",
      "2024-11-20 15:27:47.189711: Epoch 80\n",
      "2024-11-20 15:27:47.199711: Current learning rate: 0.00855\n",
      "2024-11-20 15:29:56.665580: train_loss -0.6519\n",
      "2024-11-20 15:29:56.665580: val_loss -0.4034\n",
      "2024-11-20 15:29:56.675581: Pseudo dice [0.7756]\n",
      "2024-11-20 15:29:56.675581: Epoch time: 129.48 s\n",
      "2024-11-20 15:29:57.716377: \n",
      "2024-11-20 15:29:57.716377: Epoch 81\n",
      "2024-11-20 15:29:57.726378: Current learning rate: 0.00853\n",
      "2024-11-20 15:32:07.496101: train_loss -0.6864\n",
      "2024-11-20 15:32:07.496101: val_loss -0.3162\n",
      "2024-11-20 15:32:07.506102: Pseudo dice [0.7498]\n",
      "2024-11-20 15:32:07.516101: Epoch time: 129.78 s\n",
      "2024-11-20 15:32:08.536116: \n",
      "2024-11-20 15:32:08.536116: Epoch 82\n",
      "2024-11-20 15:32:08.546116: Current learning rate: 0.00851\n",
      "2024-11-20 15:34:18.320413: train_loss -0.6958\n",
      "2024-11-20 15:34:18.320413: val_loss -0.2466\n",
      "2024-11-20 15:34:18.330413: Pseudo dice [0.7194]\n",
      "2024-11-20 15:34:18.330413: Epoch time: 129.78 s\n",
      "2024-11-20 15:34:19.460428: \n",
      "2024-11-20 15:34:19.460428: Epoch 83\n",
      "2024-11-20 15:34:19.470429: Current learning rate: 0.00849\n",
      "2024-11-20 15:36:28.988893: train_loss -0.6466\n",
      "2024-11-20 15:36:28.988893: val_loss -0.1364\n",
      "2024-11-20 15:36:28.998893: Pseudo dice [0.6707]\n",
      "2024-11-20 15:36:28.998893: Epoch time: 129.53 s\n",
      "2024-11-20 15:36:29.968906: \n",
      "2024-11-20 15:36:29.968906: Epoch 84\n",
      "2024-11-20 15:36:29.978907: Current learning rate: 0.00847\n",
      "2024-11-20 15:38:39.437710: train_loss -0.6517\n",
      "2024-11-20 15:38:39.437710: val_loss -0.2243\n",
      "2024-11-20 15:38:39.447710: Pseudo dice [0.6968]\n",
      "2024-11-20 15:38:39.457710: Epoch time: 129.47 s\n",
      "2024-11-20 15:38:40.407723: \n",
      "2024-11-20 15:38:40.407723: Epoch 85\n",
      "2024-11-20 15:38:40.417724: Current learning rate: 0.00846\n",
      "2024-11-20 15:40:49.858835: train_loss -0.6889\n",
      "2024-11-20 15:40:49.858835: val_loss -0.3522\n",
      "2024-11-20 15:40:49.868836: Pseudo dice [0.7828]\n",
      "2024-11-20 15:40:49.868836: Epoch time: 129.45 s\n",
      "2024-11-20 15:40:49.878835: Yayy! New best EMA pseudo Dice: 0.7045\n",
      "2024-11-20 15:40:51.078851: \n",
      "2024-11-20 15:40:51.078851: Epoch 86\n",
      "2024-11-20 15:40:51.088852: Current learning rate: 0.00844\n",
      "2024-11-20 15:43:00.670668: train_loss -0.6557\n",
      "2024-11-20 15:43:00.670668: val_loss -0.2125\n",
      "2024-11-20 15:43:00.690669: Pseudo dice [0.6782]\n",
      "2024-11-20 15:43:00.700670: Epoch time: 129.59 s\n",
      "2024-11-20 15:43:01.650681: \n",
      "2024-11-20 15:43:01.650681: Epoch 87\n",
      "2024-11-20 15:43:01.660682: Current learning rate: 0.00842\n",
      "2024-11-20 15:45:11.162476: train_loss -0.6495\n",
      "2024-11-20 15:45:11.162476: val_loss -0.2882\n",
      "2024-11-20 15:45:11.172476: Pseudo dice [0.7432]\n",
      "2024-11-20 15:45:11.182476: Epoch time: 129.51 s\n",
      "2024-11-20 15:45:11.182476: Yayy! New best EMA pseudo Dice: 0.706\n",
      "2024-11-20 15:45:12.383509: \n",
      "2024-11-20 15:45:12.383509: Epoch 88\n",
      "2024-11-20 15:45:12.393510: Current learning rate: 0.0084\n",
      "2024-11-20 15:47:21.792805: train_loss -0.6794\n",
      "2024-11-20 15:47:21.792805: val_loss -0.157\n",
      "2024-11-20 15:47:21.802805: Pseudo dice [0.6491]\n",
      "2024-11-20 15:47:21.812805: Epoch time: 129.41 s\n",
      "2024-11-20 15:47:22.762818: \n",
      "2024-11-20 15:47:22.762818: Epoch 89\n",
      "2024-11-20 15:47:22.772819: Current learning rate: 0.00838\n",
      "2024-11-20 15:49:32.224213: train_loss -0.6361\n",
      "2024-11-20 15:49:32.224213: val_loss -0.5\n",
      "2024-11-20 15:49:32.234214: Pseudo dice [0.7736]\n",
      "2024-11-20 15:49:32.244214: Epoch time: 129.46 s\n",
      "2024-11-20 15:49:32.244214: Yayy! New best EMA pseudo Dice: 0.7076\n",
      "2024-11-20 15:49:33.604974: \n",
      "2024-11-20 15:49:33.604974: Epoch 90\n",
      "2024-11-20 15:49:33.614974: Current learning rate: 0.00836\n",
      "2024-11-20 15:51:43.003505: train_loss -0.6731\n",
      "2024-11-20 15:51:43.003505: val_loss -0.3822\n",
      "2024-11-20 15:51:43.013505: Pseudo dice [0.7648]\n",
      "2024-11-20 15:51:43.023506: Epoch time: 129.4 s\n",
      "2024-11-20 15:51:43.023506: Yayy! New best EMA pseudo Dice: 0.7133\n",
      "2024-11-20 15:51:44.223522: \n",
      "2024-11-20 15:51:44.223522: Epoch 91\n",
      "2024-11-20 15:51:44.223522: Current learning rate: 0.00835\n",
      "2024-11-20 15:53:53.655547: train_loss -0.6236\n",
      "2024-11-20 15:53:53.655547: val_loss -0.2092\n",
      "2024-11-20 15:53:53.665548: Pseudo dice [0.7073]\n",
      "2024-11-20 15:53:53.675548: Epoch time: 129.44 s\n",
      "2024-11-20 15:53:55.305570: \n",
      "2024-11-20 15:53:55.305570: Epoch 92\n",
      "2024-11-20 15:53:55.315570: Current learning rate: 0.00833\n",
      "2024-11-20 15:56:04.717911: train_loss -0.6195\n",
      "2024-11-20 15:56:04.717911: val_loss -0.2563\n",
      "2024-11-20 15:56:04.727912: Pseudo dice [0.7135]\n",
      "2024-11-20 15:56:04.737913: Epoch time: 129.41 s\n",
      "2024-11-20 15:56:05.687925: \n",
      "2024-11-20 15:56:05.687925: Epoch 93\n",
      "2024-11-20 15:56:05.697925: Current learning rate: 0.00831\n",
      "2024-11-20 15:58:15.227288: train_loss -0.6365\n",
      "2024-11-20 15:58:15.227288: val_loss -0.1983\n",
      "2024-11-20 15:58:15.298046: Pseudo dice [0.6755]\n",
      "2024-11-20 15:58:15.298046: Epoch time: 129.54 s\n",
      "2024-11-20 15:58:16.248069: \n",
      "2024-11-20 15:58:16.248069: Epoch 94\n",
      "2024-11-20 15:58:16.258062: Current learning rate: 0.00829\n",
      "2024-11-20 16:00:25.736789: train_loss -0.6777\n",
      "2024-11-20 16:00:25.736789: val_loss -0.3366\n",
      "2024-11-20 16:00:25.746789: Pseudo dice [0.7323]\n",
      "2024-11-20 16:00:25.756789: Epoch time: 129.49 s\n",
      "2024-11-20 16:00:26.736812: \n",
      "2024-11-20 16:00:26.736812: Epoch 95\n",
      "2024-11-20 16:00:26.746804: Current learning rate: 0.00827\n",
      "2024-11-20 16:02:36.174892: train_loss -0.6748\n",
      "2024-11-20 16:02:36.174892: val_loss -0.3648\n",
      "2024-11-20 16:02:36.184892: Pseudo dice [0.759]\n",
      "2024-11-20 16:02:36.194892: Epoch time: 129.44 s\n",
      "2024-11-20 16:02:36.194892: Yayy! New best EMA pseudo Dice: 0.7161\n",
      "2024-11-20 16:02:37.384918: \n",
      "2024-11-20 16:02:37.384918: Epoch 96\n",
      "2024-11-20 16:02:37.394918: Current learning rate: 0.00825\n",
      "2024-11-20 16:04:46.791997: train_loss -0.6697\n",
      "2024-11-20 16:04:46.791997: val_loss -0.0367\n",
      "2024-11-20 16:04:46.801996: Pseudo dice [0.619]\n",
      "2024-11-20 16:04:46.811996: Epoch time: 129.41 s\n",
      "2024-11-20 16:04:47.952845: \n",
      "2024-11-20 16:04:47.952845: Epoch 97\n",
      "2024-11-20 16:04:47.962844: Current learning rate: 0.00824\n",
      "2024-11-20 16:06:57.517577: train_loss -0.6783\n",
      "2024-11-20 16:06:57.517577: val_loss 0.0614\n",
      "2024-11-20 16:06:57.527577: Pseudo dice [0.5895]\n",
      "2024-11-20 16:06:57.527577: Epoch time: 129.56 s\n",
      "2024-11-20 16:06:58.497600: \n",
      "2024-11-20 16:06:58.497600: Epoch 98\n",
      "2024-11-20 16:06:58.507592: Current learning rate: 0.00822\n",
      "2024-11-20 16:09:07.935632: train_loss -0.6217\n",
      "2024-11-20 16:09:07.935632: val_loss -0.1151\n",
      "2024-11-20 16:09:07.945633: Pseudo dice [0.6353]\n",
      "2024-11-20 16:09:07.945633: Epoch time: 129.44 s\n",
      "2024-11-20 16:09:08.916490: \n",
      "2024-11-20 16:09:08.916490: Epoch 99\n",
      "2024-11-20 16:09:08.926483: Current learning rate: 0.0082\n",
      "2024-11-20 16:11:18.379704: train_loss -0.6767\n",
      "2024-11-20 16:11:18.379704: val_loss -0.1663\n",
      "2024-11-20 16:11:18.379704: Pseudo dice [0.6704]\n",
      "2024-11-20 16:11:18.389705: Epoch time: 129.46 s\n",
      "2024-11-20 16:11:19.579729: \n",
      "2024-11-20 16:11:19.579729: Epoch 100\n",
      "2024-11-20 16:11:19.589722: Current learning rate: 0.00818\n",
      "2024-11-20 16:13:29.022531: train_loss -0.6527\n",
      "2024-11-20 16:13:29.022531: val_loss -0.1941\n",
      "2024-11-20 16:13:29.032531: Pseudo dice [0.7049]\n",
      "2024-11-20 16:13:29.042531: Epoch time: 129.44 s\n",
      "2024-11-20 16:13:30.012546: \n",
      "2024-11-20 16:13:30.012546: Epoch 101\n",
      "2024-11-20 16:13:30.012546: Current learning rate: 0.00816\n",
      "2024-11-20 16:15:39.979853: train_loss -0.6881\n",
      "2024-11-20 16:15:39.979853: val_loss -0.0313\n",
      "2024-11-20 16:15:39.989852: Pseudo dice [0.631]\n",
      "2024-11-20 16:15:39.989852: Epoch time: 129.97 s\n",
      "2024-11-20 16:15:40.980166: \n",
      "2024-11-20 16:15:40.980166: Epoch 102\n",
      "2024-11-20 16:15:40.990167: Current learning rate: 0.00814\n",
      "2024-11-20 16:17:50.413502: train_loss -0.7042\n",
      "2024-11-20 16:17:50.413502: val_loss -0.257\n",
      "2024-11-20 16:17:50.423503: Pseudo dice [0.7291]\n",
      "2024-11-20 16:17:50.433502: Epoch time: 129.43 s\n",
      "2024-11-20 16:17:51.413515: \n",
      "2024-11-20 16:17:51.413515: Epoch 103\n",
      "2024-11-20 16:17:51.423515: Current learning rate: 0.00813\n",
      "2024-11-20 16:20:00.880815: train_loss -0.6731\n",
      "2024-11-20 16:20:00.880815: val_loss -0.195\n",
      "2024-11-20 16:20:00.890816: Pseudo dice [0.7082]\n",
      "2024-11-20 16:20:00.900817: Epoch time: 129.47 s\n",
      "2024-11-20 16:20:02.050832: \n",
      "2024-11-20 16:20:02.050832: Epoch 104\n",
      "2024-11-20 16:20:02.060833: Current learning rate: 0.00811\n",
      "2024-11-20 16:22:11.639956: train_loss -0.71\n",
      "2024-11-20 16:22:11.639956: val_loss 0.1789\n",
      "2024-11-20 16:22:11.659956: Pseudo dice [0.5118]\n",
      "2024-11-20 16:22:11.669956: Epoch time: 129.59 s\n",
      "2024-11-20 16:22:12.640321: \n",
      "2024-11-20 16:22:12.640321: Epoch 105\n",
      "2024-11-20 16:22:12.640321: Current learning rate: 0.00809\n",
      "2024-11-20 16:24:22.156291: train_loss -0.6885\n",
      "2024-11-20 16:24:22.156291: val_loss -0.1663\n",
      "2024-11-20 16:24:22.166291: Pseudo dice [0.6692]\n",
      "2024-11-20 16:24:22.166291: Epoch time: 129.52 s\n",
      "2024-11-20 16:24:23.146305: \n",
      "2024-11-20 16:24:23.146305: Epoch 106\n",
      "2024-11-20 16:24:23.146305: Current learning rate: 0.00807\n",
      "2024-11-20 16:26:32.641116: train_loss -0.7066\n",
      "2024-11-20 16:26:32.641116: val_loss -0.0596\n",
      "2024-11-20 16:26:32.651116: Pseudo dice [0.6452]\n",
      "2024-11-20 16:26:32.661116: Epoch time: 129.49 s\n",
      "2024-11-20 16:26:33.632204: \n",
      "2024-11-20 16:26:33.632204: Epoch 107\n",
      "2024-11-20 16:26:33.642205: Current learning rate: 0.00805\n",
      "2024-11-20 16:28:43.109208: train_loss -0.7026\n",
      "2024-11-20 16:28:43.109208: val_loss -0.1257\n",
      "2024-11-20 16:28:43.119209: Pseudo dice [0.6723]\n",
      "2024-11-20 16:28:43.119209: Epoch time: 129.48 s\n",
      "2024-11-20 16:28:44.089221: \n",
      "2024-11-20 16:28:44.089221: Epoch 108\n",
      "2024-11-20 16:28:44.099221: Current learning rate: 0.00803\n",
      "2024-11-20 16:30:53.636560: train_loss -0.6877\n",
      "2024-11-20 16:30:53.636560: val_loss -0.2471\n",
      "2024-11-20 16:30:53.646560: Pseudo dice [0.7235]\n",
      "2024-11-20 16:30:53.646560: Epoch time: 129.55 s\n",
      "2024-11-20 16:30:54.626573: \n",
      "2024-11-20 16:30:54.626573: Epoch 109\n",
      "2024-11-20 16:30:54.636574: Current learning rate: 0.00801\n",
      "2024-11-20 16:33:04.104657: train_loss -0.6963\n",
      "2024-11-20 16:33:04.104657: val_loss -0.035\n",
      "2024-11-20 16:33:04.114658: Pseudo dice [0.607]\n",
      "2024-11-20 16:33:04.114658: Epoch time: 129.48 s\n",
      "2024-11-20 16:33:05.094671: \n",
      "2024-11-20 16:33:05.094671: Epoch 110\n",
      "2024-11-20 16:33:05.094671: Current learning rate: 0.008\n",
      "2024-11-20 16:35:14.559841: train_loss -0.6575\n",
      "2024-11-20 16:35:14.559841: val_loss -0.0966\n",
      "2024-11-20 16:35:14.569842: Pseudo dice [0.6762]\n",
      "2024-11-20 16:35:14.579843: Epoch time: 129.47 s\n",
      "2024-11-20 16:35:15.729858: \n",
      "2024-11-20 16:35:15.729858: Epoch 111\n",
      "2024-11-20 16:35:15.729858: Current learning rate: 0.00798\n",
      "2024-11-20 16:37:25.199600: train_loss -0.628\n",
      "2024-11-20 16:37:25.199600: val_loss -0.0647\n",
      "2024-11-20 16:37:25.209599: Pseudo dice [0.6437]\n",
      "2024-11-20 16:37:25.219601: Epoch time: 129.48 s\n",
      "2024-11-20 16:37:26.179917: \n",
      "2024-11-20 16:37:26.179917: Epoch 112\n",
      "2024-11-20 16:37:26.189917: Current learning rate: 0.00796\n",
      "2024-11-20 16:39:35.849591: train_loss -0.6687\n",
      "2024-11-20 16:39:35.849591: val_loss -0.1456\n",
      "2024-11-20 16:39:35.859593: Pseudo dice [0.6889]\n",
      "2024-11-20 16:39:35.869592: Epoch time: 129.67 s\n",
      "2024-11-20 16:39:36.849607: \n",
      "2024-11-20 16:39:36.849607: Epoch 113\n",
      "2024-11-20 16:39:36.849607: Current learning rate: 0.00794\n",
      "2024-11-20 16:41:46.290792: train_loss -0.7012\n",
      "2024-11-20 16:41:46.290792: val_loss -0.333\n",
      "2024-11-20 16:41:46.300792: Pseudo dice [0.7733]\n",
      "2024-11-20 16:41:46.310792: Epoch time: 129.44 s\n",
      "2024-11-20 16:41:47.281242: \n",
      "2024-11-20 16:41:47.281242: Epoch 114\n",
      "2024-11-20 16:41:47.291241: Current learning rate: 0.00792\n",
      "2024-11-20 16:43:56.702441: train_loss -0.7249\n",
      "2024-11-20 16:43:56.702441: val_loss -0.0859\n",
      "2024-11-20 16:43:56.712441: Pseudo dice [0.6394]\n",
      "2024-11-20 16:43:56.722441: Epoch time: 129.42 s\n",
      "2024-11-20 16:43:57.682949: \n",
      "2024-11-20 16:43:57.682949: Epoch 115\n",
      "2024-11-20 16:43:57.682949: Current learning rate: 0.0079\n",
      "2024-11-20 16:46:07.150239: train_loss -0.7062\n",
      "2024-11-20 16:46:07.150239: val_loss -0.206\n",
      "2024-11-20 16:46:07.160240: Pseudo dice [0.6973]\n",
      "2024-11-20 16:46:07.160240: Epoch time: 129.47 s\n",
      "2024-11-20 16:46:08.140254: \n",
      "2024-11-20 16:46:08.140254: Epoch 116\n",
      "2024-11-20 16:46:08.140254: Current learning rate: 0.00789\n",
      "2024-11-20 16:48:17.675546: train_loss -0.6935\n",
      "2024-11-20 16:48:17.675546: val_loss -0.2315\n",
      "2024-11-20 16:48:17.685545: Pseudo dice [0.6947]\n",
      "2024-11-20 16:48:17.685545: Epoch time: 129.54 s\n",
      "2024-11-20 16:48:18.666656: \n",
      "2024-11-20 16:48:18.666656: Epoch 117\n",
      "2024-11-20 16:48:18.676656: Current learning rate: 0.00787\n",
      "2024-11-20 16:50:28.142632: train_loss -0.694\n",
      "2024-11-20 16:50:28.142632: val_loss -0.0775\n",
      "2024-11-20 16:50:28.152633: Pseudo dice [0.673]\n",
      "2024-11-20 16:50:28.162633: Epoch time: 129.48 s\n",
      "2024-11-20 16:50:29.132646: \n",
      "2024-11-20 16:50:29.132646: Epoch 118\n",
      "2024-11-20 16:50:29.142646: Current learning rate: 0.00785\n",
      "2024-11-20 16:52:38.601541: train_loss -0.6587\n",
      "2024-11-20 16:52:38.601541: val_loss -0.2759\n",
      "2024-11-20 16:52:38.611541: Pseudo dice [0.7039]\n",
      "2024-11-20 16:52:38.621541: Epoch time: 129.47 s\n",
      "2024-11-20 16:52:39.771556: \n",
      "2024-11-20 16:52:39.771556: Epoch 119\n",
      "2024-11-20 16:52:39.781556: Current learning rate: 0.00783\n",
      "2024-11-20 16:54:49.249768: train_loss -0.6687\n",
      "2024-11-20 16:54:49.249768: val_loss -0.1499\n",
      "2024-11-20 16:54:49.259769: Pseudo dice [0.6489]\n",
      "2024-11-20 16:54:49.259769: Epoch time: 129.48 s\n",
      "2024-11-20 16:54:50.239783: \n",
      "2024-11-20 16:54:50.239783: Epoch 120\n",
      "2024-11-20 16:54:50.249783: Current learning rate: 0.00781\n",
      "2024-11-20 16:56:59.849452: train_loss -0.6803\n",
      "2024-11-20 16:56:59.849452: val_loss -0.0781\n",
      "2024-11-20 16:56:59.849452: Pseudo dice [0.6398]\n",
      "2024-11-20 16:56:59.859451: Epoch time: 129.61 s\n",
      "2024-11-20 16:57:00.839465: \n",
      "2024-11-20 16:57:00.839465: Epoch 121\n",
      "2024-11-20 16:57:00.849465: Current learning rate: 0.00779\n",
      "2024-11-20 16:59:10.330634: train_loss -0.6821\n",
      "2024-11-20 16:59:10.330634: val_loss -0.2946\n",
      "2024-11-20 16:59:10.340636: Pseudo dice [0.7371]\n",
      "2024-11-20 16:59:10.350636: Epoch time: 129.49 s\n",
      "2024-11-20 16:59:11.330975: \n",
      "2024-11-20 16:59:11.330975: Epoch 122\n",
      "2024-11-20 16:59:11.330975: Current learning rate: 0.00777\n",
      "2024-11-20 17:01:20.780850: train_loss -0.7239\n",
      "2024-11-20 17:01:20.780850: val_loss -0.049\n",
      "2024-11-20 17:01:20.790851: Pseudo dice [0.6411]\n",
      "2024-11-20 17:01:20.790851: Epoch time: 129.46 s\n",
      "2024-11-20 17:01:21.770864: \n",
      "2024-11-20 17:01:21.770864: Epoch 123\n",
      "2024-11-20 17:01:21.780864: Current learning rate: 0.00776\n",
      "2024-11-20 17:03:31.250826: train_loss -0.7337\n",
      "2024-11-20 17:03:31.250826: val_loss -0.071\n",
      "2024-11-20 17:03:31.260827: Pseudo dice [0.6844]\n",
      "2024-11-20 17:03:31.260827: Epoch time: 129.48 s\n",
      "2024-11-20 17:03:32.250841: \n",
      "2024-11-20 17:03:32.250841: Epoch 124\n",
      "2024-11-20 17:03:32.250841: Current learning rate: 0.00774\n",
      "2024-11-20 17:05:41.829292: train_loss -0.7151\n",
      "2024-11-20 17:05:41.829292: val_loss -0.1985\n",
      "2024-11-20 17:05:41.839293: Pseudo dice [0.7037]\n",
      "2024-11-20 17:05:41.849293: Epoch time: 129.58 s\n",
      "2024-11-20 17:05:42.839747: \n",
      "2024-11-20 17:05:42.839747: Epoch 125\n",
      "2024-11-20 17:05:42.849747: Current learning rate: 0.00772\n",
      "2024-11-20 17:07:52.326484: train_loss -0.736\n",
      "2024-11-20 17:07:52.326484: val_loss -0.1972\n",
      "2024-11-20 17:07:52.336483: Pseudo dice [0.7425]\n",
      "2024-11-20 17:07:52.346484: Epoch time: 129.49 s\n",
      "2024-11-20 17:07:53.497585: \n",
      "2024-11-20 17:07:53.497585: Epoch 126\n",
      "2024-11-20 17:07:53.507586: Current learning rate: 0.0077\n",
      "2024-11-20 17:10:02.977358: train_loss -0.6994\n",
      "2024-11-20 17:10:02.977358: val_loss -0.0551\n",
      "2024-11-20 17:10:02.997359: Pseudo dice [0.5658]\n",
      "2024-11-20 17:10:02.997359: Epoch time: 129.48 s\n",
      "2024-11-20 17:10:03.978400: \n",
      "2024-11-20 17:10:03.988400: Epoch 127\n",
      "2024-11-20 17:10:03.988400: Current learning rate: 0.00768\n",
      "2024-11-20 17:12:13.448131: train_loss -0.6873\n",
      "2024-11-20 17:12:13.448131: val_loss -0.4874\n",
      "2024-11-20 17:12:13.458132: Pseudo dice [0.8231]\n",
      "2024-11-20 17:12:13.458132: Epoch time: 129.47 s\n",
      "2024-11-20 17:12:14.438144: \n",
      "2024-11-20 17:12:14.438144: Epoch 128\n",
      "2024-11-20 17:12:14.438144: Current learning rate: 0.00766\n",
      "2024-11-20 17:14:24.190064: train_loss -0.7159\n",
      "2024-11-20 17:14:24.190064: val_loss 0.0689\n",
      "2024-11-20 17:14:24.200066: Pseudo dice [0.5809]\n",
      "2024-11-20 17:14:24.200066: Epoch time: 129.76 s\n",
      "2024-11-20 17:14:25.180078: \n",
      "2024-11-20 17:14:25.180078: Epoch 129\n",
      "2024-11-20 17:14:25.190078: Current learning rate: 0.00764\n",
      "2024-11-20 17:16:34.649150: train_loss -0.7176\n",
      "2024-11-20 17:16:34.649150: val_loss -0.2538\n",
      "2024-11-20 17:16:34.659150: Pseudo dice [0.7448]\n",
      "2024-11-20 17:16:34.669150: Epoch time: 129.47 s\n",
      "2024-11-20 17:16:35.639464: \n",
      "2024-11-20 17:16:35.639464: Epoch 130\n",
      "2024-11-20 17:16:35.649464: Current learning rate: 0.00763\n",
      "2024-11-20 17:18:45.109439: train_loss -0.7306\n",
      "2024-11-20 17:18:45.109439: val_loss -0.2656\n",
      "2024-11-20 17:18:45.119441: Pseudo dice [0.7427]\n",
      "2024-11-20 17:18:45.119441: Epoch time: 129.47 s\n",
      "2024-11-20 17:18:46.109453: \n",
      "2024-11-20 17:18:46.109453: Epoch 131\n",
      "2024-11-20 17:18:46.109453: Current learning rate: 0.00761\n",
      "2024-11-20 17:20:55.689358: train_loss -0.7151\n",
      "2024-11-20 17:20:55.689358: val_loss -0.2722\n",
      "2024-11-20 17:20:55.699361: Pseudo dice [0.7635]\n",
      "2024-11-20 17:20:55.699361: Epoch time: 129.59 s\n",
      "2024-11-20 17:20:56.689374: \n",
      "2024-11-20 17:20:56.689374: Epoch 132\n",
      "2024-11-20 17:20:56.689374: Current learning rate: 0.00759\n",
      "2024-11-20 17:23:06.124712: train_loss -0.7119\n",
      "2024-11-20 17:23:06.124712: val_loss -0.3672\n",
      "2024-11-20 17:23:06.134712: Pseudo dice [0.761]\n",
      "2024-11-20 17:23:06.144712: Epoch time: 129.44 s\n",
      "2024-11-20 17:23:07.294727: \n",
      "2024-11-20 17:23:07.294727: Epoch 133\n",
      "2024-11-20 17:23:07.304728: Current learning rate: 0.00757\n",
      "2024-11-20 17:25:16.760883: train_loss -0.7046\n",
      "2024-11-20 17:25:16.760883: val_loss -0.0968\n",
      "2024-11-20 17:25:16.770883: Pseudo dice [0.6076]\n",
      "2024-11-20 17:25:16.780883: Epoch time: 129.47 s\n",
      "2024-11-20 17:25:17.760897: \n",
      "2024-11-20 17:25:17.760897: Epoch 134\n",
      "2024-11-20 17:25:17.770897: Current learning rate: 0.00755\n",
      "2024-11-20 17:27:27.258986: train_loss -0.7027\n",
      "2024-11-20 17:27:27.258986: val_loss -0.0792\n",
      "2024-11-20 17:27:27.268986: Pseudo dice [0.6777]\n",
      "2024-11-20 17:27:27.278986: Epoch time: 129.5 s\n",
      "2024-11-20 17:27:28.279276: \n",
      "2024-11-20 17:27:28.279276: Epoch 135\n",
      "2024-11-20 17:27:28.289276: Current learning rate: 0.00753\n",
      "2024-11-20 17:29:37.839405: train_loss -0.7186\n",
      "2024-11-20 17:29:37.839405: val_loss -0.224\n",
      "2024-11-20 17:29:37.849405: Pseudo dice [0.7288]\n",
      "2024-11-20 17:29:37.849405: Epoch time: 129.56 s\n",
      "2024-11-20 17:29:38.850329: \n",
      "2024-11-20 17:29:38.850329: Epoch 136\n",
      "2024-11-20 17:29:38.850329: Current learning rate: 0.00751\n",
      "2024-11-20 17:31:48.367429: train_loss -0.6721\n",
      "2024-11-20 17:31:48.367429: val_loss -0.259\n",
      "2024-11-20 17:31:48.377430: Pseudo dice [0.7256]\n",
      "2024-11-20 17:31:48.387429: Epoch time: 129.52 s\n",
      "2024-11-20 17:31:49.387443: \n",
      "2024-11-20 17:31:49.387443: Epoch 137\n",
      "2024-11-20 17:31:49.387443: Current learning rate: 0.0075\n",
      "2024-11-20 17:33:58.887634: train_loss -0.7222\n",
      "2024-11-20 17:33:58.887634: val_loss 0.0044\n",
      "2024-11-20 17:33:58.897634: Pseudo dice [0.6541]\n",
      "2024-11-20 17:33:58.907634: Epoch time: 129.5 s\n",
      "2024-11-20 17:33:59.897954: \n",
      "2024-11-20 17:33:59.897954: Epoch 138\n",
      "2024-11-20 17:33:59.907954: Current learning rate: 0.00748\n",
      "2024-11-20 17:36:09.358538: train_loss -0.6786\n",
      "2024-11-20 17:36:09.368539: val_loss -0.2349\n",
      "2024-11-20 17:36:09.368539: Pseudo dice [0.7134]\n",
      "2024-11-20 17:36:09.378540: Epoch time: 129.46 s\n",
      "2024-11-20 17:36:10.378562: \n",
      "2024-11-20 17:36:10.378562: Epoch 139\n",
      "2024-11-20 17:36:10.388562: Current learning rate: 0.00746\n",
      "2024-11-20 17:38:19.970764: train_loss -0.7241\n",
      "2024-11-20 17:38:19.970764: val_loss -0.2489\n",
      "2024-11-20 17:38:19.990763: Pseudo dice [0.7542]\n",
      "2024-11-20 17:38:19.990763: Epoch time: 129.59 s\n",
      "2024-11-20 17:38:21.161117: \n",
      "2024-11-20 17:38:21.161117: Epoch 140\n",
      "2024-11-20 17:38:21.171117: Current learning rate: 0.00744\n",
      "2024-11-20 17:40:30.644735: train_loss -0.7112\n",
      "2024-11-20 17:40:30.644735: val_loss 0.0501\n",
      "2024-11-20 17:40:30.654735: Pseudo dice [0.6243]\n",
      "2024-11-20 17:40:30.654735: Epoch time: 129.48 s\n",
      "2024-11-20 17:40:31.654749: \n",
      "2024-11-20 17:40:31.654749: Epoch 141\n",
      "2024-11-20 17:40:31.654749: Current learning rate: 0.00742\n",
      "2024-11-20 17:42:41.105447: train_loss -0.7161\n",
      "2024-11-20 17:42:41.105447: val_loss -0.1752\n",
      "2024-11-20 17:42:41.115448: Pseudo dice [0.6822]\n",
      "2024-11-20 17:42:41.125448: Epoch time: 129.45 s\n",
      "2024-11-20 17:42:42.115460: \n",
      "2024-11-20 17:42:42.115460: Epoch 142\n",
      "2024-11-20 17:42:42.125461: Current learning rate: 0.0074\n",
      "2024-11-20 17:44:51.563515: train_loss -0.7215\n",
      "2024-11-20 17:44:51.563515: val_loss -0.2478\n",
      "2024-11-20 17:44:51.573515: Pseudo dice [0.6799]\n",
      "2024-11-20 17:44:51.583517: Epoch time: 129.45 s\n",
      "2024-11-20 17:44:52.583819: \n",
      "2024-11-20 17:44:52.583819: Epoch 143\n",
      "2024-11-20 17:44:52.593819: Current learning rate: 0.00738\n",
      "2024-11-20 17:47:02.143338: train_loss -0.7273\n",
      "2024-11-20 17:47:02.143338: val_loss 0.0466\n",
      "2024-11-20 17:47:02.163338: Pseudo dice [0.5606]\n",
      "2024-11-20 17:47:02.173339: Epoch time: 129.56 s\n",
      "2024-11-20 17:47:03.173352: \n",
      "2024-11-20 17:47:03.173352: Epoch 144\n",
      "2024-11-20 17:47:03.173352: Current learning rate: 0.00737\n",
      "2024-11-20 17:49:12.625245: train_loss -0.7023\n",
      "2024-11-20 17:49:12.625245: val_loss -0.3643\n",
      "2024-11-20 17:49:12.645245: Pseudo dice [0.7868]\n",
      "2024-11-20 17:49:12.645245: Epoch time: 129.46 s\n",
      "2024-11-20 17:49:13.655259: \n",
      "2024-11-20 17:49:13.655259: Epoch 145\n",
      "2024-11-20 17:49:13.665259: Current learning rate: 0.00735\n",
      "2024-11-20 17:51:23.142658: train_loss -0.7031\n",
      "2024-11-20 17:51:23.143690: val_loss -0.3662\n",
      "2024-11-20 17:51:23.153894: Pseudo dice [0.7964]\n",
      "2024-11-20 17:51:23.163013: Epoch time: 129.49 s\n",
      "2024-11-20 17:51:24.163413: \n",
      "2024-11-20 17:51:24.163413: Epoch 146\n",
      "2024-11-20 17:51:24.173413: Current learning rate: 0.00733\n",
      "2024-11-20 17:53:33.668046: train_loss -0.7379\n",
      "2024-11-20 17:53:33.668046: val_loss -0.1513\n",
      "2024-11-20 17:53:33.678046: Pseudo dice [0.7024]\n",
      "2024-11-20 17:53:33.688046: Epoch time: 129.5 s\n",
      "2024-11-20 17:53:34.858404: \n",
      "2024-11-20 17:53:34.858404: Epoch 147\n",
      "2024-11-20 17:53:34.868404: Current learning rate: 0.00731\n",
      "2024-11-20 17:55:44.441563: train_loss -0.7243\n",
      "2024-11-20 17:55:44.441563: val_loss -0.079\n",
      "2024-11-20 17:55:44.451562: Pseudo dice [0.6391]\n",
      "2024-11-20 17:55:44.461563: Epoch time: 129.58 s\n",
      "2024-11-20 17:55:45.471894: \n",
      "2024-11-20 17:55:45.471894: Epoch 148\n",
      "2024-11-20 17:55:45.471894: Current learning rate: 0.00729\n",
      "2024-11-20 17:57:54.983867: train_loss -0.7587\n",
      "2024-11-20 17:57:54.983867: val_loss -0.1342\n",
      "2024-11-20 17:57:54.993868: Pseudo dice [0.7151]\n",
      "2024-11-20 17:57:54.993868: Epoch time: 129.51 s\n",
      "2024-11-20 17:57:55.994182: \n",
      "2024-11-20 17:57:55.994182: Epoch 149\n",
      "2024-11-20 17:57:56.004182: Current learning rate: 0.00727\n",
      "2024-11-20 18:00:05.465864: train_loss -0.7392\n",
      "2024-11-20 18:00:05.465864: val_loss -0.2495\n",
      "2024-11-20 18:00:05.465864: Pseudo dice [0.7299]\n",
      "2024-11-20 18:00:05.475863: Epoch time: 129.47 s\n",
      "2024-11-20 18:00:06.726189: \n",
      "2024-11-20 18:00:06.726189: Epoch 150\n",
      "2024-11-20 18:00:06.736190: Current learning rate: 0.00725\n",
      "2024-11-20 18:02:16.213162: train_loss -0.7143\n",
      "2024-11-20 18:02:16.213162: val_loss -0.1261\n",
      "2024-11-20 18:02:16.223163: Pseudo dice [0.6755]\n",
      "2024-11-20 18:02:16.223163: Epoch time: 129.49 s\n",
      "2024-11-20 18:02:17.223176: \n",
      "2024-11-20 18:02:17.223176: Epoch 151\n",
      "2024-11-20 18:02:17.233176: Current learning rate: 0.00724\n",
      "2024-11-20 18:04:26.802121: train_loss -0.7146\n",
      "2024-11-20 18:04:26.802121: val_loss -0.0036\n",
      "2024-11-20 18:04:26.822119: Pseudo dice [0.6331]\n",
      "2024-11-20 18:04:26.822119: Epoch time: 129.58 s\n",
      "2024-11-20 18:04:27.822601: \n",
      "2024-11-20 18:04:27.822601: Epoch 152\n",
      "2024-11-20 18:04:27.832601: Current learning rate: 0.00722\n",
      "2024-11-20 18:06:37.263502: train_loss -0.7496\n",
      "2024-11-20 18:06:37.263502: val_loss -0.1395\n",
      "2024-11-20 18:06:37.273502: Pseudo dice [0.65]\n",
      "2024-11-20 18:06:37.273502: Epoch time: 129.44 s\n",
      "2024-11-20 18:06:38.284473: \n",
      "2024-11-20 18:06:38.284473: Epoch 153\n",
      "2024-11-20 18:06:38.294473: Current learning rate: 0.0072\n",
      "2024-11-20 18:08:47.746297: train_loss -0.7216\n",
      "2024-11-20 18:08:47.746297: val_loss -0.1708\n",
      "2024-11-20 18:08:47.756298: Pseudo dice [0.685]\n",
      "2024-11-20 18:08:47.766298: Epoch time: 129.46 s\n",
      "2024-11-20 18:08:48.957551: \n",
      "2024-11-20 18:08:48.957551: Epoch 154\n",
      "2024-11-20 18:08:48.967551: Current learning rate: 0.00718\n",
      "2024-11-20 18:10:58.449588: train_loss -0.7307\n",
      "2024-11-20 18:10:58.449588: val_loss -0.1712\n",
      "2024-11-20 18:10:58.459588: Pseudo dice [0.6491]\n",
      "2024-11-20 18:10:58.469589: Epoch time: 129.49 s\n",
      "2024-11-20 18:10:59.509603: \n",
      "2024-11-20 18:10:59.509603: Epoch 155\n",
      "2024-11-20 18:10:59.509603: Current learning rate: 0.00716\n",
      "2024-11-20 18:13:09.064730: train_loss -0.7717\n",
      "2024-11-20 18:13:09.064730: val_loss -0.1706\n",
      "2024-11-20 18:13:09.074731: Pseudo dice [0.7108]\n",
      "2024-11-20 18:13:09.084731: Epoch time: 129.56 s\n",
      "2024-11-20 18:13:10.114745: \n",
      "2024-11-20 18:13:10.114745: Epoch 156\n",
      "2024-11-20 18:13:10.114745: Current learning rate: 0.00714\n",
      "2024-11-20 18:15:19.734689: train_loss -0.7608\n",
      "2024-11-20 18:15:19.734689: val_loss -0.1446\n",
      "2024-11-20 18:15:19.744691: Pseudo dice [0.7201]\n",
      "2024-11-20 18:15:19.744691: Epoch time: 129.62 s\n",
      "2024-11-20 18:15:20.765005: \n",
      "2024-11-20 18:15:20.765005: Epoch 157\n",
      "2024-11-20 18:15:20.775005: Current learning rate: 0.00712\n",
      "2024-11-20 18:17:30.250332: train_loss -0.7303\n",
      "2024-11-20 18:17:30.250332: val_loss -0.2633\n",
      "2024-11-20 18:17:30.260332: Pseudo dice [0.6975]\n",
      "2024-11-20 18:17:30.270332: Epoch time: 129.49 s\n",
      "2024-11-20 18:17:31.290649: \n",
      "2024-11-20 18:17:31.290649: Epoch 158\n",
      "2024-11-20 18:17:31.290649: Current learning rate: 0.0071\n",
      "2024-11-20 18:19:40.842579: train_loss -0.7503\n",
      "2024-11-20 18:19:40.842579: val_loss -0.3343\n",
      "2024-11-20 18:19:40.862579: Pseudo dice [0.7627]\n",
      "2024-11-20 18:19:40.872580: Epoch time: 129.55 s\n",
      "2024-11-20 18:19:41.902593: \n",
      "2024-11-20 18:19:41.902593: Epoch 159\n",
      "2024-11-20 18:19:41.912593: Current learning rate: 0.00709\n",
      "2024-11-20 18:21:51.336886: train_loss -0.7599\n",
      "2024-11-20 18:21:51.336886: val_loss 0.0504\n",
      "2024-11-20 18:21:51.346886: Pseudo dice [0.5304]\n",
      "2024-11-20 18:21:51.356886: Epoch time: 129.43 s\n",
      "2024-11-20 18:21:52.377837: \n",
      "2024-11-20 18:21:52.377837: Epoch 160\n",
      "2024-11-20 18:21:52.387837: Current learning rate: 0.00707\n",
      "2024-11-20 18:24:01.819732: train_loss -0.7226\n",
      "2024-11-20 18:24:01.819732: val_loss 0.0108\n",
      "2024-11-20 18:24:01.819732: Pseudo dice [0.5681]\n",
      "2024-11-20 18:24:01.829732: Epoch time: 129.44 s\n",
      "2024-11-20 18:24:03.029748: \n",
      "2024-11-20 18:24:03.029748: Epoch 161\n",
      "2024-11-20 18:24:03.039749: Current learning rate: 0.00705\n",
      "2024-11-20 18:26:12.452557: train_loss -0.7323\n",
      "2024-11-20 18:26:12.452557: val_loss -0.1157\n",
      "2024-11-20 18:26:12.452557: Pseudo dice [0.6634]\n",
      "2024-11-20 18:26:12.462558: Epoch time: 129.42 s\n",
      "2024-11-20 18:26:13.492571: \n",
      "2024-11-20 18:26:13.492571: Epoch 162\n",
      "2024-11-20 18:26:13.492571: Current learning rate: 0.00703\n",
      "2024-11-20 18:28:23.060918: train_loss -0.7413\n",
      "2024-11-20 18:28:23.080918: val_loss -0.1861\n",
      "2024-11-20 18:28:23.080918: Pseudo dice [0.7521]\n",
      "2024-11-20 18:28:23.090917: Epoch time: 129.58 s\n",
      "2024-11-20 18:28:24.130932: \n",
      "2024-11-20 18:28:24.130932: Epoch 163\n",
      "2024-11-20 18:28:24.140933: Current learning rate: 0.00701\n",
      "2024-11-20 18:30:33.597105: train_loss -0.7258\n",
      "2024-11-20 18:30:33.597105: val_loss -0.2353\n",
      "2024-11-20 18:30:33.607106: Pseudo dice [0.7184]\n",
      "2024-11-20 18:30:33.617105: Epoch time: 129.47 s\n",
      "2024-11-20 18:30:34.627120: \n",
      "2024-11-20 18:30:34.627120: Epoch 164\n",
      "2024-11-20 18:30:34.637120: Current learning rate: 0.00699\n",
      "2024-11-20 18:32:44.033960: train_loss -0.734\n",
      "2024-11-20 18:32:44.033960: val_loss 0.0062\n",
      "2024-11-20 18:32:44.043961: Pseudo dice [0.5742]\n",
      "2024-11-20 18:32:44.043961: Epoch time: 129.41 s\n",
      "2024-11-20 18:32:45.033973: \n",
      "2024-11-20 18:32:45.033973: Epoch 165\n",
      "2024-11-20 18:32:45.043974: Current learning rate: 0.00697\n",
      "2024-11-20 18:34:54.609717: train_loss -0.7331\n",
      "2024-11-20 18:34:54.609717: val_loss -0.3467\n",
      "2024-11-20 18:34:54.619717: Pseudo dice [0.7885]\n",
      "2024-11-20 18:34:54.629718: Epoch time: 129.58 s\n",
      "2024-11-20 18:34:55.620023: \n",
      "2024-11-20 18:34:55.620023: Epoch 166\n",
      "2024-11-20 18:34:55.630023: Current learning rate: 0.00696\n",
      "2024-11-20 18:37:05.126656: train_loss -0.7211\n",
      "2024-11-20 18:37:05.126656: val_loss -0.1554\n",
      "2024-11-20 18:37:05.126656: Pseudo dice [0.6809]\n",
      "2024-11-20 18:37:05.136656: Epoch time: 129.51 s\n",
      "2024-11-20 18:37:06.126962: \n",
      "2024-11-20 18:37:06.126962: Epoch 167\n",
      "2024-11-20 18:37:06.136962: Current learning rate: 0.00694\n",
      "2024-11-20 18:39:15.606633: train_loss -0.7256\n",
      "2024-11-20 18:39:15.606633: val_loss -0.2349\n",
      "2024-11-20 18:39:15.616634: Pseudo dice [0.6795]\n",
      "2024-11-20 18:39:15.626633: Epoch time: 129.48 s\n",
      "2024-11-20 18:39:16.806649: \n",
      "2024-11-20 18:39:16.806649: Epoch 168\n",
      "2024-11-20 18:39:16.816649: Current learning rate: 0.00692\n",
      "2024-11-20 18:41:26.289878: train_loss -0.7536\n",
      "2024-11-20 18:41:26.289878: val_loss -0.0707\n",
      "2024-11-20 18:41:26.299878: Pseudo dice [0.6107]\n",
      "2024-11-20 18:41:26.309879: Epoch time: 129.48 s\n",
      "2024-11-20 18:41:27.309892: \n",
      "2024-11-20 18:41:27.309892: Epoch 169\n",
      "2024-11-20 18:41:27.319892: Current learning rate: 0.0069\n",
      "2024-11-20 18:43:36.861434: train_loss -0.7524\n",
      "2024-11-20 18:43:36.861434: val_loss -0.0471\n",
      "2024-11-20 18:43:36.921573: Pseudo dice [0.6421]\n",
      "2024-11-20 18:43:36.921573: Epoch time: 129.55 s\n",
      "2024-11-20 18:43:37.931590: \n",
      "2024-11-20 18:43:37.931590: Epoch 170\n",
      "2024-11-20 18:43:37.931590: Current learning rate: 0.00688\n",
      "2024-11-20 18:45:47.371962: train_loss -0.7615\n",
      "2024-11-20 18:45:47.371962: val_loss -0.2276\n",
      "2024-11-20 18:45:47.381962: Pseudo dice [0.708]\n",
      "2024-11-20 18:45:47.391962: Epoch time: 129.45 s\n",
      "2024-11-20 18:45:48.393112: \n",
      "2024-11-20 18:45:48.393112: Epoch 171\n",
      "2024-11-20 18:45:48.403112: Current learning rate: 0.00686\n",
      "2024-11-20 18:47:57.851226: train_loss -0.6651\n",
      "2024-11-20 18:47:57.851226: val_loss 0.1194\n",
      "2024-11-20 18:47:57.861227: Pseudo dice [0.453]\n",
      "2024-11-20 18:47:57.871227: Epoch time: 129.46 s\n",
      "2024-11-20 18:47:58.881240: \n",
      "2024-11-20 18:47:58.881240: Epoch 172\n",
      "2024-11-20 18:47:58.881240: Current learning rate: 0.00684\n",
      "2024-11-20 18:50:08.429427: train_loss -0.7108\n",
      "2024-11-20 18:50:08.429427: val_loss -0.3924\n",
      "2024-11-20 18:50:08.439428: Pseudo dice [0.793]\n",
      "2024-11-20 18:50:08.449428: Epoch time: 129.55 s\n",
      "2024-11-20 18:50:09.460370: \n",
      "2024-11-20 18:50:09.460370: Epoch 173\n",
      "2024-11-20 18:50:09.470370: Current learning rate: 0.00682\n",
      "2024-11-20 18:52:19.231550: train_loss -0.7196\n",
      "2024-11-20 18:52:19.231550: val_loss -0.0895\n",
      "2024-11-20 18:52:19.241551: Pseudo dice [0.6232]\n",
      "2024-11-20 18:52:19.241551: Epoch time: 129.77 s\n",
      "2024-11-20 18:52:20.421869: \n",
      "2024-11-20 18:52:20.421869: Epoch 174\n",
      "2024-11-20 18:52:20.421869: Current learning rate: 0.0068\n",
      "2024-11-20 18:54:29.872713: train_loss -0.7437\n",
      "2024-11-20 18:54:29.872713: val_loss -0.2891\n",
      "2024-11-20 18:54:29.882715: Pseudo dice [0.7846]\n",
      "2024-11-20 18:54:29.882715: Epoch time: 129.46 s\n",
      "2024-11-20 18:54:30.894172: \n",
      "2024-11-20 18:54:30.894172: Epoch 175\n",
      "2024-11-20 18:54:30.904172: Current learning rate: 0.00679\n",
      "2024-11-20 18:56:40.342664: train_loss -0.7458\n",
      "2024-11-20 18:56:40.342664: val_loss -0.2939\n",
      "2024-11-20 18:56:40.352664: Pseudo dice [0.6895]\n",
      "2024-11-20 18:56:40.362665: Epoch time: 129.45 s\n",
      "2024-11-20 18:56:41.372680: \n",
      "2024-11-20 18:56:41.372680: Epoch 176\n",
      "2024-11-20 18:56:41.372680: Current learning rate: 0.00677\n",
      "2024-11-20 18:58:50.816109: train_loss -0.743\n",
      "2024-11-20 18:58:50.816109: val_loss -0.2334\n",
      "2024-11-20 18:58:50.826110: Pseudo dice [0.6906]\n",
      "2024-11-20 18:58:50.836110: Epoch time: 129.44 s\n",
      "2024-11-20 18:58:51.846123: \n",
      "2024-11-20 18:58:51.846123: Epoch 177\n",
      "2024-11-20 18:58:51.856123: Current learning rate: 0.00675\n",
      "2024-11-20 19:01:01.407405: train_loss -0.7769\n",
      "2024-11-20 19:01:01.407405: val_loss -0.1058\n",
      "2024-11-20 19:01:01.437405: Pseudo dice [0.6427]\n",
      "2024-11-20 19:01:01.437405: Epoch time: 129.56 s\n",
      "2024-11-20 19:01:02.557821: \n",
      "2024-11-20 19:01:02.557821: Epoch 178\n",
      "2024-11-20 19:01:02.557821: Current learning rate: 0.00673\n",
      "2024-11-20 19:03:11.952193: train_loss -0.7594\n",
      "2024-11-20 19:03:11.952193: val_loss -0.1862\n",
      "2024-11-20 19:03:11.962193: Pseudo dice [0.6855]\n",
      "2024-11-20 19:03:11.962193: Epoch time: 129.4 s\n",
      "2024-11-20 19:03:12.972416: \n",
      "2024-11-20 19:03:12.982416: Epoch 179\n",
      "2024-11-20 19:03:12.982416: Current learning rate: 0.00671\n",
      "2024-11-20 19:05:22.429121: train_loss -0.7592\n",
      "2024-11-20 19:05:22.429121: val_loss -0.0276\n",
      "2024-11-20 19:05:22.429121: Pseudo dice [0.5464]\n",
      "2024-11-20 19:05:22.439121: Epoch time: 129.46 s\n",
      "2024-11-20 19:05:23.450262: \n",
      "2024-11-20 19:05:23.450262: Epoch 180\n",
      "2024-11-20 19:05:23.450262: Current learning rate: 0.00669\n",
      "2024-11-20 19:07:32.899887: train_loss -0.7417\n",
      "2024-11-20 19:07:32.899887: val_loss -0.2516\n",
      "2024-11-20 19:07:32.909887: Pseudo dice [0.754]\n",
      "2024-11-20 19:07:32.919887: Epoch time: 129.45 s\n",
      "2024-11-20 19:07:34.100827: \n",
      "2024-11-20 19:07:34.100827: Epoch 181\n",
      "2024-11-20 19:07:34.110818: Current learning rate: 0.00667\n",
      "2024-11-20 19:09:43.647327: train_loss -0.7112\n",
      "2024-11-20 19:09:43.647327: val_loss 0.0895\n",
      "2024-11-20 19:09:43.657327: Pseudo dice [0.625]\n",
      "2024-11-20 19:09:43.667327: Epoch time: 129.55 s\n",
      "2024-11-20 19:09:44.687351: \n",
      "2024-11-20 19:09:44.687351: Epoch 182\n",
      "2024-11-20 19:09:44.687351: Current learning rate: 0.00665\n",
      "2024-11-20 19:11:54.134078: train_loss -0.7463\n",
      "2024-11-20 19:11:54.134078: val_loss 0.0053\n",
      "2024-11-20 19:11:54.144078: Pseudo dice [0.6073]\n",
      "2024-11-20 19:11:54.154078: Epoch time: 129.46 s\n",
      "2024-11-20 19:11:55.164092: \n",
      "2024-11-20 19:11:55.164092: Epoch 183\n",
      "2024-11-20 19:11:55.174092: Current learning rate: 0.00664\n",
      "2024-11-20 19:14:04.632616: train_loss -0.7371\n",
      "2024-11-20 19:14:04.632616: val_loss -0.1727\n",
      "2024-11-20 19:14:04.642615: Pseudo dice [0.6197]\n",
      "2024-11-20 19:14:04.652616: Epoch time: 129.47 s\n",
      "2024-11-20 19:14:05.682639: \n",
      "2024-11-20 19:14:05.682639: Epoch 184\n",
      "2024-11-20 19:14:05.682639: Current learning rate: 0.00662\n",
      "2024-11-20 19:16:15.321519: train_loss -0.7494\n",
      "2024-11-20 19:16:15.321519: val_loss -0.3018\n",
      "2024-11-20 19:16:15.331520: Pseudo dice [0.7068]\n",
      "2024-11-20 19:16:15.331520: Epoch time: 129.64 s\n",
      "2024-11-20 19:16:16.341854: \n",
      "2024-11-20 19:16:16.341854: Epoch 185\n",
      "2024-11-20 19:16:16.351846: Current learning rate: 0.0066\n",
      "2024-11-20 19:18:25.872798: train_loss -0.7437\n",
      "2024-11-20 19:18:25.882798: val_loss -0.159\n",
      "2024-11-20 19:18:25.882798: Pseudo dice [0.6889]\n",
      "2024-11-20 19:18:25.892798: Epoch time: 129.53 s\n",
      "2024-11-20 19:18:26.902822: \n",
      "2024-11-20 19:18:26.902822: Epoch 186\n",
      "2024-11-20 19:18:26.912822: Current learning rate: 0.00658\n",
      "2024-11-20 19:20:36.391353: train_loss -0.7649\n",
      "2024-11-20 19:20:36.391353: val_loss -0.003\n",
      "2024-11-20 19:20:36.401353: Pseudo dice [0.6308]\n",
      "2024-11-20 19:20:36.411353: Epoch time: 129.49 s\n",
      "2024-11-20 19:20:37.431376: \n",
      "2024-11-20 19:20:37.431376: Epoch 187\n",
      "2024-11-20 19:20:37.431376: Current learning rate: 0.00656\n",
      "2024-11-20 19:22:46.898530: train_loss -0.7755\n",
      "2024-11-20 19:22:46.898530: val_loss -0.2395\n",
      "2024-11-20 19:22:46.908531: Pseudo dice [0.7348]\n",
      "2024-11-20 19:22:46.918531: Epoch time: 129.48 s\n",
      "2024-11-20 19:22:48.099492: \n",
      "2024-11-20 19:22:48.099492: Epoch 188\n",
      "2024-11-20 19:22:48.099492: Current learning rate: 0.00654\n",
      "2024-11-20 19:24:57.563490: train_loss -0.7547\n",
      "2024-11-20 19:24:57.563490: val_loss -0.029\n",
      "2024-11-20 19:24:57.583489: Pseudo dice [0.6133]\n",
      "2024-11-20 19:24:57.593490: Epoch time: 129.46 s\n",
      "2024-11-20 19:24:58.603514: \n",
      "2024-11-20 19:24:58.603514: Epoch 189\n",
      "2024-11-20 19:24:58.603514: Current learning rate: 0.00652\n",
      "2024-11-20 19:27:08.139295: train_loss -0.7717\n",
      "2024-11-20 19:27:08.139295: val_loss 0.171\n",
      "2024-11-20 19:27:08.149295: Pseudo dice [0.5317]\n",
      "2024-11-20 19:27:08.149295: Epoch time: 129.54 s\n",
      "2024-11-20 19:27:09.169319: \n",
      "2024-11-20 19:27:09.169319: Epoch 190\n",
      "2024-11-20 19:27:09.179318: Current learning rate: 0.0065\n",
      "2024-11-20 19:29:18.617100: train_loss -0.7623\n",
      "2024-11-20 19:29:18.617100: val_loss -0.284\n",
      "2024-11-20 19:29:18.627100: Pseudo dice [0.7222]\n",
      "2024-11-20 19:29:18.637101: Epoch time: 129.45 s\n",
      "2024-11-20 19:29:19.647966: \n",
      "2024-11-20 19:29:19.647966: Epoch 191\n",
      "2024-11-20 19:29:19.657958: Current learning rate: 0.00648\n",
      "2024-11-20 19:31:29.124023: train_loss -0.7509\n",
      "2024-11-20 19:31:29.124023: val_loss -0.1197\n",
      "2024-11-20 19:31:29.134023: Pseudo dice [0.6617]\n",
      "2024-11-20 19:31:29.134023: Epoch time: 129.48 s\n",
      "2024-11-20 19:31:30.164047: \n",
      "2024-11-20 19:31:30.164047: Epoch 192\n",
      "2024-11-20 19:31:30.164047: Current learning rate: 0.00647\n",
      "2024-11-20 19:33:39.613836: train_loss -0.7584\n",
      "2024-11-20 19:33:39.613836: val_loss -0.1185\n",
      "2024-11-20 19:33:39.623836: Pseudo dice [0.6335]\n",
      "2024-11-20 19:33:39.633836: Epoch time: 129.45 s\n",
      "2024-11-20 19:33:40.644162: \n",
      "2024-11-20 19:33:40.654162: Epoch 193\n",
      "2024-11-20 19:33:40.654162: Current learning rate: 0.00645\n",
      "2024-11-20 19:35:50.292636: train_loss -0.7537\n",
      "2024-11-20 19:35:50.292636: val_loss -0.2324\n",
      "2024-11-20 19:35:50.302637: Pseudo dice [0.7516]\n",
      "2024-11-20 19:35:50.312636: Epoch time: 129.65 s\n",
      "2024-11-20 19:35:51.343960: \n",
      "2024-11-20 19:35:51.343960: Epoch 194\n",
      "2024-11-20 19:35:51.343960: Current learning rate: 0.00643\n",
      "2024-11-20 19:38:00.809893: train_loss -0.7583\n",
      "2024-11-20 19:38:00.809893: val_loss -0.1291\n",
      "2024-11-20 19:38:00.819894: Pseudo dice [0.6446]\n",
      "2024-11-20 19:38:00.829894: Epoch time: 129.48 s\n",
      "2024-11-20 19:38:02.020804: \n",
      "2024-11-20 19:38:02.020804: Epoch 195\n",
      "2024-11-20 19:38:02.030795: Current learning rate: 0.00641\n",
      "2024-11-20 19:40:11.456615: train_loss -0.7722\n",
      "2024-11-20 19:40:11.456615: val_loss 0.1449\n",
      "2024-11-20 19:40:11.466615: Pseudo dice [0.5241]\n",
      "2024-11-20 19:40:11.476616: Epoch time: 129.44 s\n",
      "2024-11-20 19:40:12.506894: \n",
      "2024-11-20 19:40:12.507901: Epoch 196\n",
      "2024-11-20 19:40:12.509924: Current learning rate: 0.00639\n",
      "2024-11-20 19:42:21.912252: train_loss -0.7828\n",
      "2024-11-20 19:42:21.912252: val_loss -0.0036\n",
      "2024-11-20 19:42:21.922252: Pseudo dice [0.6177]\n",
      "2024-11-20 19:42:21.932252: Epoch time: 129.41 s\n",
      "2024-11-20 19:42:22.962276: \n",
      "2024-11-20 19:42:22.962276: Epoch 197\n",
      "2024-11-20 19:42:22.962276: Current learning rate: 0.00637\n",
      "2024-11-20 19:44:32.510478: train_loss -0.7881\n",
      "2024-11-20 19:44:32.510478: val_loss -0.1833\n",
      "2024-11-20 19:44:32.520479: Pseudo dice [0.7061]\n",
      "2024-11-20 19:44:32.530479: Epoch time: 129.55 s\n",
      "2024-11-20 19:44:33.550503: \n",
      "2024-11-20 19:44:33.550503: Epoch 198\n",
      "2024-11-20 19:44:33.560495: Current learning rate: 0.00635\n",
      "2024-11-20 19:46:43.036816: train_loss -0.7849\n",
      "2024-11-20 19:46:43.036816: val_loss 0.2272\n",
      "2024-11-20 19:46:43.056817: Pseudo dice [0.5157]\n",
      "2024-11-20 19:46:43.056817: Epoch time: 129.49 s\n",
      "2024-11-20 19:46:44.086842: \n",
      "2024-11-20 19:46:44.086842: Epoch 199\n",
      "2024-11-20 19:46:44.086842: Current learning rate: 0.00633\n",
      "2024-11-20 19:48:53.572783: train_loss -0.7971\n",
      "2024-11-20 19:48:53.572783: val_loss -0.0865\n",
      "2024-11-20 19:48:53.582782: Pseudo dice [0.6955]\n",
      "2024-11-20 19:48:53.592782: Epoch time: 129.49 s\n",
      "2024-11-20 19:48:54.892809: \n",
      "2024-11-20 19:48:54.892809: Epoch 200\n",
      "2024-11-20 19:48:54.902800: Current learning rate: 0.00631\n",
      "2024-11-20 19:51:04.389714: train_loss -0.7694\n",
      "2024-11-20 19:51:04.389714: val_loss -0.1562\n",
      "2024-11-20 19:51:04.389714: Pseudo dice [0.6732]\n",
      "2024-11-20 19:51:04.399715: Epoch time: 129.5 s\n",
      "2024-11-20 19:51:05.599731: \n",
      "2024-11-20 19:51:05.599731: Epoch 201\n",
      "2024-11-20 19:51:05.609731: Current learning rate: 0.0063\n",
      "2024-11-20 19:53:15.162574: train_loss -0.7877\n",
      "2024-11-20 19:53:15.162574: val_loss 0.2118\n",
      "2024-11-20 19:53:15.172574: Pseudo dice [0.4779]\n",
      "2024-11-20 19:53:15.182576: Epoch time: 129.56 s\n",
      "2024-11-20 19:53:16.222598: \n",
      "2024-11-20 19:53:16.222598: Epoch 202\n",
      "2024-11-20 19:53:16.232589: Current learning rate: 0.00628\n",
      "2024-11-20 19:55:25.671545: train_loss -0.7975\n",
      "2024-11-20 19:55:25.671545: val_loss -0.0291\n",
      "2024-11-20 19:55:25.691545: Pseudo dice [0.5712]\n",
      "2024-11-20 19:55:25.691545: Epoch time: 129.45 s\n",
      "2024-11-20 19:55:26.721569: \n",
      "2024-11-20 19:55:26.721569: Epoch 203\n",
      "2024-11-20 19:55:26.731568: Current learning rate: 0.00626\n",
      "2024-11-20 19:57:36.156505: train_loss -0.7591\n",
      "2024-11-20 19:57:36.156505: val_loss -0.3403\n",
      "2024-11-20 19:57:36.166505: Pseudo dice [0.7284]\n",
      "2024-11-20 19:57:36.176505: Epoch time: 129.43 s\n",
      "2024-11-20 19:57:37.206902: \n",
      "2024-11-20 19:57:37.206902: Epoch 204\n",
      "2024-11-20 19:57:37.216902: Current learning rate: 0.00624\n",
      "2024-11-20 19:59:46.664205: train_loss -0.7481\n",
      "2024-11-20 19:59:46.664205: val_loss -0.174\n",
      "2024-11-20 19:59:46.674206: Pseudo dice [0.6347]\n",
      "2024-11-20 19:59:46.684206: Epoch time: 129.46 s\n",
      "2024-11-20 19:59:47.714230: \n",
      "2024-11-20 19:59:47.714230: Epoch 205\n",
      "2024-11-20 19:59:47.714230: Current learning rate: 0.00622\n",
      "2024-11-20 20:01:57.208264: train_loss -0.773\n",
      "2024-11-20 20:01:57.208264: val_loss 0.1162\n",
      "2024-11-20 20:01:57.218402: Pseudo dice [0.6049]\n",
      "2024-11-20 20:01:57.223445: Epoch time: 129.49 s\n",
      "2024-11-20 20:01:58.193652: \n",
      "2024-11-20 20:01:58.193652: Epoch 206\n",
      "2024-11-20 20:01:58.193652: Current learning rate: 0.0062\n",
      "2024-11-20 20:04:07.679854: train_loss -0.7619\n",
      "2024-11-20 20:04:07.679854: val_loss -0.2222\n",
      "2024-11-20 20:04:07.689854: Pseudo dice [0.7152]\n",
      "2024-11-20 20:04:07.699855: Epoch time: 129.5 s\n",
      "2024-11-20 20:04:08.690849: \n",
      "2024-11-20 20:04:08.690849: Epoch 207\n",
      "2024-11-20 20:04:08.700848: Current learning rate: 0.00618\n",
      "2024-11-20 20:06:18.179492: train_loss -0.7696\n",
      "2024-11-20 20:06:18.179492: val_loss -0.2415\n",
      "2024-11-20 20:06:18.189492: Pseudo dice [0.6674]\n",
      "2024-11-20 20:06:18.189492: Epoch time: 129.49 s\n",
      "2024-11-20 20:06:19.359854: \n",
      "2024-11-20 20:06:19.359854: Epoch 208\n",
      "2024-11-20 20:06:19.359854: Current learning rate: 0.00616\n",
      "2024-11-20 20:08:28.810027: train_loss -0.7864\n",
      "2024-11-20 20:08:28.810027: val_loss -0.1166\n",
      "2024-11-20 20:08:28.820026: Pseudo dice [0.7147]\n",
      "2024-11-20 20:08:28.830026: Epoch time: 129.45 s\n",
      "2024-11-20 20:08:29.800049: \n",
      "2024-11-20 20:08:29.800049: Epoch 209\n",
      "2024-11-20 20:08:29.800049: Current learning rate: 0.00614\n",
      "2024-11-20 20:10:39.388732: train_loss -0.7575\n",
      "2024-11-20 20:10:39.388732: val_loss -0.3488\n",
      "2024-11-20 20:10:39.398733: Pseudo dice [0.7416]\n",
      "2024-11-20 20:10:39.408734: Epoch time: 129.59 s\n",
      "2024-11-20 20:10:40.378756: \n",
      "2024-11-20 20:10:40.378756: Epoch 210\n",
      "2024-11-20 20:10:40.388756: Current learning rate: 0.00612\n",
      "2024-11-20 20:12:49.832280: train_loss -0.7788\n",
      "2024-11-20 20:12:49.832280: val_loss -0.1213\n",
      "2024-11-20 20:12:49.852280: Pseudo dice [0.6515]\n",
      "2024-11-20 20:12:49.852280: Epoch time: 129.45 s\n",
      "2024-11-20 20:12:50.823088: \n",
      "2024-11-20 20:12:50.823088: Epoch 211\n",
      "2024-11-20 20:12:50.823088: Current learning rate: 0.00611\n",
      "2024-11-20 20:15:00.429168: train_loss -0.7843\n",
      "2024-11-20 20:15:00.429168: val_loss -0.2666\n",
      "2024-11-20 20:15:00.439168: Pseudo dice [0.7759]\n",
      "2024-11-20 20:15:00.449169: Epoch time: 129.61 s\n",
      "2024-11-20 20:15:01.439182: \n",
      "2024-11-20 20:15:01.439182: Epoch 212\n",
      "2024-11-20 20:15:01.449182: Current learning rate: 0.00609\n",
      "2024-11-20 20:17:11.024016: train_loss -0.7598\n",
      "2024-11-20 20:17:11.024016: val_loss 0.4119\n",
      "2024-11-20 20:17:11.024016: Pseudo dice [0.4631]\n",
      "2024-11-20 20:17:11.034017: Epoch time: 129.58 s\n",
      "2024-11-20 20:17:12.034047: \n",
      "2024-11-20 20:17:12.034047: Epoch 213\n",
      "2024-11-20 20:17:12.034047: Current learning rate: 0.00607\n",
      "2024-11-20 20:19:21.592188: train_loss -0.7739\n",
      "2024-11-20 20:19:21.592188: val_loss 0.2181\n",
      "2024-11-20 20:19:21.602188: Pseudo dice [0.5488]\n",
      "2024-11-20 20:19:21.602188: Epoch time: 129.56 s\n",
      "2024-11-20 20:19:22.582210: \n",
      "2024-11-20 20:19:22.582210: Epoch 214\n",
      "2024-11-20 20:19:22.592211: Current learning rate: 0.00605\n",
      "2024-11-20 20:21:32.090196: train_loss -0.7727\n",
      "2024-11-20 20:21:32.090196: val_loss -0.1632\n",
      "2024-11-20 20:21:32.100196: Pseudo dice [0.6756]\n",
      "2024-11-20 20:21:32.110195: Epoch time: 129.51 s\n",
      "2024-11-20 20:21:33.091240: \n",
      "2024-11-20 20:21:33.095179: Epoch 215\n",
      "2024-11-20 20:21:33.095683: Current learning rate: 0.00603\n",
      "2024-11-20 20:23:42.551910: train_loss -0.7797\n",
      "2024-11-20 20:23:42.551910: val_loss 0.1525\n",
      "2024-11-20 20:23:42.561911: Pseudo dice [0.5028]\n",
      "2024-11-20 20:23:42.571910: Epoch time: 129.46 s\n",
      "2024-11-20 20:23:43.721926: \n",
      "2024-11-20 20:23:43.721926: Epoch 216\n",
      "2024-11-20 20:23:43.731927: Current learning rate: 0.00601\n",
      "2024-11-20 20:25:53.172664: train_loss -0.7736\n",
      "2024-11-20 20:25:53.172664: val_loss -0.0753\n",
      "2024-11-20 20:25:53.181787: Pseudo dice [0.65]\n",
      "2024-11-20 20:25:53.187860: Epoch time: 129.45 s\n",
      "2024-11-20 20:25:54.161428: \n",
      "2024-11-20 20:25:54.161428: Epoch 217\n",
      "2024-11-20 20:25:54.171427: Current learning rate: 0.00599\n",
      "2024-11-20 20:28:03.639853: train_loss -0.7793\n",
      "2024-11-20 20:28:03.639853: val_loss -0.2266\n",
      "2024-11-20 20:28:03.649853: Pseudo dice [0.7185]\n",
      "2024-11-20 20:28:03.649853: Epoch time: 129.48 s\n",
      "2024-11-20 20:28:04.629869: \n",
      "2024-11-20 20:28:04.629869: Epoch 218\n",
      "2024-11-20 20:28:04.629869: Current learning rate: 0.00597\n",
      "2024-11-20 20:30:14.117802: train_loss -0.7386\n",
      "2024-11-20 20:30:14.117802: val_loss -0.1096\n",
      "2024-11-20 20:30:14.127802: Pseudo dice [0.5833]\n",
      "2024-11-20 20:30:14.127802: Epoch time: 129.49 s\n",
      "2024-11-20 20:30:15.097815: \n",
      "2024-11-20 20:30:15.097815: Epoch 219\n",
      "2024-11-20 20:30:15.107816: Current learning rate: 0.00595\n",
      "2024-11-20 20:32:24.604170: train_loss -0.7532\n",
      "2024-11-20 20:32:24.604170: val_loss -0.3399\n",
      "2024-11-20 20:32:24.614169: Pseudo dice [0.782]\n",
      "2024-11-20 20:32:24.624171: Epoch time: 129.51 s\n",
      "2024-11-20 20:32:25.594184: \n",
      "2024-11-20 20:32:25.594184: Epoch 220\n",
      "2024-11-20 20:32:25.604184: Current learning rate: 0.00593\n",
      "2024-11-20 20:34:35.234615: train_loss -0.7782\n",
      "2024-11-20 20:34:35.234615: val_loss -0.1343\n",
      "2024-11-20 20:34:35.254616: Pseudo dice [0.6598]\n",
      "2024-11-20 20:34:35.264618: Epoch time: 129.64 s\n",
      "2024-11-20 20:34:36.235898: \n",
      "2024-11-20 20:34:36.235898: Epoch 221\n",
      "2024-11-20 20:34:36.245900: Current learning rate: 0.00592\n",
      "2024-11-20 20:36:45.725308: train_loss -0.786\n",
      "2024-11-20 20:36:45.725308: val_loss 0.1765\n",
      "2024-11-20 20:36:45.735308: Pseudo dice [0.535]\n",
      "2024-11-20 20:36:45.745308: Epoch time: 129.49 s\n",
      "2024-11-20 20:36:46.715321: \n",
      "2024-11-20 20:36:46.715321: Epoch 222\n",
      "2024-11-20 20:36:46.725322: Current learning rate: 0.0059\n",
      "2024-11-20 20:38:56.216321: train_loss -0.7837\n",
      "2024-11-20 20:38:56.216321: val_loss -0.0197\n",
      "2024-11-20 20:38:56.226321: Pseudo dice [0.5927]\n",
      "2024-11-20 20:38:56.226321: Epoch time: 129.5 s\n",
      "2024-11-20 20:38:57.366336: \n",
      "2024-11-20 20:38:57.366336: Epoch 223\n",
      "2024-11-20 20:38:57.376337: Current learning rate: 0.00588\n",
      "2024-11-20 20:41:06.834100: train_loss -0.7822\n",
      "2024-11-20 20:41:06.834100: val_loss 0.1838\n",
      "2024-11-20 20:41:06.844100: Pseudo dice [0.5529]\n",
      "2024-11-20 20:41:06.844100: Epoch time: 129.47 s\n",
      "2024-11-20 20:41:07.814116: \n",
      "2024-11-20 20:41:07.814116: Epoch 224\n",
      "2024-11-20 20:41:07.814116: Current learning rate: 0.00586\n",
      "2024-11-20 20:43:17.312953: train_loss -0.7486\n",
      "2024-11-20 20:43:17.312953: val_loss 0.1293\n",
      "2024-11-20 20:43:17.312953: Pseudo dice [0.487]\n",
      "2024-11-20 20:43:17.322953: Epoch time: 129.51 s\n",
      "2024-11-20 20:43:18.282966: \n",
      "2024-11-20 20:43:18.282966: Epoch 225\n",
      "2024-11-20 20:43:18.292966: Current learning rate: 0.00584\n",
      "2024-11-20 20:45:27.794234: train_loss -0.7758\n",
      "2024-11-20 20:45:27.794234: val_loss 0.0588\n",
      "2024-11-20 20:45:27.804234: Pseudo dice [0.5909]\n",
      "2024-11-20 20:45:27.814233: Epoch time: 129.51 s\n",
      "2024-11-20 20:45:28.784247: \n",
      "2024-11-20 20:45:28.784247: Epoch 226\n",
      "2024-11-20 20:45:28.794247: Current learning rate: 0.00582\n",
      "2024-11-20 20:47:38.252468: train_loss -0.7637\n",
      "2024-11-20 20:47:38.252468: val_loss 0.2027\n",
      "2024-11-20 20:47:38.262469: Pseudo dice [0.4604]\n",
      "2024-11-20 20:47:38.272678: Epoch time: 129.47 s\n",
      "2024-11-20 20:47:39.243377: \n",
      "2024-11-20 20:47:39.243377: Epoch 227\n",
      "2024-11-20 20:47:39.243377: Current learning rate: 0.0058\n",
      "2024-11-20 20:49:48.682670: train_loss -0.8023\n",
      "2024-11-20 20:49:48.682670: val_loss -0.2804\n",
      "2024-11-20 20:49:48.692671: Pseudo dice [0.7718]\n",
      "2024-11-20 20:49:48.702670: Epoch time: 129.45 s\n",
      "2024-11-20 20:49:49.672685: \n",
      "2024-11-20 20:49:49.672685: Epoch 228\n",
      "2024-11-20 20:49:49.672685: Current learning rate: 0.00578\n",
      "2024-11-20 20:51:59.258761: train_loss -0.7695\n",
      "2024-11-20 20:51:59.258761: val_loss 0.2422\n",
      "2024-11-20 20:51:59.268762: Pseudo dice [0.4938]\n",
      "2024-11-20 20:51:59.268762: Epoch time: 129.59 s\n",
      "2024-11-20 20:52:00.238775: \n",
      "2024-11-20 20:52:00.238775: Epoch 229\n",
      "2024-11-20 20:52:00.248774: Current learning rate: 0.00576\n",
      "2024-11-20 20:54:09.716455: train_loss -0.7654\n",
      "2024-11-20 20:54:09.716455: val_loss 0.1141\n",
      "2024-11-20 20:54:09.736455: Pseudo dice [0.5052]\n",
      "2024-11-20 20:54:09.736455: Epoch time: 129.48 s\n",
      "2024-11-20 20:54:10.726775: \n",
      "2024-11-20 20:54:10.726775: Epoch 230\n",
      "2024-11-20 20:54:10.736775: Current learning rate: 0.00574\n",
      "2024-11-20 20:56:20.204107: train_loss -0.8076\n",
      "2024-11-20 20:56:20.204107: val_loss -0.0492\n",
      "2024-11-20 20:56:20.214107: Pseudo dice [0.6093]\n",
      "2024-11-20 20:56:20.224108: Epoch time: 129.48 s\n",
      "2024-11-20 20:56:21.194419: \n",
      "2024-11-20 20:56:21.194419: Epoch 231\n",
      "2024-11-20 20:56:21.194419: Current learning rate: 0.00572\n",
      "2024-11-20 20:58:30.622264: train_loss -0.8082\n",
      "2024-11-20 20:58:30.622264: val_loss -0.1385\n",
      "2024-11-20 20:58:30.632265: Pseudo dice [0.6632]\n",
      "2024-11-20 20:58:30.632265: Epoch time: 129.44 s\n",
      "2024-11-20 20:58:31.602280: \n",
      "2024-11-20 20:58:31.602280: Epoch 232\n",
      "2024-11-20 20:58:31.602280: Current learning rate: 0.0057\n",
      "2024-11-20 21:00:41.144864: train_loss -0.7754\n",
      "2024-11-20 21:00:41.144864: val_loss 0.1648\n",
      "2024-11-20 21:00:41.154864: Pseudo dice [0.567]\n",
      "2024-11-20 21:00:41.164864: Epoch time: 129.54 s\n",
      "2024-11-20 21:00:42.134878: \n",
      "2024-11-20 21:00:42.134878: Epoch 233\n",
      "2024-11-20 21:00:42.190790: Current learning rate: 0.00569\n",
      "2024-11-20 21:02:51.615057: train_loss -0.7793\n",
      "2024-11-20 21:02:51.615057: val_loss 0.1772\n",
      "2024-11-20 21:02:51.625057: Pseudo dice [0.5676]\n",
      "2024-11-20 21:02:51.635057: Epoch time: 129.48 s\n",
      "2024-11-20 21:02:52.615080: \n",
      "2024-11-20 21:02:52.615080: Epoch 234\n",
      "2024-11-20 21:02:52.625072: Current learning rate: 0.00567\n",
      "2024-11-20 21:05:02.103132: train_loss -0.7947\n",
      "2024-11-20 21:05:02.103132: val_loss 0.4525\n",
      "2024-11-20 21:05:02.113132: Pseudo dice [0.4067]\n",
      "2024-11-20 21:05:02.113132: Epoch time: 129.49 s\n",
      "2024-11-20 21:05:03.083379: \n",
      "2024-11-20 21:05:03.083379: Epoch 235\n",
      "2024-11-20 21:05:03.083379: Current learning rate: 0.00565\n",
      "2024-11-20 21:07:12.540822: train_loss -0.753\n",
      "2024-11-20 21:07:12.540822: val_loss 0.0409\n",
      "2024-11-20 21:07:12.550822: Pseudo dice [0.6108]\n",
      "2024-11-20 21:07:12.550822: Epoch time: 129.46 s\n",
      "2024-11-20 21:07:13.530836: \n",
      "2024-11-20 21:07:13.530836: Epoch 236\n",
      "2024-11-20 21:07:13.530836: Current learning rate: 0.00563\n",
      "2024-11-20 21:09:23.190340: train_loss -0.7624\n",
      "2024-11-20 21:09:23.190340: val_loss -0.2155\n",
      "2024-11-20 21:09:23.220340: Pseudo dice [0.6993]\n",
      "2024-11-20 21:09:23.220340: Epoch time: 129.66 s\n",
      "2024-11-20 21:09:24.210364: \n",
      "2024-11-20 21:09:24.210364: Epoch 237\n",
      "2024-11-20 21:09:24.220355: Current learning rate: 0.00561\n",
      "2024-11-20 21:11:33.679769: train_loss -0.7665\n",
      "2024-11-20 21:11:33.679769: val_loss 0.2077\n",
      "2024-11-20 21:11:33.689769: Pseudo dice [0.5433]\n",
      "2024-11-20 21:11:33.689769: Epoch time: 129.47 s\n",
      "2024-11-20 21:11:34.829803: \n",
      "2024-11-20 21:11:34.829803: Epoch 238\n",
      "2024-11-20 21:11:34.839803: Current learning rate: 0.00559\n",
      "2024-11-20 21:13:44.285258: train_loss -0.7685\n",
      "2024-11-20 21:13:44.285258: val_loss -0.0994\n",
      "2024-11-20 21:13:44.295259: Pseudo dice [0.6451]\n",
      "2024-11-20 21:13:44.305259: Epoch time: 129.46 s\n",
      "2024-11-20 21:13:45.295620: \n",
      "2024-11-20 21:13:45.295620: Epoch 239\n",
      "2024-11-20 21:13:45.295620: Current learning rate: 0.00557\n",
      "2024-11-20 21:15:54.941832: train_loss -0.7999\n",
      "2024-11-20 21:15:54.941832: val_loss 0.012\n",
      "2024-11-20 21:15:54.951832: Pseudo dice [0.5367]\n",
      "2024-11-20 21:15:54.961832: Epoch time: 129.65 s\n",
      "2024-11-20 21:15:55.951845: \n",
      "2024-11-20 21:15:55.951845: Epoch 240\n",
      "2024-11-20 21:15:55.951845: Current learning rate: 0.00555\n",
      "2024-11-20 21:18:05.515584: train_loss -0.7898\n",
      "2024-11-20 21:18:05.515584: val_loss 0.0847\n",
      "2024-11-20 21:18:05.525585: Pseudo dice [0.5625]\n",
      "2024-11-20 21:18:05.535586: Epoch time: 129.57 s\n",
      "2024-11-20 21:18:06.526514: \n",
      "2024-11-20 21:18:06.526514: Epoch 241\n",
      "2024-11-20 21:18:06.536515: Current learning rate: 0.00553\n",
      "2024-11-20 21:20:15.953706: train_loss -0.7999\n",
      "2024-11-20 21:20:15.953706: val_loss 0.0655\n",
      "2024-11-20 21:20:15.963704: Pseudo dice [0.4665]\n",
      "2024-11-20 21:20:15.973704: Epoch time: 129.43 s\n",
      "2024-11-20 21:20:17.004360: \n",
      "2024-11-20 21:20:17.004360: Epoch 242\n",
      "2024-11-20 21:20:17.014360: Current learning rate: 0.00551\n",
      "2024-11-20 21:22:26.441633: train_loss -0.8139\n",
      "2024-11-20 21:22:26.441633: val_loss -0.1338\n",
      "2024-11-20 21:22:26.451633: Pseudo dice [0.6261]\n",
      "2024-11-20 21:22:26.451633: Epoch time: 129.44 s\n",
      "2024-11-20 21:22:27.431656: \n",
      "2024-11-20 21:22:27.431656: Epoch 243\n",
      "2024-11-20 21:22:27.441656: Current learning rate: 0.00549\n",
      "2024-11-20 21:24:36.872200: train_loss -0.813\n",
      "2024-11-20 21:24:36.872200: val_loss -0.2708\n",
      "2024-11-20 21:24:36.882202: Pseudo dice [0.71]\n",
      "2024-11-20 21:24:36.882202: Epoch time: 129.44 s\n",
      "2024-11-20 21:24:37.862224: \n",
      "2024-11-20 21:24:37.862224: Epoch 244\n",
      "2024-11-20 21:24:37.872224: Current learning rate: 0.00547\n",
      "2024-11-20 21:26:47.459266: train_loss -0.811\n",
      "2024-11-20 21:26:47.459266: val_loss -0.3351\n",
      "2024-11-20 21:26:47.469267: Pseudo dice [0.7649]\n",
      "2024-11-20 21:26:47.479266: Epoch time: 129.6 s\n",
      "2024-11-20 21:26:48.639291: \n",
      "2024-11-20 21:26:48.639291: Epoch 245\n",
      "2024-11-20 21:26:48.639291: Current learning rate: 0.00546\n",
      "2024-11-20 21:28:58.127099: train_loss -0.7959\n",
      "2024-11-20 21:28:58.127099: val_loss -0.2202\n",
      "2024-11-20 21:28:58.137099: Pseudo dice [0.7035]\n",
      "2024-11-20 21:28:58.137099: Epoch time: 129.5 s\n",
      "2024-11-20 21:28:59.117121: \n",
      "2024-11-20 21:28:59.117121: Epoch 246\n",
      "2024-11-20 21:28:59.127122: Current learning rate: 0.00544\n",
      "2024-11-20 21:31:08.603018: train_loss -0.7923\n",
      "2024-11-20 21:31:08.603018: val_loss -0.1449\n",
      "2024-11-20 21:31:08.603018: Pseudo dice [0.6148]\n",
      "2024-11-20 21:31:08.613017: Epoch time: 129.49 s\n",
      "2024-11-20 21:31:09.603040: \n",
      "2024-11-20 21:31:09.603040: Epoch 247\n",
      "2024-11-20 21:31:09.603040: Current learning rate: 0.00542\n",
      "2024-11-20 21:33:19.051083: train_loss -0.8063\n",
      "2024-11-20 21:33:19.051083: val_loss 0.3819\n",
      "2024-11-20 21:33:19.061083: Pseudo dice [0.4062]\n",
      "2024-11-20 21:33:19.071084: Epoch time: 129.46 s\n",
      "2024-11-20 21:33:20.052085: \n",
      "2024-11-20 21:33:20.052085: Epoch 248\n",
      "2024-11-20 21:33:20.062085: Current learning rate: 0.0054\n",
      "2024-11-20 21:35:29.613339: train_loss -0.7919\n",
      "2024-11-20 21:35:29.613339: val_loss 0.3913\n",
      "2024-11-20 21:35:29.623339: Pseudo dice [0.4719]\n",
      "2024-11-20 21:35:29.633339: Epoch time: 129.56 s\n",
      "2024-11-20 21:35:30.623660: \n",
      "2024-11-20 21:35:30.623660: Epoch 249\n",
      "2024-11-20 21:35:30.623660: Current learning rate: 0.00538\n",
      "2024-11-20 21:37:40.081573: train_loss -0.7885\n",
      "2024-11-20 21:37:40.081573: val_loss -0.2151\n",
      "2024-11-20 21:37:40.091573: Pseudo dice [0.752]\n",
      "2024-11-20 21:37:40.091573: Epoch time: 129.46 s\n",
      "2024-11-20 21:37:41.311600: \n",
      "2024-11-20 21:37:41.311600: Epoch 250\n",
      "2024-11-20 21:37:41.321599: Current learning rate: 0.00536\n",
      "2024-11-20 21:39:50.779817: train_loss -0.7712\n",
      "2024-11-20 21:39:50.779817: val_loss -0.2332\n",
      "2024-11-20 21:39:50.789817: Pseudo dice [0.6677]\n",
      "2024-11-20 21:39:50.789817: Epoch time: 129.47 s\n",
      "2024-11-20 21:39:51.779840: \n",
      "2024-11-20 21:39:51.779840: Epoch 251\n",
      "2024-11-20 21:39:51.789840: Current learning rate: 0.00534\n",
      "2024-11-20 21:42:01.274904: train_loss -0.7832\n",
      "2024-11-20 21:42:01.274904: val_loss -0.2365\n",
      "2024-11-20 21:42:01.284904: Pseudo dice [0.6657]\n",
      "2024-11-20 21:42:01.294904: Epoch time: 129.5 s\n",
      "2024-11-20 21:42:02.295280: \n",
      "2024-11-20 21:42:02.295280: Epoch 252\n",
      "2024-11-20 21:42:02.305279: Current learning rate: 0.00532\n",
      "2024-11-20 21:44:11.883372: train_loss -0.7768\n",
      "2024-11-20 21:44:11.883372: val_loss 0.2275\n",
      "2024-11-20 21:44:11.893372: Pseudo dice [0.4324]\n",
      "2024-11-20 21:44:11.903372: Epoch time: 129.59 s\n",
      "2024-11-20 21:44:13.073399: \n",
      "2024-11-20 21:44:13.073399: Epoch 253\n",
      "2024-11-20 21:44:13.073399: Current learning rate: 0.0053\n",
      "2024-11-20 21:46:22.539250: train_loss -0.7709\n",
      "2024-11-20 21:46:22.539250: val_loss -0.0224\n",
      "2024-11-20 21:46:22.549250: Pseudo dice [0.6264]\n",
      "2024-11-20 21:46:22.549250: Epoch time: 129.47 s\n",
      "2024-11-20 21:46:23.550333: \n",
      "2024-11-20 21:46:23.550333: Epoch 254\n",
      "2024-11-20 21:46:23.550333: Current learning rate: 0.00528\n",
      "2024-11-20 21:48:33.016721: train_loss -0.8028\n",
      "2024-11-20 21:48:33.016721: val_loss 0.1634\n",
      "2024-11-20 21:48:33.026722: Pseudo dice [0.5187]\n",
      "2024-11-20 21:48:33.036722: Epoch time: 129.48 s\n",
      "2024-11-20 21:48:34.017766: \n",
      "2024-11-20 21:48:34.017766: Epoch 255\n",
      "2024-11-20 21:48:34.027766: Current learning rate: 0.00526\n",
      "2024-11-20 21:50:43.527409: train_loss -0.8072\n",
      "2024-11-20 21:50:43.527409: val_loss 0.541\n",
      "2024-11-20 21:50:43.537409: Pseudo dice [0.352]\n",
      "2024-11-20 21:50:43.547409: Epoch time: 129.51 s\n",
      "2024-11-20 21:50:44.527432: \n",
      "2024-11-20 21:50:44.527432: Epoch 256\n",
      "2024-11-20 21:50:44.537432: Current learning rate: 0.00524\n",
      "2024-11-20 21:52:54.096318: train_loss -0.7947\n",
      "2024-11-20 21:52:54.096318: val_loss -0.171\n",
      "2024-11-20 21:52:54.106318: Pseudo dice [0.6964]\n",
      "2024-11-20 21:52:54.116318: Epoch time: 129.57 s\n",
      "2024-11-20 21:52:55.106341: \n",
      "2024-11-20 21:52:55.106341: Epoch 257\n",
      "2024-11-20 21:52:55.116340: Current learning rate: 0.00522\n",
      "2024-11-20 21:55:04.543784: train_loss -0.8023\n",
      "2024-11-20 21:55:04.543784: val_loss -0.2266\n",
      "2024-11-20 21:55:04.553784: Pseudo dice [0.6604]\n",
      "2024-11-20 21:55:04.563783: Epoch time: 129.44 s\n",
      "2024-11-20 21:55:05.553806: \n",
      "2024-11-20 21:55:05.553806: Epoch 258\n",
      "2024-11-20 21:55:05.563806: Current learning rate: 0.0052\n",
      "2024-11-20 21:57:14.990968: train_loss -0.7673\n",
      "2024-11-20 21:57:14.990968: val_loss -0.1345\n",
      "2024-11-20 21:57:15.000969: Pseudo dice [0.6804]\n",
      "2024-11-20 21:57:15.010969: Epoch time: 129.44 s\n",
      "2024-11-20 21:57:16.011344: \n",
      "2024-11-20 21:57:16.011344: Epoch 259\n",
      "2024-11-20 21:57:16.011344: Current learning rate: 0.00518\n",
      "2024-11-20 21:59:25.490524: train_loss -0.7638\n",
      "2024-11-20 21:59:25.490524: val_loss -0.3397\n",
      "2024-11-20 21:59:25.500524: Pseudo dice [0.7329]\n",
      "2024-11-20 21:59:25.500524: Epoch time: 129.48 s\n",
      "2024-11-20 21:59:26.670919: \n",
      "2024-11-20 21:59:26.670919: Epoch 260\n",
      "2024-11-20 21:59:26.670919: Current learning rate: 0.00517\n",
      "2024-11-20 22:01:36.229986: train_loss -0.7728\n",
      "2024-11-20 22:01:36.229986: val_loss -0.2453\n",
      "2024-11-20 22:01:36.239984: Pseudo dice [0.6126]\n",
      "2024-11-20 22:01:36.249984: Epoch time: 129.56 s\n",
      "2024-11-20 22:01:37.250016: \n",
      "2024-11-20 22:01:37.250016: Epoch 261\n",
      "2024-11-20 22:01:37.250016: Current learning rate: 0.00515\n",
      "2024-11-20 22:03:46.657269: train_loss -0.7852\n",
      "2024-11-20 22:03:46.657269: val_loss 0.203\n",
      "2024-11-20 22:03:46.667270: Pseudo dice [0.4742]\n",
      "2024-11-20 22:03:46.667270: Epoch time: 129.41 s\n",
      "2024-11-20 22:03:47.667645: \n",
      "2024-11-20 22:03:47.667645: Epoch 262\n",
      "2024-11-20 22:03:47.667645: Current learning rate: 0.00513\n",
      "2024-11-20 22:05:57.097298: train_loss -0.7691\n",
      "2024-11-20 22:05:57.097298: val_loss 0.2886\n",
      "2024-11-20 22:05:57.107299: Pseudo dice [0.4941]\n",
      "2024-11-20 22:05:57.117299: Epoch time: 129.43 s\n",
      "2024-11-20 22:05:58.127760: \n",
      "2024-11-20 22:05:58.127760: Epoch 263\n",
      "2024-11-20 22:05:58.137758: Current learning rate: 0.00511\n",
      "2024-11-20 22:08:07.572716: train_loss -0.7868\n",
      "2024-11-20 22:08:07.572716: val_loss -0.3149\n",
      "2024-11-20 22:08:07.582717: Pseudo dice [0.749]\n",
      "2024-11-20 22:08:07.592717: Epoch time: 129.44 s\n",
      "2024-11-20 22:08:08.593792: \n",
      "2024-11-20 22:08:08.593792: Epoch 264\n",
      "2024-11-20 22:08:08.603792: Current learning rate: 0.00509\n",
      "2024-11-20 22:10:18.165861: train_loss -0.7889\n",
      "2024-11-20 22:10:18.165861: val_loss -0.1917\n",
      "2024-11-20 22:10:18.165861: Pseudo dice [0.7257]\n",
      "2024-11-20 22:10:18.175861: Epoch time: 129.57 s\n",
      "2024-11-20 22:10:19.175886: \n",
      "2024-11-20 22:10:19.175886: Epoch 265\n",
      "2024-11-20 22:10:19.175886: Current learning rate: 0.00507\n",
      "2024-11-20 22:12:28.668702: train_loss -0.7935\n",
      "2024-11-20 22:12:28.668702: val_loss -0.2379\n",
      "2024-11-20 22:12:28.678703: Pseudo dice [0.6856]\n",
      "2024-11-20 22:12:28.688703: Epoch time: 129.49 s\n",
      "2024-11-20 22:12:29.688725: \n",
      "2024-11-20 22:12:29.688725: Epoch 266\n",
      "2024-11-20 22:12:29.688725: Current learning rate: 0.00505\n",
      "2024-11-20 22:14:39.188046: train_loss -0.7956\n",
      "2024-11-20 22:14:39.188046: val_loss -0.0793\n",
      "2024-11-20 22:14:39.198047: Pseudo dice [0.6322]\n",
      "2024-11-20 22:14:39.208047: Epoch time: 129.51 s\n",
      "2024-11-20 22:14:40.208071: \n",
      "2024-11-20 22:14:40.208071: Epoch 267\n",
      "2024-11-20 22:14:40.218061: Current learning rate: 0.00503\n",
      "2024-11-20 22:16:49.820557: train_loss -0.8076\n",
      "2024-11-20 22:16:49.820557: val_loss -0.2097\n",
      "2024-11-20 22:16:49.830557: Pseudo dice [0.7127]\n",
      "2024-11-20 22:16:49.830557: Epoch time: 129.62 s\n",
      "2024-11-20 22:16:50.830580: \n",
      "2024-11-20 22:16:50.830580: Epoch 268\n",
      "2024-11-20 22:16:50.840580: Current learning rate: 0.00501\n",
      "2024-11-20 22:19:00.408124: train_loss -0.8051\n",
      "2024-11-20 22:19:00.408124: val_loss 0.1892\n",
      "2024-11-20 22:19:00.428124: Pseudo dice [0.4599]\n",
      "2024-11-20 22:19:00.428124: Epoch time: 129.58 s\n",
      "2024-11-20 22:19:01.428147: \n",
      "2024-11-20 22:19:01.428147: Epoch 269\n",
      "2024-11-20 22:19:01.438147: Current learning rate: 0.00499\n",
      "2024-11-20 22:21:10.886143: train_loss -0.8157\n",
      "2024-11-20 22:21:10.886143: val_loss 0.1422\n",
      "2024-11-20 22:21:10.896143: Pseudo dice [0.4732]\n",
      "2024-11-20 22:21:10.896143: Epoch time: 129.46 s\n",
      "2024-11-20 22:21:11.906168: \n",
      "2024-11-20 22:21:11.906168: Epoch 270\n",
      "2024-11-20 22:21:11.906168: Current learning rate: 0.00497\n",
      "2024-11-20 22:23:21.355013: train_loss -0.7823\n",
      "2024-11-20 22:23:21.355013: val_loss 0.2159\n",
      "2024-11-20 22:23:21.365014: Pseudo dice [0.4823]\n",
      "2024-11-20 22:23:21.375013: Epoch time: 129.45 s\n",
      "2024-11-20 22:23:22.375036: \n",
      "2024-11-20 22:23:22.375036: Epoch 271\n",
      "2024-11-20 22:23:22.385036: Current learning rate: 0.00495\n",
      "2024-11-20 22:25:31.829681: train_loss -0.8117\n",
      "2024-11-20 22:25:31.829681: val_loss -0.1211\n",
      "2024-11-20 22:25:31.839682: Pseudo dice [0.6371]\n",
      "2024-11-20 22:25:31.849682: Epoch time: 129.45 s\n",
      "2024-11-20 22:25:32.849704: \n",
      "2024-11-20 22:25:32.849704: Epoch 272\n",
      "2024-11-20 22:25:32.859704: Current learning rate: 0.00493\n",
      "2024-11-20 22:27:42.386063: train_loss -0.8262\n",
      "2024-11-20 22:27:42.386063: val_loss -0.1568\n",
      "2024-11-20 22:27:42.396064: Pseudo dice [0.6451]\n",
      "2024-11-20 22:27:42.396064: Epoch time: 129.54 s\n",
      "2024-11-20 22:27:43.396312: \n",
      "2024-11-20 22:27:43.396312: Epoch 273\n",
      "2024-11-20 22:27:43.406312: Current learning rate: 0.00491\n",
      "2024-11-20 22:29:52.795994: train_loss -0.8178\n",
      "2024-11-20 22:29:52.795994: val_loss 0.1218\n",
      "2024-11-20 22:29:52.805994: Pseudo dice [0.5336]\n",
      "2024-11-20 22:29:52.805994: Epoch time: 129.4 s\n",
      "2024-11-20 22:29:53.816018: \n",
      "2024-11-20 22:29:53.816018: Epoch 274\n",
      "2024-11-20 22:29:53.816018: Current learning rate: 0.00489\n",
      "2024-11-20 22:32:03.249740: train_loss -0.8221\n",
      "2024-11-20 22:32:03.249740: val_loss 0.0713\n",
      "2024-11-20 22:32:03.259740: Pseudo dice [0.531]\n",
      "2024-11-20 22:32:03.269741: Epoch time: 129.43 s\n",
      "2024-11-20 22:32:04.439774: \n",
      "2024-11-20 22:32:04.439774: Epoch 275\n",
      "2024-11-20 22:32:04.439774: Current learning rate: 0.00487\n",
      "2024-11-20 22:34:13.881665: train_loss -0.8119\n",
      "2024-11-20 22:34:13.881665: val_loss -0.1813\n",
      "2024-11-20 22:34:13.891665: Pseudo dice [0.658]\n",
      "2024-11-20 22:34:13.901665: Epoch time: 129.45 s\n",
      "2024-11-20 22:34:14.891688: \n",
      "2024-11-20 22:34:14.891688: Epoch 276\n",
      "2024-11-20 22:34:14.901688: Current learning rate: 0.00485\n",
      "2024-11-20 22:36:24.474168: train_loss -0.7677\n",
      "2024-11-20 22:36:24.474168: val_loss -0.2361\n",
      "2024-11-20 22:36:24.484168: Pseudo dice [0.6957]\n",
      "2024-11-20 22:36:24.494168: Epoch time: 129.58 s\n",
      "2024-11-20 22:36:25.484190: \n",
      "2024-11-20 22:36:25.494190: Epoch 277\n",
      "2024-11-20 22:36:25.494190: Current learning rate: 0.00484\n",
      "2024-11-20 22:38:34.953944: train_loss -0.7757\n",
      "2024-11-20 22:38:34.953944: val_loss -0.2514\n",
      "2024-11-20 22:38:34.963944: Pseudo dice [0.7042]\n",
      "2024-11-20 22:38:34.973946: Epoch time: 129.47 s\n",
      "2024-11-20 22:38:35.963969: \n",
      "2024-11-20 22:38:35.963969: Epoch 278\n",
      "2024-11-20 22:38:35.963969: Current learning rate: 0.00482\n",
      "2024-11-20 22:40:45.462203: train_loss -0.8001\n",
      "2024-11-20 22:40:45.462203: val_loss -0.037\n",
      "2024-11-20 22:40:45.472203: Pseudo dice [0.628]\n",
      "2024-11-20 22:40:45.472203: Epoch time: 129.5 s\n",
      "2024-11-20 22:40:46.472574: \n",
      "2024-11-20 22:40:46.472574: Epoch 279\n",
      "2024-11-20 22:40:46.472574: Current learning rate: 0.0048\n",
      "2024-11-20 22:42:55.962377: train_loss -0.7952\n",
      "2024-11-20 22:42:55.962377: val_loss 0.1558\n",
      "2024-11-20 22:42:55.972378: Pseudo dice [0.4533]\n",
      "2024-11-20 22:42:55.972378: Epoch time: 129.5 s\n",
      "2024-11-20 22:42:56.972776: \n",
      "2024-11-20 22:42:56.972776: Epoch 280\n",
      "2024-11-20 22:42:56.972776: Current learning rate: 0.00478\n",
      "2024-11-20 22:45:06.671231: train_loss -0.7943\n",
      "2024-11-20 22:45:06.671231: val_loss -0.0162\n",
      "2024-11-20 22:45:06.691231: Pseudo dice [0.6284]\n",
      "2024-11-20 22:45:06.701232: Epoch time: 129.7 s\n",
      "2024-11-20 22:45:07.711255: \n",
      "2024-11-20 22:45:07.711255: Epoch 281\n",
      "2024-11-20 22:45:07.711255: Current learning rate: 0.00476\n",
      "2024-11-20 22:47:17.226143: train_loss -0.802\n",
      "2024-11-20 22:47:17.226143: val_loss -0.029\n",
      "2024-11-20 22:47:17.236143: Pseudo dice [0.5963]\n",
      "2024-11-20 22:47:17.246143: Epoch time: 129.51 s\n",
      "2024-11-20 22:47:18.406168: \n",
      "2024-11-20 22:47:18.406168: Epoch 282\n",
      "2024-11-20 22:47:18.416168: Current learning rate: 0.00474\n",
      "2024-11-20 22:49:27.875571: train_loss -0.8305\n",
      "2024-11-20 22:49:27.875571: val_loss -0.0369\n",
      "2024-11-20 22:49:27.885571: Pseudo dice [0.5951]\n",
      "2024-11-20 22:49:27.895571: Epoch time: 129.47 s\n",
      "2024-11-20 22:49:28.895594: \n",
      "2024-11-20 22:49:28.895594: Epoch 283\n",
      "2024-11-20 22:49:28.895594: Current learning rate: 0.00472\n",
      "2024-11-20 22:51:38.354950: train_loss -0.8124\n",
      "2024-11-20 22:51:38.354950: val_loss -0.0995\n",
      "2024-11-20 22:51:38.364951: Pseudo dice [0.6563]\n",
      "2024-11-20 22:51:38.364951: Epoch time: 129.46 s\n",
      "2024-11-20 22:51:39.364973: \n",
      "2024-11-20 22:51:39.364973: Epoch 284\n",
      "2024-11-20 22:51:39.364973: Current learning rate: 0.0047\n",
      "2024-11-20 22:53:48.883586: train_loss -0.7947\n",
      "2024-11-20 22:53:48.883586: val_loss 0.2416\n",
      "2024-11-20 22:53:48.893587: Pseudo dice [0.3865]\n",
      "2024-11-20 22:53:48.903587: Epoch time: 129.52 s\n",
      "2024-11-20 22:53:49.903609: \n",
      "2024-11-20 22:53:49.903609: Epoch 285\n",
      "2024-11-20 22:53:49.903609: Current learning rate: 0.00468\n",
      "2024-11-20 22:55:59.362382: train_loss -0.8077\n",
      "2024-11-20 22:55:59.362382: val_loss 0.0306\n",
      "2024-11-20 22:55:59.372382: Pseudo dice [0.5543]\n",
      "2024-11-20 22:55:59.382383: Epoch time: 129.47 s\n",
      "2024-11-20 22:56:00.382406: \n",
      "2024-11-20 22:56:00.382406: Epoch 286\n",
      "2024-11-20 22:56:00.382406: Current learning rate: 0.00466\n",
      "2024-11-20 22:58:09.830114: train_loss -0.7894\n",
      "2024-11-20 22:58:09.830114: val_loss 0.135\n",
      "2024-11-20 22:58:09.830114: Pseudo dice [0.6069]\n",
      "2024-11-20 22:58:09.840114: Epoch time: 129.45 s\n",
      "2024-11-20 22:58:10.860137: \n",
      "2024-11-20 22:58:10.860137: Epoch 287\n",
      "2024-11-20 22:58:10.870136: Current learning rate: 0.00464\n",
      "2024-11-20 23:00:20.356809: train_loss -0.7833\n",
      "2024-11-20 23:00:20.356809: val_loss -0.2363\n",
      "2024-11-20 23:00:20.366809: Pseudo dice [0.7261]\n",
      "2024-11-20 23:00:20.379104: Epoch time: 129.5 s\n",
      "2024-11-20 23:00:21.388064: \n",
      "2024-11-20 23:00:21.388064: Epoch 288\n",
      "2024-11-20 23:00:21.388064: Current learning rate: 0.00462\n",
      "2024-11-20 23:02:30.934985: train_loss -0.8021\n",
      "2024-11-20 23:02:30.934985: val_loss -0.0448\n",
      "2024-11-20 23:02:30.944986: Pseudo dice [0.4971]\n",
      "2024-11-20 23:02:30.944986: Epoch time: 129.55 s\n",
      "2024-11-20 23:02:32.135012: \n",
      "2024-11-20 23:02:32.135012: Epoch 289\n",
      "2024-11-20 23:02:32.145011: Current learning rate: 0.0046\n",
      "2024-11-20 23:04:41.572515: train_loss -0.8148\n",
      "2024-11-20 23:04:41.572515: val_loss 0.1121\n",
      "2024-11-20 23:04:41.582515: Pseudo dice [0.5479]\n",
      "2024-11-20 23:04:41.592515: Epoch time: 129.44 s\n",
      "2024-11-20 23:04:42.602900: \n",
      "2024-11-20 23:04:42.602900: Epoch 290\n",
      "2024-11-20 23:04:42.612900: Current learning rate: 0.00458\n",
      "2024-11-20 23:06:52.060542: train_loss -0.8151\n",
      "2024-11-20 23:06:52.060542: val_loss -0.2576\n",
      "2024-11-20 23:06:52.070543: Pseudo dice [0.7092]\n",
      "2024-11-20 23:06:52.080543: Epoch time: 129.46 s\n",
      "2024-11-20 23:06:53.100566: \n",
      "2024-11-20 23:06:53.100566: Epoch 291\n",
      "2024-11-20 23:06:53.100566: Current learning rate: 0.00456\n",
      "2024-11-20 23:09:02.579194: train_loss -0.8053\n",
      "2024-11-20 23:09:02.579194: val_loss 0.3024\n",
      "2024-11-20 23:09:02.589194: Pseudo dice [0.412]\n",
      "2024-11-20 23:09:02.599194: Epoch time: 129.48 s\n",
      "2024-11-20 23:09:03.610178: \n",
      "2024-11-20 23:09:03.610178: Epoch 292\n",
      "2024-11-20 23:09:03.610178: Current learning rate: 0.00454\n",
      "2024-11-20 23:11:13.161250: train_loss -0.8239\n",
      "2024-11-20 23:11:13.161250: val_loss -0.0831\n",
      "2024-11-20 23:11:13.171250: Pseudo dice [0.6333]\n",
      "2024-11-20 23:11:13.181250: Epoch time: 129.55 s\n",
      "2024-11-20 23:11:14.201274: \n",
      "2024-11-20 23:11:14.201274: Epoch 293\n",
      "2024-11-20 23:11:14.201274: Current learning rate: 0.00452\n",
      "2024-11-20 23:13:23.715787: train_loss -0.8312\n",
      "2024-11-20 23:13:23.715787: val_loss -0.0155\n",
      "2024-11-20 23:13:23.725787: Pseudo dice [0.6349]\n",
      "2024-11-20 23:13:23.735788: Epoch time: 129.51 s\n",
      "2024-11-20 23:13:24.745810: \n",
      "2024-11-20 23:13:24.745810: Epoch 294\n",
      "2024-11-20 23:13:24.755809: Current learning rate: 0.0045\n",
      "2024-11-20 23:15:34.372023: train_loss -0.8196\n",
      "2024-11-20 23:15:34.372023: val_loss -0.4259\n",
      "2024-11-20 23:15:34.382025: Pseudo dice [0.7849]\n",
      "2024-11-20 23:15:34.392025: Epoch time: 129.63 s\n",
      "2024-11-20 23:15:35.412047: \n",
      "2024-11-20 23:15:35.412047: Epoch 295\n",
      "2024-11-20 23:15:35.412047: Current learning rate: 0.00448\n",
      "2024-11-20 23:17:44.889915: train_loss -0.8278\n",
      "2024-11-20 23:17:44.889915: val_loss 0.1155\n",
      "2024-11-20 23:17:44.899915: Pseudo dice [0.5282]\n",
      "2024-11-20 23:17:44.899915: Epoch time: 129.49 s\n",
      "2024-11-20 23:17:46.090293: \n",
      "2024-11-20 23:17:46.090293: Epoch 296\n",
      "2024-11-20 23:17:46.100292: Current learning rate: 0.00446\n",
      "2024-11-20 23:19:55.548198: train_loss -0.8243\n",
      "2024-11-20 23:19:55.548198: val_loss -0.1801\n",
      "2024-11-20 23:19:55.568198: Pseudo dice [0.7225]\n",
      "2024-11-20 23:19:55.568198: Epoch time: 129.46 s\n",
      "2024-11-20 23:19:56.588222: \n",
      "2024-11-20 23:19:56.588222: Epoch 297\n",
      "2024-11-20 23:19:56.588222: Current learning rate: 0.00444\n",
      "2024-11-20 23:22:06.005641: train_loss -0.8075\n",
      "2024-11-20 23:22:06.005641: val_loss 0.0394\n",
      "2024-11-20 23:22:06.015642: Pseudo dice [0.577]\n",
      "2024-11-20 23:22:06.025642: Epoch time: 129.43 s\n",
      "2024-11-20 23:22:07.035666: \n",
      "2024-11-20 23:22:07.035666: Epoch 298\n",
      "2024-11-20 23:22:07.045665: Current learning rate: 0.00442\n",
      "2024-11-20 23:24:16.504793: train_loss -0.8238\n",
      "2024-11-20 23:24:16.504793: val_loss -0.0487\n",
      "2024-11-20 23:24:16.514793: Pseudo dice [0.6395]\n",
      "2024-11-20 23:24:16.524793: Epoch time: 129.47 s\n",
      "2024-11-20 23:24:17.545585: \n",
      "2024-11-20 23:24:17.545585: Epoch 299\n",
      "2024-11-20 23:24:17.545585: Current learning rate: 0.0044\n",
      "2024-11-20 23:26:27.132796: train_loss -0.8307\n",
      "2024-11-20 23:26:27.132796: val_loss 0.2614\n",
      "2024-11-20 23:26:27.142796: Pseudo dice [0.5392]\n",
      "2024-11-20 23:26:27.152797: Epoch time: 129.6 s\n",
      "2024-11-20 23:26:28.433170: \n",
      "2024-11-20 23:26:28.433170: Epoch 300\n",
      "2024-11-20 23:26:28.433170: Current learning rate: 0.00438\n",
      "2024-11-20 23:28:37.872878: train_loss -0.8205\n",
      "2024-11-20 23:28:37.872878: val_loss -0.1172\n",
      "2024-11-20 23:28:37.882877: Pseudo dice [0.6353]\n",
      "2024-11-20 23:28:37.892878: Epoch time: 129.44 s\n",
      "2024-11-20 23:28:38.903783: \n",
      "2024-11-20 23:28:38.903783: Epoch 301\n",
      "2024-11-20 23:28:38.903783: Current learning rate: 0.00436\n",
      "2024-11-20 23:30:48.320836: train_loss -0.8073\n",
      "2024-11-20 23:30:48.320836: val_loss -0.2069\n",
      "2024-11-20 23:30:48.330836: Pseudo dice [0.7279]\n",
      "2024-11-20 23:30:48.330836: Epoch time: 129.42 s\n",
      "2024-11-20 23:30:49.350859: \n",
      "2024-11-20 23:30:49.350859: Epoch 302\n",
      "2024-11-20 23:30:49.360858: Current learning rate: 0.00434\n",
      "2024-11-20 23:32:58.757658: train_loss -0.825\n",
      "2024-11-20 23:32:58.757658: val_loss -0.0293\n",
      "2024-11-20 23:32:58.767659: Pseudo dice [0.6468]\n",
      "2024-11-20 23:32:58.777658: Epoch time: 129.41 s\n",
      "2024-11-20 23:32:59.977685: \n",
      "2024-11-20 23:32:59.977685: Epoch 303\n",
      "2024-11-20 23:32:59.977685: Current learning rate: 0.00432\n",
      "2024-11-20 23:35:09.495502: train_loss -0.8329\n",
      "2024-11-20 23:35:09.495502: val_loss -0.008\n",
      "2024-11-20 23:35:09.515502: Pseudo dice [0.6114]\n",
      "2024-11-20 23:35:09.525502: Epoch time: 129.52 s\n",
      "2024-11-20 23:35:10.535526: \n",
      "2024-11-20 23:35:10.535526: Epoch 304\n",
      "2024-11-20 23:35:10.535526: Current learning rate: 0.0043\n",
      "2024-11-20 23:37:19.913053: train_loss -0.8249\n",
      "2024-11-20 23:37:19.913053: val_loss 0.2351\n",
      "2024-11-20 23:37:19.923053: Pseudo dice [0.4087]\n",
      "2024-11-20 23:37:19.923053: Epoch time: 129.38 s\n",
      "2024-11-20 23:37:20.943407: \n",
      "2024-11-20 23:37:20.943407: Epoch 305\n",
      "2024-11-20 23:37:20.943407: Current learning rate: 0.00429\n",
      "2024-11-20 23:39:30.350233: train_loss -0.8188\n",
      "2024-11-20 23:39:30.350233: val_loss -0.1275\n",
      "2024-11-20 23:39:30.360233: Pseudo dice [0.6542]\n",
      "2024-11-20 23:39:30.360233: Epoch time: 129.42 s\n",
      "2024-11-20 23:39:31.380544: \n",
      "2024-11-20 23:39:31.380544: Epoch 306\n",
      "2024-11-20 23:39:31.390544: Current learning rate: 0.00427\n",
      "2024-11-20 23:41:40.843085: train_loss -0.8217\n",
      "2024-11-20 23:41:40.843085: val_loss -0.0265\n",
      "2024-11-20 23:41:40.853085: Pseudo dice [0.5356]\n",
      "2024-11-20 23:41:40.853085: Epoch time: 129.46 s\n",
      "2024-11-20 23:41:41.873108: \n",
      "2024-11-20 23:41:41.873108: Epoch 307\n",
      "2024-11-20 23:41:41.873108: Current learning rate: 0.00425\n",
      "2024-11-20 23:43:51.478442: train_loss -0.8214\n",
      "2024-11-20 23:43:51.478442: val_loss -0.0962\n",
      "2024-11-20 23:43:51.498442: Pseudo dice [0.6699]\n",
      "2024-11-20 23:43:51.508442: Epoch time: 129.61 s\n",
      "2024-11-20 23:43:52.548465: \n",
      "2024-11-20 23:43:52.548465: Epoch 308\n",
      "2024-11-20 23:43:52.548465: Current learning rate: 0.00423\n",
      "2024-11-20 23:46:01.949271: train_loss -0.8126\n",
      "2024-11-20 23:46:01.949271: val_loss 0.0687\n",
      "2024-11-20 23:46:01.959271: Pseudo dice [0.5117]\n",
      "2024-11-20 23:46:01.959271: Epoch time: 129.41 s\n",
      "2024-11-20 23:46:02.989296: \n",
      "2024-11-20 23:46:02.989296: Epoch 309\n",
      "2024-11-20 23:46:02.989296: Current learning rate: 0.00421\n",
      "2024-11-20 23:48:12.433822: train_loss -0.8306\n",
      "2024-11-20 23:48:12.433822: val_loss 0.0317\n",
      "2024-11-20 23:48:12.443822: Pseudo dice [0.5731]\n",
      "2024-11-20 23:48:12.453821: Epoch time: 129.44 s\n",
      "2024-11-20 23:48:13.664204: \n",
      "2024-11-20 23:48:13.664204: Epoch 310\n",
      "2024-11-20 23:48:13.664204: Current learning rate: 0.00419\n",
      "2024-11-20 23:50:23.085067: train_loss -0.8151\n",
      "2024-11-20 23:50:23.085067: val_loss -0.1783\n",
      "2024-11-20 23:50:23.095067: Pseudo dice [0.7289]\n",
      "2024-11-20 23:50:23.095067: Epoch time: 129.43 s\n",
      "2024-11-20 23:50:24.116159: \n",
      "2024-11-20 23:50:24.116159: Epoch 311\n",
      "2024-11-20 23:50:24.126158: Current learning rate: 0.00417\n",
      "2024-11-20 23:52:33.685221: train_loss -0.8211\n",
      "2024-11-20 23:52:33.685221: val_loss -0.2492\n",
      "2024-11-20 23:52:33.695221: Pseudo dice [0.7055]\n",
      "2024-11-20 23:52:33.705222: Epoch time: 129.57 s\n",
      "2024-11-20 23:52:34.735245: \n",
      "2024-11-20 23:52:34.735245: Epoch 312\n",
      "2024-11-20 23:52:34.735245: Current learning rate: 0.00415\n",
      "2024-11-20 23:54:44.180452: train_loss -0.8309\n",
      "2024-11-20 23:54:44.180452: val_loss 0.0598\n",
      "2024-11-20 23:54:44.190453: Pseudo dice [0.5329]\n",
      "2024-11-20 23:54:44.190453: Epoch time: 129.45 s\n",
      "2024-11-20 23:54:45.220888: \n",
      "2024-11-20 23:54:45.220888: Epoch 313\n",
      "2024-11-20 23:54:45.220888: Current learning rate: 0.00413\n",
      "2024-11-20 23:56:54.657935: train_loss -0.8158\n",
      "2024-11-20 23:56:54.657935: val_loss 0.2258\n",
      "2024-11-20 23:56:54.667935: Pseudo dice [0.5305]\n",
      "2024-11-20 23:56:54.677935: Epoch time: 129.44 s\n",
      "2024-11-20 23:56:55.717966: \n",
      "2024-11-20 23:56:55.717966: Epoch 314\n",
      "2024-11-20 23:56:55.727966: Current learning rate: 0.00411\n",
      "2024-11-20 23:59:05.145443: train_loss -0.8313\n",
      "2024-11-20 23:59:05.145443: val_loss -0.0458\n",
      "2024-11-20 23:59:05.155443: Pseudo dice [0.5811]\n",
      "2024-11-20 23:59:05.155443: Epoch time: 129.43 s\n",
      "2024-11-20 23:59:06.195755: \n",
      "2024-11-20 23:59:06.195755: Epoch 315\n",
      "2024-11-20 23:59:06.205755: Current learning rate: 0.00409\n",
      "2024-11-21 00:01:15.695811: train_loss -0.8255\n",
      "2024-11-21 00:01:15.695811: val_loss 0.0497\n",
      "2024-11-21 00:01:15.705811: Pseudo dice [0.5323]\n",
      "2024-11-21 00:01:15.715811: Epoch time: 129.5 s\n",
      "2024-11-21 00:01:16.735836: \n",
      "2024-11-21 00:01:16.735836: Epoch 316\n",
      "2024-11-21 00:01:16.735836: Current learning rate: 0.00407\n",
      "2024-11-21 00:03:26.204818: train_loss -0.7863\n",
      "2024-11-21 00:03:26.204818: val_loss -0.1077\n",
      "2024-11-21 00:03:26.214819: Pseudo dice [0.6351]\n",
      "2024-11-21 00:03:26.224819: Epoch time: 129.47 s\n",
      "2024-11-21 00:03:27.424845: \n",
      "2024-11-21 00:03:27.424845: Epoch 317\n",
      "2024-11-21 00:03:27.434844: Current learning rate: 0.00405\n",
      "2024-11-21 00:05:36.862442: train_loss -0.7751\n",
      "2024-11-21 00:05:36.872442: val_loss 0.1829\n",
      "2024-11-21 00:05:36.882442: Pseudo dice [0.5188]\n",
      "2024-11-21 00:05:36.882442: Epoch time: 129.44 s\n",
      "2024-11-21 00:05:37.902465: \n",
      "2024-11-21 00:05:37.902465: Epoch 318\n",
      "2024-11-21 00:05:37.912464: Current learning rate: 0.00403\n",
      "2024-11-21 00:07:47.312702: train_loss -0.8016\n",
      "2024-11-21 00:07:47.312702: val_loss 0.2657\n",
      "2024-11-21 00:07:47.322702: Pseudo dice [0.4411]\n",
      "2024-11-21 00:07:47.332702: Epoch time: 129.41 s\n",
      "2024-11-21 00:07:48.353800: \n",
      "2024-11-21 00:07:48.353800: Epoch 319\n",
      "2024-11-21 00:07:48.363800: Current learning rate: 0.00401\n",
      "2024-11-21 00:09:57.930803: train_loss -0.795\n",
      "2024-11-21 00:09:57.930803: val_loss -0.4359\n",
      "2024-11-21 00:09:57.940803: Pseudo dice [0.7798]\n",
      "2024-11-21 00:09:57.950804: Epoch time: 129.58 s\n",
      "2024-11-21 00:09:58.970827: \n",
      "2024-11-21 00:09:58.970827: Epoch 320\n",
      "2024-11-21 00:09:58.980827: Current learning rate: 0.00399\n",
      "2024-11-21 00:12:08.396794: train_loss -0.7624\n",
      "2024-11-21 00:12:08.396794: val_loss 0.0143\n",
      "2024-11-21 00:12:08.406794: Pseudo dice [0.5986]\n",
      "2024-11-21 00:12:08.406794: Epoch time: 129.43 s\n",
      "2024-11-21 00:12:09.436827: \n",
      "2024-11-21 00:12:09.436827: Epoch 321\n",
      "2024-11-21 00:12:09.436827: Current learning rate: 0.00397\n",
      "2024-11-21 00:14:18.867033: train_loss -0.7625\n",
      "2024-11-21 00:14:18.867033: val_loss 0.2623\n",
      "2024-11-21 00:14:18.877033: Pseudo dice [0.2652]\n",
      "2024-11-21 00:14:18.887034: Epoch time: 129.44 s\n",
      "2024-11-21 00:14:19.907057: \n",
      "2024-11-21 00:14:19.907057: Epoch 322\n",
      "2024-11-21 00:14:19.907057: Current learning rate: 0.00395\n",
      "2024-11-21 00:16:29.588676: train_loss -0.8111\n",
      "2024-11-21 00:16:29.588676: val_loss 0.0773\n",
      "2024-11-21 00:16:29.608677: Pseudo dice [0.5988]\n",
      "2024-11-21 00:16:29.618677: Epoch time: 129.68 s\n",
      "2024-11-21 00:16:30.651027: \n",
      "2024-11-21 00:16:30.651027: Epoch 323\n",
      "2024-11-21 00:16:30.659039: Current learning rate: 0.00393\n",
      "2024-11-21 00:18:40.068894: train_loss -0.8244\n",
      "2024-11-21 00:18:40.068894: val_loss 0.5667\n",
      "2024-11-21 00:18:40.078895: Pseudo dice [0.3365]\n",
      "2024-11-21 00:18:40.088894: Epoch time: 129.42 s\n",
      "2024-11-21 00:18:41.289269: \n",
      "2024-11-21 00:18:41.289269: Epoch 324\n",
      "2024-11-21 00:18:41.289269: Current learning rate: 0.00391\n",
      "2024-11-21 00:20:50.768415: train_loss -0.8297\n",
      "2024-11-21 00:20:50.768415: val_loss -0.1294\n",
      "2024-11-21 00:20:50.788415: Pseudo dice [0.6476]\n",
      "2024-11-21 00:20:50.798415: Epoch time: 129.48 s\n",
      "2024-11-21 00:20:51.819219: \n",
      "2024-11-21 00:20:51.819219: Epoch 325\n",
      "2024-11-21 00:20:51.829219: Current learning rate: 0.00389\n",
      "2024-11-21 00:23:01.296845: train_loss -0.8197\n",
      "2024-11-21 00:23:01.306845: val_loss 0.5694\n",
      "2024-11-21 00:23:01.306845: Pseudo dice [0.1559]\n",
      "2024-11-21 00:23:01.316844: Epoch time: 129.48 s\n",
      "2024-11-21 00:23:02.347819: \n",
      "2024-11-21 00:23:02.347819: Epoch 326\n",
      "2024-11-21 00:23:02.347819: Current learning rate: 0.00387\n",
      "2024-11-21 00:25:11.858246: train_loss -0.811\n",
      "2024-11-21 00:25:11.858246: val_loss -0.0149\n",
      "2024-11-21 00:25:11.868247: Pseudo dice [0.5837]\n",
      "2024-11-21 00:25:11.878247: Epoch time: 129.52 s\n",
      "2024-11-21 00:25:12.898270: \n",
      "2024-11-21 00:25:12.898270: Epoch 327\n",
      "2024-11-21 00:25:12.908271: Current learning rate: 0.00385\n",
      "2024-11-21 00:27:22.355542: train_loss -0.8278\n",
      "2024-11-21 00:27:22.355542: val_loss 0.0531\n",
      "2024-11-21 00:27:22.365542: Pseudo dice [0.6134]\n",
      "2024-11-21 00:27:22.365542: Epoch time: 129.46 s\n",
      "2024-11-21 00:27:23.385565: \n",
      "2024-11-21 00:27:23.385565: Epoch 328\n",
      "2024-11-21 00:27:23.395565: Current learning rate: 0.00383\n",
      "2024-11-21 00:29:32.799428: train_loss -0.8315\n",
      "2024-11-21 00:29:32.799428: val_loss -0.1763\n",
      "2024-11-21 00:29:32.809428: Pseudo dice [0.715]\n",
      "2024-11-21 00:29:32.819428: Epoch time: 129.41 s\n",
      "2024-11-21 00:29:33.840429: \n",
      "2024-11-21 00:29:33.840429: Epoch 329\n",
      "2024-11-21 00:29:33.850428: Current learning rate: 0.00381\n",
      "2024-11-21 00:31:43.304605: train_loss -0.8255\n",
      "2024-11-21 00:31:43.304605: val_loss -0.2836\n",
      "2024-11-21 00:31:43.314605: Pseudo dice [0.7138]\n",
      "2024-11-21 00:31:43.324605: Epoch time: 129.46 s\n",
      "2024-11-21 00:31:44.334629: \n",
      "2024-11-21 00:31:44.334629: Epoch 330\n",
      "2024-11-21 00:31:44.344628: Current learning rate: 0.00379\n",
      "2024-11-21 00:33:53.888329: train_loss -0.832\n",
      "2024-11-21 00:33:53.888329: val_loss -0.2646\n",
      "2024-11-21 00:33:53.898329: Pseudo dice [0.7317]\n",
      "2024-11-21 00:33:53.908330: Epoch time: 129.55 s\n",
      "2024-11-21 00:33:54.939336: \n",
      "2024-11-21 00:33:54.939336: Epoch 331\n",
      "2024-11-21 00:33:54.939336: Current learning rate: 0.00377\n",
      "2024-11-21 00:36:04.368404: train_loss -0.7918\n",
      "2024-11-21 00:36:04.368404: val_loss -0.0592\n",
      "2024-11-21 00:36:04.378404: Pseudo dice [0.6666]\n",
      "2024-11-21 00:36:04.378404: Epoch time: 129.43 s\n",
      "2024-11-21 00:36:05.408427: \n",
      "2024-11-21 00:36:05.408427: Epoch 332\n",
      "2024-11-21 00:36:05.408427: Current learning rate: 0.00375\n",
      "2024-11-21 00:38:14.879691: train_loss -0.7983\n",
      "2024-11-21 00:38:14.879691: val_loss -0.0351\n",
      "2024-11-21 00:38:14.889691: Pseudo dice [0.6149]\n",
      "2024-11-21 00:38:14.889691: Epoch time: 129.48 s\n",
      "2024-11-21 00:38:15.920647: \n",
      "2024-11-21 00:38:15.920647: Epoch 333\n",
      "2024-11-21 00:38:15.920647: Current learning rate: 0.00373\n",
      "2024-11-21 00:40:25.348433: train_loss -0.8331\n",
      "2024-11-21 00:40:25.348433: val_loss -0.1564\n",
      "2024-11-21 00:40:25.368434: Pseudo dice [0.6564]\n",
      "2024-11-21 00:40:25.378434: Epoch time: 129.43 s\n",
      "2024-11-21 00:40:26.398458: \n",
      "2024-11-21 00:40:26.398458: Epoch 334\n",
      "2024-11-21 00:40:26.398458: Current learning rate: 0.00371\n",
      "2024-11-21 00:42:35.884722: train_loss -0.8167\n",
      "2024-11-21 00:42:35.884722: val_loss -0.1042\n",
      "2024-11-21 00:42:35.894722: Pseudo dice [0.6552]\n",
      "2024-11-21 00:42:35.904722: Epoch time: 129.49 s\n",
      "2024-11-21 00:42:36.944746: \n",
      "2024-11-21 00:42:36.944746: Epoch 335\n",
      "2024-11-21 00:42:36.944746: Current learning rate: 0.00369\n",
      "2024-11-21 00:44:45.933481: train_loss -0.8179\n",
      "2024-11-21 00:44:45.933481: val_loss 0.6924\n",
      "2024-11-21 00:44:45.943481: Pseudo dice [0.1016]\n",
      "2024-11-21 00:44:45.943481: Epoch time: 129.0 s\n",
      "2024-11-21 00:44:46.973794: \n",
      "2024-11-21 00:44:46.973794: Epoch 336\n",
      "2024-11-21 00:44:46.983794: Current learning rate: 0.00367\n",
      "2024-11-21 00:46:55.910466: train_loss -0.7977\n",
      "2024-11-21 00:46:55.910466: val_loss -0.1291\n",
      "2024-11-21 00:46:55.920466: Pseudo dice [0.6662]\n",
      "2024-11-21 00:46:55.930466: Epoch time: 128.94 s\n",
      "2024-11-21 00:46:56.960490: \n",
      "2024-11-21 00:46:56.960490: Epoch 337\n",
      "2024-11-21 00:46:56.970490: Current learning rate: 0.00365\n",
      "2024-11-21 00:49:05.833622: train_loss -0.8082\n",
      "2024-11-21 00:49:05.833622: val_loss -0.2693\n",
      "2024-11-21 00:49:05.843622: Pseudo dice [0.7462]\n",
      "2024-11-21 00:49:05.853623: Epoch time: 128.87 s\n",
      "2024-11-21 00:49:07.053649: \n",
      "2024-11-21 00:49:07.053649: Epoch 338\n",
      "2024-11-21 00:49:07.063648: Current learning rate: 0.00363\n",
      "2024-11-21 00:51:16.111566: train_loss -0.8061\n",
      "2024-11-21 00:51:16.121567: val_loss -0.0046\n",
      "2024-11-21 00:51:16.121567: Pseudo dice [0.5859]\n",
      "2024-11-21 00:51:16.131566: Epoch time: 129.06 s\n",
      "2024-11-21 00:51:17.151590: \n",
      "2024-11-21 00:51:17.151590: Epoch 339\n",
      "2024-11-21 00:51:17.161590: Current learning rate: 0.00361\n",
      "2024-11-21 00:53:26.050619: train_loss -0.7984\n",
      "2024-11-21 00:53:26.051629: val_loss -0.1074\n",
      "2024-11-21 00:53:26.054682: Pseudo dice [0.6581]\n",
      "2024-11-21 00:53:26.062686: Epoch time: 128.9 s\n",
      "2024-11-21 00:53:27.092712: \n",
      "2024-11-21 00:53:27.092712: Epoch 340\n",
      "2024-11-21 00:53:27.092712: Current learning rate: 0.00359\n",
      "2024-11-21 00:55:36.008994: train_loss -0.8297\n",
      "2024-11-21 00:55:36.008994: val_loss -0.2147\n",
      "2024-11-21 00:55:36.018994: Pseudo dice [0.6923]\n",
      "2024-11-21 00:55:36.028994: Epoch time: 128.92 s\n",
      "2024-11-21 00:55:37.059018: \n",
      "2024-11-21 00:55:37.059018: Epoch 341\n",
      "2024-11-21 00:55:37.069017: Current learning rate: 0.00357\n",
      "2024-11-21 00:57:45.955740: train_loss -0.8303\n",
      "2024-11-21 00:57:45.965740: val_loss -0.4157\n",
      "2024-11-21 00:57:45.975741: Pseudo dice [0.7433]\n",
      "2024-11-21 00:57:45.975741: Epoch time: 128.9 s\n",
      "2024-11-21 00:57:47.015764: \n",
      "2024-11-21 00:57:47.015764: Epoch 342\n",
      "2024-11-21 00:57:47.015764: Current learning rate: 0.00355\n",
      "2024-11-21 00:59:55.992247: train_loss -0.8365\n",
      "2024-11-21 00:59:55.992247: val_loss -0.2276\n",
      "2024-11-21 00:59:56.002247: Pseudo dice [0.7002]\n",
      "2024-11-21 00:59:56.012247: Epoch time: 128.99 s\n",
      "2024-11-21 00:59:57.052270: \n",
      "2024-11-21 00:59:57.052270: Epoch 343\n",
      "2024-11-21 00:59:57.062270: Current learning rate: 0.00353\n",
      "2024-11-21 01:02:05.958523: train_loss -0.8259\n",
      "2024-11-21 01:02:05.958523: val_loss -0.0208\n",
      "2024-11-21 01:02:05.968523: Pseudo dice [0.6252]\n",
      "2024-11-21 01:02:05.978523: Epoch time: 128.91 s\n",
      "2024-11-21 01:02:07.008546: \n",
      "2024-11-21 01:02:07.008546: Epoch 344\n",
      "2024-11-21 01:02:07.018545: Current learning rate: 0.00351\n",
      "2024-11-21 01:04:15.967692: train_loss -0.8145\n",
      "2024-11-21 01:04:15.967692: val_loss 0.0065\n",
      "2024-11-21 01:04:15.977691: Pseudo dice [0.601]\n",
      "2024-11-21 01:04:15.987691: Epoch time: 128.96 s\n",
      "2024-11-21 01:04:17.187717: \n",
      "2024-11-21 01:04:17.187717: Epoch 345\n",
      "2024-11-21 01:04:17.197716: Current learning rate: 0.00349\n",
      "2024-11-21 01:06:26.124258: train_loss -0.8235\n",
      "2024-11-21 01:06:26.124258: val_loss -0.1016\n",
      "2024-11-21 01:06:26.134259: Pseudo dice [0.6663]\n",
      "2024-11-21 01:06:26.144258: Epoch time: 128.94 s\n",
      "2024-11-21 01:06:27.164282: \n",
      "2024-11-21 01:06:27.164282: Epoch 346\n",
      "2024-11-21 01:06:27.174283: Current learning rate: 0.00346\n",
      "2024-11-21 01:08:36.194392: train_loss -0.8295\n",
      "2024-11-21 01:08:36.194392: val_loss 0.2957\n",
      "2024-11-21 01:08:36.204392: Pseudo dice [0.4459]\n",
      "2024-11-21 01:08:36.204392: Epoch time: 129.03 s\n",
      "2024-11-21 01:08:37.244416: \n",
      "2024-11-21 01:08:37.244416: Epoch 347\n",
      "2024-11-21 01:08:37.254416: Current learning rate: 0.00344\n",
      "2024-11-21 01:10:46.213893: train_loss -0.831\n",
      "2024-11-21 01:10:46.213893: val_loss -0.0691\n",
      "2024-11-21 01:10:46.223893: Pseudo dice [0.661]\n",
      "2024-11-21 01:10:46.223893: Epoch time: 128.97 s\n",
      "2024-11-21 01:10:47.253918: \n",
      "2024-11-21 01:10:47.253918: Epoch 348\n",
      "2024-11-21 01:10:47.253918: Current learning rate: 0.00342\n",
      "2024-11-21 01:12:56.246444: train_loss -0.8192\n",
      "2024-11-21 01:12:56.246444: val_loss 0.4396\n",
      "2024-11-21 01:12:56.256443: Pseudo dice [0.322]\n",
      "2024-11-21 01:12:56.266444: Epoch time: 128.99 s\n",
      "2024-11-21 01:12:57.296466: \n",
      "2024-11-21 01:12:57.296466: Epoch 349\n",
      "2024-11-21 01:12:57.306466: Current learning rate: 0.0034\n",
      "2024-11-21 01:15:06.281929: train_loss -0.7951\n",
      "2024-11-21 01:15:06.281929: val_loss 0.3365\n",
      "2024-11-21 01:15:06.291929: Pseudo dice [0.3356]\n",
      "2024-11-21 01:15:06.301930: Epoch time: 128.99 s\n",
      "2024-11-21 01:15:07.551956: \n",
      "2024-11-21 01:15:07.551956: Epoch 350\n",
      "2024-11-21 01:15:07.561956: Current learning rate: 0.00338\n",
      "2024-11-21 01:17:16.789168: train_loss -0.8165\n",
      "2024-11-21 01:17:16.789168: val_loss 0.0508\n",
      "2024-11-21 01:17:16.789168: Pseudo dice [0.5541]\n",
      "2024-11-21 01:17:16.799169: Epoch time: 129.24 s\n",
      "2024-11-21 01:17:17.839193: \n",
      "2024-11-21 01:17:17.839193: Epoch 351\n",
      "2024-11-21 01:17:17.849192: Current learning rate: 0.00336\n",
      "2024-11-21 01:19:26.840308: train_loss -0.8281\n",
      "2024-11-21 01:19:26.840308: val_loss 0.4276\n",
      "2024-11-21 01:19:26.850308: Pseudo dice [0.2031]\n",
      "2024-11-21 01:19:26.860308: Epoch time: 129.0 s\n",
      "2024-11-21 01:19:28.070326: \n",
      "2024-11-21 01:19:28.070326: Epoch 352\n",
      "2024-11-21 01:19:28.070326: Current learning rate: 0.00334\n",
      "2024-11-21 01:21:37.008215: train_loss -0.8442\n",
      "2024-11-21 01:21:37.008215: val_loss 0.0067\n",
      "2024-11-21 01:21:37.018215: Pseudo dice [0.5927]\n",
      "2024-11-21 01:21:37.028215: Epoch time: 128.95 s\n",
      "2024-11-21 01:21:38.068239: \n",
      "2024-11-21 01:21:38.068239: Epoch 353\n",
      "2024-11-21 01:21:38.130112: Current learning rate: 0.00332\n",
      "2024-11-21 01:23:47.104355: train_loss -0.8324\n",
      "2024-11-21 01:23:47.104355: val_loss -0.1017\n",
      "2024-11-21 01:23:47.114355: Pseudo dice [0.6487]\n",
      "2024-11-21 01:23:47.124354: Epoch time: 129.04 s\n",
      "2024-11-21 01:23:48.174378: \n",
      "2024-11-21 01:23:48.174378: Epoch 354\n",
      "2024-11-21 01:23:48.184376: Current learning rate: 0.0033\n",
      "2024-11-21 01:25:57.241153: train_loss -0.8291\n",
      "2024-11-21 01:25:57.241153: val_loss 0.193\n",
      "2024-11-21 01:25:57.261153: Pseudo dice [0.4559]\n",
      "2024-11-21 01:25:57.261153: Epoch time: 129.07 s\n",
      "2024-11-21 01:25:58.301177: \n",
      "2024-11-21 01:25:58.301177: Epoch 355\n",
      "2024-11-21 01:25:58.311176: Current learning rate: 0.00328\n",
      "2024-11-21 01:28:07.227932: train_loss -0.8267\n",
      "2024-11-21 01:28:07.227932: val_loss 0.3136\n",
      "2024-11-21 01:28:07.247932: Pseudo dice [0.3999]\n",
      "2024-11-21 01:28:07.247932: Epoch time: 128.93 s\n",
      "2024-11-21 01:28:08.288840: \n",
      "2024-11-21 01:28:08.288840: Epoch 356\n",
      "2024-11-21 01:28:08.288840: Current learning rate: 0.00326\n",
      "2024-11-21 01:30:17.263984: train_loss -0.8222\n",
      "2024-11-21 01:30:17.263984: val_loss 0.4861\n",
      "2024-11-21 01:30:17.273985: Pseudo dice [0.2669]\n",
      "2024-11-21 01:30:17.273985: Epoch time: 128.98 s\n",
      "2024-11-21 01:30:18.313998: \n",
      "2024-11-21 01:30:18.313998: Epoch 357\n",
      "2024-11-21 01:30:18.313998: Current learning rate: 0.00324\n",
      "2024-11-21 01:32:27.301014: train_loss -0.8003\n",
      "2024-11-21 01:32:27.301014: val_loss 0.3486\n",
      "2024-11-21 01:32:27.311015: Pseudo dice [0.3746]\n",
      "2024-11-21 01:32:27.321014: Epoch time: 128.99 s\n",
      "2024-11-21 01:32:28.361276: \n",
      "2024-11-21 01:32:28.361276: Epoch 358\n",
      "2024-11-21 01:32:28.361276: Current learning rate: 0.00322\n",
      "2024-11-21 01:34:37.399523: train_loss -0.7947\n",
      "2024-11-21 01:34:37.399523: val_loss 0.0456\n",
      "2024-11-21 01:34:37.409523: Pseudo dice [0.5451]\n",
      "2024-11-21 01:34:37.419523: Epoch time: 129.04 s\n",
      "2024-11-21 01:34:38.629865: \n",
      "2024-11-21 01:34:38.629865: Epoch 359\n",
      "2024-11-21 01:34:38.629865: Current learning rate: 0.0032\n",
      "2024-11-21 01:36:47.655279: train_loss -0.8115\n",
      "2024-11-21 01:36:47.655279: val_loss -0.1202\n",
      "2024-11-21 01:36:47.665279: Pseudo dice [0.6779]\n",
      "2024-11-21 01:36:47.665279: Epoch time: 129.03 s\n",
      "2024-11-21 01:36:48.705974: \n",
      "2024-11-21 01:36:48.705974: Epoch 360\n",
      "2024-11-21 01:36:48.705974: Current learning rate: 0.00318\n",
      "2024-11-21 01:38:57.905607: train_loss -0.8169\n",
      "2024-11-21 01:38:57.905607: val_loss 0.2148\n",
      "2024-11-21 01:38:57.915607: Pseudo dice [0.5261]\n",
      "2024-11-21 01:38:57.925607: Epoch time: 129.2 s\n",
      "2024-11-21 01:38:58.965630: \n",
      "2024-11-21 01:38:58.965630: Epoch 361\n",
      "2024-11-21 01:38:58.965630: Current learning rate: 0.00316\n",
      "2024-11-21 01:41:08.191424: train_loss -0.8341\n",
      "2024-11-21 01:41:08.191424: val_loss -0.0039\n",
      "2024-11-21 01:41:08.201424: Pseudo dice [0.6157]\n",
      "2024-11-21 01:41:08.201424: Epoch time: 129.23 s\n",
      "2024-11-21 01:41:09.251447: \n",
      "2024-11-21 01:41:09.261438: Epoch 362\n",
      "2024-11-21 01:41:09.261438: Current learning rate: 0.00314\n",
      "2024-11-21 01:43:18.822603: train_loss -0.8157\n",
      "2024-11-21 01:43:18.822603: val_loss 0.1126\n",
      "2024-11-21 01:43:18.832603: Pseudo dice [0.5355]\n",
      "2024-11-21 01:43:18.842603: Epoch time: 129.57 s\n",
      "2024-11-21 01:43:19.892626: \n",
      "2024-11-21 01:43:19.892626: Epoch 363\n",
      "2024-11-21 01:43:19.892626: Current learning rate: 0.00312\n",
      "2024-11-21 01:45:29.120663: train_loss -0.8272\n",
      "2024-11-21 01:45:29.130664: val_loss -0.1957\n",
      "2024-11-21 01:45:29.140664: Pseudo dice [0.6827]\n",
      "2024-11-21 01:45:29.140664: Epoch time: 129.24 s\n",
      "2024-11-21 01:45:30.180686: \n",
      "2024-11-21 01:45:30.180686: Epoch 364\n",
      "2024-11-21 01:45:30.190679: Current learning rate: 0.0031\n",
      "2024-11-21 01:47:39.451531: train_loss -0.8402\n",
      "2024-11-21 01:47:39.451531: val_loss -0.0452\n",
      "2024-11-21 01:47:39.461531: Pseudo dice [0.6523]\n",
      "2024-11-21 01:47:39.471531: Epoch time: 129.27 s\n",
      "2024-11-21 01:47:40.521881: \n",
      "2024-11-21 01:47:40.521881: Epoch 365\n",
      "2024-11-21 01:47:40.521881: Current learning rate: 0.00308\n",
      "2024-11-21 01:49:49.744748: train_loss -0.8359\n",
      "2024-11-21 01:49:49.744748: val_loss 0.3161\n",
      "2024-11-21 01:49:49.754748: Pseudo dice [0.438]\n",
      "2024-11-21 01:49:49.754748: Epoch time: 129.22 s\n",
      "2024-11-21 01:49:50.974681: \n",
      "2024-11-21 01:49:50.974681: Epoch 366\n",
      "2024-11-21 01:49:50.980750: Current learning rate: 0.00306\n",
      "2024-11-21 01:52:00.247539: train_loss -0.8276\n",
      "2024-11-21 01:52:00.247539: val_loss 0.2397\n",
      "2024-11-21 01:52:00.257540: Pseudo dice [0.4775]\n",
      "2024-11-21 01:52:00.267540: Epoch time: 129.27 s\n",
      "2024-11-21 01:52:01.308671: \n",
      "2024-11-21 01:52:01.308671: Epoch 367\n",
      "2024-11-21 01:52:01.308671: Current learning rate: 0.00304\n",
      "2024-11-21 01:54:10.546603: train_loss -0.837\n",
      "2024-11-21 01:54:10.546603: val_loss -0.2572\n",
      "2024-11-21 01:54:10.556604: Pseudo dice [0.7861]\n",
      "2024-11-21 01:54:10.556604: Epoch time: 129.25 s\n",
      "2024-11-21 01:54:11.606926: \n",
      "2024-11-21 01:54:11.606926: Epoch 368\n",
      "2024-11-21 01:54:11.606926: Current learning rate: 0.00302\n",
      "2024-11-21 01:56:20.847464: train_loss -0.8403\n",
      "2024-11-21 01:56:20.847464: val_loss 0.0731\n",
      "2024-11-21 01:56:20.857464: Pseudo dice [0.5943]\n",
      "2024-11-21 01:56:20.867464: Epoch time: 129.24 s\n",
      "2024-11-21 01:56:21.927486: \n",
      "2024-11-21 01:56:21.927486: Epoch 369\n",
      "2024-11-21 01:56:21.927486: Current learning rate: 0.003\n",
      "2024-11-21 01:58:31.191792: train_loss -0.8282\n",
      "2024-11-21 01:58:31.191792: val_loss 0.3703\n",
      "2024-11-21 01:58:31.201792: Pseudo dice [0.3461]\n",
      "2024-11-21 01:58:31.201792: Epoch time: 129.27 s\n",
      "2024-11-21 01:58:32.252839: \n",
      "2024-11-21 01:58:32.252839: Epoch 370\n",
      "2024-11-21 01:58:32.262832: Current learning rate: 0.00297\n",
      "2024-11-21 02:00:41.656706: train_loss -0.8165\n",
      "2024-11-21 02:00:41.656706: val_loss 0.4401\n",
      "2024-11-21 02:00:41.686706: Pseudo dice [0.3799]\n",
      "2024-11-21 02:00:41.686706: Epoch time: 129.4 s\n",
      "2024-11-21 02:00:42.737074: \n",
      "2024-11-21 02:00:42.737074: Epoch 371\n",
      "2024-11-21 02:00:42.737074: Current learning rate: 0.00295\n",
      "2024-11-21 02:02:52.044488: train_loss -0.8276\n",
      "2024-11-21 02:02:52.044488: val_loss -0.0864\n",
      "2024-11-21 02:02:52.054488: Pseudo dice [0.5981]\n",
      "2024-11-21 02:02:52.064488: Epoch time: 129.32 s\n",
      "2024-11-21 02:02:53.275421: \n",
      "2024-11-21 02:02:53.275421: Epoch 372\n",
      "2024-11-21 02:02:53.275421: Current learning rate: 0.00293\n",
      "2024-11-21 02:05:02.569025: train_loss -0.8243\n",
      "2024-11-21 02:05:02.569025: val_loss -0.1226\n",
      "2024-11-21 02:05:02.579026: Pseudo dice [0.5611]\n",
      "2024-11-21 02:05:02.589025: Epoch time: 129.3 s\n",
      "2024-11-21 02:05:03.629049: \n",
      "2024-11-21 02:05:03.629049: Epoch 373\n",
      "2024-11-21 02:05:03.639040: Current learning rate: 0.00291\n",
      "2024-11-21 02:07:12.917422: train_loss -0.8314\n",
      "2024-11-21 02:07:12.917422: val_loss 0.6028\n",
      "2024-11-21 02:07:12.927423: Pseudo dice [0.2902]\n",
      "2024-11-21 02:07:12.937424: Epoch time: 129.29 s\n",
      "2024-11-21 02:07:13.987445: \n",
      "2024-11-21 02:07:13.987445: Epoch 374\n",
      "2024-11-21 02:07:13.987445: Current learning rate: 0.00289\n",
      "2024-11-21 02:09:23.373900: train_loss -0.836\n",
      "2024-11-21 02:09:23.373900: val_loss 0.177\n",
      "2024-11-21 02:09:23.393901: Pseudo dice [0.5109]\n",
      "2024-11-21 02:09:23.403900: Epoch time: 129.4 s\n",
      "2024-11-21 02:09:24.433923: \n",
      "2024-11-21 02:09:24.433923: Epoch 375\n",
      "2024-11-21 02:09:24.443915: Current learning rate: 0.00287\n",
      "2024-11-21 02:11:33.702252: train_loss -0.8359\n",
      "2024-11-21 02:11:33.702252: val_loss 0.2447\n",
      "2024-11-21 02:11:33.712252: Pseudo dice [0.4295]\n",
      "2024-11-21 02:11:33.722253: Epoch time: 129.27 s\n",
      "2024-11-21 02:11:34.772276: \n",
      "2024-11-21 02:11:34.772276: Epoch 376\n",
      "2024-11-21 02:11:34.782268: Current learning rate: 0.00285\n",
      "2024-11-21 02:13:44.138850: train_loss -0.8295\n",
      "2024-11-21 02:13:44.138850: val_loss -0.1422\n",
      "2024-11-21 02:13:44.148850: Pseudo dice [0.6605]\n",
      "2024-11-21 02:13:44.158850: Epoch time: 129.37 s\n",
      "2024-11-21 02:13:45.208874: \n",
      "2024-11-21 02:13:45.208874: Epoch 377\n",
      "2024-11-21 02:13:45.218865: Current learning rate: 0.00283\n",
      "2024-11-21 02:15:54.573446: train_loss -0.8173\n",
      "2024-11-21 02:15:54.573446: val_loss 0.0051\n",
      "2024-11-21 02:15:54.583447: Pseudo dice [0.6135]\n",
      "2024-11-21 02:15:54.583447: Epoch time: 129.36 s\n",
      "2024-11-21 02:15:55.633468: \n",
      "2024-11-21 02:15:55.633468: Epoch 378\n",
      "2024-11-21 02:15:55.633468: Current learning rate: 0.00281\n",
      "2024-11-21 02:18:05.115229: train_loss -0.8064\n",
      "2024-11-21 02:18:05.115229: val_loss -0.1836\n",
      "2024-11-21 02:18:05.125229: Pseudo dice [0.6881]\n",
      "2024-11-21 02:18:05.125229: Epoch time: 129.48 s\n",
      "2024-11-21 02:18:06.355247: \n",
      "2024-11-21 02:18:06.355247: Epoch 379\n",
      "2024-11-21 02:18:06.365247: Current learning rate: 0.00279\n",
      "2024-11-21 02:20:15.719372: train_loss -0.8132\n",
      "2024-11-21 02:20:15.719372: val_loss -0.1722\n",
      "2024-11-21 02:20:15.729373: Pseudo dice [0.6657]\n",
      "2024-11-21 02:20:15.739372: Epoch time: 129.36 s\n",
      "2024-11-21 02:20:16.779395: \n",
      "2024-11-21 02:20:16.779395: Epoch 380\n",
      "2024-11-21 02:20:16.789395: Current learning rate: 0.00277\n",
      "2024-11-21 02:22:26.134061: train_loss -0.8338\n",
      "2024-11-21 02:22:26.134061: val_loss 0.1625\n",
      "2024-11-21 02:22:26.154062: Pseudo dice [0.5067]\n",
      "2024-11-21 02:22:26.164062: Epoch time: 129.35 s\n",
      "2024-11-21 02:22:27.204377: \n",
      "2024-11-21 02:22:27.204377: Epoch 381\n",
      "2024-11-21 02:22:27.214368: Current learning rate: 0.00275\n",
      "2024-11-21 02:24:36.655129: train_loss -0.8086\n",
      "2024-11-21 02:24:36.655129: val_loss 0.1427\n",
      "2024-11-21 02:24:36.665129: Pseudo dice [0.5002]\n",
      "2024-11-21 02:24:36.675129: Epoch time: 129.45 s\n",
      "2024-11-21 02:24:37.775145: \n",
      "2024-11-21 02:24:37.775145: Epoch 382\n",
      "2024-11-21 02:24:37.785145: Current learning rate: 0.00273\n",
      "2024-11-21 02:26:47.516410: train_loss -0.8133\n",
      "2024-11-21 02:26:47.516410: val_loss 0.0344\n",
      "2024-11-21 02:26:47.526411: Pseudo dice [0.6305]\n",
      "2024-11-21 02:26:47.526411: Epoch time: 129.74 s\n",
      "2024-11-21 02:26:48.587154: \n",
      "2024-11-21 02:26:48.587154: Epoch 383\n",
      "2024-11-21 02:26:48.597144: Current learning rate: 0.00271\n",
      "2024-11-21 02:28:58.043058: train_loss -0.8396\n",
      "2024-11-21 02:28:58.043058: val_loss -0.0577\n",
      "2024-11-21 02:28:58.053059: Pseudo dice [0.6278]\n",
      "2024-11-21 02:28:58.063058: Epoch time: 129.46 s\n",
      "2024-11-21 02:28:59.143082: \n",
      "2024-11-21 02:28:59.143082: Epoch 384\n",
      "2024-11-21 02:28:59.143082: Current learning rate: 0.00268\n",
      "2024-11-21 02:31:08.548078: train_loss -0.835\n",
      "2024-11-21 02:31:08.548078: val_loss 0.2136\n",
      "2024-11-21 02:31:08.558079: Pseudo dice [0.4596]\n",
      "2024-11-21 02:31:08.558079: Epoch time: 129.4 s\n",
      "2024-11-21 02:31:09.628093: \n",
      "2024-11-21 02:31:09.628093: Epoch 385\n",
      "2024-11-21 02:31:09.628093: Current learning rate: 0.00266\n",
      "2024-11-21 02:33:19.155972: train_loss -0.8339\n",
      "2024-11-21 02:33:19.155972: val_loss -0.1206\n",
      "2024-11-21 02:33:19.175973: Pseudo dice [0.6315]\n",
      "2024-11-21 02:33:19.185972: Epoch time: 129.53 s\n",
      "2024-11-21 02:33:20.416328: \n",
      "2024-11-21 02:33:20.416328: Epoch 386\n",
      "2024-11-21 02:33:20.426328: Current learning rate: 0.00264\n",
      "2024-11-21 02:35:29.825909: train_loss -0.8396\n",
      "2024-11-21 02:35:29.825909: val_loss 0.1809\n",
      "2024-11-21 02:35:29.835908: Pseudo dice [0.4765]\n",
      "2024-11-21 02:35:29.835908: Epoch time: 129.41 s\n",
      "2024-11-21 02:35:30.915932: \n",
      "2024-11-21 02:35:30.915932: Epoch 387\n",
      "2024-11-21 02:35:30.925923: Current learning rate: 0.00262\n",
      "2024-11-21 02:37:40.324703: train_loss -0.8375\n",
      "2024-11-21 02:37:40.324703: val_loss 0.3551\n",
      "2024-11-21 02:37:40.334702: Pseudo dice [0.395]\n",
      "2024-11-21 02:37:40.344703: Epoch time: 129.41 s\n",
      "2024-11-21 02:37:41.405049: \n",
      "2024-11-21 02:37:41.405049: Epoch 388\n",
      "2024-11-21 02:37:41.415048: Current learning rate: 0.0026\n",
      "2024-11-21 02:39:50.746739: train_loss -0.8452\n",
      "2024-11-21 02:39:50.746739: val_loss 0.0757\n",
      "2024-11-21 02:39:50.756739: Pseudo dice [0.521]\n",
      "2024-11-21 02:39:50.766740: Epoch time: 129.34 s\n",
      "2024-11-21 02:39:51.826753: \n",
      "2024-11-21 02:39:51.826753: Epoch 389\n",
      "2024-11-21 02:39:51.826753: Current learning rate: 0.00258\n",
      "2024-11-21 02:42:01.220833: train_loss -0.8368\n",
      "2024-11-21 02:42:01.230832: val_loss 0.3466\n",
      "2024-11-21 02:42:01.240833: Pseudo dice [0.3203]\n",
      "2024-11-21 02:42:01.240833: Epoch time: 129.39 s\n",
      "2024-11-21 02:42:02.300857: \n",
      "2024-11-21 02:42:02.300857: Epoch 390\n",
      "2024-11-21 02:42:02.310848: Current learning rate: 0.00256\n",
      "2024-11-21 02:44:11.692735: train_loss -0.8182\n",
      "2024-11-21 02:44:11.692735: val_loss 0.308\n",
      "2024-11-21 02:44:11.702735: Pseudo dice [0.4452]\n",
      "2024-11-21 02:44:11.712735: Epoch time: 129.39 s\n",
      "2024-11-21 02:44:12.773584: \n",
      "2024-11-21 02:44:12.773584: Epoch 391\n",
      "2024-11-21 02:44:12.773584: Current learning rate: 0.00254\n",
      "2024-11-21 02:46:22.146997: train_loss -0.8387\n",
      "2024-11-21 02:46:22.146997: val_loss 0.0554\n",
      "2024-11-21 02:46:22.156998: Pseudo dice [0.5497]\n",
      "2024-11-21 02:46:22.166997: Epoch time: 129.37 s\n",
      "2024-11-21 02:46:23.397981: \n",
      "2024-11-21 02:46:23.397981: Epoch 392\n",
      "2024-11-21 02:46:23.407981: Current learning rate: 0.00252\n",
      "2024-11-21 02:48:32.745000: train_loss -0.8345\n",
      "2024-11-21 02:48:32.745000: val_loss -0.1342\n",
      "2024-11-21 02:48:32.755001: Pseudo dice [0.6412]\n",
      "2024-11-21 02:48:32.755001: Epoch time: 129.35 s\n",
      "2024-11-21 02:48:33.816125: \n",
      "2024-11-21 02:48:33.816125: Epoch 393\n",
      "2024-11-21 02:48:33.826117: Current learning rate: 0.0025\n",
      "2024-11-21 02:50:43.222309: train_loss -0.8231\n",
      "2024-11-21 02:50:43.222309: val_loss -0.2383\n",
      "2024-11-21 02:50:43.232310: Pseudo dice [0.6789]\n",
      "2024-11-21 02:50:43.232310: Epoch time: 129.41 s\n",
      "2024-11-21 02:50:44.302332: \n",
      "2024-11-21 02:50:44.302332: Epoch 394\n",
      "2024-11-21 02:50:44.302332: Current learning rate: 0.00248\n",
      "2024-11-21 02:52:53.678873: train_loss -0.8253\n",
      "2024-11-21 02:52:53.678873: val_loss 0.4253\n",
      "2024-11-21 02:52:53.688874: Pseudo dice [0.4039]\n",
      "2024-11-21 02:52:53.688874: Epoch time: 129.39 s\n",
      "2024-11-21 02:52:54.748897: \n",
      "2024-11-21 02:52:54.748897: Epoch 395\n",
      "2024-11-21 02:52:54.758888: Current learning rate: 0.00245\n",
      "2024-11-21 02:55:04.129202: train_loss -0.8276\n",
      "2024-11-21 02:55:04.129202: val_loss 0.0624\n",
      "2024-11-21 02:55:04.139203: Pseudo dice [0.5881]\n",
      "2024-11-21 02:55:04.139203: Epoch time: 129.38 s\n",
      "2024-11-21 02:55:05.209226: \n",
      "2024-11-21 02:55:05.209226: Epoch 396\n",
      "2024-11-21 02:55:05.219226: Current learning rate: 0.00243\n",
      "2024-11-21 02:57:14.565133: train_loss -0.8333\n",
      "2024-11-21 02:57:14.565133: val_loss 0.7754\n",
      "2024-11-21 02:57:14.585134: Pseudo dice [0.1245]\n",
      "2024-11-21 02:57:14.585134: Epoch time: 129.36 s\n",
      "2024-11-21 02:57:15.645157: \n",
      "2024-11-21 02:57:15.645157: Epoch 397\n",
      "2024-11-21 02:57:15.655156: Current learning rate: 0.00241\n",
      "2024-11-21 02:59:25.052318: train_loss -0.8131\n",
      "2024-11-21 02:59:25.052318: val_loss 0.1805\n",
      "2024-11-21 02:59:25.062318: Pseudo dice [0.4715]\n",
      "2024-11-21 02:59:25.062318: Epoch time: 129.41 s\n",
      "2024-11-21 02:59:26.132341: \n",
      "2024-11-21 02:59:26.132341: Epoch 398\n",
      "2024-11-21 02:59:26.142332: Current learning rate: 0.00239\n",
      "2024-11-21 03:01:35.577907: train_loss -0.839\n",
      "2024-11-21 03:01:35.577907: val_loss 0.1361\n",
      "2024-11-21 03:01:35.587908: Pseudo dice [0.5432]\n",
      "2024-11-21 03:01:35.597907: Epoch time: 129.45 s\n",
      "2024-11-21 03:01:36.848254: \n",
      "2024-11-21 03:01:36.848254: Epoch 399\n",
      "2024-11-21 03:01:36.848254: Current learning rate: 0.00237\n",
      "2024-11-21 03:03:46.299197: train_loss -0.8509\n",
      "2024-11-21 03:03:46.299197: val_loss -0.034\n",
      "2024-11-21 03:03:46.299197: Pseudo dice [0.6126]\n",
      "2024-11-21 03:03:46.309197: Epoch time: 129.46 s\n",
      "2024-11-21 03:03:47.609225: \n",
      "2024-11-21 03:03:47.609225: Epoch 400\n",
      "2024-11-21 03:03:47.619215: Current learning rate: 0.00235\n",
      "2024-11-21 03:05:57.015110: train_loss -0.8396\n",
      "2024-11-21 03:05:57.015110: val_loss 0.3325\n",
      "2024-11-21 03:05:57.025110: Pseudo dice [0.4077]\n",
      "2024-11-21 03:05:57.025110: Epoch time: 129.41 s\n",
      "2024-11-21 03:05:58.095583: \n",
      "2024-11-21 03:05:58.095583: Epoch 401\n",
      "2024-11-21 03:05:58.105582: Current learning rate: 0.00233\n",
      "2024-11-21 03:08:07.562680: train_loss -0.8392\n",
      "2024-11-21 03:08:07.562680: val_loss 0.203\n",
      "2024-11-21 03:08:07.572680: Pseudo dice [0.4539]\n",
      "2024-11-21 03:08:07.572680: Epoch time: 129.47 s\n",
      "2024-11-21 03:08:08.652698: \n",
      "2024-11-21 03:08:08.652698: Epoch 402\n",
      "2024-11-21 03:08:08.652698: Current learning rate: 0.00231\n",
      "2024-11-21 03:10:18.117203: train_loss -0.8416\n",
      "2024-11-21 03:10:18.117203: val_loss 0.1758\n",
      "2024-11-21 03:10:18.127203: Pseudo dice [0.4171]\n",
      "2024-11-21 03:10:18.127203: Epoch time: 129.46 s\n",
      "2024-11-21 03:10:19.198042: \n",
      "2024-11-21 03:10:19.198042: Epoch 403\n",
      "2024-11-21 03:10:19.208033: Current learning rate: 0.00229\n",
      "2024-11-21 03:12:28.637190: train_loss -0.8396\n",
      "2024-11-21 03:12:28.637190: val_loss 0.1888\n",
      "2024-11-21 03:12:28.647191: Pseudo dice [0.497]\n",
      "2024-11-21 03:12:28.647191: Epoch time: 129.44 s\n",
      "2024-11-21 03:12:29.727206: \n",
      "2024-11-21 03:12:29.727206: Epoch 404\n",
      "2024-11-21 03:12:29.727206: Current learning rate: 0.00226\n",
      "2024-11-21 03:14:39.205004: train_loss -0.8492\n",
      "2024-11-21 03:14:39.205004: val_loss 0.3382\n",
      "2024-11-21 03:14:39.215004: Pseudo dice [0.4653]\n",
      "2024-11-21 03:14:39.215004: Epoch time: 129.48 s\n",
      "2024-11-21 03:14:40.295020: \n",
      "2024-11-21 03:14:40.295020: Epoch 405\n",
      "2024-11-21 03:14:40.295020: Current learning rate: 0.00224\n",
      "2024-11-21 03:16:49.735584: train_loss -0.8504\n",
      "2024-11-21 03:16:49.735584: val_loss 0.3309\n",
      "2024-11-21 03:16:49.745584: Pseudo dice [0.391]\n",
      "2024-11-21 03:16:49.755584: Epoch time: 129.45 s\n",
      "2024-11-21 03:16:51.005610: \n",
      "2024-11-21 03:16:51.005610: Epoch 406\n",
      "2024-11-21 03:16:51.015601: Current learning rate: 0.00222\n",
      "2024-11-21 03:19:00.495836: train_loss -0.8486\n",
      "2024-11-21 03:19:00.495836: val_loss 0.0319\n",
      "2024-11-21 03:19:00.505836: Pseudo dice [0.5894]\n",
      "2024-11-21 03:19:00.505836: Epoch time: 129.49 s\n",
      "2024-11-21 03:19:01.585853: \n",
      "2024-11-21 03:19:01.585853: Epoch 407\n",
      "2024-11-21 03:19:01.585853: Current learning rate: 0.0022\n",
      "2024-11-21 03:21:11.042916: train_loss -0.8359\n",
      "2024-11-21 03:21:11.042916: val_loss 0.3974\n",
      "2024-11-21 03:21:11.052916: Pseudo dice [0.3922]\n",
      "2024-11-21 03:21:11.052916: Epoch time: 129.46 s\n",
      "2024-11-21 03:21:12.132931: \n",
      "2024-11-21 03:21:12.132931: Epoch 408\n",
      "2024-11-21 03:21:12.132931: Current learning rate: 0.00218\n",
      "2024-11-21 03:23:21.563295: train_loss -0.8515\n",
      "2024-11-21 03:23:21.563295: val_loss 0.375\n",
      "2024-11-21 03:23:21.573294: Pseudo dice [0.4654]\n",
      "2024-11-21 03:23:21.573294: Epoch time: 129.43 s\n",
      "2024-11-21 03:23:22.643317: \n",
      "2024-11-21 03:23:22.643317: Epoch 409\n",
      "2024-11-21 03:23:22.643317: Current learning rate: 0.00216\n",
      "2024-11-21 03:25:32.277855: train_loss -0.8539\n",
      "2024-11-21 03:25:32.277855: val_loss 0.0429\n",
      "2024-11-21 03:25:32.287856: Pseudo dice [0.6142]\n",
      "2024-11-21 03:25:32.287856: Epoch time: 129.64 s\n",
      "2024-11-21 03:25:33.357879: \n",
      "2024-11-21 03:25:33.357879: Epoch 410\n",
      "2024-11-21 03:25:33.367871: Current learning rate: 0.00214\n",
      "2024-11-21 03:27:42.742932: train_loss -0.8581\n",
      "2024-11-21 03:27:42.742932: val_loss 0.4417\n",
      "2024-11-21 03:27:42.752932: Pseudo dice [0.422]\n",
      "2024-11-21 03:27:42.762932: Epoch time: 129.39 s\n",
      "2024-11-21 03:27:43.772947: \n",
      "2024-11-21 03:27:43.772947: Epoch 411\n",
      "2024-11-21 03:27:43.772947: Current learning rate: 0.00212\n",
      "2024-11-21 03:29:53.136982: train_loss -0.8559\n",
      "2024-11-21 03:29:53.136982: val_loss 0.24\n",
      "2024-11-21 03:29:53.146982: Pseudo dice [0.533]\n",
      "2024-11-21 03:29:53.156983: Epoch time: 129.37 s\n",
      "2024-11-21 03:29:54.347769: \n",
      "2024-11-21 03:29:54.347769: Epoch 412\n",
      "2024-11-21 03:29:54.347769: Current learning rate: 0.00209\n",
      "2024-11-21 03:32:03.785916: train_loss -0.8478\n",
      "2024-11-21 03:32:03.785916: val_loss 0.2257\n",
      "2024-11-21 03:32:03.795916: Pseudo dice [0.5632]\n",
      "2024-11-21 03:32:03.805916: Epoch time: 129.44 s\n",
      "2024-11-21 03:32:04.815931: \n",
      "2024-11-21 03:32:04.815931: Epoch 413\n",
      "2024-11-21 03:32:04.815931: Current learning rate: 0.00207\n",
      "2024-11-21 03:34:14.275102: train_loss -0.8419\n",
      "2024-11-21 03:34:14.275102: val_loss 0.2398\n",
      "2024-11-21 03:34:14.285102: Pseudo dice [0.4349]\n",
      "2024-11-21 03:34:14.295103: Epoch time: 129.47 s\n",
      "2024-11-21 03:34:15.305452: \n",
      "2024-11-21 03:34:15.305452: Epoch 414\n",
      "2024-11-21 03:34:15.305452: Current learning rate: 0.00205\n",
      "2024-11-21 03:36:24.755466: train_loss -0.8555\n",
      "2024-11-21 03:36:24.755466: val_loss 0.2357\n",
      "2024-11-21 03:36:24.765466: Pseudo dice [0.5794]\n",
      "2024-11-21 03:36:24.775466: Epoch time: 129.45 s\n",
      "2024-11-21 03:36:25.785776: \n",
      "2024-11-21 03:36:25.785776: Epoch 415\n",
      "2024-11-21 03:36:25.795768: Current learning rate: 0.00203\n",
      "2024-11-21 03:38:35.216061: train_loss -0.853\n",
      "2024-11-21 03:38:35.216061: val_loss 0.3672\n",
      "2024-11-21 03:38:35.226062: Pseudo dice [0.4829]\n",
      "2024-11-21 03:38:35.226062: Epoch time: 129.43 s\n",
      "2024-11-21 03:38:36.236395: \n",
      "2024-11-21 03:38:36.236395: Epoch 416\n",
      "2024-11-21 03:38:36.246387: Current learning rate: 0.00201\n",
      "2024-11-21 03:40:45.680269: train_loss -0.8416\n",
      "2024-11-21 03:40:45.680269: val_loss 0.2684\n",
      "2024-11-21 03:40:45.690269: Pseudo dice [0.4727]\n",
      "2024-11-21 03:40:45.700269: Epoch time: 129.44 s\n",
      "2024-11-21 03:40:46.710292: \n",
      "2024-11-21 03:40:46.710292: Epoch 417\n",
      "2024-11-21 03:40:46.710292: Current learning rate: 0.00199\n",
      "2024-11-21 03:42:56.171794: train_loss -0.8453\n",
      "2024-11-21 03:42:56.171794: val_loss -0.1059\n",
      "2024-11-21 03:42:56.181794: Pseudo dice [0.6994]\n",
      "2024-11-21 03:42:56.181794: Epoch time: 129.46 s\n",
      "2024-11-21 03:42:57.191818: \n",
      "2024-11-21 03:42:57.191818: Epoch 418\n",
      "2024-11-21 03:42:57.201816: Current learning rate: 0.00196\n",
      "2024-11-21 03:45:06.682250: train_loss -0.8538\n",
      "2024-11-21 03:45:06.682250: val_loss -0.0364\n",
      "2024-11-21 03:45:06.692250: Pseudo dice [0.6461]\n",
      "2024-11-21 03:45:06.702251: Epoch time: 129.49 s\n",
      "2024-11-21 03:45:07.892276: \n",
      "2024-11-21 03:45:07.892276: Epoch 419\n",
      "2024-11-21 03:45:07.902267: Current learning rate: 0.00194\n",
      "2024-11-21 03:47:17.337053: train_loss -0.8526\n",
      "2024-11-21 03:47:17.337053: val_loss 0.2114\n",
      "2024-11-21 03:47:17.347054: Pseudo dice [0.473]\n",
      "2024-11-21 03:47:17.347054: Epoch time: 129.44 s\n",
      "2024-11-21 03:47:18.357077: \n",
      "2024-11-21 03:47:18.357077: Epoch 420\n",
      "2024-11-21 03:47:18.367076: Current learning rate: 0.00192\n",
      "2024-11-21 03:49:27.852354: train_loss -0.8556\n",
      "2024-11-21 03:49:27.852354: val_loss 0.4186\n",
      "2024-11-21 03:49:27.862355: Pseudo dice [0.464]\n",
      "2024-11-21 03:49:27.872355: Epoch time: 129.5 s\n",
      "2024-11-21 03:49:28.882378: \n",
      "2024-11-21 03:49:28.882378: Epoch 421\n",
      "2024-11-21 03:49:28.892378: Current learning rate: 0.0019\n",
      "2024-11-21 03:51:38.366568: train_loss -0.8599\n",
      "2024-11-21 03:51:38.366568: val_loss -0.0551\n",
      "2024-11-21 03:51:38.386568: Pseudo dice [0.6219]\n",
      "2024-11-21 03:51:38.396569: Epoch time: 129.48 s\n",
      "2024-11-21 03:51:39.396591: \n",
      "2024-11-21 03:51:39.396591: Epoch 422\n",
      "2024-11-21 03:51:39.406582: Current learning rate: 0.00188\n",
      "2024-11-21 03:53:48.857113: train_loss -0.8544\n",
      "2024-11-21 03:53:48.857113: val_loss 0.388\n",
      "2024-11-21 03:53:48.867114: Pseudo dice [0.3993]\n",
      "2024-11-21 03:53:48.867114: Epoch time: 129.46 s\n",
      "2024-11-21 03:53:49.887137: \n",
      "2024-11-21 03:53:49.887137: Epoch 423\n",
      "2024-11-21 03:53:49.887137: Current learning rate: 0.00186\n",
      "2024-11-21 03:55:59.354407: train_loss -0.8504\n",
      "2024-11-21 03:55:59.354407: val_loss 0.1413\n",
      "2024-11-21 03:55:59.364407: Pseudo dice [0.5466]\n",
      "2024-11-21 03:55:59.364407: Epoch time: 129.47 s\n",
      "2024-11-21 03:56:00.374756: \n",
      "2024-11-21 03:56:00.374756: Epoch 424\n",
      "2024-11-21 03:56:00.384748: Current learning rate: 0.00184\n",
      "2024-11-21 03:58:09.812762: train_loss -0.8541\n",
      "2024-11-21 03:58:09.812762: val_loss 0.4035\n",
      "2024-11-21 03:58:09.822762: Pseudo dice [0.4117]\n",
      "2024-11-21 03:58:09.832762: Epoch time: 129.44 s\n",
      "2024-11-21 03:58:10.843115: \n",
      "2024-11-21 03:58:10.843115: Epoch 425\n",
      "2024-11-21 03:58:10.853114: Current learning rate: 0.00181\n",
      "2024-11-21 04:00:20.310842: train_loss -0.8532\n",
      "2024-11-21 04:00:20.310842: val_loss 0.2428\n",
      "2024-11-21 04:00:20.320842: Pseudo dice [0.5087]\n",
      "2024-11-21 04:00:20.320842: Epoch time: 129.47 s\n",
      "2024-11-21 04:00:21.511197: \n",
      "2024-11-21 04:00:21.511197: Epoch 426\n",
      "2024-11-21 04:00:21.511197: Current learning rate: 0.00179\n",
      "2024-11-21 04:02:31.020452: train_loss -0.844\n",
      "2024-11-21 04:02:31.020452: val_loss 0.1842\n",
      "2024-11-21 04:02:31.030452: Pseudo dice [0.5266]\n",
      "2024-11-21 04:02:31.030452: Epoch time: 129.52 s\n",
      "2024-11-21 04:02:32.030474: \n",
      "2024-11-21 04:02:32.030474: Epoch 427\n",
      "2024-11-21 04:02:32.040465: Current learning rate: 0.00177\n",
      "2024-11-21 04:04:41.528341: train_loss -0.8556\n",
      "2024-11-21 04:04:41.528341: val_loss -0.2036\n",
      "2024-11-21 04:04:41.538341: Pseudo dice [0.6823]\n",
      "2024-11-21 04:04:41.548342: Epoch time: 129.5 s\n",
      "2024-11-21 04:04:42.548563: \n",
      "2024-11-21 04:04:42.548563: Epoch 428\n",
      "2024-11-21 04:04:42.558555: Current learning rate: 0.00175\n",
      "2024-11-21 04:06:52.036157: train_loss -0.8581\n",
      "2024-11-21 04:06:52.036157: val_loss 0.5375\n",
      "2024-11-21 04:06:52.046157: Pseudo dice [0.3504]\n",
      "2024-11-21 04:06:52.056158: Epoch time: 129.49 s\n",
      "2024-11-21 04:06:53.066180: \n",
      "2024-11-21 04:06:53.066180: Epoch 429\n",
      "2024-11-21 04:06:53.076172: Current learning rate: 0.00173\n",
      "2024-11-21 04:09:02.552630: train_loss -0.8546\n",
      "2024-11-21 04:09:02.552630: val_loss 0.354\n",
      "2024-11-21 04:09:02.562630: Pseudo dice [0.393]\n",
      "2024-11-21 04:09:02.572631: Epoch time: 129.49 s\n",
      "2024-11-21 04:09:03.582644: \n",
      "2024-11-21 04:09:03.582644: Epoch 430\n",
      "2024-11-21 04:09:03.582644: Current learning rate: 0.0017\n",
      "2024-11-21 04:11:13.083681: train_loss -0.8554\n",
      "2024-11-21 04:11:13.083681: val_loss 0.1666\n",
      "2024-11-21 04:11:13.093681: Pseudo dice [0.516]\n",
      "2024-11-21 04:11:13.103682: Epoch time: 129.51 s\n",
      "2024-11-21 04:11:14.103703: \n",
      "2024-11-21 04:11:14.103703: Epoch 431\n",
      "2024-11-21 04:11:14.103703: Current learning rate: 0.00168\n",
      "2024-11-21 04:13:23.622804: train_loss -0.8499\n",
      "2024-11-21 04:13:23.622804: val_loss 0.2553\n",
      "2024-11-21 04:13:23.632806: Pseudo dice [0.4673]\n",
      "2024-11-21 04:13:23.642805: Epoch time: 129.52 s\n",
      "2024-11-21 04:13:24.652818: \n",
      "2024-11-21 04:13:24.652818: Epoch 432\n",
      "2024-11-21 04:13:24.652818: Current learning rate: 0.00166\n",
      "2024-11-21 04:15:34.467534: train_loss -0.8479\n",
      "2024-11-21 04:15:34.467534: val_loss 0.2172\n",
      "2024-11-21 04:15:34.477534: Pseudo dice [0.5135]\n",
      "2024-11-21 04:15:34.477534: Epoch time: 129.81 s\n",
      "2024-11-21 04:15:35.477557: \n",
      "2024-11-21 04:15:35.487557: Epoch 433\n",
      "2024-11-21 04:15:35.487557: Current learning rate: 0.00164\n",
      "2024-11-21 04:17:44.953911: train_loss -0.853\n",
      "2024-11-21 04:17:44.963912: val_loss 0.1941\n",
      "2024-11-21 04:17:44.963912: Pseudo dice [0.5234]\n",
      "2024-11-21 04:17:44.973912: Epoch time: 129.48 s\n",
      "2024-11-21 04:17:46.163937: \n",
      "2024-11-21 04:17:46.163937: Epoch 434\n",
      "2024-11-21 04:17:46.173928: Current learning rate: 0.00162\n",
      "2024-11-21 04:19:55.595995: train_loss -0.8547\n",
      "2024-11-21 04:19:55.595995: val_loss 0.4798\n",
      "2024-11-21 04:19:55.605995: Pseudo dice [0.3088]\n",
      "2024-11-21 04:19:55.605995: Epoch time: 129.43 s\n",
      "2024-11-21 04:19:56.616803: \n",
      "2024-11-21 04:19:56.616803: Epoch 435\n",
      "2024-11-21 04:19:56.626803: Current learning rate: 0.00159\n",
      "2024-11-21 04:22:06.055450: train_loss -0.8624\n",
      "2024-11-21 04:22:06.055450: val_loss 0.432\n",
      "2024-11-21 04:22:06.065450: Pseudo dice [0.4899]\n",
      "2024-11-21 04:22:06.075451: Epoch time: 129.44 s\n",
      "2024-11-21 04:22:07.075473: \n",
      "2024-11-21 04:22:07.075473: Epoch 436\n",
      "2024-11-21 04:22:07.085473: Current learning rate: 0.00157\n",
      "2024-11-21 04:24:16.522442: train_loss -0.8619\n",
      "2024-11-21 04:24:16.522442: val_loss 0.3532\n",
      "2024-11-21 04:24:16.532442: Pseudo dice [0.393]\n",
      "2024-11-21 04:24:16.542442: Epoch time: 129.45 s\n",
      "2024-11-21 04:24:17.542456: \n",
      "2024-11-21 04:24:17.542456: Epoch 437\n",
      "2024-11-21 04:24:17.542456: Current learning rate: 0.00155\n",
      "2024-11-21 04:26:26.959749: train_loss -0.858\n",
      "2024-11-21 04:26:26.959749: val_loss 0.0657\n",
      "2024-11-21 04:26:26.969749: Pseudo dice [0.5995]\n",
      "2024-11-21 04:26:26.969749: Epoch time: 129.42 s\n",
      "2024-11-21 04:26:27.970068: \n",
      "2024-11-21 04:26:27.970068: Epoch 438\n",
      "2024-11-21 04:26:27.980059: Current learning rate: 0.00153\n",
      "2024-11-21 04:28:37.424671: train_loss -0.8546\n",
      "2024-11-21 04:28:37.424671: val_loss 0.3417\n",
      "2024-11-21 04:28:37.434671: Pseudo dice [0.4498]\n",
      "2024-11-21 04:28:37.434671: Epoch time: 129.45 s\n",
      "2024-11-21 04:28:38.444685: \n",
      "2024-11-21 04:28:38.444685: Epoch 439\n",
      "2024-11-21 04:28:38.444685: Current learning rate: 0.00151\n",
      "2024-11-21 04:30:47.913871: train_loss -0.8554\n",
      "2024-11-21 04:30:47.913871: val_loss 0.5127\n",
      "2024-11-21 04:30:47.923872: Pseudo dice [0.4419]\n",
      "2024-11-21 04:30:47.933872: Epoch time: 129.48 s\n",
      "2024-11-21 04:30:48.934906: \n",
      "2024-11-21 04:30:48.934906: Epoch 440\n",
      "2024-11-21 04:30:48.944905: Current learning rate: 0.00148\n",
      "2024-11-21 04:32:58.408078: train_loss -0.8604\n",
      "2024-11-21 04:32:58.408078: val_loss 0.4184\n",
      "2024-11-21 04:32:58.428078: Pseudo dice [0.4309]\n",
      "2024-11-21 04:32:58.428078: Epoch time: 129.47 s\n",
      "2024-11-21 04:32:59.608104: \n",
      "2024-11-21 04:32:59.608104: Epoch 441\n",
      "2024-11-21 04:32:59.618103: Current learning rate: 0.00146\n",
      "2024-11-21 04:35:09.095379: train_loss -0.8563\n",
      "2024-11-21 04:35:09.095379: val_loss 0.3335\n",
      "2024-11-21 04:35:09.105379: Pseudo dice [0.3802]\n",
      "2024-11-21 04:35:09.115380: Epoch time: 129.49 s\n",
      "2024-11-21 04:35:10.115401: \n",
      "2024-11-21 04:35:10.115401: Epoch 442\n",
      "2024-11-21 04:35:10.115401: Current learning rate: 0.00144\n",
      "2024-11-21 04:37:19.553503: train_loss -0.8571\n",
      "2024-11-21 04:37:19.553503: val_loss -0.3759\n",
      "2024-11-21 04:37:19.563503: Pseudo dice [0.7729]\n",
      "2024-11-21 04:37:19.573503: Epoch time: 129.45 s\n",
      "2024-11-21 04:37:20.573526: \n",
      "2024-11-21 04:37:20.573526: Epoch 443\n",
      "2024-11-21 04:37:20.583526: Current learning rate: 0.00142\n",
      "2024-11-21 04:39:30.050588: train_loss -0.8555\n",
      "2024-11-21 04:39:30.050588: val_loss -0.0935\n",
      "2024-11-21 04:39:30.060588: Pseudo dice [0.7013]\n",
      "2024-11-21 04:39:30.070588: Epoch time: 129.48 s\n",
      "2024-11-21 04:39:31.070611: \n",
      "2024-11-21 04:39:31.070611: Epoch 444\n",
      "2024-11-21 04:39:31.080610: Current learning rate: 0.00139\n",
      "2024-11-21 04:41:40.511029: train_loss -0.8566\n",
      "2024-11-21 04:41:40.511029: val_loss 0.1316\n",
      "2024-11-21 04:41:40.521030: Pseudo dice [0.5489]\n",
      "2024-11-21 04:41:40.531029: Epoch time: 129.44 s\n",
      "2024-11-21 04:41:41.531328: \n",
      "2024-11-21 04:41:41.531328: Epoch 445\n",
      "2024-11-21 04:41:41.531328: Current learning rate: 0.00137\n",
      "2024-11-21 04:43:51.001195: train_loss -0.8632\n",
      "2024-11-21 04:43:51.001195: val_loss 0.1305\n",
      "2024-11-21 04:43:51.011195: Pseudo dice [0.5822]\n",
      "2024-11-21 04:43:51.011195: Epoch time: 129.48 s\n",
      "2024-11-21 04:43:52.011544: \n",
      "2024-11-21 04:43:52.011544: Epoch 446\n",
      "2024-11-21 04:43:52.021543: Current learning rate: 0.00135\n",
      "2024-11-21 04:46:01.470487: train_loss -0.8591\n",
      "2024-11-21 04:46:01.470487: val_loss 0.1557\n",
      "2024-11-21 04:46:01.480487: Pseudo dice [0.5119]\n",
      "2024-11-21 04:46:01.490487: Epoch time: 129.46 s\n",
      "2024-11-21 04:46:02.501191: \n",
      "2024-11-21 04:46:02.501191: Epoch 447\n",
      "2024-11-21 04:46:02.511182: Current learning rate: 0.00133\n",
      "2024-11-21 04:48:11.981157: train_loss -0.8596\n",
      "2024-11-21 04:48:11.981157: val_loss 0.1277\n",
      "2024-11-21 04:48:11.991158: Pseudo dice [0.4856]\n",
      "2024-11-21 04:48:12.001158: Epoch time: 129.48 s\n",
      "2024-11-21 04:48:13.181583: \n",
      "2024-11-21 04:48:13.181583: Epoch 448\n",
      "2024-11-21 04:48:13.191574: Current learning rate: 0.0013\n",
      "2024-11-21 04:50:22.652891: train_loss -0.8537\n",
      "2024-11-21 04:50:22.652891: val_loss 0.0645\n",
      "2024-11-21 04:50:22.662891: Pseudo dice [0.5467]\n",
      "2024-11-21 04:50:22.672891: Epoch time: 129.47 s\n",
      "2024-11-21 04:50:23.673933: \n",
      "2024-11-21 04:50:23.673933: Epoch 449\n",
      "2024-11-21 04:50:23.683925: Current learning rate: 0.00128\n",
      "2024-11-21 04:52:33.108766: train_loss -0.85\n",
      "2024-11-21 04:52:33.108766: val_loss 0.0419\n",
      "2024-11-21 04:52:33.118766: Pseudo dice [0.5394]\n",
      "2024-11-21 04:52:33.128767: Epoch time: 129.43 s\n",
      "2024-11-21 04:52:34.389670: \n",
      "2024-11-21 04:52:34.389670: Epoch 450\n",
      "2024-11-21 04:52:34.399669: Current learning rate: 0.00126\n",
      "2024-11-21 04:54:43.898852: train_loss -0.8525\n",
      "2024-11-21 04:54:43.898852: val_loss 0.1226\n",
      "2024-11-21 04:54:43.908852: Pseudo dice [0.463]\n",
      "2024-11-21 04:54:43.918852: Epoch time: 129.51 s\n",
      "2024-11-21 04:54:44.919178: \n",
      "2024-11-21 04:54:44.919178: Epoch 451\n",
      "2024-11-21 04:54:44.929168: Current learning rate: 0.00124\n",
      "2024-11-21 04:56:54.436339: train_loss -0.8552\n",
      "2024-11-21 04:56:54.436339: val_loss -0.0603\n",
      "2024-11-21 04:56:54.446339: Pseudo dice [0.5852]\n",
      "2024-11-21 04:56:54.446339: Epoch time: 129.52 s\n",
      "2024-11-21 04:56:55.446361: \n",
      "2024-11-21 04:56:55.456362: Epoch 452\n",
      "2024-11-21 04:56:55.456362: Current learning rate: 0.00121\n",
      "2024-11-21 04:59:04.959688: train_loss -0.8558\n",
      "2024-11-21 04:59:04.969688: val_loss 0.5523\n",
      "2024-11-21 04:59:04.979689: Pseudo dice [0.2793]\n",
      "2024-11-21 04:59:04.979689: Epoch time: 129.51 s\n",
      "2024-11-21 04:59:05.979711: \n",
      "2024-11-21 04:59:05.979711: Epoch 453\n",
      "2024-11-21 04:59:05.989702: Current learning rate: 0.00119\n",
      "2024-11-21 05:01:15.459331: train_loss -0.8592\n",
      "2024-11-21 05:01:15.459331: val_loss -0.0064\n",
      "2024-11-21 05:01:15.479331: Pseudo dice [0.5923]\n",
      "2024-11-21 05:01:15.479331: Epoch time: 129.48 s\n",
      "2024-11-21 05:01:16.489345: \n",
      "2024-11-21 05:01:16.489345: Epoch 454\n",
      "2024-11-21 05:01:16.489345: Current learning rate: 0.00117\n",
      "2024-11-21 05:03:25.966728: train_loss -0.8649\n",
      "2024-11-21 05:03:25.966728: val_loss 0.1449\n",
      "2024-11-21 05:03:25.976727: Pseudo dice [0.4873]\n",
      "2024-11-21 05:03:25.986728: Epoch time: 129.48 s\n",
      "2024-11-21 05:03:26.996751: \n",
      "2024-11-21 05:03:26.996751: Epoch 455\n",
      "2024-11-21 05:03:27.006750: Current learning rate: 0.00115\n",
      "2024-11-21 05:05:36.473195: train_loss -0.8605\n",
      "2024-11-21 05:05:36.473195: val_loss -0.0175\n",
      "2024-11-21 05:05:36.483196: Pseudo dice [0.6102]\n",
      "2024-11-21 05:05:36.493196: Epoch time: 129.48 s\n",
      "2024-11-21 05:05:37.673221: \n",
      "2024-11-21 05:05:37.673221: Epoch 456\n",
      "2024-11-21 05:05:37.683220: Current learning rate: 0.00112\n",
      "2024-11-21 05:07:47.159680: train_loss -0.8642\n",
      "2024-11-21 05:07:47.159680: val_loss 0.103\n",
      "2024-11-21 05:07:47.169680: Pseudo dice [0.549]\n",
      "2024-11-21 05:07:47.179681: Epoch time: 129.49 s\n",
      "2024-11-21 05:07:48.180455: \n",
      "2024-11-21 05:07:48.180455: Epoch 457\n",
      "2024-11-21 05:07:48.190448: Current learning rate: 0.0011\n",
      "2024-11-21 05:09:57.660388: train_loss -0.857\n",
      "2024-11-21 05:09:57.670385: val_loss -0.3267\n",
      "2024-11-21 05:09:57.680385: Pseudo dice [0.7269]\n",
      "2024-11-21 05:09:57.680385: Epoch time: 129.48 s\n",
      "2024-11-21 05:09:58.690399: \n",
      "2024-11-21 05:09:58.690399: Epoch 458\n",
      "2024-11-21 05:09:58.690399: Current learning rate: 0.00108\n",
      "2024-11-21 05:12:08.131547: train_loss -0.8593\n",
      "2024-11-21 05:12:08.131547: val_loss 0.3742\n",
      "2024-11-21 05:12:08.141548: Pseudo dice [0.3386]\n",
      "2024-11-21 05:12:08.151548: Epoch time: 129.45 s\n",
      "2024-11-21 05:12:09.161561: \n",
      "2024-11-21 05:12:09.161561: Epoch 459\n",
      "2024-11-21 05:12:09.161561: Current learning rate: 0.00105\n",
      "2024-11-21 05:14:18.654066: train_loss -0.8652\n",
      "2024-11-21 05:14:18.654066: val_loss 0.1608\n",
      "2024-11-21 05:14:18.664067: Pseudo dice [0.4594]\n",
      "2024-11-21 05:14:18.674066: Epoch time: 129.49 s\n",
      "2024-11-21 05:14:19.674089: \n",
      "2024-11-21 05:14:19.674089: Epoch 460\n",
      "2024-11-21 05:14:19.684088: Current learning rate: 0.00103\n",
      "2024-11-21 05:16:29.272904: train_loss -0.8636\n",
      "2024-11-21 05:16:29.272904: val_loss 0.4363\n",
      "2024-11-21 05:16:29.292905: Pseudo dice [0.3594]\n",
      "2024-11-21 05:16:29.292905: Epoch time: 129.6 s\n",
      "2024-11-21 05:16:30.313273: \n",
      "2024-11-21 05:16:30.313273: Epoch 461\n",
      "2024-11-21 05:16:30.313273: Current learning rate: 0.00101\n",
      "2024-11-21 05:18:39.699990: train_loss -0.8621\n",
      "2024-11-21 05:18:39.709990: val_loss 0.0644\n",
      "2024-11-21 05:18:39.709990: Pseudo dice [0.5347]\n",
      "2024-11-21 05:18:39.719990: Epoch time: 129.39 s\n",
      "2024-11-21 05:18:40.730005: \n",
      "2024-11-21 05:18:40.730005: Epoch 462\n",
      "2024-11-21 05:18:40.730005: Current learning rate: 0.00098\n",
      "2024-11-21 05:20:50.151221: train_loss -0.8595\n",
      "2024-11-21 05:20:50.151221: val_loss 0.1797\n",
      "2024-11-21 05:20:50.161221: Pseudo dice [0.506]\n",
      "2024-11-21 05:20:50.171221: Epoch time: 129.42 s\n",
      "2024-11-21 05:20:51.341549: \n",
      "2024-11-21 05:20:51.341549: Epoch 463\n",
      "2024-11-21 05:20:51.341549: Current learning rate: 0.00096\n",
      "2024-11-21 05:23:00.750257: train_loss -0.8609\n",
      "2024-11-21 05:23:00.750257: val_loss 0.0462\n",
      "2024-11-21 05:23:00.760257: Pseudo dice [0.5323]\n",
      "2024-11-21 05:23:00.770257: Epoch time: 129.41 s\n",
      "2024-11-21 05:23:01.770586: \n",
      "2024-11-21 05:23:01.770586: Epoch 464\n",
      "2024-11-21 05:23:01.780577: Current learning rate: 0.00094\n",
      "2024-11-21 05:25:11.209497: train_loss -0.8678\n",
      "2024-11-21 05:25:11.209497: val_loss 0.3607\n",
      "2024-11-21 05:25:11.209497: Pseudo dice [0.4248]\n",
      "2024-11-21 05:25:11.219497: Epoch time: 129.44 s\n",
      "2024-11-21 05:25:12.229512: \n",
      "2024-11-21 05:25:12.229512: Epoch 465\n",
      "2024-11-21 05:25:12.239511: Current learning rate: 0.00091\n",
      "2024-11-21 05:27:21.635591: train_loss -0.8598\n",
      "2024-11-21 05:27:21.635591: val_loss 0.2802\n",
      "2024-11-21 05:27:21.645591: Pseudo dice [0.4216]\n",
      "2024-11-21 05:27:21.645591: Epoch time: 129.41 s\n",
      "2024-11-21 05:27:22.655613: \n",
      "2024-11-21 05:27:22.655613: Epoch 466\n",
      "2024-11-21 05:27:22.665604: Current learning rate: 0.00089\n",
      "2024-11-21 05:29:32.040675: train_loss -0.8623\n",
      "2024-11-21 05:29:32.040675: val_loss 0.3626\n",
      "2024-11-21 05:29:32.050675: Pseudo dice [0.4731]\n",
      "2024-11-21 05:29:32.060675: Epoch time: 129.39 s\n",
      "2024-11-21 05:29:33.070179: \n",
      "2024-11-21 05:29:33.070179: Epoch 467\n",
      "2024-11-21 05:29:33.076273: Current learning rate: 0.00087\n",
      "2024-11-21 05:31:42.470555: train_loss -0.8669\n",
      "2024-11-21 05:31:42.470555: val_loss 0.5399\n",
      "2024-11-21 05:31:42.480683: Pseudo dice [0.356]\n",
      "2024-11-21 05:31:42.486736: Epoch time: 129.4 s\n",
      "2024-11-21 05:31:43.489062: \n",
      "2024-11-21 05:31:43.489062: Epoch 468\n",
      "2024-11-21 05:31:43.499053: Current learning rate: 0.00084\n",
      "2024-11-21 05:33:52.887169: train_loss -0.86\n",
      "2024-11-21 05:33:52.887169: val_loss 0.5206\n",
      "2024-11-21 05:33:52.897169: Pseudo dice [0.3021]\n",
      "2024-11-21 05:33:52.897169: Epoch time: 129.4 s\n",
      "2024-11-21 05:33:53.897543: \n",
      "2024-11-21 05:33:53.897543: Epoch 469\n",
      "2024-11-21 05:33:53.907535: Current learning rate: 0.00082\n",
      "2024-11-21 05:36:03.215543: train_loss -0.8585\n",
      "2024-11-21 05:36:03.225543: val_loss 0.4179\n",
      "2024-11-21 05:36:03.225543: Pseudo dice [0.2758]\n",
      "2024-11-21 05:36:03.235543: Epoch time: 129.32 s\n",
      "2024-11-21 05:36:04.246453: \n",
      "2024-11-21 05:36:04.246453: Epoch 470\n",
      "2024-11-21 05:36:04.256445: Current learning rate: 0.00079\n",
      "2024-11-21 05:38:13.676946: train_loss -0.8566\n",
      "2024-11-21 05:38:13.686946: val_loss -0.1872\n",
      "2024-11-21 05:38:13.686946: Pseudo dice [0.6943]\n",
      "2024-11-21 05:38:13.696946: Epoch time: 129.43 s\n",
      "2024-11-21 05:38:14.896965: \n",
      "2024-11-21 05:38:14.896965: Epoch 471\n",
      "2024-11-21 05:38:14.896965: Current learning rate: 0.00077\n",
      "2024-11-21 05:40:24.311960: train_loss -0.86\n",
      "2024-11-21 05:40:24.311960: val_loss 0.2049\n",
      "2024-11-21 05:40:24.311960: Pseudo dice [0.4581]\n",
      "2024-11-21 05:40:24.321960: Epoch time: 129.41 s\n",
      "2024-11-21 05:40:25.321983: \n",
      "2024-11-21 05:40:25.321983: Epoch 472\n",
      "2024-11-21 05:40:25.331983: Current learning rate: 0.00075\n",
      "2024-11-21 05:42:34.709884: train_loss -0.8589\n",
      "2024-11-21 05:42:34.709884: val_loss 0.0038\n",
      "2024-11-21 05:42:34.719884: Pseudo dice [0.5844]\n",
      "2024-11-21 05:42:34.729884: Epoch time: 129.39 s\n",
      "2024-11-21 05:42:35.740248: \n",
      "2024-11-21 05:42:35.740248: Epoch 473\n",
      "2024-11-21 05:42:35.740248: Current learning rate: 0.00072\n",
      "2024-11-21 05:44:45.139476: train_loss -0.8627\n",
      "2024-11-21 05:44:45.139476: val_loss 0.4516\n",
      "2024-11-21 05:44:45.149476: Pseudo dice [0.4397]\n",
      "2024-11-21 05:44:45.159476: Epoch time: 129.4 s\n",
      "2024-11-21 05:44:46.160362: \n",
      "2024-11-21 05:44:46.160362: Epoch 474\n",
      "2024-11-21 05:44:46.170362: Current learning rate: 0.0007\n",
      "2024-11-21 05:46:55.604240: train_loss -0.8654\n",
      "2024-11-21 05:46:55.604240: val_loss 0.2923\n",
      "2024-11-21 05:46:55.614247: Pseudo dice [0.436]\n",
      "2024-11-21 05:46:55.614247: Epoch time: 129.44 s\n",
      "2024-11-21 05:46:56.625050: \n",
      "2024-11-21 05:46:56.625050: Epoch 475\n",
      "2024-11-21 05:46:56.635049: Current learning rate: 0.00067\n",
      "2024-11-21 05:49:06.042973: train_loss -0.8624\n",
      "2024-11-21 05:49:06.042973: val_loss 0.124\n",
      "2024-11-21 05:49:06.052973: Pseudo dice [0.5056]\n",
      "2024-11-21 05:49:06.062973: Epoch time: 129.42 s\n",
      "2024-11-21 05:49:07.073319: \n",
      "2024-11-21 05:49:07.073319: Epoch 476\n",
      "2024-11-21 05:49:07.073319: Current learning rate: 0.00065\n",
      "2024-11-21 05:51:16.532080: train_loss -0.8665\n",
      "2024-11-21 05:51:16.532080: val_loss 0.1047\n",
      "2024-11-21 05:51:16.552080: Pseudo dice [0.5478]\n",
      "2024-11-21 05:51:16.552080: Epoch time: 129.47 s\n",
      "2024-11-21 05:51:17.562920: \n",
      "2024-11-21 05:51:17.562920: Epoch 477\n",
      "2024-11-21 05:51:17.572912: Current learning rate: 0.00063\n",
      "2024-11-21 05:53:26.994079: train_loss -0.8705\n",
      "2024-11-21 05:53:26.994079: val_loss 0.1015\n",
      "2024-11-21 05:53:27.004078: Pseudo dice [0.5756]\n",
      "2024-11-21 05:53:27.014080: Epoch time: 129.43 s\n",
      "2024-11-21 05:53:28.204863: \n",
      "2024-11-21 05:53:28.204863: Epoch 478\n",
      "2024-11-21 05:53:28.204863: Current learning rate: 0.0006\n",
      "2024-11-21 05:55:37.624711: train_loss -0.862\n",
      "2024-11-21 05:55:37.624711: val_loss 0.1544\n",
      "2024-11-21 05:55:37.634712: Pseudo dice [0.5358]\n",
      "2024-11-21 05:55:37.644712: Epoch time: 129.43 s\n",
      "2024-11-21 05:55:38.665790: \n",
      "2024-11-21 05:55:38.665790: Epoch 479\n",
      "2024-11-21 05:55:38.675790: Current learning rate: 0.00058\n",
      "2024-11-21 05:57:48.064077: train_loss -0.8656\n",
      "2024-11-21 05:57:48.064077: val_loss 0.5533\n",
      "2024-11-21 05:57:48.079444: Pseudo dice [0.3704]\n",
      "2024-11-21 05:57:48.086547: Epoch time: 129.4 s\n",
      "2024-11-21 05:57:49.105129: \n",
      "2024-11-21 05:57:49.105129: Epoch 480\n",
      "2024-11-21 05:57:49.105129: Current learning rate: 0.00055\n",
      "2024-11-21 05:59:58.516340: train_loss -0.8649\n",
      "2024-11-21 05:59:58.516340: val_loss 0.2026\n",
      "2024-11-21 05:59:58.526340: Pseudo dice [0.4698]\n",
      "2024-11-21 05:59:58.536340: Epoch time: 129.41 s\n",
      "2024-11-21 05:59:59.556363: \n",
      "2024-11-21 05:59:59.556363: Epoch 481\n",
      "2024-11-21 05:59:59.566356: Current learning rate: 0.00053\n",
      "2024-11-21 06:02:09.011513: train_loss -0.8652\n",
      "2024-11-21 06:02:09.011513: val_loss 0.5834\n",
      "2024-11-21 06:02:09.021513: Pseudo dice [0.3954]\n",
      "2024-11-21 06:02:09.021513: Epoch time: 129.46 s\n",
      "2024-11-21 06:02:10.041536: \n",
      "2024-11-21 06:02:10.041536: Epoch 482\n",
      "2024-11-21 06:02:10.051528: Current learning rate: 0.0005\n",
      "2024-11-21 06:04:19.497722: train_loss -0.8635\n",
      "2024-11-21 06:04:19.497722: val_loss 0.1486\n",
      "2024-11-21 06:04:19.507724: Pseudo dice [0.4827]\n",
      "2024-11-21 06:04:19.517723: Epoch time: 129.46 s\n",
      "2024-11-21 06:04:20.538108: \n",
      "2024-11-21 06:04:20.538108: Epoch 483\n",
      "2024-11-21 06:04:20.548100: Current learning rate: 0.00048\n",
      "2024-11-21 06:06:29.946136: train_loss -0.8597\n",
      "2024-11-21 06:06:29.946136: val_loss 0.2035\n",
      "2024-11-21 06:06:29.956136: Pseudo dice [0.4502]\n",
      "2024-11-21 06:06:29.966137: Epoch time: 129.41 s\n",
      "2024-11-21 06:06:30.986151: \n",
      "2024-11-21 06:06:30.986151: Epoch 484\n",
      "2024-11-21 06:06:30.986151: Current learning rate: 0.00045\n",
      "2024-11-21 06:08:40.357793: train_loss -0.8654\n",
      "2024-11-21 06:08:40.357793: val_loss 0.3134\n",
      "2024-11-21 06:08:40.367792: Pseudo dice [0.4326]\n",
      "2024-11-21 06:08:40.367792: Epoch time: 129.37 s\n",
      "2024-11-21 06:08:41.577809: \n",
      "2024-11-21 06:08:41.577809: Epoch 485\n",
      "2024-11-21 06:08:41.577809: Current learning rate: 0.00043\n",
      "2024-11-21 06:10:50.984822: train_loss -0.8676\n",
      "2024-11-21 06:10:50.984822: val_loss 0.3954\n",
      "2024-11-21 06:10:50.994823: Pseudo dice [0.3794]\n",
      "2024-11-21 06:10:50.994823: Epoch time: 129.41 s\n",
      "2024-11-21 06:10:52.024838: \n",
      "2024-11-21 06:10:52.024838: Epoch 486\n",
      "2024-11-21 06:10:52.024838: Current learning rate: 0.0004\n",
      "2024-11-21 06:13:01.455040: train_loss -0.873\n",
      "2024-11-21 06:13:01.455040: val_loss 0.2404\n",
      "2024-11-21 06:13:01.465040: Pseudo dice [0.5159]\n",
      "2024-11-21 06:13:01.475040: Epoch time: 129.43 s\n",
      "2024-11-21 06:13:02.505055: \n",
      "2024-11-21 06:13:02.505055: Epoch 487\n",
      "2024-11-21 06:13:02.505055: Current learning rate: 0.00037\n",
      "2024-11-21 06:15:12.088426: train_loss -0.8644\n",
      "2024-11-21 06:15:12.098426: val_loss 0.2821\n",
      "2024-11-21 06:15:12.098426: Pseudo dice [0.4998]\n",
      "2024-11-21 06:15:12.108426: Epoch time: 129.58 s\n",
      "2024-11-21 06:15:13.138448: \n",
      "2024-11-21 06:15:13.138448: Epoch 488\n",
      "2024-11-21 06:15:13.138448: Current learning rate: 0.00035\n",
      "2024-11-21 06:17:22.599236: train_loss -0.8599\n",
      "2024-11-21 06:17:22.599236: val_loss 0.5473\n",
      "2024-11-21 06:17:22.609236: Pseudo dice [0.3315]\n",
      "2024-11-21 06:17:22.619237: Epoch time: 129.46 s\n",
      "2024-11-21 06:17:23.650135: \n",
      "2024-11-21 06:17:23.650135: Epoch 489\n",
      "2024-11-21 06:17:23.660126: Current learning rate: 0.00032\n",
      "2024-11-21 06:19:33.045673: train_loss -0.8707\n",
      "2024-11-21 06:19:33.045673: val_loss 0.4839\n",
      "2024-11-21 06:19:33.055673: Pseudo dice [0.3598]\n",
      "2024-11-21 06:19:33.065674: Epoch time: 129.4 s\n",
      "2024-11-21 06:19:34.095687: \n",
      "2024-11-21 06:19:34.095687: Epoch 490\n",
      "2024-11-21 06:19:34.095687: Current learning rate: 0.0003\n",
      "2024-11-21 06:21:43.533621: train_loss -0.8714\n",
      "2024-11-21 06:21:43.533621: val_loss 0.4158\n",
      "2024-11-21 06:21:43.543621: Pseudo dice [0.3242]\n",
      "2024-11-21 06:21:43.553622: Epoch time: 129.44 s\n",
      "2024-11-21 06:21:44.573644: \n",
      "2024-11-21 06:21:44.573644: Epoch 491\n",
      "2024-11-21 06:21:44.583635: Current learning rate: 0.00027\n",
      "2024-11-21 06:23:54.021565: train_loss -0.8654\n",
      "2024-11-21 06:23:54.021565: val_loss 0.3418\n",
      "2024-11-21 06:23:54.021565: Pseudo dice [0.3869]\n",
      "2024-11-21 06:23:54.031565: Epoch time: 129.45 s\n",
      "2024-11-21 06:23:55.061580: \n",
      "2024-11-21 06:23:55.061580: Epoch 492\n",
      "2024-11-21 06:23:55.061580: Current learning rate: 0.00024\n",
      "2024-11-21 06:26:04.459918: train_loss -0.865\n",
      "2024-11-21 06:26:04.459918: val_loss 0.5519\n",
      "2024-11-21 06:26:04.459918: Pseudo dice [0.3322]\n",
      "2024-11-21 06:26:04.479918: Epoch time: 129.41 s\n",
      "2024-11-21 06:26:05.689934: \n",
      "2024-11-21 06:26:05.689934: Epoch 493\n",
      "2024-11-21 06:26:05.689934: Current learning rate: 0.00021\n",
      "2024-11-21 06:28:15.098392: train_loss -0.8695\n",
      "2024-11-21 06:28:15.098392: val_loss 0.2727\n",
      "2024-11-21 06:28:15.118392: Pseudo dice [0.4166]\n",
      "2024-11-21 06:28:15.118392: Epoch time: 129.41 s\n",
      "2024-11-21 06:28:16.148416: \n",
      "2024-11-21 06:28:16.148416: Epoch 494\n",
      "2024-11-21 06:28:16.158414: Current learning rate: 0.00019\n",
      "2024-11-21 06:30:25.554560: train_loss -0.8645\n",
      "2024-11-21 06:30:25.554560: val_loss 0.4725\n",
      "2024-11-21 06:30:25.554560: Pseudo dice [0.3612]\n",
      "2024-11-21 06:30:25.564560: Epoch time: 129.41 s\n",
      "2024-11-21 06:30:26.594878: \n",
      "2024-11-21 06:30:26.594878: Epoch 495\n",
      "2024-11-21 06:30:26.594878: Current learning rate: 0.00016\n",
      "2024-11-21 06:32:36.020045: train_loss -0.8696\n",
      "2024-11-21 06:32:36.020045: val_loss 0.5283\n",
      "2024-11-21 06:32:36.030046: Pseudo dice [0.3551]\n",
      "2024-11-21 06:32:36.030046: Epoch time: 129.44 s\n",
      "2024-11-21 06:32:37.060798: \n",
      "2024-11-21 06:32:37.060798: Epoch 496\n",
      "2024-11-21 06:32:37.060798: Current learning rate: 0.00013\n",
      "2024-11-21 06:34:46.459170: train_loss -0.8605\n",
      "2024-11-21 06:34:46.459170: val_loss 0.4488\n",
      "2024-11-21 06:34:46.469170: Pseudo dice [0.4764]\n",
      "2024-11-21 06:34:46.479170: Epoch time: 129.4 s\n",
      "2024-11-21 06:34:47.499192: \n",
      "2024-11-21 06:34:47.509192: Epoch 497\n",
      "2024-11-21 06:34:47.509192: Current learning rate: 0.0001\n",
      "2024-11-21 06:36:56.885642: train_loss -0.8624\n",
      "2024-11-21 06:36:56.885642: val_loss 0.586\n",
      "2024-11-21 06:36:56.895641: Pseudo dice [0.2933]\n",
      "2024-11-21 06:36:56.895641: Epoch time: 129.39 s\n",
      "2024-11-21 06:36:57.925865: \n",
      "2024-11-21 06:36:57.925865: Epoch 498\n",
      "2024-11-21 06:36:57.935856: Current learning rate: 7e-05\n",
      "2024-11-21 06:39:07.346037: train_loss -0.8625\n",
      "2024-11-21 06:39:07.346037: val_loss 0.3406\n",
      "2024-11-21 06:39:07.356037: Pseudo dice [0.4391]\n",
      "2024-11-21 06:39:07.356037: Epoch time: 129.42 s\n",
      "2024-11-21 06:39:08.406052: \n",
      "2024-11-21 06:39:08.406052: Epoch 499\n",
      "2024-11-21 06:39:08.416052: Current learning rate: 4e-05\n",
      "2024-11-21 06:41:17.874840: train_loss -0.8671\n",
      "2024-11-21 06:41:17.874840: val_loss 0.3141\n",
      "2024-11-21 06:41:17.884840: Pseudo dice [0.3892]\n",
      "2024-11-21 06:41:17.894841: Epoch time: 129.47 s\n",
      "2024-11-21 06:41:19.385254: Training done.\n",
      "2024-11-21 06:41:19.425257: Using splits from existing split file: D:/Liver Segmentation Meena 2024/nnUNet_blastoma_2025/nnUNet_preprocessed\\Dataset007_Blastoma\\splits_final.json\n",
      "2024-11-21 06:41:19.445257: The split file contains 5 splits.\n",
      "2024-11-21 06:41:19.451262: Desired fold for training: 0\n",
      "2024-11-21 06:41:19.455273: This split has 19 training and 5 validation cases.\n",
      "2024-11-21 06:41:19.455273: predicting volume_2\n",
      "2024-11-21 06:41:19.475276: volume_2, shape torch.Size([1, 470, 512, 512]), rank 0\n",
      "2024-11-21 06:44:47.602802: predicting volume_34\n",
      "2024-11-21 06:44:47.652803: volume_34, shape torch.Size([1, 746, 553, 553]), rank 0\n",
      "2024-11-21 06:51:50.331994: predicting volume_36\n",
      "2024-11-21 06:51:50.421994: volume_36, shape torch.Size([1, 481, 463, 463]), rank 0\n",
      "2024-11-21 06:55:16.613211: predicting volume_41\n",
      "2024-11-21 06:55:16.653455: volume_41, shape torch.Size([1, 697, 512, 512]), rank 0\n",
      "2024-11-21 07:00:12.873446: predicting volume_6\n",
      "2024-11-21 07:00:12.933679: volume_6, shape torch.Size([1, 800, 512, 512]), rank 0\n",
      "2024-11-21 07:06:30.846586: Validation complete\n",
      "2024-11-21 07:06:30.846586: Mean Validation Dice:  0.3813023280231401\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "try:\n",
    "    !nnUNetv2_train 007 3d_fullres 0 -tr nnUNetTrainer\n",
    "except Exception as e:\n",
    "    print(f\"Error during training: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2024-11-22 08:31:43.442461: do_dummy_2d_data_aug: False\n",
      "2024-11-22 08:31:43.447464: Using splits from existing split file: D:/Liver Segmentation Meena 2024/nnUNet_blastoma_2025/nnUNet_preprocessed\\Dataset007_Blastoma\\splits_final.json\n",
      "2024-11-22 08:31:43.455465: The split file contains 5 splits.\n",
      "2024-11-22 08:31:43.459170: Desired fold for training: 1\n",
      "2024-11-22 08:31:43.462173: This split has 19 training and 5 validation cases.\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 3d_fullres\n",
      " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [569.5, 512.0, 512.0], 'spacing': [0.625, 0.4882810115814209, 0.4882810115814209], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset007_Blastoma', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.625, 0.4882810115814209, 0.4882810115814209], 'original_median_shape_after_transp': [471, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2609.056396484375, 'mean': 68.07295227050781, 'median': 66.0, 'min': -1028.0, 'percentile_00_5': -59.0, 'percentile_99_5': 248.0, 'std': 47.62541198730469}}} \n",
      "\n",
      "2024-11-22 08:31:52.453196: unpacking dataset...\n",
      "2024-11-22 08:31:52.987315: unpacking done...\n",
      "2024-11-22 08:31:53.000319: Unable to plot network architecture:\n",
      "2024-11-22 08:31:53.004319: No module named 'hiddenlayer'\n",
      "2024-11-22 08:31:53.029325: \n",
      "2024-11-22 08:31:53.034326: Epoch 0\n",
      "2024-11-22 08:31:53.038326: Current learning rate: 0.01\n",
      "2024-11-22 08:34:18.209274: train_loss 0.0265\n",
      "2024-11-22 08:34:18.218277: val_loss -0.1778\n",
      "2024-11-22 08:34:18.223278: Pseudo dice [0.5226]\n",
      "2024-11-22 08:34:18.230279: Epoch time: 145.18 s\n",
      "2024-11-22 08:34:18.239282: Yayy! New best EMA pseudo Dice: 0.5226\n",
      "2024-11-22 08:34:19.592560: \n",
      "2024-11-22 08:34:19.599562: Epoch 1\n",
      "2024-11-22 08:34:19.604563: Current learning rate: 0.00998\n",
      "2024-11-22 08:36:37.644229: train_loss -0.129\n",
      "2024-11-22 08:36:37.666234: val_loss -0.0708\n",
      "2024-11-22 08:36:37.673236: Pseudo dice [0.4349]\n",
      "2024-11-22 08:36:37.679237: Epoch time: 138.05 s\n",
      "2024-11-22 08:36:38.674460: \n",
      "2024-11-22 08:36:38.681462: Epoch 2\n",
      "2024-11-22 08:36:38.686463: Current learning rate: 0.00996\n",
      "2024-11-22 08:38:48.967868: train_loss -0.1729\n",
      "2024-11-22 08:38:48.977868: val_loss -0.1455\n",
      "2024-11-22 08:38:48.977868: Pseudo dice [0.4536]\n",
      "2024-11-22 08:38:48.987868: Epoch time: 130.29 s\n",
      "2024-11-22 08:38:49.987883: \n",
      "2024-11-22 08:38:49.987883: Epoch 3\n",
      "2024-11-22 08:38:49.997892: Current learning rate: 0.00995\n",
      "2024-11-22 08:41:00.553180: train_loss -0.2018\n",
      "2024-11-22 08:41:00.563180: val_loss -0.292\n",
      "2024-11-22 08:41:00.563180: Pseudo dice [0.5905]\n",
      "2024-11-22 08:41:00.573180: Epoch time: 130.57 s\n",
      "2024-11-22 08:41:01.533203: \n",
      "2024-11-22 08:41:01.543203: Epoch 4\n",
      "2024-11-22 08:41:01.543203: Current learning rate: 0.00993\n",
      "2024-11-22 08:43:12.152899: train_loss -0.225\n",
      "2024-11-22 08:43:12.162900: val_loss -0.2199\n",
      "2024-11-22 08:43:12.162900: Pseudo dice [0.4972]\n",
      "2024-11-22 08:43:12.172900: Epoch time: 130.62 s\n",
      "2024-11-22 08:43:13.172923: \n",
      "2024-11-22 08:43:13.182914: Epoch 5\n",
      "2024-11-22 08:43:13.182914: Current learning rate: 0.00991\n",
      "2024-11-22 08:45:24.351820: train_loss -0.2778\n",
      "2024-11-22 08:45:24.371820: val_loss -0.2879\n",
      "2024-11-22 08:45:24.371820: Pseudo dice [0.5815]\n",
      "2024-11-22 08:45:24.381821: Epoch time: 131.18 s\n",
      "2024-11-22 08:45:25.331843: \n",
      "2024-11-22 08:45:25.341842: Epoch 6\n",
      "2024-11-22 08:45:25.341842: Current learning rate: 0.00989\n",
      "2024-11-22 08:47:35.855292: train_loss -0.2598\n",
      "2024-11-22 08:47:35.865292: val_loss -0.1448\n",
      "2024-11-22 08:47:35.875292: Pseudo dice [0.4628]\n",
      "2024-11-22 08:47:35.875292: Epoch time: 130.52 s\n",
      "2024-11-22 08:47:36.855314: \n",
      "2024-11-22 08:47:36.865314: Epoch 7\n",
      "2024-11-22 08:47:36.865314: Current learning rate: 0.00987\n",
      "2024-11-22 08:49:47.433026: train_loss -0.2975\n",
      "2024-11-22 08:49:47.443026: val_loss -0.2583\n",
      "2024-11-22 08:49:47.453026: Pseudo dice [0.5574]\n",
      "2024-11-22 08:49:47.453026: Epoch time: 130.58 s\n",
      "2024-11-22 08:49:48.603051: \n",
      "2024-11-22 08:49:48.613042: Epoch 8\n",
      "2024-11-22 08:49:48.613042: Current learning rate: 0.00986\n",
      "2024-11-22 08:51:59.219696: train_loss -0.3236\n",
      "2024-11-22 08:51:59.229697: val_loss -0.2644\n",
      "2024-11-22 08:51:59.229697: Pseudo dice [0.5298]\n",
      "2024-11-22 08:51:59.229697: Epoch time: 130.62 s\n",
      "2024-11-22 08:52:00.240019: \n",
      "2024-11-22 08:52:00.250018: Epoch 9\n",
      "2024-11-22 08:52:00.250018: Current learning rate: 0.00984\n",
      "2024-11-22 08:54:11.623169: train_loss -0.301\n",
      "2024-11-22 08:54:11.643179: val_loss -0.2868\n",
      "2024-11-22 08:54:11.643179: Pseudo dice [0.5766]\n",
      "2024-11-22 08:54:11.655457: Epoch time: 131.38 s\n",
      "2024-11-22 08:54:11.660527: Yayy! New best EMA pseudo Dice: 0.526\n",
      "2024-11-22 08:54:12.824256: \n",
      "2024-11-22 08:54:12.824256: Epoch 10\n",
      "2024-11-22 08:54:12.834256: Current learning rate: 0.00982\n",
      "2024-11-22 08:56:23.401304: train_loss -0.3605\n",
      "2024-11-22 08:56:23.401304: val_loss -0.2785\n",
      "2024-11-22 08:56:23.411305: Pseudo dice [0.5448]\n",
      "2024-11-22 08:56:23.411305: Epoch time: 130.58 s\n",
      "2024-11-22 08:56:23.421304: Yayy! New best EMA pseudo Dice: 0.5279\n",
      "2024-11-22 08:56:24.621616: \n",
      "2024-11-22 08:56:24.631607: Epoch 11\n",
      "2024-11-22 08:56:24.631607: Current learning rate: 0.0098\n",
      "2024-11-22 08:58:35.258537: train_loss -0.3255\n",
      "2024-11-22 08:58:35.268539: val_loss -0.193\n",
      "2024-11-22 08:58:35.278541: Pseudo dice [0.548]\n",
      "2024-11-22 08:58:35.338907: Epoch time: 130.64 s\n",
      "2024-11-22 08:58:35.338907: Yayy! New best EMA pseudo Dice: 0.5299\n",
      "2024-11-22 08:58:36.538934: \n",
      "2024-11-22 08:58:36.548925: Epoch 12\n",
      "2024-11-22 08:58:36.548925: Current learning rate: 0.00978\n",
      "2024-11-22 09:00:47.123039: train_loss -0.4027\n",
      "2024-11-22 09:00:47.133040: val_loss -0.3313\n",
      "2024-11-22 09:00:47.143040: Pseudo dice [0.6134]\n",
      "2024-11-22 09:00:47.143040: Epoch time: 130.58 s\n",
      "2024-11-22 09:00:47.153040: Yayy! New best EMA pseudo Dice: 0.5382\n",
      "2024-11-22 09:00:48.353402: \n",
      "2024-11-22 09:00:48.363402: Epoch 13\n",
      "2024-11-22 09:00:48.363402: Current learning rate: 0.00977\n",
      "2024-11-22 09:02:59.381150: train_loss -0.4539\n",
      "2024-11-22 09:02:59.391150: val_loss -0.2908\n",
      "2024-11-22 09:02:59.391150: Pseudo dice [0.5799]\n",
      "2024-11-22 09:02:59.401150: Epoch time: 131.03 s\n",
      "2024-11-22 09:02:59.401150: Yayy! New best EMA pseudo Dice: 0.5424\n",
      "2024-11-22 09:03:00.762712: \n",
      "2024-11-22 09:03:00.762712: Epoch 14\n",
      "2024-11-22 09:03:00.772704: Current learning rate: 0.00975\n",
      "2024-11-22 09:05:11.317642: train_loss -0.3668\n",
      "2024-11-22 09:05:11.327643: val_loss -0.2174\n",
      "2024-11-22 09:05:11.337642: Pseudo dice [0.518]\n",
      "2024-11-22 09:05:11.337642: Epoch time: 130.55 s\n",
      "2024-11-22 09:05:12.317666: \n",
      "2024-11-22 09:05:12.327665: Epoch 15\n",
      "2024-11-22 09:05:12.327665: Current learning rate: 0.00973\n",
      "2024-11-22 09:07:22.817638: train_loss -0.4136\n",
      "2024-11-22 09:07:22.817638: val_loss -0.239\n",
      "2024-11-22 09:07:22.827638: Pseudo dice [0.5532]\n",
      "2024-11-22 09:07:22.837638: Epoch time: 130.5 s\n",
      "2024-11-22 09:07:23.817987: \n",
      "2024-11-22 09:07:23.827987: Epoch 16\n",
      "2024-11-22 09:07:23.827987: Current learning rate: 0.00971\n",
      "2024-11-22 09:09:34.382605: train_loss -0.4031\n",
      "2024-11-22 09:09:34.392606: val_loss -0.3203\n",
      "2024-11-22 09:09:34.392606: Pseudo dice [0.6608]\n",
      "2024-11-22 09:09:34.402606: Epoch time: 130.56 s\n",
      "2024-11-22 09:09:34.402606: Yayy! New best EMA pseudo Dice: 0.5532\n",
      "2024-11-22 09:09:35.632632: \n",
      "2024-11-22 09:09:35.642631: Epoch 17\n",
      "2024-11-22 09:09:35.642631: Current learning rate: 0.00969\n",
      "2024-11-22 09:11:46.737527: train_loss -0.4881\n",
      "2024-11-22 09:11:46.747527: val_loss -0.312\n",
      "2024-11-22 09:11:46.757528: Pseudo dice [0.5942]\n",
      "2024-11-22 09:11:46.767527: Epoch time: 131.1 s\n",
      "2024-11-22 09:11:46.767527: Yayy! New best EMA pseudo Dice: 0.5573\n",
      "2024-11-22 09:11:47.998904: \n",
      "2024-11-22 09:11:47.999924: Epoch 18\n",
      "2024-11-22 09:11:48.007936: Current learning rate: 0.00968\n",
      "2024-11-22 09:13:58.565533: train_loss -0.4805\n",
      "2024-11-22 09:13:58.585533: val_loss -0.3561\n",
      "2024-11-22 09:13:58.585533: Pseudo dice [0.624]\n",
      "2024-11-22 09:13:58.595534: Epoch time: 130.57 s\n",
      "2024-11-22 09:13:58.655796: Yayy! New best EMA pseudo Dice: 0.564\n",
      "2024-11-22 09:13:59.875825: \n",
      "2024-11-22 09:13:59.875825: Epoch 19\n",
      "2024-11-22 09:13:59.885815: Current learning rate: 0.00966\n",
      "2024-11-22 09:16:10.475715: train_loss -0.4557\n",
      "2024-11-22 09:16:10.485715: val_loss -0.3134\n",
      "2024-11-22 09:16:10.495715: Pseudo dice [0.5331]\n",
      "2024-11-22 09:16:10.495715: Epoch time: 130.6 s\n",
      "2024-11-22 09:16:11.495729: \n",
      "2024-11-22 09:16:11.495729: Epoch 20\n",
      "2024-11-22 09:16:11.505729: Current learning rate: 0.00964\n",
      "2024-11-22 09:18:22.089313: train_loss -0.4849\n",
      "2024-11-22 09:18:22.099312: val_loss -0.3128\n",
      "2024-11-22 09:18:22.109313: Pseudo dice [0.5839]\n",
      "2024-11-22 09:18:22.109313: Epoch time: 130.59 s\n",
      "2024-11-22 09:18:23.269338: \n",
      "2024-11-22 09:18:23.279338: Epoch 21\n",
      "2024-11-22 09:18:23.279338: Current learning rate: 0.00962\n",
      "2024-11-22 09:20:33.868030: train_loss -0.464\n",
      "2024-11-22 09:20:33.878030: val_loss -0.2907\n",
      "2024-11-22 09:20:33.888030: Pseudo dice [0.5598]\n",
      "2024-11-22 09:20:33.888030: Epoch time: 130.6 s\n",
      "2024-11-22 09:20:34.838055: \n",
      "2024-11-22 09:20:34.838055: Epoch 22\n",
      "2024-11-22 09:20:34.848043: Current learning rate: 0.0096\n",
      "2024-11-22 09:22:45.453915: train_loss -0.4498\n",
      "2024-11-22 09:22:45.463916: val_loss -0.4311\n",
      "2024-11-22 09:22:45.473916: Pseudo dice [0.6775]\n",
      "2024-11-22 09:22:45.483917: Epoch time: 130.62 s\n",
      "2024-11-22 09:22:45.483917: Yayy! New best EMA pseudo Dice: 0.5743\n",
      "2024-11-22 09:22:46.674187: \n",
      "2024-11-22 09:22:46.674187: Epoch 23\n",
      "2024-11-22 09:22:46.684184: Current learning rate: 0.00959\n",
      "2024-11-22 09:24:57.250442: train_loss -0.4776\n",
      "2024-11-22 09:24:57.260441: val_loss -0.3024\n",
      "2024-11-22 09:24:57.270442: Pseudo dice [0.5572]\n",
      "2024-11-22 09:24:57.280442: Epoch time: 130.58 s\n",
      "2024-11-22 09:24:58.210463: \n",
      "2024-11-22 09:24:58.220454: Epoch 24\n",
      "2024-11-22 09:24:58.220454: Current learning rate: 0.00957\n",
      "2024-11-22 09:27:08.729236: train_loss -0.5115\n",
      "2024-11-22 09:27:08.739237: val_loss -0.4098\n",
      "2024-11-22 09:27:08.749237: Pseudo dice [0.6544]\n",
      "2024-11-22 09:27:08.749237: Epoch time: 130.52 s\n",
      "2024-11-22 09:27:08.759237: Yayy! New best EMA pseudo Dice: 0.5808\n",
      "2024-11-22 09:27:09.949263: \n",
      "2024-11-22 09:27:09.949263: Epoch 25\n",
      "2024-11-22 09:27:09.959262: Current learning rate: 0.00955\n",
      "2024-11-22 09:29:20.853280: train_loss -0.4897\n",
      "2024-11-22 09:29:20.863280: val_loss -0.4046\n",
      "2024-11-22 09:29:20.873280: Pseudo dice [0.6381]\n",
      "2024-11-22 09:29:20.873280: Epoch time: 130.9 s\n",
      "2024-11-22 09:29:20.883281: Yayy! New best EMA pseudo Dice: 0.5865\n",
      "2024-11-22 09:29:22.063385: \n",
      "2024-11-22 09:29:22.063385: Epoch 26\n",
      "2024-11-22 09:29:22.073385: Current learning rate: 0.00953\n",
      "2024-11-22 09:31:32.600811: train_loss -0.4927\n",
      "2024-11-22 09:31:32.620811: val_loss -0.3324\n",
      "2024-11-22 09:31:32.620811: Pseudo dice [0.6133]\n",
      "2024-11-22 09:31:32.630811: Epoch time: 130.54 s\n",
      "2024-11-22 09:31:32.630811: Yayy! New best EMA pseudo Dice: 0.5892\n",
      "2024-11-22 09:31:33.921164: \n",
      "2024-11-22 09:31:33.931164: Epoch 27\n",
      "2024-11-22 09:31:33.931164: Current learning rate: 0.00951\n",
      "2024-11-22 09:33:44.418342: train_loss -0.4735\n",
      "2024-11-22 09:33:44.428343: val_loss -0.2442\n",
      "2024-11-22 09:33:44.428343: Pseudo dice [0.515]\n",
      "2024-11-22 09:33:44.438343: Epoch time: 130.5 s\n",
      "2024-11-22 09:33:45.548366: \n",
      "2024-11-22 09:33:45.558358: Epoch 28\n",
      "2024-11-22 09:33:45.558358: Current learning rate: 0.00949\n",
      "2024-11-22 09:35:56.046465: train_loss -0.5104\n",
      "2024-11-22 09:35:56.056465: val_loss -0.3792\n",
      "2024-11-22 09:35:56.056465: Pseudo dice [0.6144]\n",
      "2024-11-22 09:35:56.066465: Epoch time: 130.5 s\n",
      "2024-11-22 09:35:57.016487: \n",
      "2024-11-22 09:35:57.016487: Epoch 29\n",
      "2024-11-22 09:35:57.026478: Current learning rate: 0.00948\n",
      "2024-11-22 09:38:07.594169: train_loss -0.511\n",
      "2024-11-22 09:38:07.604169: val_loss -0.4279\n",
      "2024-11-22 09:38:07.614169: Pseudo dice [0.6465]\n",
      "2024-11-22 09:38:07.614169: Epoch time: 130.58 s\n",
      "2024-11-22 09:38:07.624169: Yayy! New best EMA pseudo Dice: 0.5912\n",
      "2024-11-22 09:38:08.824195: \n",
      "2024-11-22 09:38:08.834185: Epoch 30\n",
      "2024-11-22 09:38:08.834185: Current learning rate: 0.00946\n",
      "2024-11-22 09:40:19.371107: train_loss -0.5147\n",
      "2024-11-22 09:40:19.381107: val_loss -0.366\n",
      "2024-11-22 09:40:19.391107: Pseudo dice [0.6275]\n",
      "2024-11-22 09:40:19.391107: Epoch time: 130.55 s\n",
      "2024-11-22 09:40:19.391107: Yayy! New best EMA pseudo Dice: 0.5948\n",
      "2024-11-22 09:40:20.601894: \n",
      "2024-11-22 09:40:20.601894: Epoch 31\n",
      "2024-11-22 09:40:20.611894: Current learning rate: 0.00944\n",
      "2024-11-22 09:42:31.066452: train_loss -0.5154\n",
      "2024-11-22 09:42:31.076453: val_loss -0.3933\n",
      "2024-11-22 09:42:31.086452: Pseudo dice [0.6432]\n",
      "2024-11-22 09:42:31.086452: Epoch time: 130.46 s\n",
      "2024-11-22 09:42:31.096452: Yayy! New best EMA pseudo Dice: 0.5997\n",
      "2024-11-22 09:42:32.306478: \n",
      "2024-11-22 09:42:32.306478: Epoch 32\n",
      "2024-11-22 09:42:32.316478: Current learning rate: 0.00942\n",
      "2024-11-22 09:44:42.818396: train_loss -0.5545\n",
      "2024-11-22 09:44:42.879453: val_loss -0.3629\n",
      "2024-11-22 09:44:42.889455: Pseudo dice [0.6053]\n",
      "2024-11-22 09:44:42.889455: Epoch time: 130.51 s\n",
      "2024-11-22 09:44:42.889455: Yayy! New best EMA pseudo Dice: 0.6002\n",
      "2024-11-22 09:44:44.099480: \n",
      "2024-11-22 09:44:44.109479: Epoch 33\n",
      "2024-11-22 09:44:44.109479: Current learning rate: 0.0094\n",
      "2024-11-22 09:46:54.629199: train_loss -0.5417\n",
      "2024-11-22 09:46:54.639199: val_loss -0.4023\n",
      "2024-11-22 09:46:54.639199: Pseudo dice [0.6283]\n",
      "2024-11-22 09:46:54.649199: Epoch time: 130.53 s\n",
      "2024-11-22 09:46:54.659199: Yayy! New best EMA pseudo Dice: 0.603\n",
      "2024-11-22 09:46:56.030228: \n",
      "2024-11-22 09:46:56.030228: Epoch 34\n",
      "2024-11-22 09:46:56.040224: Current learning rate: 0.00939\n",
      "2024-11-22 09:49:06.578139: train_loss -0.5641\n",
      "2024-11-22 09:49:06.588139: val_loss -0.423\n",
      "2024-11-22 09:49:06.598139: Pseudo dice [0.6482]\n",
      "2024-11-22 09:49:06.598139: Epoch time: 130.55 s\n",
      "2024-11-22 09:49:06.608140: Yayy! New best EMA pseudo Dice: 0.6076\n",
      "2024-11-22 09:49:07.828973: \n",
      "2024-11-22 09:49:07.828973: Epoch 35\n",
      "2024-11-22 09:49:07.828973: Current learning rate: 0.00937\n",
      "2024-11-22 09:51:18.304880: train_loss -0.5621\n",
      "2024-11-22 09:51:18.304880: val_loss -0.4326\n",
      "2024-11-22 09:51:18.314879: Pseudo dice [0.6671]\n",
      "2024-11-22 09:51:18.324881: Epoch time: 130.48 s\n",
      "2024-11-22 09:51:18.324881: Yayy! New best EMA pseudo Dice: 0.6135\n",
      "2024-11-22 09:51:19.555211: \n",
      "2024-11-22 09:51:19.555211: Epoch 36\n",
      "2024-11-22 09:51:19.555211: Current learning rate: 0.00935\n",
      "2024-11-22 09:53:30.092129: train_loss -0.5293\n",
      "2024-11-22 09:53:30.102129: val_loss -0.2918\n",
      "2024-11-22 09:53:30.112129: Pseudo dice [0.6122]\n",
      "2024-11-22 09:53:30.122130: Epoch time: 130.55 s\n",
      "2024-11-22 09:53:31.102980: \n",
      "2024-11-22 09:53:31.112972: Epoch 37\n",
      "2024-11-22 09:53:31.112972: Current learning rate: 0.00933\n",
      "2024-11-22 09:55:42.330806: train_loss -0.5447\n",
      "2024-11-22 09:55:42.350806: val_loss -0.4118\n",
      "2024-11-22 09:55:42.360806: Pseudo dice [0.6684]\n",
      "2024-11-22 09:55:42.360806: Epoch time: 131.23 s\n",
      "2024-11-22 09:55:42.370806: Yayy! New best EMA pseudo Dice: 0.6189\n",
      "2024-11-22 09:55:43.600825: \n",
      "2024-11-22 09:55:43.600825: Epoch 38\n",
      "2024-11-22 09:55:43.600825: Current learning rate: 0.00931\n",
      "2024-11-22 09:57:54.129361: train_loss -0.5339\n",
      "2024-11-22 09:57:54.139361: val_loss -0.4353\n",
      "2024-11-22 09:57:54.139361: Pseudo dice [0.6579]\n",
      "2024-11-22 09:57:54.149360: Epoch time: 130.53 s\n",
      "2024-11-22 09:57:54.159362: Yayy! New best EMA pseudo Dice: 0.6228\n",
      "2024-11-22 09:57:55.389380: \n",
      "2024-11-22 09:57:55.389380: Epoch 39\n",
      "2024-11-22 09:57:55.399378: Current learning rate: 0.0093\n",
      "2024-11-22 10:00:05.905949: train_loss -0.5655\n",
      "2024-11-22 10:00:05.915949: val_loss -0.3449\n",
      "2024-11-22 10:00:05.915949: Pseudo dice [0.62]\n",
      "2024-11-22 10:00:05.915949: Epoch time: 130.52 s\n",
      "2024-11-22 10:00:06.925972: \n",
      "2024-11-22 10:00:06.935972: Epoch 40\n",
      "2024-11-22 10:00:06.935972: Current learning rate: 0.00928\n",
      "2024-11-22 10:02:17.484485: train_loss -0.5497\n",
      "2024-11-22 10:02:17.494485: val_loss -0.505\n",
      "2024-11-22 10:02:17.494485: Pseudo dice [0.7092]\n",
      "2024-11-22 10:02:17.494485: Epoch time: 130.56 s\n",
      "2024-11-22 10:02:17.504485: Yayy! New best EMA pseudo Dice: 0.6312\n",
      "2024-11-22 10:02:18.914513: \n",
      "2024-11-22 10:02:18.924505: Epoch 41\n",
      "2024-11-22 10:02:18.924505: Current learning rate: 0.00926\n",
      "2024-11-22 10:04:29.435033: train_loss -0.5474\n",
      "2024-11-22 10:04:29.445033: val_loss -0.3236\n",
      "2024-11-22 10:04:29.455033: Pseudo dice [0.5648]\n",
      "2024-11-22 10:04:29.465034: Epoch time: 130.52 s\n",
      "2024-11-22 10:04:30.405055: \n",
      "2024-11-22 10:04:30.415047: Epoch 42\n",
      "2024-11-22 10:04:30.415047: Current learning rate: 0.00924\n",
      "2024-11-22 10:06:40.981281: train_loss -0.5615\n",
      "2024-11-22 10:06:40.991281: val_loss -0.4122\n",
      "2024-11-22 10:06:40.991281: Pseudo dice [0.6339]\n",
      "2024-11-22 10:06:41.001281: Epoch time: 130.58 s\n",
      "2024-11-22 10:06:41.941304: \n",
      "2024-11-22 10:06:41.951304: Epoch 43\n",
      "2024-11-22 10:06:41.951304: Current learning rate: 0.00922\n",
      "2024-11-22 10:08:52.533434: train_loss -0.5948\n",
      "2024-11-22 10:08:52.543434: val_loss -0.2997\n",
      "2024-11-22 10:08:52.543434: Pseudo dice [0.6013]\n",
      "2024-11-22 10:08:52.553434: Epoch time: 130.59 s\n",
      "2024-11-22 10:08:53.503455: \n",
      "2024-11-22 10:08:53.503455: Epoch 44\n",
      "2024-11-22 10:08:53.513455: Current learning rate: 0.0092\n",
      "2024-11-22 10:11:04.050770: train_loss -0.5847\n",
      "2024-11-22 10:11:04.060771: val_loss -0.3599\n",
      "2024-11-22 10:11:04.070771: Pseudo dice [0.6221]\n",
      "2024-11-22 10:11:04.070771: Epoch time: 130.55 s\n",
      "2024-11-22 10:11:05.030785: \n",
      "2024-11-22 10:11:05.030785: Epoch 45\n",
      "2024-11-22 10:11:05.040784: Current learning rate: 0.00919\n",
      "2024-11-22 10:13:15.637110: train_loss -0.5743\n",
      "2024-11-22 10:13:15.647110: val_loss -0.3668\n",
      "2024-11-22 10:13:15.657111: Pseudo dice [0.6043]\n",
      "2024-11-22 10:13:15.657111: Epoch time: 130.61 s\n",
      "2024-11-22 10:13:16.607174: \n",
      "2024-11-22 10:13:16.617174: Epoch 46\n",
      "2024-11-22 10:13:16.617174: Current learning rate: 0.00917\n",
      "2024-11-22 10:15:27.155962: train_loss -0.5693\n",
      "2024-11-22 10:15:27.165962: val_loss -0.347\n",
      "2024-11-22 10:15:27.175963: Pseudo dice [0.6317]\n",
      "2024-11-22 10:15:27.175963: Epoch time: 130.55 s\n",
      "2024-11-22 10:15:28.135977: \n",
      "2024-11-22 10:15:28.135977: Epoch 47\n",
      "2024-11-22 10:15:28.145984: Current learning rate: 0.00915\n",
      "2024-11-22 10:17:38.767395: train_loss -0.5782\n",
      "2024-11-22 10:17:38.777395: val_loss -0.4131\n",
      "2024-11-22 10:17:38.787395: Pseudo dice [0.6327]\n",
      "2024-11-22 10:17:38.787395: Epoch time: 130.63 s\n",
      "2024-11-22 10:17:39.907763: \n",
      "2024-11-22 10:17:39.917762: Epoch 48\n",
      "2024-11-22 10:17:39.917762: Current learning rate: 0.00913\n",
      "2024-11-22 10:19:50.514120: train_loss -0.5687\n",
      "2024-11-22 10:19:50.524120: val_loss -0.4022\n",
      "2024-11-22 10:19:50.534119: Pseudo dice [0.6484]\n",
      "2024-11-22 10:19:50.534119: Epoch time: 130.61 s\n",
      "2024-11-22 10:19:51.505354: \n",
      "2024-11-22 10:19:51.505354: Epoch 49\n",
      "2024-11-22 10:19:51.515354: Current learning rate: 0.00911\n",
      "2024-11-22 10:22:02.108763: train_loss -0.5488\n",
      "2024-11-22 10:22:02.118763: val_loss -0.3362\n",
      "2024-11-22 10:22:02.128763: Pseudo dice [0.5778]\n",
      "2024-11-22 10:22:02.138763: Epoch time: 130.6 s\n",
      "2024-11-22 10:22:03.309460: \n",
      "2024-11-22 10:22:03.319459: Epoch 50\n",
      "2024-11-22 10:22:03.319459: Current learning rate: 0.0091\n",
      "2024-11-22 10:24:13.848406: train_loss -0.555\n",
      "2024-11-22 10:24:13.858406: val_loss -0.3809\n",
      "2024-11-22 10:24:13.868407: Pseudo dice [0.639]\n",
      "2024-11-22 10:24:13.868407: Epoch time: 130.54 s\n",
      "2024-11-22 10:24:14.828712: \n",
      "2024-11-22 10:24:14.838713: Epoch 51\n",
      "2024-11-22 10:24:14.838713: Current learning rate: 0.00908\n",
      "2024-11-22 10:26:25.362126: train_loss -0.6197\n",
      "2024-11-22 10:26:25.372125: val_loss -0.3455\n",
      "2024-11-22 10:26:25.372125: Pseudo dice [0.5751]\n",
      "2024-11-22 10:26:25.382126: Epoch time: 130.53 s\n",
      "2024-11-22 10:26:26.342148: \n",
      "2024-11-22 10:26:26.352148: Epoch 52\n",
      "2024-11-22 10:26:26.352148: Current learning rate: 0.00906\n",
      "2024-11-22 10:28:36.909326: train_loss -0.5268\n",
      "2024-11-22 10:28:36.919326: val_loss -0.4883\n",
      "2024-11-22 10:28:36.919326: Pseudo dice [0.6691]\n",
      "2024-11-22 10:28:36.929326: Epoch time: 130.57 s\n",
      "2024-11-22 10:28:37.889349: \n",
      "2024-11-22 10:28:37.889349: Epoch 53\n",
      "2024-11-22 10:28:37.899348: Current learning rate: 0.00904\n",
      "2024-11-22 10:30:48.455925: train_loss -0.6478\n",
      "2024-11-22 10:30:48.465924: val_loss -0.3182\n",
      "2024-11-22 10:30:48.475924: Pseudo dice [0.5971]\n",
      "2024-11-22 10:30:48.475924: Epoch time: 130.57 s\n",
      "2024-11-22 10:30:49.435946: \n",
      "2024-11-22 10:30:49.445937: Epoch 54\n",
      "2024-11-22 10:30:49.445937: Current learning rate: 0.00902\n",
      "2024-11-22 10:33:00.042953: train_loss -0.5786\n",
      "2024-11-22 10:33:00.042953: val_loss -0.2627\n",
      "2024-11-22 10:33:00.052953: Pseudo dice [0.6033]\n",
      "2024-11-22 10:33:00.062953: Epoch time: 130.61 s\n",
      "2024-11-22 10:33:01.022975: \n",
      "2024-11-22 10:33:01.022975: Epoch 55\n",
      "2024-11-22 10:33:01.032966: Current learning rate: 0.009\n",
      "2024-11-22 10:35:11.581808: train_loss -0.5971\n",
      "2024-11-22 10:35:11.591808: val_loss -0.4157\n",
      "2024-11-22 10:35:11.601808: Pseudo dice [0.6253]\n",
      "2024-11-22 10:35:11.601808: Epoch time: 130.56 s\n",
      "2024-11-22 10:35:12.561830: \n",
      "2024-11-22 10:35:12.571821: Epoch 56\n",
      "2024-11-22 10:35:12.571821: Current learning rate: 0.00899\n",
      "2024-11-22 10:37:23.149152: train_loss -0.6046\n",
      "2024-11-22 10:37:23.159152: val_loss -0.2823\n",
      "2024-11-22 10:37:23.169152: Pseudo dice [0.5965]\n",
      "2024-11-22 10:37:23.169152: Epoch time: 130.59 s\n",
      "2024-11-22 10:37:24.139508: \n",
      "2024-11-22 10:37:24.139508: Epoch 57\n",
      "2024-11-22 10:37:24.139508: Current learning rate: 0.00897\n",
      "2024-11-22 10:39:34.717079: train_loss -0.6051\n",
      "2024-11-22 10:39:34.727079: val_loss -0.3375\n",
      "2024-11-22 10:39:34.737080: Pseudo dice [0.6027]\n",
      "2024-11-22 10:39:34.737080: Epoch time: 130.58 s\n",
      "2024-11-22 10:39:35.697102: \n",
      "2024-11-22 10:39:35.707093: Epoch 58\n",
      "2024-11-22 10:39:35.707093: Current learning rate: 0.00895\n",
      "2024-11-22 10:41:46.227733: train_loss -0.5962\n",
      "2024-11-22 10:41:46.237733: val_loss -0.3678\n",
      "2024-11-22 10:41:46.237733: Pseudo dice [0.6385]\n",
      "2024-11-22 10:41:46.247733: Epoch time: 130.53 s\n",
      "2024-11-22 10:41:47.217755: \n",
      "2024-11-22 10:41:47.227746: Epoch 59\n",
      "2024-11-22 10:41:47.227746: Current learning rate: 0.00893\n",
      "2024-11-22 10:43:57.766025: train_loss -0.6394\n",
      "2024-11-22 10:43:57.776024: val_loss -0.4031\n",
      "2024-11-22 10:43:57.786024: Pseudo dice [0.6895]\n",
      "2024-11-22 10:43:57.786024: Epoch time: 130.55 s\n",
      "2024-11-22 10:43:58.766047: \n",
      "2024-11-22 10:43:58.776038: Epoch 60\n",
      "2024-11-22 10:43:58.776038: Current learning rate: 0.00891\n",
      "2024-11-22 10:46:09.323637: train_loss -0.6058\n",
      "2024-11-22 10:46:09.333637: val_loss -0.2623\n",
      "2024-11-22 10:46:09.343637: Pseudo dice [0.5823]\n",
      "2024-11-22 10:46:09.343637: Epoch time: 130.56 s\n",
      "2024-11-22 10:46:10.313660: \n",
      "2024-11-22 10:46:10.323653: Epoch 61\n",
      "2024-11-22 10:46:10.323653: Current learning rate: 0.00889\n",
      "2024-11-22 10:48:21.209422: train_loss -0.5982\n",
      "2024-11-22 10:48:21.219422: val_loss -0.4395\n",
      "2024-11-22 10:48:21.219422: Pseudo dice [0.6313]\n",
      "2024-11-22 10:48:21.229422: Epoch time: 130.9 s\n",
      "2024-11-22 10:48:22.210478: \n",
      "2024-11-22 10:48:22.210478: Epoch 62\n",
      "2024-11-22 10:48:22.220476: Current learning rate: 0.00888\n",
      "2024-11-22 10:50:32.668887: train_loss -0.6002\n",
      "2024-11-22 10:50:32.678887: val_loss -0.1914\n",
      "2024-11-22 10:50:32.688887: Pseudo dice [0.5565]\n",
      "2024-11-22 10:50:32.688887: Epoch time: 130.46 s\n",
      "2024-11-22 10:50:33.828911: \n",
      "2024-11-22 10:50:33.838902: Epoch 63\n",
      "2024-11-22 10:50:33.838902: Current learning rate: 0.00886\n",
      "2024-11-22 10:52:44.346276: train_loss -0.6404\n",
      "2024-11-22 10:52:44.356275: val_loss -0.4135\n",
      "2024-11-22 10:52:44.366275: Pseudo dice [0.6495]\n",
      "2024-11-22 10:52:44.376276: Epoch time: 130.52 s\n",
      "2024-11-22 10:52:45.356290: \n",
      "2024-11-22 10:52:45.356290: Epoch 64\n",
      "2024-11-22 10:52:45.366289: Current learning rate: 0.00884\n",
      "2024-11-22 10:54:55.891476: train_loss -0.6203\n",
      "2024-11-22 10:54:55.891476: val_loss -0.3869\n",
      "2024-11-22 10:54:55.901477: Pseudo dice [0.6284]\n",
      "2024-11-22 10:54:55.911477: Epoch time: 130.54 s\n",
      "2024-11-22 10:54:56.881499: \n",
      "2024-11-22 10:54:56.891490: Epoch 65\n",
      "2024-11-22 10:54:56.891490: Current learning rate: 0.00882\n",
      "2024-11-22 10:57:07.496792: train_loss -0.6253\n",
      "2024-11-22 10:57:07.506792: val_loss -0.4116\n",
      "2024-11-22 10:57:07.506792: Pseudo dice [0.6339]\n",
      "2024-11-22 10:57:07.516792: Epoch time: 130.62 s\n",
      "2024-11-22 10:57:08.496815: \n",
      "2024-11-22 10:57:08.496815: Epoch 66\n",
      "2024-11-22 10:57:08.506815: Current learning rate: 0.0088\n",
      "2024-11-22 10:59:19.044688: train_loss -0.626\n",
      "2024-11-22 10:59:19.054689: val_loss -0.2429\n",
      "2024-11-22 10:59:19.064688: Pseudo dice [0.5108]\n",
      "2024-11-22 10:59:19.064688: Epoch time: 130.55 s\n",
      "2024-11-22 10:59:20.054702: \n",
      "2024-11-22 10:59:20.054702: Epoch 67\n",
      "2024-11-22 10:59:20.064702: Current learning rate: 0.00879\n",
      "2024-11-22 11:01:30.561822: train_loss -0.6315\n",
      "2024-11-22 11:01:30.571822: val_loss -0.4112\n",
      "2024-11-22 11:01:30.581822: Pseudo dice [0.6568]\n",
      "2024-11-22 11:01:30.581822: Epoch time: 130.51 s\n",
      "2024-11-22 11:01:31.581947: \n",
      "2024-11-22 11:01:31.581947: Epoch 68\n",
      "2024-11-22 11:01:31.591940: Current learning rate: 0.00877\n",
      "2024-11-22 11:03:42.129363: train_loss -0.6344\n",
      "2024-11-22 11:03:42.139363: val_loss -0.4049\n",
      "2024-11-22 11:03:42.149363: Pseudo dice [0.6562]\n",
      "2024-11-22 11:03:42.149363: Epoch time: 130.55 s\n",
      "2024-11-22 11:03:43.149380: \n",
      "2024-11-22 11:03:43.149380: Epoch 69\n",
      "2024-11-22 11:03:43.149380: Current learning rate: 0.00875\n",
      "2024-11-22 11:05:54.457023: train_loss -0.6499\n",
      "2024-11-22 11:05:54.467023: val_loss -0.5437\n",
      "2024-11-22 11:05:54.477023: Pseudo dice [0.7411]\n",
      "2024-11-22 11:05:54.487023: Epoch time: 131.32 s\n",
      "2024-11-22 11:05:55.647039: \n",
      "2024-11-22 11:05:55.647039: Epoch 70\n",
      "2024-11-22 11:05:55.657048: Current learning rate: 0.00873\n",
      "2024-11-22 11:08:06.144606: train_loss -0.654\n",
      "2024-11-22 11:08:06.154606: val_loss -0.4249\n",
      "2024-11-22 11:08:06.164606: Pseudo dice [0.6457]\n",
      "2024-11-22 11:08:06.164606: Epoch time: 130.5 s\n",
      "2024-11-22 11:08:06.174606: Yayy! New best EMA pseudo Dice: 0.6326\n",
      "2024-11-22 11:08:07.385596: \n",
      "2024-11-22 11:08:07.395595: Epoch 71\n",
      "2024-11-22 11:08:07.395595: Current learning rate: 0.00871\n",
      "2024-11-22 11:10:17.896894: train_loss -0.6471\n",
      "2024-11-22 11:10:17.906893: val_loss -0.3325\n",
      "2024-11-22 11:10:17.916893: Pseudo dice [0.5939]\n",
      "2024-11-22 11:10:17.916893: Epoch time: 130.51 s\n",
      "2024-11-22 11:10:18.917248: \n",
      "2024-11-22 11:10:18.917248: Epoch 72\n",
      "2024-11-22 11:10:18.927248: Current learning rate: 0.00869\n",
      "2024-11-22 11:12:29.445737: train_loss -0.6657\n",
      "2024-11-22 11:12:29.455737: val_loss -0.3172\n",
      "2024-11-22 11:12:29.465737: Pseudo dice [0.6012]\n",
      "2024-11-22 11:12:29.465737: Epoch time: 130.53 s\n",
      "2024-11-22 11:12:30.475754: \n",
      "2024-11-22 11:12:30.475754: Epoch 73\n",
      "2024-11-22 11:12:30.485751: Current learning rate: 0.00868\n",
      "2024-11-22 11:14:41.573185: train_loss -0.6884\n",
      "2024-11-22 11:14:41.593184: val_loss -0.312\n",
      "2024-11-22 11:14:41.593184: Pseudo dice [0.6147]\n",
      "2024-11-22 11:14:41.603184: Epoch time: 131.1 s\n",
      "2024-11-22 11:14:42.611545: \n",
      "2024-11-22 11:14:42.616665: Epoch 74\n",
      "2024-11-22 11:14:42.620713: Current learning rate: 0.00866\n",
      "2024-11-22 11:16:53.161014: train_loss -0.631\n",
      "2024-11-22 11:16:53.171013: val_loss -0.336\n",
      "2024-11-22 11:16:53.181013: Pseudo dice [0.597]\n",
      "2024-11-22 11:16:53.181013: Epoch time: 130.55 s\n",
      "2024-11-22 11:16:54.191370: \n",
      "2024-11-22 11:16:54.191370: Epoch 75\n",
      "2024-11-22 11:16:54.201362: Current learning rate: 0.00864\n",
      "2024-11-22 11:19:04.748699: train_loss -0.6617\n",
      "2024-11-22 11:19:04.758699: val_loss -0.4389\n",
      "2024-11-22 11:19:04.758699: Pseudo dice [0.6568]\n",
      "2024-11-22 11:19:04.768699: Epoch time: 130.56 s\n",
      "2024-11-22 11:19:05.938724: \n",
      "2024-11-22 11:19:05.948714: Epoch 76\n",
      "2024-11-22 11:19:05.948714: Current learning rate: 0.00862\n",
      "2024-11-22 11:21:16.456292: train_loss -0.6576\n",
      "2024-11-22 11:21:16.466292: val_loss -0.4667\n",
      "2024-11-22 11:21:16.466292: Pseudo dice [0.6529]\n",
      "2024-11-22 11:21:16.476292: Epoch time: 130.52 s\n",
      "2024-11-22 11:21:17.476316: \n",
      "2024-11-22 11:21:17.486306: Epoch 77\n",
      "2024-11-22 11:21:17.486306: Current learning rate: 0.0086\n",
      "2024-11-22 11:23:28.031760: train_loss -0.6505\n",
      "2024-11-22 11:23:28.041759: val_loss -0.4928\n",
      "2024-11-22 11:23:28.051760: Pseudo dice [0.7154]\n",
      "2024-11-22 11:23:28.051760: Epoch time: 130.56 s\n",
      "2024-11-22 11:23:28.051760: Yayy! New best EMA pseudo Dice: 0.637\n",
      "2024-11-22 11:23:29.321779: \n",
      "2024-11-22 11:23:29.321779: Epoch 78\n",
      "2024-11-22 11:23:29.331786: Current learning rate: 0.00858\n",
      "2024-11-22 11:25:39.882276: train_loss -0.6165\n",
      "2024-11-22 11:25:39.892276: val_loss -0.5428\n",
      "2024-11-22 11:25:39.902277: Pseudo dice [0.7309]\n",
      "2024-11-22 11:25:39.902277: Epoch time: 130.56 s\n",
      "2024-11-22 11:25:39.912276: Yayy! New best EMA pseudo Dice: 0.6464\n",
      "2024-11-22 11:25:41.162606: \n",
      "2024-11-22 11:25:41.172597: Epoch 79\n",
      "2024-11-22 11:25:41.172597: Current learning rate: 0.00857\n",
      "2024-11-22 11:27:51.639209: train_loss -0.6399\n",
      "2024-11-22 11:27:51.649209: val_loss -0.3931\n",
      "2024-11-22 11:27:51.649209: Pseudo dice [0.6119]\n",
      "2024-11-22 11:27:51.659209: Epoch time: 130.48 s\n",
      "2024-11-22 11:27:52.679226: \n",
      "2024-11-22 11:27:52.679226: Epoch 80\n",
      "2024-11-22 11:27:52.689224: Current learning rate: 0.00855\n",
      "2024-11-22 11:30:03.237524: train_loss -0.6682\n",
      "2024-11-22 11:30:03.247524: val_loss -0.4333\n",
      "2024-11-22 11:30:03.247524: Pseudo dice [0.6638]\n",
      "2024-11-22 11:30:03.257524: Epoch time: 130.56 s\n",
      "2024-11-22 11:30:04.277540: \n",
      "2024-11-22 11:30:04.277540: Epoch 81\n",
      "2024-11-22 11:30:04.287538: Current learning rate: 0.00853\n",
      "2024-11-22 11:32:15.262513: train_loss -0.6259\n",
      "2024-11-22 11:32:15.272513: val_loss -0.1888\n",
      "2024-11-22 11:32:15.282513: Pseudo dice [0.499]\n",
      "2024-11-22 11:32:15.282513: Epoch time: 130.98 s\n",
      "2024-11-22 11:32:16.302710: \n",
      "2024-11-22 11:32:16.302710: Epoch 82\n",
      "2024-11-22 11:32:16.312709: Current learning rate: 0.00851\n",
      "2024-11-22 11:34:26.771185: train_loss -0.6252\n",
      "2024-11-22 11:34:26.781185: val_loss -0.254\n",
      "2024-11-22 11:34:26.791185: Pseudo dice [0.6138]\n",
      "2024-11-22 11:34:26.801185: Epoch time: 130.47 s\n",
      "2024-11-22 11:34:27.941210: \n",
      "2024-11-22 11:34:27.951202: Epoch 83\n",
      "2024-11-22 11:34:27.951202: Current learning rate: 0.00849\n",
      "2024-11-22 11:36:38.418952: train_loss -0.623\n",
      "2024-11-22 11:36:38.428952: val_loss -0.2819\n",
      "2024-11-22 11:36:38.438952: Pseudo dice [0.5606]\n",
      "2024-11-22 11:36:38.438952: Epoch time: 130.48 s\n",
      "2024-11-22 11:36:39.399275: \n",
      "2024-11-22 11:36:39.409266: Epoch 84\n",
      "2024-11-22 11:36:39.409266: Current learning rate: 0.00847\n",
      "2024-11-22 11:38:49.913261: train_loss -0.6813\n",
      "2024-11-22 11:38:49.923261: val_loss -0.3361\n",
      "2024-11-22 11:38:49.933261: Pseudo dice [0.5793]\n",
      "2024-11-22 11:38:49.943261: Epoch time: 130.51 s\n",
      "2024-11-22 11:38:50.903912: \n",
      "2024-11-22 11:38:50.903912: Epoch 85\n",
      "2024-11-22 11:38:50.913909: Current learning rate: 0.00846\n",
      "2024-11-22 11:41:01.473027: train_loss -0.6472\n",
      "2024-11-22 11:41:01.483027: val_loss -0.2966\n",
      "2024-11-22 11:41:01.483027: Pseudo dice [0.5946]\n",
      "2024-11-22 11:41:01.493028: Epoch time: 130.57 s\n",
      "2024-11-22 11:41:02.463041: \n",
      "2024-11-22 11:41:02.463041: Epoch 86\n",
      "2024-11-22 11:41:02.473041: Current learning rate: 0.00844\n",
      "2024-11-22 11:43:13.027437: train_loss -0.643\n",
      "2024-11-22 11:43:13.037437: val_loss -0.4868\n",
      "2024-11-22 11:43:13.037437: Pseudo dice [0.7074]\n",
      "2024-11-22 11:43:13.047437: Epoch time: 130.57 s\n",
      "2024-11-22 11:43:14.007458: \n",
      "2024-11-22 11:43:14.007458: Epoch 87\n",
      "2024-11-22 11:43:14.017451: Current learning rate: 0.00842\n",
      "2024-11-22 11:45:24.606349: train_loss -0.674\n",
      "2024-11-22 11:45:24.606349: val_loss -0.5244\n",
      "2024-11-22 11:45:24.616349: Pseudo dice [0.696]\n",
      "2024-11-22 11:45:24.626349: Epoch time: 130.6 s\n",
      "2024-11-22 11:45:25.586364: \n",
      "2024-11-22 11:45:25.586364: Epoch 88\n",
      "2024-11-22 11:45:25.596363: Current learning rate: 0.0084\n",
      "2024-11-22 11:47:36.080634: train_loss -0.6373\n",
      "2024-11-22 11:47:36.090634: val_loss -0.2715\n",
      "2024-11-22 11:47:36.090634: Pseudo dice [0.5569]\n",
      "2024-11-22 11:47:36.090634: Epoch time: 130.49 s\n",
      "2024-11-22 11:47:37.061005: \n",
      "2024-11-22 11:47:37.061005: Epoch 89\n",
      "2024-11-22 11:47:37.070997: Current learning rate: 0.00838\n",
      "2024-11-22 11:49:49.365479: train_loss -0.6245\n",
      "2024-11-22 11:49:49.365479: val_loss -0.4044\n",
      "2024-11-22 11:49:49.375479: Pseudo dice [0.6062]\n",
      "2024-11-22 11:49:49.385480: Epoch time: 132.3 s\n",
      "2024-11-22 11:49:50.516652: \n",
      "2024-11-22 11:49:50.526652: Epoch 90\n",
      "2024-11-22 11:49:50.526652: Current learning rate: 0.00836\n",
      "2024-11-22 11:52:01.023863: train_loss -0.638\n",
      "2024-11-22 11:52:01.033863: val_loss -0.4478\n",
      "2024-11-22 11:52:01.033863: Pseudo dice [0.6856]\n",
      "2024-11-22 11:52:01.043864: Epoch time: 130.51 s\n",
      "2024-11-22 11:52:02.003876: \n",
      "2024-11-22 11:52:02.013876: Epoch 91\n",
      "2024-11-22 11:52:02.013876: Current learning rate: 0.00835\n",
      "2024-11-22 11:54:12.584749: train_loss -0.6779\n",
      "2024-11-22 11:54:12.594749: val_loss -0.3746\n",
      "2024-11-22 11:54:12.604749: Pseudo dice [0.6617]\n",
      "2024-11-22 11:54:12.604749: Epoch time: 130.58 s\n",
      "2024-11-22 11:54:13.564764: \n",
      "2024-11-22 11:54:13.564764: Epoch 92\n",
      "2024-11-22 11:54:13.564764: Current learning rate: 0.00833\n",
      "2024-11-22 11:56:24.136548: train_loss -0.6836\n",
      "2024-11-22 11:56:24.146548: val_loss -0.2788\n",
      "2024-11-22 11:56:24.156548: Pseudo dice [0.5951]\n",
      "2024-11-22 11:56:24.156548: Epoch time: 130.57 s\n",
      "2024-11-22 11:56:25.126564: \n",
      "2024-11-22 11:56:25.126564: Epoch 93\n",
      "2024-11-22 11:56:25.136561: Current learning rate: 0.00831\n",
      "2024-11-22 11:58:36.211628: train_loss -0.7035\n",
      "2024-11-22 11:58:36.221628: val_loss -0.4034\n",
      "2024-11-22 11:58:36.231629: Pseudo dice [0.6964]\n",
      "2024-11-22 11:58:36.231629: Epoch time: 131.09 s\n",
      "2024-11-22 11:58:37.192683: \n",
      "2024-11-22 11:58:37.192683: Epoch 94\n",
      "2024-11-22 11:58:37.202683: Current learning rate: 0.00829\n",
      "2024-11-22 12:00:47.684476: train_loss -0.6933\n",
      "2024-11-22 12:00:47.694477: val_loss -0.3653\n",
      "2024-11-22 12:00:47.694477: Pseudo dice [0.619]\n",
      "2024-11-22 12:00:47.704477: Epoch time: 130.49 s\n",
      "2024-11-22 12:00:48.674850: \n",
      "2024-11-22 12:00:48.674850: Epoch 95\n",
      "2024-11-22 12:00:48.684850: Current learning rate: 0.00827\n",
      "2024-11-22 12:02:59.200211: train_loss -0.656\n",
      "2024-11-22 12:02:59.210211: val_loss -0.2997\n",
      "2024-11-22 12:02:59.220212: Pseudo dice [0.5988]\n",
      "2024-11-22 12:02:59.220212: Epoch time: 130.53 s\n",
      "2024-11-22 12:03:00.191256: \n",
      "2024-11-22 12:03:00.191256: Epoch 96\n",
      "2024-11-22 12:03:00.201255: Current learning rate: 0.00825\n",
      "2024-11-22 12:05:10.699736: train_loss -0.6876\n",
      "2024-11-22 12:05:10.709736: val_loss -0.2629\n",
      "2024-11-22 12:05:10.719737: Pseudo dice [0.5886]\n",
      "2024-11-22 12:05:10.719737: Epoch time: 130.52 s\n",
      "2024-11-22 12:05:11.700752: \n",
      "2024-11-22 12:05:11.700752: Epoch 97\n",
      "2024-11-22 12:05:11.710748: Current learning rate: 0.00824\n",
      "2024-11-22 12:07:22.577371: train_loss -0.7038\n",
      "2024-11-22 12:07:22.587372: val_loss -0.2947\n",
      "2024-11-22 12:07:22.597371: Pseudo dice [0.6]\n",
      "2024-11-22 12:07:22.607373: Epoch time: 130.88 s\n",
      "2024-11-22 12:07:23.577385: \n",
      "2024-11-22 12:07:23.587385: Epoch 98\n",
      "2024-11-22 12:07:23.587385: Current learning rate: 0.00822\n",
      "2024-11-22 12:09:34.069009: train_loss -0.598\n",
      "2024-11-22 12:09:34.079011: val_loss -0.3954\n",
      "2024-11-22 12:09:34.089010: Pseudo dice [0.6256]\n",
      "2024-11-22 12:09:34.099009: Epoch time: 130.49 s\n",
      "2024-11-22 12:09:35.069023: \n",
      "2024-11-22 12:09:35.079023: Epoch 99\n",
      "2024-11-22 12:09:35.079023: Current learning rate: 0.0082\n",
      "2024-11-22 12:11:45.529071: train_loss -0.6682\n",
      "2024-11-22 12:11:45.539070: val_loss -0.3048\n",
      "2024-11-22 12:11:45.539070: Pseudo dice [0.585]\n",
      "2024-11-22 12:11:45.549071: Epoch time: 130.46 s\n",
      "2024-11-22 12:11:46.749088: \n",
      "2024-11-22 12:11:46.759088: Epoch 100\n",
      "2024-11-22 12:11:46.759088: Current learning rate: 0.00818\n",
      "2024-11-22 12:13:57.309019: train_loss -0.6655\n",
      "2024-11-22 12:13:57.319018: val_loss -0.2329\n",
      "2024-11-22 12:13:57.329020: Pseudo dice [0.5447]\n",
      "2024-11-22 12:13:57.329020: Epoch time: 130.56 s\n",
      "2024-11-22 12:13:58.309033: \n",
      "2024-11-22 12:13:58.309033: Epoch 101\n",
      "2024-11-22 12:13:58.319032: Current learning rate: 0.00816\n",
      "2024-11-22 12:16:09.460930: train_loss -0.6951\n",
      "2024-11-22 12:16:09.470930: val_loss -0.381\n",
      "2024-11-22 12:16:09.480931: Pseudo dice [0.6591]\n",
      "2024-11-22 12:16:09.490931: Epoch time: 131.15 s\n",
      "2024-11-22 12:16:10.470943: \n",
      "2024-11-22 12:16:10.480944: Epoch 102\n",
      "2024-11-22 12:16:10.480944: Current learning rate: 0.00814\n",
      "2024-11-22 12:18:20.944128: train_loss -0.6608\n",
      "2024-11-22 12:18:20.954128: val_loss -0.4464\n",
      "2024-11-22 12:18:20.964128: Pseudo dice [0.7169]\n",
      "2024-11-22 12:18:20.964128: Epoch time: 130.47 s\n",
      "2024-11-22 12:18:21.954143: \n",
      "2024-11-22 12:18:21.954143: Epoch 103\n",
      "2024-11-22 12:18:21.964141: Current learning rate: 0.00813\n",
      "2024-11-22 12:20:32.423295: train_loss -0.5795\n",
      "2024-11-22 12:20:32.433296: val_loss -0.3715\n",
      "2024-11-22 12:20:32.443296: Pseudo dice [0.6106]\n",
      "2024-11-22 12:20:32.443296: Epoch time: 130.47 s\n",
      "2024-11-22 12:20:33.593311: \n",
      "2024-11-22 12:20:33.593311: Epoch 104\n",
      "2024-11-22 12:20:33.603311: Current learning rate: 0.00811\n",
      "2024-11-22 12:22:44.101332: train_loss -0.6624\n",
      "2024-11-22 12:22:44.111332: val_loss -0.4686\n",
      "2024-11-22 12:22:44.121334: Pseudo dice [0.7078]\n",
      "2024-11-22 12:22:44.131333: Epoch time: 130.51 s\n",
      "2024-11-22 12:22:45.102391: \n",
      "2024-11-22 12:22:45.112391: Epoch 105\n",
      "2024-11-22 12:22:45.112391: Current learning rate: 0.00809\n",
      "2024-11-22 12:24:56.340779: train_loss -0.6812\n",
      "2024-11-22 12:24:56.360779: val_loss -0.4362\n",
      "2024-11-22 12:24:56.370778: Pseudo dice [0.6677]\n",
      "2024-11-22 12:24:56.370778: Epoch time: 131.24 s\n",
      "2024-11-22 12:24:57.351843: \n",
      "2024-11-22 12:24:57.361843: Epoch 106\n",
      "2024-11-22 12:24:57.361843: Current learning rate: 0.00807\n",
      "2024-11-22 12:27:07.828271: train_loss -0.7194\n",
      "2024-11-22 12:27:07.838271: val_loss -0.4221\n",
      "2024-11-22 12:27:07.838271: Pseudo dice [0.691]\n",
      "2024-11-22 12:27:07.848273: Epoch time: 130.48 s\n",
      "2024-11-22 12:27:08.828286: \n",
      "2024-11-22 12:27:08.828286: Epoch 107\n",
      "2024-11-22 12:27:08.838286: Current learning rate: 0.00805\n",
      "2024-11-22 12:29:19.359474: train_loss -0.6939\n",
      "2024-11-22 12:29:19.359474: val_loss -0.3553\n",
      "2024-11-22 12:29:19.369475: Pseudo dice [0.6548]\n",
      "2024-11-22 12:29:19.379474: Epoch time: 130.53 s\n",
      "2024-11-22 12:29:20.359488: \n",
      "2024-11-22 12:29:20.359488: Epoch 108\n",
      "2024-11-22 12:29:20.369488: Current learning rate: 0.00803\n",
      "2024-11-22 12:31:30.932798: train_loss -0.692\n",
      "2024-11-22 12:31:30.942799: val_loss -0.4853\n",
      "2024-11-22 12:31:30.942799: Pseudo dice [0.6919]\n",
      "2024-11-22 12:31:30.952800: Epoch time: 130.57 s\n",
      "2024-11-22 12:31:30.962799: Yayy! New best EMA pseudo Dice: 0.6484\n",
      "2024-11-22 12:31:32.162815: \n",
      "2024-11-22 12:31:32.162815: Epoch 109\n",
      "2024-11-22 12:31:32.172815: Current learning rate: 0.00801\n",
      "2024-11-22 12:33:43.235892: train_loss -0.6958\n",
      "2024-11-22 12:33:43.245893: val_loss -0.4146\n",
      "2024-11-22 12:33:43.245893: Pseudo dice [0.6628]\n",
      "2024-11-22 12:33:43.255892: Epoch time: 131.07 s\n",
      "2024-11-22 12:33:43.265892: Yayy! New best EMA pseudo Dice: 0.6498\n",
      "2024-11-22 12:33:44.485909: \n",
      "2024-11-22 12:33:44.495909: Epoch 110\n",
      "2024-11-22 12:33:44.495909: Current learning rate: 0.008\n",
      "2024-11-22 12:35:55.036580: train_loss -0.6977\n",
      "2024-11-22 12:35:55.046580: val_loss -0.4493\n",
      "2024-11-22 12:35:55.046580: Pseudo dice [0.6898]\n",
      "2024-11-22 12:35:55.056579: Epoch time: 130.55 s\n",
      "2024-11-22 12:35:55.056579: Yayy! New best EMA pseudo Dice: 0.6538\n",
      "2024-11-22 12:35:56.277715: \n",
      "2024-11-22 12:35:56.287715: Epoch 111\n",
      "2024-11-22 12:35:56.287715: Current learning rate: 0.00798\n",
      "2024-11-22 12:38:06.825456: train_loss -0.7162\n",
      "2024-11-22 12:38:06.835457: val_loss -0.3498\n",
      "2024-11-22 12:38:06.845456: Pseudo dice [0.6447]\n",
      "2024-11-22 12:38:06.855457: Epoch time: 130.55 s\n",
      "2024-11-22 12:38:07.835470: \n",
      "2024-11-22 12:38:07.835470: Epoch 112\n",
      "2024-11-22 12:38:07.845469: Current learning rate: 0.00796\n",
      "2024-11-22 12:40:18.378052: train_loss -0.6894\n",
      "2024-11-22 12:40:18.388051: val_loss -0.4465\n",
      "2024-11-22 12:40:18.388051: Pseudo dice [0.6891]\n",
      "2024-11-22 12:40:18.398052: Epoch time: 130.54 s\n",
      "2024-11-22 12:40:18.398052: Yayy! New best EMA pseudo Dice: 0.6566\n",
      "2024-11-22 12:40:19.618407: \n",
      "2024-11-22 12:40:19.628407: Epoch 113\n",
      "2024-11-22 12:40:19.628407: Current learning rate: 0.00794\n",
      "2024-11-22 12:42:30.743503: train_loss -0.6985\n",
      "2024-11-22 12:42:30.753503: val_loss -0.4\n",
      "2024-11-22 12:42:30.753503: Pseudo dice [0.618]\n",
      "2024-11-22 12:42:30.763502: Epoch time: 131.13 s\n",
      "2024-11-22 12:42:31.733951: \n",
      "2024-11-22 12:42:31.743952: Epoch 114\n",
      "2024-11-22 12:42:31.743952: Current learning rate: 0.00792\n",
      "2024-11-22 12:44:42.296364: train_loss -0.7079\n",
      "2024-11-22 12:44:42.306365: val_loss -0.3712\n",
      "2024-11-22 12:44:42.306365: Pseudo dice [0.6533]\n",
      "2024-11-22 12:44:42.316365: Epoch time: 130.56 s\n",
      "2024-11-22 12:44:43.286378: \n",
      "2024-11-22 12:44:43.296378: Epoch 115\n",
      "2024-11-22 12:44:43.296378: Current learning rate: 0.0079\n",
      "2024-11-22 12:46:53.872649: train_loss -0.7009\n",
      "2024-11-22 12:46:53.882650: val_loss -0.4804\n",
      "2024-11-22 12:46:53.892650: Pseudo dice [0.7107]\n",
      "2024-11-22 12:46:53.892650: Epoch time: 130.59 s\n",
      "2024-11-22 12:46:53.902650: Yayy! New best EMA pseudo Dice: 0.6586\n",
      "2024-11-22 12:46:55.122963: \n",
      "2024-11-22 12:46:55.132963: Epoch 116\n",
      "2024-11-22 12:46:55.132963: Current learning rate: 0.00789\n",
      "2024-11-22 12:49:05.634856: train_loss -0.717\n",
      "2024-11-22 12:49:05.644857: val_loss -0.4962\n",
      "2024-11-22 12:49:05.654857: Pseudo dice [0.686]\n",
      "2024-11-22 12:49:05.654857: Epoch time: 130.51 s\n",
      "2024-11-22 12:49:05.664857: Yayy! New best EMA pseudo Dice: 0.6613\n",
      "2024-11-22 12:49:06.885880: \n",
      "2024-11-22 12:49:06.895880: Epoch 117\n",
      "2024-11-22 12:49:06.895880: Current learning rate: 0.00787\n",
      "2024-11-22 12:51:18.133342: train_loss -0.699\n",
      "2024-11-22 12:51:18.153343: val_loss -0.2469\n",
      "2024-11-22 12:51:18.163343: Pseudo dice [0.6182]\n",
      "2024-11-22 12:51:18.173343: Epoch time: 131.25 s\n",
      "2024-11-22 12:51:19.154248: \n",
      "2024-11-22 12:51:19.164247: Epoch 118\n",
      "2024-11-22 12:51:19.164247: Current learning rate: 0.00785\n",
      "2024-11-22 12:53:29.684236: train_loss -0.7082\n",
      "2024-11-22 12:53:29.694237: val_loss -0.4084\n",
      "2024-11-22 12:53:29.704238: Pseudo dice [0.642]\n",
      "2024-11-22 12:53:29.704238: Epoch time: 130.53 s\n",
      "2024-11-22 12:53:30.864895: \n",
      "2024-11-22 12:53:30.874894: Epoch 119\n",
      "2024-11-22 12:53:30.874894: Current learning rate: 0.00783\n",
      "2024-11-22 12:55:41.514112: train_loss -0.699\n",
      "2024-11-22 12:55:41.524111: val_loss -0.3366\n",
      "2024-11-22 12:55:41.534112: Pseudo dice [0.6206]\n",
      "2024-11-22 12:55:41.534112: Epoch time: 130.65 s\n",
      "2024-11-22 12:55:42.524126: \n",
      "2024-11-22 12:55:42.534126: Epoch 120\n",
      "2024-11-22 12:55:42.534126: Current learning rate: 0.00781\n",
      "2024-11-22 12:57:53.072021: train_loss -0.7082\n",
      "2024-11-22 12:57:53.082023: val_loss -0.3879\n",
      "2024-11-22 12:57:53.092022: Pseudo dice [0.6662]\n",
      "2024-11-22 12:57:53.092022: Epoch time: 130.55 s\n",
      "2024-11-22 12:57:54.082340: \n",
      "2024-11-22 12:57:54.082340: Epoch 121\n",
      "2024-11-22 12:57:54.082340: Current learning rate: 0.00779\n",
      "2024-11-22 13:00:05.312726: train_loss -0.7489\n",
      "2024-11-22 13:00:05.342727: val_loss -0.458\n",
      "2024-11-22 13:00:05.342727: Pseudo dice [0.6708]\n",
      "2024-11-22 13:00:05.352728: Epoch time: 131.24 s\n",
      "2024-11-22 13:00:06.333793: \n",
      "2024-11-22 13:00:06.343793: Epoch 122\n",
      "2024-11-22 13:00:06.343793: Current learning rate: 0.00777\n",
      "2024-11-22 13:02:16.960130: train_loss -0.7002\n",
      "2024-11-22 13:02:16.970130: val_loss -0.4085\n",
      "2024-11-22 13:02:16.980131: Pseudo dice [0.6538]\n",
      "2024-11-22 13:02:16.990131: Epoch time: 130.63 s\n",
      "2024-11-22 13:02:17.970144: \n",
      "2024-11-22 13:02:17.980145: Epoch 123\n",
      "2024-11-22 13:02:17.980145: Current learning rate: 0.00776\n",
      "2024-11-22 13:04:28.551845: train_loss -0.7139\n",
      "2024-11-22 13:04:28.561846: val_loss -0.3985\n",
      "2024-11-22 13:04:28.571846: Pseudo dice [0.6633]\n",
      "2024-11-22 13:04:28.581846: Epoch time: 130.58 s\n",
      "2024-11-22 13:04:29.562183: \n",
      "2024-11-22 13:04:29.572182: Epoch 124\n",
      "2024-11-22 13:04:29.572182: Current learning rate: 0.00774\n",
      "2024-11-22 13:06:40.169694: train_loss -0.6822\n",
      "2024-11-22 13:06:40.179694: val_loss -0.4401\n",
      "2024-11-22 13:06:40.189695: Pseudo dice [0.6586]\n",
      "2024-11-22 13:06:40.199695: Epoch time: 130.61 s\n",
      "2024-11-22 13:06:41.179707: \n",
      "2024-11-22 13:06:41.189708: Epoch 125\n",
      "2024-11-22 13:06:41.189708: Current learning rate: 0.00772\n",
      "2024-11-22 13:08:51.879479: train_loss -0.7226\n",
      "2024-11-22 13:08:51.899480: val_loss -0.4002\n",
      "2024-11-22 13:08:51.899480: Pseudo dice [0.5962]\n",
      "2024-11-22 13:08:51.909480: Epoch time: 130.7 s\n",
      "2024-11-22 13:08:53.059495: \n",
      "2024-11-22 13:08:53.069495: Epoch 126\n",
      "2024-11-22 13:08:53.069495: Current learning rate: 0.0077\n",
      "2024-11-22 13:11:03.680755: train_loss -0.7118\n",
      "2024-11-22 13:11:03.690756: val_loss -0.3799\n",
      "2024-11-22 13:11:03.690756: Pseudo dice [0.6446]\n",
      "2024-11-22 13:11:03.700755: Epoch time: 130.62 s\n",
      "2024-11-22 13:11:04.681075: \n",
      "2024-11-22 13:11:04.681075: Epoch 127\n",
      "2024-11-22 13:11:04.691075: Current learning rate: 0.00768\n",
      "2024-11-22 13:13:15.281566: train_loss -0.7568\n",
      "2024-11-22 13:13:15.291566: val_loss -0.383\n",
      "2024-11-22 13:13:15.291566: Pseudo dice [0.6341]\n",
      "2024-11-22 13:13:15.301568: Epoch time: 130.6 s\n",
      "2024-11-22 13:13:16.281580: \n",
      "2024-11-22 13:13:16.291580: Epoch 128\n",
      "2024-11-22 13:13:16.291580: Current learning rate: 0.00766\n",
      "2024-11-22 13:15:26.966650: train_loss -0.7218\n",
      "2024-11-22 13:15:26.976651: val_loss -0.3656\n",
      "2024-11-22 13:15:26.986651: Pseudo dice [0.6126]\n",
      "2024-11-22 13:15:26.996652: Epoch time: 130.69 s\n",
      "2024-11-22 13:15:27.976664: \n",
      "2024-11-22 13:15:27.986664: Epoch 129\n",
      "2024-11-22 13:15:27.986664: Current learning rate: 0.00764\n",
      "2024-11-22 13:17:38.548354: train_loss -0.6531\n",
      "2024-11-22 13:17:38.558355: val_loss -0.3562\n",
      "2024-11-22 13:17:38.568355: Pseudo dice [0.6715]\n",
      "2024-11-22 13:17:38.578356: Epoch time: 130.57 s\n",
      "2024-11-22 13:17:39.558368: \n",
      "2024-11-22 13:17:39.568368: Epoch 130\n",
      "2024-11-22 13:17:39.568368: Current learning rate: 0.00763\n",
      "2024-11-22 13:19:50.219012: train_loss -0.647\n",
      "2024-11-22 13:19:50.227016: val_loss -0.3554\n",
      "2024-11-22 13:19:50.237019: Pseudo dice [0.6198]\n",
      "2024-11-22 13:19:50.237019: Epoch time: 130.66 s\n",
      "2024-11-22 13:19:51.227032: \n",
      "2024-11-22 13:19:51.237032: Epoch 131\n",
      "2024-11-22 13:19:51.237032: Current learning rate: 0.00761\n",
      "2024-11-22 13:22:01.826526: train_loss -0.7075\n",
      "2024-11-22 13:22:01.836526: val_loss -0.5273\n",
      "2024-11-22 13:22:01.836526: Pseudo dice [0.7357]\n",
      "2024-11-22 13:22:01.846527: Epoch time: 130.6 s\n",
      "2024-11-22 13:22:02.836541: \n",
      "2024-11-22 13:22:02.836541: Epoch 132\n",
      "2024-11-22 13:22:02.846540: Current learning rate: 0.00759\n",
      "2024-11-22 13:24:13.375929: train_loss -0.7346\n",
      "2024-11-22 13:24:13.395930: val_loss -0.2488\n",
      "2024-11-22 13:24:13.405930: Pseudo dice [0.605]\n",
      "2024-11-22 13:24:13.405930: Epoch time: 130.54 s\n",
      "2024-11-22 13:24:14.565948: \n",
      "2024-11-22 13:24:14.565948: Epoch 133\n",
      "2024-11-22 13:24:14.575945: Current learning rate: 0.00757\n",
      "2024-11-22 13:26:25.167320: train_loss -0.7116\n",
      "2024-11-22 13:26:25.177321: val_loss -0.3456\n",
      "2024-11-22 13:26:25.187322: Pseudo dice [0.6315]\n",
      "2024-11-22 13:26:25.197322: Epoch time: 130.6 s\n",
      "2024-11-22 13:26:26.187336: \n",
      "2024-11-22 13:26:26.187336: Epoch 134\n",
      "2024-11-22 13:26:26.197335: Current learning rate: 0.00755\n",
      "2024-11-22 13:28:36.736264: train_loss -0.7398\n",
      "2024-11-22 13:28:36.746264: val_loss -0.3555\n",
      "2024-11-22 13:28:36.756265: Pseudo dice [0.5943]\n",
      "2024-11-22 13:28:36.766264: Epoch time: 130.55 s\n",
      "2024-11-22 13:28:37.766596: \n",
      "2024-11-22 13:28:37.776596: Epoch 135\n",
      "2024-11-22 13:28:37.776596: Current learning rate: 0.00753\n",
      "2024-11-22 13:30:48.395192: train_loss -0.6762\n",
      "2024-11-22 13:30:48.405192: val_loss -0.4129\n",
      "2024-11-22 13:30:48.415192: Pseudo dice [0.7056]\n",
      "2024-11-22 13:30:48.415192: Epoch time: 130.63 s\n",
      "2024-11-22 13:30:49.425208: \n",
      "2024-11-22 13:30:49.425208: Epoch 136\n",
      "2024-11-22 13:30:49.425208: Current learning rate: 0.00751\n",
      "2024-11-22 13:32:59.999487: train_loss -0.7102\n",
      "2024-11-22 13:33:00.009488: val_loss -0.4657\n",
      "2024-11-22 13:33:00.009488: Pseudo dice [0.7289]\n",
      "2024-11-22 13:33:00.019487: Epoch time: 130.58 s\n",
      "2024-11-22 13:33:01.029503: \n",
      "2024-11-22 13:33:01.029503: Epoch 137\n",
      "2024-11-22 13:33:01.039501: Current learning rate: 0.0075\n",
      "2024-11-22 13:35:11.604498: train_loss -0.7235\n",
      "2024-11-22 13:35:11.614499: val_loss -0.4483\n",
      "2024-11-22 13:35:11.624500: Pseudo dice [0.7002]\n",
      "2024-11-22 13:35:11.624500: Epoch time: 130.57 s\n",
      "2024-11-22 13:35:12.635664: \n",
      "2024-11-22 13:35:12.645664: Epoch 138\n",
      "2024-11-22 13:35:12.645664: Current learning rate: 0.00748\n",
      "2024-11-22 13:37:23.240282: train_loss -0.6903\n",
      "2024-11-22 13:37:23.250282: val_loss -0.3847\n",
      "2024-11-22 13:37:23.260283: Pseudo dice [0.6863]\n",
      "2024-11-22 13:37:23.270283: Epoch time: 130.6 s\n",
      "2024-11-22 13:37:23.270283: Yayy! New best EMA pseudo Dice: 0.6632\n",
      "2024-11-22 13:37:24.510612: \n",
      "2024-11-22 13:37:24.520612: Epoch 139\n",
      "2024-11-22 13:37:24.530612: Current learning rate: 0.00746\n",
      "2024-11-22 13:39:35.061804: train_loss -0.719\n",
      "2024-11-22 13:39:35.081805: val_loss -0.4027\n",
      "2024-11-22 13:39:35.081805: Pseudo dice [0.6461]\n",
      "2024-11-22 13:39:35.091805: Epoch time: 130.55 s\n",
      "2024-11-22 13:39:36.271820: \n",
      "2024-11-22 13:39:36.281820: Epoch 140\n",
      "2024-11-22 13:39:36.281820: Current learning rate: 0.00744\n",
      "2024-11-22 13:41:46.752176: train_loss -0.7147\n",
      "2024-11-22 13:41:46.762175: val_loss -0.291\n",
      "2024-11-22 13:41:46.772176: Pseudo dice [0.6063]\n",
      "2024-11-22 13:41:46.782177: Epoch time: 130.48 s\n",
      "2024-11-22 13:41:47.792193: \n",
      "2024-11-22 13:41:47.792193: Epoch 141\n",
      "2024-11-22 13:41:47.802190: Current learning rate: 0.00742\n",
      "2024-11-22 13:44:00.661486: train_loss -0.7562\n",
      "2024-11-22 13:44:00.674489: val_loss -0.251\n",
      "2024-11-22 13:44:00.680490: Pseudo dice [0.6493]\n",
      "2024-11-22 13:44:00.687493: Epoch time: 132.87 s\n",
      "2024-11-22 13:44:01.700828: \n",
      "2024-11-22 13:44:01.707832: Epoch 142\n",
      "2024-11-22 13:44:01.712832: Current learning rate: 0.0074\n",
      "2024-11-22 13:46:14.544701: train_loss -0.7014\n",
      "2024-11-22 13:46:14.552892: val_loss -0.5402\n",
      "2024-11-22 13:46:14.557885: Pseudo dice [0.7187]\n",
      "2024-11-22 13:46:14.566389: Epoch time: 132.85 s\n",
      "2024-11-22 13:46:15.592473: \n",
      "2024-11-22 13:46:15.599991: Epoch 143\n",
      "2024-11-22 13:46:15.604992: Current learning rate: 0.00738\n",
      "2024-11-22 13:48:26.432279: train_loss -0.7324\n",
      "2024-11-22 13:48:26.467792: val_loss -0.5154\n",
      "2024-11-22 13:48:26.474794: Pseudo dice [0.6906]\n",
      "2024-11-22 13:48:26.481796: Epoch time: 130.84 s\n",
      "2024-11-22 13:48:26.488797: Yayy! New best EMA pseudo Dice: 0.6645\n",
      "2024-11-22 13:48:27.804483: \n",
      "2024-11-22 13:48:27.815947: Epoch 144\n",
      "2024-11-22 13:48:27.821949: Current learning rate: 0.00737\n",
      "2024-11-22 13:50:38.645970: train_loss -0.7047\n",
      "2024-11-22 13:50:38.657973: val_loss -0.4083\n",
      "2024-11-22 13:50:38.665975: Pseudo dice [0.6574]\n",
      "2024-11-22 13:50:38.672976: Epoch time: 130.84 s\n",
      "2024-11-22 13:50:39.742220: \n",
      "2024-11-22 13:50:39.748222: Epoch 145\n",
      "2024-11-22 13:50:39.754224: Current learning rate: 0.00735\n",
      "2024-11-22 13:52:51.185827: train_loss -0.6913\n",
      "2024-11-22 13:52:51.194831: val_loss -0.4784\n",
      "2024-11-22 13:52:51.202832: Pseudo dice [0.66]\n",
      "2024-11-22 13:52:51.208853: Epoch time: 131.44 s\n",
      "2024-11-22 13:52:52.425903: \n",
      "2024-11-22 13:52:52.432904: Epoch 146\n",
      "2024-11-22 13:52:52.437906: Current learning rate: 0.00733\n",
      "2024-11-22 13:55:04.961873: train_loss -0.7169\n",
      "2024-11-22 13:55:04.969877: val_loss -0.3032\n",
      "2024-11-22 13:55:04.977878: Pseudo dice [0.6279]\n",
      "2024-11-22 13:55:04.982384: Epoch time: 132.54 s\n",
      "2024-11-22 13:55:06.007011: \n",
      "2024-11-22 13:55:06.017449: Epoch 147\n",
      "2024-11-22 13:55:06.022450: Current learning rate: 0.00731\n",
      "2024-11-22 13:57:18.268062: train_loss -0.7276\n",
      "2024-11-22 13:57:18.277064: val_loss -0.3701\n",
      "2024-11-22 13:57:18.283065: Pseudo dice [0.6718]\n",
      "2024-11-22 13:57:18.288066: Epoch time: 132.26 s\n",
      "2024-11-22 13:57:19.301134: \n",
      "2024-11-22 13:57:19.307136: Epoch 148\n",
      "2024-11-22 13:57:19.312136: Current learning rate: 0.00729\n",
      "2024-11-22 13:59:31.333546: train_loss -0.7184\n",
      "2024-11-22 13:59:31.344550: val_loss -0.4254\n",
      "2024-11-22 13:59:31.350551: Pseudo dice [0.712]\n",
      "2024-11-22 13:59:31.355552: Epoch time: 132.03 s\n",
      "2024-11-22 13:59:31.360555: Yayy! New best EMA pseudo Dice: 0.6662\n",
      "2024-11-22 13:59:32.623477: \n",
      "2024-11-22 13:59:32.630479: Epoch 149\n",
      "2024-11-22 13:59:32.635481: Current learning rate: 0.00727\n",
      "2024-11-22 14:01:44.137783: train_loss -0.7177\n",
      "2024-11-22 14:01:44.144784: val_loss -0.4912\n",
      "2024-11-22 14:01:44.151786: Pseudo dice [0.67]\n",
      "2024-11-22 14:01:44.157786: Epoch time: 131.52 s\n",
      "2024-11-22 14:01:44.386202: Yayy! New best EMA pseudo Dice: 0.6665\n",
      "2024-11-22 14:01:45.638058: \n",
      "2024-11-22 14:01:45.648102: Epoch 150\n",
      "2024-11-22 14:01:45.652102: Current learning rate: 0.00725\n",
      "2024-11-22 14:03:57.404838: train_loss -0.7233\n",
      "2024-11-22 14:03:57.417840: val_loss -0.3759\n",
      "2024-11-22 14:03:57.424842: Pseudo dice [0.6498]\n",
      "2024-11-22 14:03:57.431843: Epoch time: 131.77 s\n",
      "2024-11-22 14:03:58.455957: \n",
      "2024-11-22 14:03:58.462958: Epoch 151\n",
      "2024-11-22 14:03:58.467959: Current learning rate: 0.00724\n",
      "2024-11-22 14:06:09.080834: train_loss -0.756\n",
      "2024-11-22 14:06:09.092837: val_loss -0.4838\n",
      "2024-11-22 14:06:09.100839: Pseudo dice [0.7146]\n",
      "2024-11-22 14:06:09.107841: Epoch time: 130.63 s\n",
      "2024-11-22 14:06:09.114842: Yayy! New best EMA pseudo Dice: 0.6698\n",
      "2024-11-22 14:06:10.402783: \n",
      "2024-11-22 14:06:10.409784: Epoch 152\n",
      "2024-11-22 14:06:10.414784: Current learning rate: 0.00722\n",
      "2024-11-22 14:08:21.348255: train_loss -0.7603\n",
      "2024-11-22 14:08:21.371765: val_loss -0.546\n",
      "2024-11-22 14:08:21.379766: Pseudo dice [0.7293]\n",
      "2024-11-22 14:08:21.386768: Epoch time: 130.95 s\n",
      "2024-11-22 14:08:21.391770: Yayy! New best EMA pseudo Dice: 0.6758\n",
      "2024-11-22 14:08:22.865098: \n",
      "2024-11-22 14:08:22.873100: Epoch 153\n",
      "2024-11-22 14:08:22.878102: Current learning rate: 0.0072\n",
      "2024-11-22 14:10:33.660373: train_loss -0.7286\n",
      "2024-11-22 14:10:33.672375: val_loss -0.4145\n",
      "2024-11-22 14:10:33.679378: Pseudo dice [0.7022]\n",
      "2024-11-22 14:10:33.685379: Epoch time: 130.8 s\n",
      "2024-11-22 14:10:33.690380: Yayy! New best EMA pseudo Dice: 0.6784\n",
      "2024-11-22 14:10:35.023659: \n",
      "2024-11-22 14:10:35.036859: Epoch 154\n",
      "2024-11-22 14:10:35.041860: Current learning rate: 0.00718\n",
      "2024-11-22 14:12:44.867415: train_loss -0.7373\n",
      "2024-11-22 14:12:44.875419: val_loss -0.4538\n",
      "2024-11-22 14:12:44.881420: Pseudo dice [0.6727]\n",
      "2024-11-22 14:12:44.886421: Epoch time: 129.84 s\n",
      "2024-11-22 14:12:45.933220: \n",
      "2024-11-22 14:12:45.939221: Epoch 155\n",
      "2024-11-22 14:12:45.943222: Current learning rate: 0.00716\n",
      "2024-11-22 14:14:56.186768: train_loss -0.7388\n",
      "2024-11-22 14:14:56.199771: val_loss -0.44\n",
      "2024-11-22 14:14:56.206772: Pseudo dice [0.6143]\n",
      "2024-11-22 14:14:56.211773: Epoch time: 130.25 s\n",
      "2024-11-22 14:14:57.237071: \n",
      "2024-11-22 14:14:57.242577: Epoch 156\n",
      "2024-11-22 14:14:57.246578: Current learning rate: 0.00714\n",
      "2024-11-22 14:17:07.240760: train_loss -0.7555\n",
      "2024-11-22 14:17:07.240760: val_loss -0.3559\n",
      "2024-11-22 14:17:07.250760: Pseudo dice [0.6501]\n",
      "2024-11-22 14:17:07.260761: Epoch time: 130.0 s\n",
      "2024-11-22 14:17:08.290778: \n",
      "2024-11-22 14:17:08.290778: Epoch 157\n",
      "2024-11-22 14:17:08.300776: Current learning rate: 0.00712\n",
      "2024-11-22 14:19:18.810051: train_loss -0.7347\n",
      "2024-11-22 14:19:18.830053: val_loss -0.4187\n",
      "2024-11-22 14:19:18.830053: Pseudo dice [0.6557]\n",
      "2024-11-22 14:19:18.840053: Epoch time: 130.52 s\n",
      "2024-11-22 14:19:19.870440: \n",
      "2024-11-22 14:19:19.870440: Epoch 158\n",
      "2024-11-22 14:19:19.870440: Current learning rate: 0.0071\n",
      "2024-11-22 14:21:30.411084: train_loss -0.7392\n",
      "2024-11-22 14:21:30.421084: val_loss -0.515\n",
      "2024-11-22 14:21:30.431085: Pseudo dice [0.6705]\n",
      "2024-11-22 14:21:30.431085: Epoch time: 130.55 s\n",
      "2024-11-22 14:21:31.451477: \n",
      "2024-11-22 14:21:31.461470: Epoch 159\n",
      "2024-11-22 14:21:31.461470: Current learning rate: 0.00709\n",
      "2024-11-22 14:23:42.027095: train_loss -0.7617\n",
      "2024-11-22 14:23:42.047095: val_loss -0.4957\n",
      "2024-11-22 14:23:42.047095: Pseudo dice [0.6979]\n",
      "2024-11-22 14:23:42.057095: Epoch time: 130.58 s\n",
      "2024-11-22 14:23:43.257120: \n",
      "2024-11-22 14:23:43.267113: Epoch 160\n",
      "2024-11-22 14:23:43.267113: Current learning rate: 0.00707\n",
      "2024-11-22 14:25:53.808104: train_loss -0.7482\n",
      "2024-11-22 14:25:53.818104: val_loss -0.1768\n",
      "2024-11-22 14:25:53.818104: Pseudo dice [0.5625]\n",
      "2024-11-22 14:25:53.828104: Epoch time: 130.55 s\n",
      "2024-11-22 14:25:54.858474: \n",
      "2024-11-22 14:25:54.858474: Epoch 161\n",
      "2024-11-22 14:25:54.858474: Current learning rate: 0.00705\n",
      "2024-11-22 14:28:05.501913: train_loss -0.7344\n",
      "2024-11-22 14:28:05.511913: val_loss -0.5535\n",
      "2024-11-22 14:28:05.521913: Pseudo dice [0.7066]\n",
      "2024-11-22 14:28:05.531914: Epoch time: 130.65 s\n",
      "2024-11-22 14:28:06.561936: \n",
      "2024-11-22 14:28:06.571935: Epoch 162\n",
      "2024-11-22 14:28:06.571935: Current learning rate: 0.00703\n",
      "2024-11-22 14:30:17.079323: train_loss -0.7679\n",
      "2024-11-22 14:30:17.089324: val_loss -0.5468\n",
      "2024-11-22 14:30:17.099324: Pseudo dice [0.7301]\n",
      "2024-11-22 14:30:17.109324: Epoch time: 130.52 s\n",
      "2024-11-22 14:30:18.139349: \n",
      "2024-11-22 14:30:18.139349: Epoch 163\n",
      "2024-11-22 14:30:18.149347: Current learning rate: 0.00701\n",
      "2024-11-22 14:32:28.649525: train_loss -0.7463\n",
      "2024-11-22 14:32:28.659525: val_loss -0.4311\n",
      "2024-11-22 14:32:28.659525: Pseudo dice [0.6841]\n",
      "2024-11-22 14:32:28.669526: Epoch time: 130.51 s\n",
      "2024-11-22 14:32:29.709545: \n",
      "2024-11-22 14:32:29.709545: Epoch 164\n",
      "2024-11-22 14:32:29.719541: Current learning rate: 0.00699\n",
      "2024-11-22 14:34:40.235781: train_loss -0.698\n",
      "2024-11-22 14:34:40.245781: val_loss -0.4336\n",
      "2024-11-22 14:34:40.255781: Pseudo dice [0.616]\n",
      "2024-11-22 14:34:40.255781: Epoch time: 130.53 s\n",
      "2024-11-22 14:34:41.265805: \n",
      "2024-11-22 14:34:41.265805: Epoch 165\n",
      "2024-11-22 14:34:41.275796: Current learning rate: 0.00697\n",
      "2024-11-22 14:36:51.850029: train_loss -0.7134\n",
      "2024-11-22 14:36:51.860029: val_loss -0.3782\n",
      "2024-11-22 14:36:51.870030: Pseudo dice [0.5969]\n",
      "2024-11-22 14:36:51.870030: Epoch time: 130.58 s\n",
      "2024-11-22 14:36:52.870862: \n",
      "2024-11-22 14:36:52.880856: Epoch 166\n",
      "2024-11-22 14:36:52.880856: Current learning rate: 0.00696\n",
      "2024-11-22 14:39:03.382769: train_loss -0.7514\n",
      "2024-11-22 14:39:03.402769: val_loss -0.3659\n",
      "2024-11-22 14:39:03.412769: Pseudo dice [0.6757]\n",
      "2024-11-22 14:39:03.412769: Epoch time: 130.51 s\n",
      "2024-11-22 14:39:04.593147: \n",
      "2024-11-22 14:39:04.603140: Epoch 167\n",
      "2024-11-22 14:39:04.603140: Current learning rate: 0.00694\n",
      "2024-11-22 14:41:15.200526: train_loss -0.7563\n",
      "2024-11-22 14:41:15.210526: val_loss -0.3875\n",
      "2024-11-22 14:41:15.220526: Pseudo dice [0.6567]\n",
      "2024-11-22 14:41:15.220526: Epoch time: 130.61 s\n",
      "2024-11-22 14:41:16.240549: \n",
      "2024-11-22 14:41:16.250548: Epoch 168\n",
      "2024-11-22 14:41:16.250548: Current learning rate: 0.00692\n",
      "2024-11-22 14:43:26.926789: train_loss -0.7472\n",
      "2024-11-22 14:43:26.936790: val_loss -0.5207\n",
      "2024-11-22 14:43:26.936790: Pseudo dice [0.738]\n",
      "2024-11-22 14:43:26.946790: Epoch time: 130.69 s\n",
      "2024-11-22 14:43:27.966812: \n",
      "2024-11-22 14:43:27.976812: Epoch 169\n",
      "2024-11-22 14:43:27.976812: Current learning rate: 0.0069\n",
      "2024-11-22 14:45:38.514005: train_loss -0.7555\n",
      "2024-11-22 14:45:38.524005: val_loss -0.4088\n",
      "2024-11-22 14:45:38.534005: Pseudo dice [0.6554]\n",
      "2024-11-22 14:45:38.534005: Epoch time: 130.55 s\n",
      "2024-11-22 14:45:39.554410: \n",
      "2024-11-22 14:45:39.554410: Epoch 170\n",
      "2024-11-22 14:45:39.564408: Current learning rate: 0.00688\n",
      "2024-11-22 14:47:50.824491: train_loss -0.7317\n",
      "2024-11-22 14:47:50.844491: val_loss -0.4187\n",
      "2024-11-22 14:47:50.854491: Pseudo dice [0.6484]\n",
      "2024-11-22 14:47:50.854491: Epoch time: 131.27 s\n",
      "2024-11-22 14:47:51.874514: \n",
      "2024-11-22 14:47:51.884513: Epoch 171\n",
      "2024-11-22 14:47:51.884513: Current learning rate: 0.00686\n",
      "2024-11-22 14:50:02.332114: train_loss -0.7336\n",
      "2024-11-22 14:50:02.352114: val_loss -0.4169\n",
      "2024-11-22 14:50:02.352114: Pseudo dice [0.6768]\n",
      "2024-11-22 14:50:02.362114: Epoch time: 130.46 s\n",
      "2024-11-22 14:50:03.382138: \n",
      "2024-11-22 14:50:03.382138: Epoch 172\n",
      "2024-11-22 14:50:03.392137: Current learning rate: 0.00684\n",
      "2024-11-22 14:52:13.917462: train_loss -0.7366\n",
      "2024-11-22 14:52:13.927462: val_loss -0.5192\n",
      "2024-11-22 14:52:13.937462: Pseudo dice [0.7145]\n",
      "2024-11-22 14:52:13.937462: Epoch time: 130.54 s\n",
      "2024-11-22 14:52:14.957485: \n",
      "2024-11-22 14:52:14.957485: Epoch 173\n",
      "2024-11-22 14:52:14.967478: Current learning rate: 0.00682\n",
      "2024-11-22 14:54:25.442786: train_loss -0.7581\n",
      "2024-11-22 14:54:25.452786: val_loss -0.3196\n",
      "2024-11-22 14:54:25.462786: Pseudo dice [0.6353]\n",
      "2024-11-22 14:54:25.462786: Epoch time: 130.49 s\n",
      "2024-11-22 14:54:26.662972: \n",
      "2024-11-22 14:54:26.662972: Epoch 174\n",
      "2024-11-22 14:54:26.672964: Current learning rate: 0.0068\n",
      "2024-11-22 14:56:37.159848: train_loss -0.746\n",
      "2024-11-22 14:56:37.169848: val_loss -0.4862\n",
      "2024-11-22 14:56:37.179849: Pseudo dice [0.6992]\n",
      "2024-11-22 14:56:37.189849: Epoch time: 130.5 s\n",
      "2024-11-22 14:56:38.209872: \n",
      "2024-11-22 14:56:38.209872: Epoch 175\n",
      "2024-11-22 14:56:38.219871: Current learning rate: 0.00679\n",
      "2024-11-22 14:58:48.724413: train_loss -0.7623\n",
      "2024-11-22 14:58:48.734413: val_loss -0.3145\n",
      "2024-11-22 14:58:48.734413: Pseudo dice [0.5845]\n",
      "2024-11-22 14:58:48.744414: Epoch time: 130.51 s\n",
      "2024-11-22 14:58:49.764782: \n",
      "2024-11-22 14:58:49.764782: Epoch 176\n",
      "2024-11-22 14:58:49.774782: Current learning rate: 0.00677\n",
      "2024-11-22 15:01:00.272166: train_loss -0.7094\n",
      "2024-11-22 15:01:00.282167: val_loss -0.5043\n",
      "2024-11-22 15:01:00.292167: Pseudo dice [0.6955]\n",
      "2024-11-22 15:01:00.292167: Epoch time: 130.51 s\n",
      "2024-11-22 15:01:01.322192: \n",
      "2024-11-22 15:01:01.322192: Epoch 177\n",
      "2024-11-22 15:01:01.332190: Current learning rate: 0.00675\n",
      "2024-11-22 15:03:11.919113: train_loss -0.7213\n",
      "2024-11-22 15:03:11.929114: val_loss -0.427\n",
      "2024-11-22 15:03:11.939115: Pseudo dice [0.6573]\n",
      "2024-11-22 15:03:11.939115: Epoch time: 130.6 s\n",
      "2024-11-22 15:03:12.959140: \n",
      "2024-11-22 15:03:12.959140: Epoch 178\n",
      "2024-11-22 15:03:12.969147: Current learning rate: 0.00673\n",
      "2024-11-22 15:05:23.492715: train_loss -0.7665\n",
      "2024-11-22 15:05:23.502715: val_loss -0.5525\n",
      "2024-11-22 15:05:23.512716: Pseudo dice [0.7093]\n",
      "2024-11-22 15:05:23.512716: Epoch time: 130.53 s\n",
      "2024-11-22 15:05:24.532740: \n",
      "2024-11-22 15:05:24.542738: Epoch 179\n",
      "2024-11-22 15:05:24.542738: Current learning rate: 0.00671\n",
      "2024-11-22 15:07:35.078169: train_loss -0.7437\n",
      "2024-11-22 15:07:35.088168: val_loss -0.4905\n",
      "2024-11-22 15:07:35.098169: Pseudo dice [0.6823]\n",
      "2024-11-22 15:07:35.108169: Epoch time: 130.55 s\n",
      "2024-11-22 15:07:36.118192: \n",
      "2024-11-22 15:07:36.128185: Epoch 180\n",
      "2024-11-22 15:07:36.128185: Current learning rate: 0.00669\n",
      "2024-11-22 15:09:46.677977: train_loss -0.7652\n",
      "2024-11-22 15:09:46.687977: val_loss -0.4601\n",
      "2024-11-22 15:09:46.697978: Pseudo dice [0.6683]\n",
      "2024-11-22 15:09:46.697978: Epoch time: 130.56 s\n",
      "2024-11-22 15:09:47.898003: \n",
      "2024-11-22 15:09:47.898003: Epoch 181\n",
      "2024-11-22 15:09:47.907995: Current learning rate: 0.00667\n",
      "2024-11-22 15:11:58.504445: train_loss -0.7471\n",
      "2024-11-22 15:11:58.514446: val_loss -0.397\n",
      "2024-11-22 15:11:58.524446: Pseudo dice [0.6661]\n",
      "2024-11-22 15:11:58.534446: Epoch time: 130.61 s\n",
      "2024-11-22 15:11:59.544790: \n",
      "2024-11-22 15:11:59.554780: Epoch 182\n",
      "2024-11-22 15:11:59.554780: Current learning rate: 0.00665\n",
      "2024-11-22 15:14:10.100417: train_loss -0.7601\n",
      "2024-11-22 15:14:10.110417: val_loss -0.4536\n",
      "2024-11-22 15:14:10.110417: Pseudo dice [0.6611]\n",
      "2024-11-22 15:14:10.120418: Epoch time: 130.56 s\n",
      "2024-11-22 15:14:11.150443: \n",
      "2024-11-22 15:14:11.150443: Epoch 183\n",
      "2024-11-22 15:14:11.160432: Current learning rate: 0.00664\n",
      "2024-11-22 15:16:21.765956: train_loss -0.7441\n",
      "2024-11-22 15:16:21.775958: val_loss -0.4886\n",
      "2024-11-22 15:16:21.785958: Pseudo dice [0.7071]\n",
      "2024-11-22 15:16:21.785958: Epoch time: 130.62 s\n",
      "2024-11-22 15:16:22.815982: \n",
      "2024-11-22 15:16:22.815982: Epoch 184\n",
      "2024-11-22 15:16:22.825972: Current learning rate: 0.00662\n",
      "2024-11-22 15:18:33.361895: train_loss -0.7304\n",
      "2024-11-22 15:18:33.371895: val_loss -0.5021\n",
      "2024-11-22 15:18:33.381896: Pseudo dice [0.6822]\n",
      "2024-11-22 15:18:33.391896: Epoch time: 130.55 s\n",
      "2024-11-22 15:18:34.411919: \n",
      "2024-11-22 15:18:34.421911: Epoch 185\n",
      "2024-11-22 15:18:34.421911: Current learning rate: 0.0066\n",
      "2024-11-22 15:20:44.919422: train_loss -0.7464\n",
      "2024-11-22 15:20:44.929423: val_loss -0.4469\n",
      "2024-11-22 15:20:44.939422: Pseudo dice [0.7188]\n",
      "2024-11-22 15:20:44.939422: Epoch time: 130.51 s\n",
      "2024-11-22 15:20:45.969820: \n",
      "2024-11-22 15:20:45.969820: Epoch 186\n",
      "2024-11-22 15:20:45.969820: Current learning rate: 0.00658\n",
      "2024-11-22 15:22:56.436163: train_loss -0.7789\n",
      "2024-11-22 15:22:56.446164: val_loss -0.5751\n",
      "2024-11-22 15:22:56.446164: Pseudo dice [0.7609]\n",
      "2024-11-22 15:22:56.456164: Epoch time: 130.48 s\n",
      "2024-11-22 15:22:56.456164: Yayy! New best EMA pseudo Dice: 0.6865\n",
      "2024-11-22 15:22:57.896193: \n",
      "2024-11-22 15:22:57.906193: Epoch 187\n",
      "2024-11-22 15:22:57.906193: Current learning rate: 0.00656\n",
      "2024-11-22 15:25:08.491752: train_loss -0.7676\n",
      "2024-11-22 15:25:08.491752: val_loss -0.3297\n",
      "2024-11-22 15:25:08.501751: Pseudo dice [0.6367]\n",
      "2024-11-22 15:25:08.511752: Epoch time: 130.6 s\n",
      "2024-11-22 15:25:09.532077: \n",
      "2024-11-22 15:25:09.532077: Epoch 188\n",
      "2024-11-22 15:25:09.542074: Current learning rate: 0.00654\n",
      "2024-11-22 15:27:20.117996: train_loss -0.7595\n",
      "2024-11-22 15:27:20.127996: val_loss -0.5061\n",
      "2024-11-22 15:27:20.137996: Pseudo dice [0.7179]\n",
      "2024-11-22 15:27:20.147996: Epoch time: 130.59 s\n",
      "2024-11-22 15:27:21.168966: \n",
      "2024-11-22 15:27:21.168966: Epoch 189\n",
      "2024-11-22 15:27:21.178963: Current learning rate: 0.00652\n",
      "2024-11-22 15:29:31.725019: train_loss -0.7817\n",
      "2024-11-22 15:29:31.735019: val_loss -0.3661\n",
      "2024-11-22 15:29:31.745019: Pseudo dice [0.6632]\n",
      "2024-11-22 15:29:31.755019: Epoch time: 130.56 s\n",
      "2024-11-22 15:29:32.775042: \n",
      "2024-11-22 15:29:32.775042: Epoch 190\n",
      "2024-11-22 15:29:32.775042: Current learning rate: 0.0065\n",
      "2024-11-22 15:31:43.327358: train_loss -0.774\n",
      "2024-11-22 15:31:43.337358: val_loss -0.3793\n",
      "2024-11-22 15:31:43.347358: Pseudo dice [0.6518]\n",
      "2024-11-22 15:31:43.347358: Epoch time: 130.55 s\n",
      "2024-11-22 15:31:44.367382: \n",
      "2024-11-22 15:31:44.377374: Epoch 191\n",
      "2024-11-22 15:31:44.377374: Current learning rate: 0.00648\n",
      "2024-11-22 15:33:54.962007: train_loss -0.7899\n",
      "2024-11-22 15:33:54.972007: val_loss -0.4641\n",
      "2024-11-22 15:33:54.972007: Pseudo dice [0.6844]\n",
      "2024-11-22 15:33:54.982008: Epoch time: 130.59 s\n",
      "2024-11-22 15:33:56.012373: \n",
      "2024-11-22 15:33:56.022366: Epoch 192\n",
      "2024-11-22 15:33:56.022366: Current learning rate: 0.00647\n",
      "2024-11-22 15:36:06.564665: train_loss -0.7715\n",
      "2024-11-22 15:36:06.584665: val_loss -0.5237\n",
      "2024-11-22 15:36:06.584665: Pseudo dice [0.7116]\n",
      "2024-11-22 15:36:06.594665: Epoch time: 130.55 s\n",
      "2024-11-22 15:36:07.634688: \n",
      "2024-11-22 15:36:07.644688: Epoch 193\n",
      "2024-11-22 15:36:07.644688: Current learning rate: 0.00645\n",
      "2024-11-22 15:38:18.626469: train_loss -0.7846\n",
      "2024-11-22 15:38:18.636469: val_loss -0.5071\n",
      "2024-11-22 15:38:18.646469: Pseudo dice [0.7025]\n",
      "2024-11-22 15:38:18.646469: Epoch time: 130.99 s\n",
      "2024-11-22 15:38:19.856799: \n",
      "2024-11-22 15:38:19.866798: Epoch 194\n",
      "2024-11-22 15:38:19.866798: Current learning rate: 0.00643\n",
      "2024-11-22 15:40:30.503476: train_loss -0.7867\n",
      "2024-11-22 15:40:30.513476: val_loss -0.4472\n",
      "2024-11-22 15:40:30.513476: Pseudo dice [0.7224]\n",
      "2024-11-22 15:40:30.523476: Epoch time: 130.65 s\n",
      "2024-11-22 15:40:30.523476: Yayy! New best EMA pseudo Dice: 0.689\n",
      "2024-11-22 15:40:31.803749: \n",
      "2024-11-22 15:40:31.813749: Epoch 195\n",
      "2024-11-22 15:40:31.813749: Current learning rate: 0.00641\n",
      "2024-11-22 15:42:42.448275: train_loss -0.7551\n",
      "2024-11-22 15:42:42.458275: val_loss -0.5044\n",
      "2024-11-22 15:42:42.468275: Pseudo dice [0.6888]\n",
      "2024-11-22 15:42:42.468275: Epoch time: 130.64 s\n",
      "2024-11-22 15:42:43.508612: \n",
      "2024-11-22 15:42:43.518612: Epoch 196\n",
      "2024-11-22 15:42:43.518612: Current learning rate: 0.00639\n",
      "2024-11-22 15:44:54.027015: train_loss -0.7361\n",
      "2024-11-22 15:44:54.037016: val_loss -0.4388\n",
      "2024-11-22 15:44:54.037016: Pseudo dice [0.6492]\n",
      "2024-11-22 15:44:54.047015: Epoch time: 130.52 s\n",
      "2024-11-22 15:44:55.077029: \n",
      "2024-11-22 15:44:55.087029: Epoch 197\n",
      "2024-11-22 15:44:55.087029: Current learning rate: 0.00637\n",
      "2024-11-22 15:47:05.587446: train_loss -0.7846\n",
      "2024-11-22 15:47:05.597445: val_loss -0.4509\n",
      "2024-11-22 15:47:05.597445: Pseudo dice [0.6851]\n",
      "2024-11-22 15:47:05.607445: Epoch time: 130.51 s\n",
      "2024-11-22 15:47:06.647701: \n",
      "2024-11-22 15:47:06.647701: Epoch 198\n",
      "2024-11-22 15:47:06.657696: Current learning rate: 0.00635\n",
      "2024-11-22 15:49:17.094525: train_loss -0.7676\n",
      "2024-11-22 15:49:17.104524: val_loss -0.6115\n",
      "2024-11-22 15:49:17.114526: Pseudo dice [0.7422]\n",
      "2024-11-22 15:49:17.114526: Epoch time: 130.45 s\n",
      "2024-11-22 15:49:17.124527: Yayy! New best EMA pseudo Dice: 0.6908\n",
      "2024-11-22 15:49:18.394837: \n",
      "2024-11-22 15:49:18.404837: Epoch 199\n",
      "2024-11-22 15:49:18.404837: Current learning rate: 0.00633\n",
      "2024-11-22 15:51:28.923503: train_loss -0.7503\n",
      "2024-11-22 15:51:28.933503: val_loss -0.495\n",
      "2024-11-22 15:51:28.943504: Pseudo dice [0.7031]\n",
      "2024-11-22 15:51:28.943504: Epoch time: 130.53 s\n",
      "2024-11-22 15:51:29.183833: Yayy! New best EMA pseudo Dice: 0.692\n",
      "2024-11-22 15:51:30.613853: \n",
      "2024-11-22 15:51:30.613853: Epoch 200\n",
      "2024-11-22 15:51:30.623852: Current learning rate: 0.00631\n",
      "2024-11-22 15:53:41.143589: train_loss -0.7521\n",
      "2024-11-22 15:53:41.153589: val_loss -0.5881\n",
      "2024-11-22 15:53:41.163589: Pseudo dice [0.7507]\n",
      "2024-11-22 15:53:41.163589: Epoch time: 130.53 s\n",
      "2024-11-22 15:53:41.173589: Yayy! New best EMA pseudo Dice: 0.6979\n",
      "2024-11-22 15:53:42.456453: \n",
      "2024-11-22 15:53:42.462544: Epoch 201\n",
      "2024-11-22 15:53:42.466616: Current learning rate: 0.0063\n",
      "2024-11-22 15:55:52.979377: train_loss -0.7028\n",
      "2024-11-22 15:55:52.999378: val_loss -0.4893\n",
      "2024-11-22 15:55:52.999378: Pseudo dice [0.6522]\n",
      "2024-11-22 15:55:53.009378: Epoch time: 130.52 s\n",
      "2024-11-22 15:55:54.039707: \n",
      "2024-11-22 15:55:54.049706: Epoch 202\n",
      "2024-11-22 15:55:54.049706: Current learning rate: 0.00628\n",
      "2024-11-22 15:58:04.554171: train_loss -0.7732\n",
      "2024-11-22 15:58:04.564172: val_loss -0.5704\n",
      "2024-11-22 15:58:04.574173: Pseudo dice [0.7566]\n",
      "2024-11-22 15:58:04.574173: Epoch time: 130.51 s\n",
      "2024-11-22 15:58:04.574173: Yayy! New best EMA pseudo Dice: 0.6996\n",
      "2024-11-22 15:58:05.864191: \n",
      "2024-11-22 15:58:05.864191: Epoch 203\n",
      "2024-11-22 15:58:05.874190: Current learning rate: 0.00626\n",
      "2024-11-22 16:00:16.502886: train_loss -0.7578\n",
      "2024-11-22 16:00:16.522886: val_loss -0.581\n",
      "2024-11-22 16:00:16.532888: Pseudo dice [0.7412]\n",
      "2024-11-22 16:00:16.532888: Epoch time: 130.64 s\n",
      "2024-11-22 16:00:16.542888: Yayy! New best EMA pseudo Dice: 0.7038\n",
      "2024-11-22 16:00:17.812905: \n",
      "2024-11-22 16:00:17.822904: Epoch 204\n",
      "2024-11-22 16:00:17.822904: Current learning rate: 0.00624\n",
      "2024-11-22 16:02:28.451247: train_loss -0.7689\n",
      "2024-11-22 16:02:28.461247: val_loss -0.4444\n",
      "2024-11-22 16:02:28.471248: Pseudo dice [0.7087]\n",
      "2024-11-22 16:02:28.471248: Epoch time: 130.64 s\n",
      "2024-11-22 16:02:28.481247: Yayy! New best EMA pseudo Dice: 0.7043\n",
      "2024-11-22 16:02:29.761493: \n",
      "2024-11-22 16:02:29.761493: Epoch 205\n",
      "2024-11-22 16:02:29.761493: Current learning rate: 0.00622\n",
      "2024-11-22 16:04:40.413604: train_loss -0.7368\n",
      "2024-11-22 16:04:40.423605: val_loss -0.2988\n",
      "2024-11-22 16:04:40.433605: Pseudo dice [0.6069]\n",
      "2024-11-22 16:04:40.433605: Epoch time: 130.66 s\n",
      "2024-11-22 16:04:41.413619: \n",
      "2024-11-22 16:04:41.423619: Epoch 206\n",
      "2024-11-22 16:04:41.423619: Current learning rate: 0.0062\n",
      "2024-11-22 16:06:52.011313: train_loss -0.7021\n",
      "2024-11-22 16:06:52.021312: val_loss -0.4315\n",
      "2024-11-22 16:06:52.031313: Pseudo dice [0.6314]\n",
      "2024-11-22 16:06:52.031313: Epoch time: 130.6 s\n",
      "2024-11-22 16:06:53.191329: \n",
      "2024-11-22 16:06:53.191329: Epoch 207\n",
      "2024-11-22 16:06:53.201328: Current learning rate: 0.00618\n",
      "2024-11-22 16:09:03.746173: train_loss -0.7346\n",
      "2024-11-22 16:09:03.766173: val_loss -0.5005\n",
      "2024-11-22 16:09:03.766173: Pseudo dice [0.7211]\n",
      "2024-11-22 16:09:03.776174: Epoch time: 130.55 s\n",
      "2024-11-22 16:09:04.756187: \n",
      "2024-11-22 16:09:04.766186: Epoch 208\n",
      "2024-11-22 16:09:04.766186: Current learning rate: 0.00616\n",
      "2024-11-22 16:11:15.314662: train_loss -0.7378\n",
      "2024-11-22 16:11:15.324662: val_loss -0.5177\n",
      "2024-11-22 16:11:15.324662: Pseudo dice [0.6992]\n",
      "2024-11-22 16:11:15.334662: Epoch time: 130.56 s\n",
      "2024-11-22 16:11:16.314802: \n",
      "2024-11-22 16:11:16.324802: Epoch 209\n",
      "2024-11-22 16:11:16.324802: Current learning rate: 0.00614\n",
      "2024-11-22 16:13:26.859643: train_loss -0.7747\n",
      "2024-11-22 16:13:26.869643: val_loss -0.5593\n",
      "2024-11-22 16:13:26.879644: Pseudo dice [0.733]\n",
      "2024-11-22 16:13:26.879644: Epoch time: 130.54 s\n",
      "2024-11-22 16:13:27.859657: \n",
      "2024-11-22 16:13:27.869657: Epoch 210\n",
      "2024-11-22 16:13:27.869657: Current learning rate: 0.00612\n",
      "2024-11-22 16:15:38.335776: train_loss -0.7363\n",
      "2024-11-22 16:15:38.345776: val_loss -0.4237\n",
      "2024-11-22 16:15:38.355777: Pseudo dice [0.6606]\n",
      "2024-11-22 16:15:38.355777: Epoch time: 130.48 s\n",
      "2024-11-22 16:15:39.336128: \n",
      "2024-11-22 16:15:39.346128: Epoch 211\n",
      "2024-11-22 16:15:39.346128: Current learning rate: 0.00611\n",
      "2024-11-22 16:17:49.864281: train_loss -0.7546\n",
      "2024-11-22 16:17:49.874283: val_loss -0.4132\n",
      "2024-11-22 16:17:49.884283: Pseudo dice [0.6541]\n",
      "2024-11-22 16:17:49.894283: Epoch time: 130.53 s\n",
      "2024-11-22 16:17:50.864295: \n",
      "2024-11-22 16:17:50.874295: Epoch 212\n",
      "2024-11-22 16:17:50.874295: Current learning rate: 0.00609\n",
      "2024-11-22 16:20:01.463114: train_loss -0.7486\n",
      "2024-11-22 16:20:01.473114: val_loss -0.4278\n",
      "2024-11-22 16:20:01.483115: Pseudo dice [0.6489]\n",
      "2024-11-22 16:20:01.483115: Epoch time: 130.6 s\n",
      "2024-11-22 16:20:02.463128: \n",
      "2024-11-22 16:20:02.463128: Epoch 213\n",
      "2024-11-22 16:20:02.473128: Current learning rate: 0.00607\n",
      "2024-11-22 16:22:13.014650: train_loss -0.7693\n",
      "2024-11-22 16:22:13.024649: val_loss -0.473\n",
      "2024-11-22 16:22:13.034650: Pseudo dice [0.7107]\n",
      "2024-11-22 16:22:13.034650: Epoch time: 130.55 s\n",
      "2024-11-22 16:22:14.184665: \n",
      "2024-11-22 16:22:14.194665: Epoch 214\n",
      "2024-11-22 16:22:14.194665: Current learning rate: 0.00605\n",
      "2024-11-22 16:24:24.742729: train_loss -0.7761\n",
      "2024-11-22 16:24:24.752729: val_loss -0.4624\n",
      "2024-11-22 16:24:24.762729: Pseudo dice [0.6322]\n",
      "2024-11-22 16:24:24.772730: Epoch time: 130.56 s\n",
      "2024-11-22 16:24:25.742743: \n",
      "2024-11-22 16:24:25.752742: Epoch 215\n",
      "2024-11-22 16:24:25.752742: Current learning rate: 0.00603\n",
      "2024-11-22 16:26:36.320816: train_loss -0.7871\n",
      "2024-11-22 16:26:36.330816: val_loss -0.5229\n",
      "2024-11-22 16:26:36.340816: Pseudo dice [0.6987]\n",
      "2024-11-22 16:26:36.340816: Epoch time: 130.58 s\n",
      "2024-11-22 16:26:37.331919: \n",
      "2024-11-22 16:26:37.331919: Epoch 216\n",
      "2024-11-22 16:26:37.331919: Current learning rate: 0.00601\n",
      "2024-11-22 16:28:47.817266: train_loss -0.7853\n",
      "2024-11-22 16:28:47.827265: val_loss -0.5268\n",
      "2024-11-22 16:28:47.827265: Pseudo dice [0.6881]\n",
      "2024-11-22 16:28:47.837266: Epoch time: 130.5 s\n",
      "2024-11-22 16:28:48.817279: \n",
      "2024-11-22 16:28:48.827279: Epoch 217\n",
      "2024-11-22 16:28:48.827279: Current learning rate: 0.00599\n",
      "2024-11-22 16:30:59.454779: train_loss -0.7575\n",
      "2024-11-22 16:30:59.464779: val_loss -0.349\n",
      "2024-11-22 16:30:59.474779: Pseudo dice [0.6482]\n",
      "2024-11-22 16:30:59.484780: Epoch time: 130.64 s\n",
      "2024-11-22 16:31:00.464756: \n",
      "2024-11-22 16:31:00.464756: Epoch 218\n",
      "2024-11-22 16:31:00.474753: Current learning rate: 0.00597\n",
      "2024-11-22 16:33:11.056241: train_loss -0.7629\n",
      "2024-11-22 16:33:11.065349: val_loss -0.4466\n",
      "2024-11-22 16:33:11.069411: Pseudo dice [0.7164]\n",
      "2024-11-22 16:33:11.074497: Epoch time: 130.59 s\n",
      "2024-11-22 16:33:12.053694: \n",
      "2024-11-22 16:33:12.063694: Epoch 219\n",
      "2024-11-22 16:33:12.063694: Current learning rate: 0.00595\n",
      "2024-11-22 16:35:22.611077: train_loss -0.7142\n",
      "2024-11-22 16:35:22.621077: val_loss -0.4814\n",
      "2024-11-22 16:35:22.631078: Pseudo dice [0.7099]\n",
      "2024-11-22 16:35:22.631078: Epoch time: 130.56 s\n",
      "2024-11-22 16:35:23.621090: \n",
      "2024-11-22 16:35:23.621090: Epoch 220\n",
      "2024-11-22 16:35:23.621090: Current learning rate: 0.00593\n",
      "2024-11-22 16:37:34.127591: train_loss -0.7827\n",
      "2024-11-22 16:37:34.137593: val_loss -0.4704\n",
      "2024-11-22 16:37:34.137593: Pseudo dice [0.6615]\n",
      "2024-11-22 16:37:34.147593: Epoch time: 130.52 s\n",
      "2024-11-22 16:37:35.297608: \n",
      "2024-11-22 16:37:35.307608: Epoch 221\n",
      "2024-11-22 16:37:35.307608: Current learning rate: 0.00592\n",
      "2024-11-22 16:39:45.872200: train_loss -0.7435\n",
      "2024-11-22 16:39:45.872200: val_loss -0.3008\n",
      "2024-11-22 16:39:45.882200: Pseudo dice [0.6231]\n",
      "2024-11-22 16:39:45.892201: Epoch time: 130.57 s\n",
      "2024-11-22 16:39:46.872216: \n",
      "2024-11-22 16:39:46.872216: Epoch 222\n",
      "2024-11-22 16:39:46.872216: Current learning rate: 0.0059\n",
      "2024-11-22 16:41:57.453175: train_loss -0.7715\n",
      "2024-11-22 16:41:57.463176: val_loss -0.4716\n",
      "2024-11-22 16:41:57.463176: Pseudo dice [0.6694]\n",
      "2024-11-22 16:41:57.473176: Epoch time: 130.59 s\n",
      "2024-11-22 16:41:58.443189: \n",
      "2024-11-22 16:41:58.453189: Epoch 223\n",
      "2024-11-22 16:41:58.453189: Current learning rate: 0.00588\n",
      "2024-11-22 16:44:08.993231: train_loss -0.7304\n",
      "2024-11-22 16:44:09.003232: val_loss -0.4734\n",
      "2024-11-22 16:44:09.003232: Pseudo dice [0.6819]\n",
      "2024-11-22 16:44:09.013232: Epoch time: 130.55 s\n",
      "2024-11-22 16:44:09.983544: \n",
      "2024-11-22 16:44:09.993544: Epoch 224\n",
      "2024-11-22 16:44:09.993544: Current learning rate: 0.00586\n",
      "2024-11-22 16:46:20.516723: train_loss -0.7877\n",
      "2024-11-22 16:46:20.526723: val_loss -0.5294\n",
      "2024-11-22 16:46:20.536723: Pseudo dice [0.7281]\n",
      "2024-11-22 16:46:20.546724: Epoch time: 130.53 s\n",
      "2024-11-22 16:46:21.522764: \n",
      "2024-11-22 16:46:21.527874: Epoch 225\n",
      "2024-11-22 16:46:21.531973: Current learning rate: 0.00584\n",
      "2024-11-22 16:48:32.065477: train_loss -0.7811\n",
      "2024-11-22 16:48:32.075478: val_loss -0.3662\n",
      "2024-11-22 16:48:32.085478: Pseudo dice [0.671]\n",
      "2024-11-22 16:48:32.085478: Epoch time: 130.54 s\n",
      "2024-11-22 16:48:33.065491: \n",
      "2024-11-22 16:48:33.065491: Epoch 226\n",
      "2024-11-22 16:48:33.075491: Current learning rate: 0.00582\n",
      "2024-11-22 16:50:43.667506: train_loss -0.7841\n",
      "2024-11-22 16:50:43.677507: val_loss -0.565\n",
      "2024-11-22 16:50:43.677507: Pseudo dice [0.7162]\n",
      "2024-11-22 16:50:43.687505: Epoch time: 130.59 s\n",
      "2024-11-22 16:50:44.647822: \n",
      "2024-11-22 16:50:44.657822: Epoch 227\n",
      "2024-11-22 16:50:44.657822: Current learning rate: 0.0058\n",
      "2024-11-22 16:52:55.220344: train_loss -0.7828\n",
      "2024-11-22 16:52:55.230343: val_loss -0.5896\n",
      "2024-11-22 16:52:55.240343: Pseudo dice [0.7648]\n",
      "2024-11-22 16:52:55.250345: Epoch time: 130.57 s\n",
      "2024-11-22 16:52:56.391630: \n",
      "2024-11-22 16:52:56.391630: Epoch 228\n",
      "2024-11-22 16:52:56.401627: Current learning rate: 0.00578\n",
      "2024-11-22 16:55:06.941074: train_loss -0.7913\n",
      "2024-11-22 16:55:06.951074: val_loss -0.5605\n",
      "2024-11-22 16:55:06.951074: Pseudo dice [0.7383]\n",
      "2024-11-22 16:55:06.961075: Epoch time: 130.55 s\n",
      "2024-11-22 16:55:07.931087: \n",
      "2024-11-22 16:55:07.931087: Epoch 229\n",
      "2024-11-22 16:55:07.941087: Current learning rate: 0.00576\n",
      "2024-11-22 16:57:18.510746: train_loss -0.7615\n",
      "2024-11-22 16:57:18.520746: val_loss -0.5322\n",
      "2024-11-22 16:57:18.530747: Pseudo dice [0.7132]\n",
      "2024-11-22 16:57:18.530747: Epoch time: 130.58 s\n",
      "2024-11-22 16:57:19.500760: \n",
      "2024-11-22 16:57:19.510759: Epoch 230\n",
      "2024-11-22 16:57:19.510759: Current learning rate: 0.00574\n",
      "2024-11-22 16:59:30.131386: train_loss -0.7568\n",
      "2024-11-22 16:59:30.141385: val_loss -0.3866\n",
      "2024-11-22 16:59:30.151386: Pseudo dice [0.6843]\n",
      "2024-11-22 16:59:30.151386: Epoch time: 130.63 s\n",
      "2024-11-22 16:59:31.121892: \n",
      "2024-11-22 16:59:31.131892: Epoch 231\n",
      "2024-11-22 16:59:31.131892: Current learning rate: 0.00572\n",
      "2024-11-22 17:01:41.716356: train_loss -0.7499\n",
      "2024-11-22 17:01:41.724427: val_loss -0.5074\n",
      "2024-11-22 17:01:41.728498: Pseudo dice [0.7003]\n",
      "2024-11-22 17:01:41.734502: Epoch time: 130.59 s\n",
      "2024-11-22 17:01:42.704518: \n",
      "2024-11-22 17:01:42.714518: Epoch 232\n",
      "2024-11-22 17:01:42.714518: Current learning rate: 0.0057\n",
      "2024-11-22 17:03:53.163942: train_loss -0.75\n",
      "2024-11-22 17:03:53.173942: val_loss -0.2556\n",
      "2024-11-22 17:03:53.173942: Pseudo dice [0.6127]\n",
      "2024-11-22 17:03:53.183941: Epoch time: 130.46 s\n",
      "2024-11-22 17:03:54.163955: \n",
      "2024-11-22 17:03:54.173956: Epoch 233\n",
      "2024-11-22 17:03:54.173956: Current learning rate: 0.00569\n",
      "2024-11-22 17:06:04.673807: train_loss -0.7689\n",
      "2024-11-22 17:06:04.683808: val_loss -0.3873\n",
      "2024-11-22 17:06:04.693809: Pseudo dice [0.681]\n",
      "2024-11-22 17:06:04.703808: Epoch time: 130.51 s\n",
      "2024-11-22 17:06:05.674867: \n",
      "2024-11-22 17:06:05.684867: Epoch 234\n",
      "2024-11-22 17:06:05.684867: Current learning rate: 0.00567\n",
      "2024-11-22 17:08:16.266400: train_loss -0.6981\n",
      "2024-11-22 17:08:16.276400: val_loss -0.2092\n",
      "2024-11-22 17:08:16.286400: Pseudo dice [0.5916]\n",
      "2024-11-22 17:08:16.286400: Epoch time: 130.59 s\n",
      "2024-11-22 17:08:17.256413: \n",
      "2024-11-22 17:08:17.266413: Epoch 235\n",
      "2024-11-22 17:08:17.266413: Current learning rate: 0.00565\n",
      "2024-11-22 17:10:27.781423: train_loss -0.7681\n",
      "2024-11-22 17:10:27.791422: val_loss -0.4854\n",
      "2024-11-22 17:10:27.801424: Pseudo dice [0.7059]\n",
      "2024-11-22 17:10:27.811424: Epoch time: 130.53 s\n",
      "2024-11-22 17:10:28.961439: \n",
      "2024-11-22 17:10:28.971439: Epoch 236\n",
      "2024-11-22 17:10:28.971439: Current learning rate: 0.00563\n",
      "2024-11-22 17:12:39.499342: train_loss -0.7784\n",
      "2024-11-22 17:12:39.509344: val_loss -0.54\n",
      "2024-11-22 17:12:39.516761: Pseudo dice [0.7354]\n",
      "2024-11-22 17:12:39.524762: Epoch time: 130.54 s\n",
      "2024-11-22 17:12:40.512555: \n",
      "2024-11-22 17:12:40.522555: Epoch 237\n",
      "2024-11-22 17:12:40.522555: Current learning rate: 0.00561\n",
      "2024-11-22 17:14:51.003607: train_loss -0.7855\n",
      "2024-11-22 17:14:51.013608: val_loss -0.5501\n",
      "2024-11-22 17:14:51.013608: Pseudo dice [0.7305]\n",
      "2024-11-22 17:14:51.023608: Epoch time: 130.49 s\n",
      "2024-11-22 17:14:52.004550: \n",
      "2024-11-22 17:14:52.004550: Epoch 238\n",
      "2024-11-22 17:14:52.004550: Current learning rate: 0.00559\n",
      "2024-11-22 17:17:02.511009: train_loss -0.7575\n",
      "2024-11-22 17:17:02.531009: val_loss -0.4875\n",
      "2024-11-22 17:17:02.531009: Pseudo dice [0.7236]\n",
      "2024-11-22 17:17:02.531009: Epoch time: 130.52 s\n",
      "2024-11-22 17:17:03.511320: \n",
      "2024-11-22 17:17:03.511320: Epoch 239\n",
      "2024-11-22 17:17:03.521317: Current learning rate: 0.00557\n",
      "2024-11-22 17:19:14.105392: train_loss -0.7636\n",
      "2024-11-22 17:19:14.115394: val_loss -0.5368\n",
      "2024-11-22 17:19:14.115394: Pseudo dice [0.7085]\n",
      "2024-11-22 17:19:14.125393: Epoch time: 130.59 s\n",
      "2024-11-22 17:19:15.115711: \n",
      "2024-11-22 17:19:15.115711: Epoch 240\n",
      "2024-11-22 17:19:15.125710: Current learning rate: 0.00555\n",
      "2024-11-22 17:21:25.636075: train_loss -0.7915\n",
      "2024-11-22 17:21:25.656075: val_loss -0.5476\n",
      "2024-11-22 17:21:25.656075: Pseudo dice [0.6978]\n",
      "2024-11-22 17:21:25.666076: Epoch time: 130.52 s\n",
      "2024-11-22 17:21:26.656089: \n",
      "2024-11-22 17:21:26.656089: Epoch 241\n",
      "2024-11-22 17:21:26.666088: Current learning rate: 0.00553\n",
      "2024-11-22 17:23:37.215828: train_loss -0.7888\n",
      "2024-11-22 17:23:37.225830: val_loss -0.4648\n",
      "2024-11-22 17:23:37.235828: Pseudo dice [0.6597]\n",
      "2024-11-22 17:23:37.235828: Epoch time: 130.57 s\n",
      "2024-11-22 17:23:38.225853: \n",
      "2024-11-22 17:23:38.235854: Epoch 242\n",
      "2024-11-22 17:23:38.235854: Current learning rate: 0.00551\n",
      "2024-11-22 17:25:48.720544: train_loss -0.7655\n",
      "2024-11-22 17:25:48.730544: val_loss -0.4471\n",
      "2024-11-22 17:25:48.730544: Pseudo dice [0.6643]\n",
      "2024-11-22 17:25:48.740545: Epoch time: 130.49 s\n",
      "2024-11-22 17:25:49.900560: \n",
      "2024-11-22 17:25:49.900560: Epoch 243\n",
      "2024-11-22 17:25:49.910560: Current learning rate: 0.00549\n",
      "2024-11-22 17:28:00.487169: train_loss -0.731\n",
      "2024-11-22 17:28:00.497170: val_loss -0.3673\n",
      "2024-11-22 17:28:00.507171: Pseudo dice [0.6553]\n",
      "2024-11-22 17:28:00.507171: Epoch time: 130.59 s\n",
      "2024-11-22 17:28:01.507184: \n",
      "2024-11-22 17:28:01.517184: Epoch 244\n",
      "2024-11-22 17:28:01.517184: Current learning rate: 0.00547\n",
      "2024-11-22 17:30:12.007487: train_loss -0.7596\n",
      "2024-11-22 17:30:12.017486: val_loss -0.5241\n",
      "2024-11-22 17:30:12.027486: Pseudo dice [0.7072]\n",
      "2024-11-22 17:30:12.037487: Epoch time: 130.5 s\n",
      "2024-11-22 17:30:13.017501: \n",
      "2024-11-22 17:30:13.027501: Epoch 245\n",
      "2024-11-22 17:30:13.027501: Current learning rate: 0.00546\n",
      "2024-11-22 17:32:23.590197: train_loss -0.7446\n",
      "2024-11-22 17:32:23.600197: val_loss -0.4997\n",
      "2024-11-22 17:32:23.610198: Pseudo dice [0.6868]\n",
      "2024-11-22 17:32:23.610198: Epoch time: 130.57 s\n",
      "2024-11-22 17:32:24.600509: \n",
      "2024-11-22 17:32:24.610509: Epoch 246\n",
      "2024-11-22 17:32:24.610509: Current learning rate: 0.00544\n",
      "2024-11-22 17:34:35.158642: train_loss -0.7362\n",
      "2024-11-22 17:34:35.168642: val_loss -0.2162\n",
      "2024-11-22 17:34:35.178643: Pseudo dice [0.554]\n",
      "2024-11-22 17:34:35.178643: Epoch time: 130.56 s\n",
      "2024-11-22 17:34:36.169756: \n",
      "2024-11-22 17:34:36.179756: Epoch 247\n",
      "2024-11-22 17:34:36.179756: Current learning rate: 0.00542\n",
      "2024-11-22 17:36:46.689524: train_loss -0.7494\n",
      "2024-11-22 17:36:46.699525: val_loss -0.5457\n",
      "2024-11-22 17:36:46.709525: Pseudo dice [0.737]\n",
      "2024-11-22 17:36:46.709525: Epoch time: 130.52 s\n",
      "2024-11-22 17:36:47.709540: \n",
      "2024-11-22 17:36:47.709540: Epoch 248\n",
      "2024-11-22 17:36:47.719537: Current learning rate: 0.0054\n",
      "2024-11-22 17:38:58.318832: train_loss -0.7701\n",
      "2024-11-22 17:38:58.328833: val_loss -0.419\n",
      "2024-11-22 17:38:58.328833: Pseudo dice [0.6453]\n",
      "2024-11-22 17:38:58.338832: Epoch time: 130.62 s\n",
      "2024-11-22 17:38:59.338846: \n",
      "2024-11-22 17:38:59.348846: Epoch 249\n",
      "2024-11-22 17:38:59.348846: Current learning rate: 0.00538\n",
      "2024-11-22 17:41:09.971511: train_loss -0.7843\n",
      "2024-11-22 17:41:09.981510: val_loss -0.4942\n",
      "2024-11-22 17:41:09.981510: Pseudo dice [0.6639]\n",
      "2024-11-22 17:41:09.991511: Epoch time: 130.63 s\n",
      "2024-11-22 17:41:11.411531: \n",
      "2024-11-22 17:41:11.421531: Epoch 250\n",
      "2024-11-22 17:41:11.421531: Current learning rate: 0.00536\n",
      "2024-11-22 17:43:22.015711: train_loss -0.7666\n",
      "2024-11-22 17:43:22.025712: val_loss -0.4956\n",
      "2024-11-22 17:43:22.025712: Pseudo dice [0.6773]\n",
      "2024-11-22 17:43:22.035712: Epoch time: 130.6 s\n",
      "2024-11-22 17:43:23.025725: \n",
      "2024-11-22 17:43:23.035725: Epoch 251\n",
      "2024-11-22 17:43:23.035725: Current learning rate: 0.00534\n",
      "2024-11-22 17:45:33.533453: train_loss -0.7983\n",
      "2024-11-22 17:45:33.543453: val_loss -0.4086\n",
      "2024-11-22 17:45:33.553455: Pseudo dice [0.6391]\n",
      "2024-11-22 17:45:33.563455: Epoch time: 130.51 s\n",
      "2024-11-22 17:45:34.543468: \n",
      "2024-11-22 17:45:34.553468: Epoch 252\n",
      "2024-11-22 17:45:34.553468: Current learning rate: 0.00532\n",
      "2024-11-22 17:47:45.092765: train_loss -0.7941\n",
      "2024-11-22 17:47:45.102765: val_loss -0.4068\n",
      "2024-11-22 17:47:45.112766: Pseudo dice [0.6811]\n",
      "2024-11-22 17:47:45.122766: Epoch time: 130.55 s\n",
      "2024-11-22 17:47:46.102779: \n",
      "2024-11-22 17:47:46.112779: Epoch 253\n",
      "2024-11-22 17:47:46.112779: Current learning rate: 0.0053\n",
      "2024-11-22 17:49:57.184351: train_loss -0.7754\n",
      "2024-11-22 17:49:57.194351: val_loss -0.5011\n",
      "2024-11-22 17:49:57.204351: Pseudo dice [0.705]\n",
      "2024-11-22 17:49:57.204351: Epoch time: 131.08 s\n",
      "2024-11-22 17:49:58.195513: \n",
      "2024-11-22 17:49:58.195513: Epoch 254\n",
      "2024-11-22 17:49:58.205510: Current learning rate: 0.00528\n",
      "2024-11-22 17:52:08.770630: train_loss -0.7907\n",
      "2024-11-22 17:52:08.780630: val_loss -0.4112\n",
      "2024-11-22 17:52:08.780630: Pseudo dice [0.6371]\n",
      "2024-11-22 17:52:08.790631: Epoch time: 130.57 s\n",
      "2024-11-22 17:52:09.780644: \n",
      "2024-11-22 17:52:09.780644: Epoch 255\n",
      "2024-11-22 17:52:09.780644: Current learning rate: 0.00526\n",
      "2024-11-22 17:54:20.359432: train_loss -0.7853\n",
      "2024-11-22 17:54:20.369431: val_loss -0.5225\n",
      "2024-11-22 17:54:20.369431: Pseudo dice [0.6976]\n",
      "2024-11-22 17:54:20.379432: Epoch time: 130.59 s\n",
      "2024-11-22 17:54:21.359445: \n",
      "2024-11-22 17:54:21.369445: Epoch 256\n",
      "2024-11-22 17:54:21.369445: Current learning rate: 0.00524\n",
      "2024-11-22 17:56:31.955383: train_loss -0.8004\n",
      "2024-11-22 17:56:31.955383: val_loss -0.3374\n",
      "2024-11-22 17:56:31.965383: Pseudo dice [0.6304]\n",
      "2024-11-22 17:56:31.975383: Epoch time: 130.6 s\n",
      "2024-11-22 17:56:32.955396: \n",
      "2024-11-22 17:56:32.965396: Epoch 257\n",
      "2024-11-22 17:56:32.965396: Current learning rate: 0.00522\n",
      "2024-11-22 17:58:43.614193: train_loss -0.7907\n",
      "2024-11-22 17:58:43.634194: val_loss -0.381\n",
      "2024-11-22 17:58:43.634194: Pseudo dice [0.6835]\n",
      "2024-11-22 17:58:43.634194: Epoch time: 130.66 s\n",
      "2024-11-22 17:58:44.814210: \n",
      "2024-11-22 17:58:44.824210: Epoch 258\n",
      "2024-11-22 17:58:44.824210: Current learning rate: 0.0052\n",
      "2024-11-22 18:00:55.407336: train_loss -0.791\n",
      "2024-11-22 18:00:55.427336: val_loss -0.498\n",
      "2024-11-22 18:00:55.437336: Pseudo dice [0.7048]\n",
      "2024-11-22 18:00:55.437336: Epoch time: 130.59 s\n",
      "2024-11-22 18:00:56.427350: \n",
      "2024-11-22 18:00:56.437349: Epoch 259\n",
      "2024-11-22 18:00:56.437349: Current learning rate: 0.00518\n",
      "2024-11-22 18:03:07.004754: train_loss -0.7957\n",
      "2024-11-22 18:03:07.014754: val_loss -0.3977\n",
      "2024-11-22 18:03:07.024755: Pseudo dice [0.7062]\n",
      "2024-11-22 18:03:07.024755: Epoch time: 130.58 s\n",
      "2024-11-22 18:03:08.016165: \n",
      "2024-11-22 18:03:08.016165: Epoch 260\n",
      "2024-11-22 18:03:08.026165: Current learning rate: 0.00517\n",
      "2024-11-22 18:05:18.569729: train_loss -0.7915\n",
      "2024-11-22 18:05:18.579729: val_loss -0.3028\n",
      "2024-11-22 18:05:18.589729: Pseudo dice [0.6448]\n",
      "2024-11-22 18:05:18.589729: Epoch time: 130.55 s\n",
      "2024-11-22 18:05:19.579743: \n",
      "2024-11-22 18:05:19.589743: Epoch 261\n",
      "2024-11-22 18:05:19.589743: Current learning rate: 0.00515\n",
      "2024-11-22 18:07:30.141384: train_loss -0.7914\n",
      "2024-11-22 18:07:30.151384: val_loss -0.5024\n",
      "2024-11-22 18:07:30.161384: Pseudo dice [0.7128]\n",
      "2024-11-22 18:07:30.161384: Epoch time: 130.56 s\n",
      "2024-11-22 18:07:31.141894: \n",
      "2024-11-22 18:07:31.151894: Epoch 262\n",
      "2024-11-22 18:07:31.151894: Current learning rate: 0.00513\n",
      "2024-11-22 18:09:41.891140: train_loss -0.7887\n",
      "2024-11-22 18:09:41.901140: val_loss -0.4073\n",
      "2024-11-22 18:09:41.901140: Pseudo dice [0.6584]\n",
      "2024-11-22 18:09:41.911141: Epoch time: 130.75 s\n",
      "2024-11-22 18:09:42.901155: \n",
      "2024-11-22 18:09:42.901155: Epoch 263\n",
      "2024-11-22 18:09:42.911154: Current learning rate: 0.00511\n",
      "2024-11-22 18:11:53.462190: train_loss -0.7108\n",
      "2024-11-22 18:11:53.482189: val_loss -0.3684\n",
      "2024-11-22 18:11:53.482189: Pseudo dice [0.6761]\n",
      "2024-11-22 18:11:53.492191: Epoch time: 130.56 s\n",
      "2024-11-22 18:11:54.492500: \n",
      "2024-11-22 18:11:54.492500: Epoch 264\n",
      "2024-11-22 18:11:54.502500: Current learning rate: 0.00509\n",
      "2024-11-22 18:14:05.167315: train_loss -0.7806\n",
      "2024-11-22 18:14:05.177316: val_loss -0.3827\n",
      "2024-11-22 18:14:05.187316: Pseudo dice [0.6777]\n",
      "2024-11-22 18:14:05.187316: Epoch time: 130.68 s\n",
      "2024-11-22 18:14:06.347332: \n",
      "2024-11-22 18:14:06.357332: Epoch 265\n",
      "2024-11-22 18:14:06.357332: Current learning rate: 0.00507\n",
      "2024-11-22 18:16:16.945497: train_loss -0.7942\n",
      "2024-11-22 18:16:16.955496: val_loss -0.5372\n",
      "2024-11-22 18:16:16.965497: Pseudo dice [0.7158]\n",
      "2024-11-22 18:16:16.965497: Epoch time: 130.6 s\n",
      "2024-11-22 18:16:17.955510: \n",
      "2024-11-22 18:16:17.965510: Epoch 266\n",
      "2024-11-22 18:16:17.965510: Current learning rate: 0.00505\n",
      "2024-11-22 18:18:28.588883: train_loss -0.7968\n",
      "2024-11-22 18:18:28.598884: val_loss -0.5322\n",
      "2024-11-22 18:18:28.608883: Pseudo dice [0.7193]\n",
      "2024-11-22 18:18:28.608883: Epoch time: 130.63 s\n",
      "2024-11-22 18:18:29.599245: \n",
      "2024-11-22 18:18:29.599245: Epoch 267\n",
      "2024-11-22 18:18:29.609244: Current learning rate: 0.00503\n",
      "2024-11-22 18:20:40.209500: train_loss -0.8093\n",
      "2024-11-22 18:20:40.219500: val_loss -0.3978\n",
      "2024-11-22 18:20:40.219500: Pseudo dice [0.659]\n",
      "2024-11-22 18:20:40.229501: Epoch time: 130.61 s\n",
      "2024-11-22 18:20:41.209513: \n",
      "2024-11-22 18:20:41.219513: Epoch 268\n",
      "2024-11-22 18:20:41.219513: Current learning rate: 0.00501\n",
      "2024-11-22 18:22:51.780788: train_loss -0.8013\n",
      "2024-11-22 18:22:51.800789: val_loss -0.4739\n",
      "2024-11-22 18:22:51.800789: Pseudo dice [0.6983]\n",
      "2024-11-22 18:22:51.810790: Epoch time: 130.57 s\n",
      "2024-11-22 18:22:52.800802: \n",
      "2024-11-22 18:22:52.800802: Epoch 269\n",
      "2024-11-22 18:22:52.810803: Current learning rate: 0.00499\n",
      "2024-11-22 18:25:03.362164: train_loss -0.8167\n",
      "2024-11-22 18:25:03.372164: val_loss -0.4919\n",
      "2024-11-22 18:25:03.382164: Pseudo dice [0.6864]\n",
      "2024-11-22 18:25:03.392165: Epoch time: 130.57 s\n",
      "2024-11-22 18:25:04.372178: \n",
      "2024-11-22 18:25:04.372178: Epoch 270\n",
      "2024-11-22 18:25:04.382178: Current learning rate: 0.00497\n",
      "2024-11-22 18:27:14.929875: train_loss -0.8168\n",
      "2024-11-22 18:27:14.939875: val_loss -0.5026\n",
      "2024-11-22 18:27:14.939875: Pseudo dice [0.6942]\n",
      "2024-11-22 18:27:14.949875: Epoch time: 130.56 s\n",
      "2024-11-22 18:27:15.940269: \n",
      "2024-11-22 18:27:15.940269: Epoch 271\n",
      "2024-11-22 18:27:15.950267: Current learning rate: 0.00495\n",
      "2024-11-22 18:29:27.188377: train_loss -0.802\n",
      "2024-11-22 18:29:27.198376: val_loss -0.463\n",
      "2024-11-22 18:29:27.208378: Pseudo dice [0.6558]\n",
      "2024-11-22 18:29:27.208378: Epoch time: 131.25 s\n",
      "2024-11-22 18:29:28.368392: \n",
      "2024-11-22 18:29:28.378392: Epoch 272\n",
      "2024-11-22 18:29:28.378392: Current learning rate: 0.00493\n",
      "2024-11-22 18:31:39.016562: train_loss -0.7643\n",
      "2024-11-22 18:31:39.026561: val_loss -0.5708\n",
      "2024-11-22 18:31:39.036563: Pseudo dice [0.7261]\n",
      "2024-11-22 18:31:39.036563: Epoch time: 130.65 s\n",
      "2024-11-22 18:31:40.026576: \n",
      "2024-11-22 18:31:40.036576: Epoch 273\n",
      "2024-11-22 18:31:40.036576: Current learning rate: 0.00491\n",
      "2024-11-22 18:33:50.625823: train_loss -0.7866\n",
      "2024-11-22 18:33:50.625823: val_loss -0.5072\n",
      "2024-11-22 18:33:50.635824: Pseudo dice [0.713]\n",
      "2024-11-22 18:33:50.635824: Epoch time: 130.6 s\n",
      "2024-11-22 18:33:51.616804: \n",
      "2024-11-22 18:33:51.626805: Epoch 274\n",
      "2024-11-22 18:33:51.626805: Current learning rate: 0.00489\n",
      "2024-11-22 18:36:02.224620: train_loss -0.7988\n",
      "2024-11-22 18:36:02.234621: val_loss -0.52\n",
      "2024-11-22 18:36:02.244621: Pseudo dice [0.6984]\n",
      "2024-11-22 18:36:02.254622: Epoch time: 130.61 s\n",
      "2024-11-22 18:36:03.244637: \n",
      "2024-11-22 18:36:03.244637: Epoch 275\n",
      "2024-11-22 18:36:03.254634: Current learning rate: 0.00487\n",
      "2024-11-22 18:38:13.823000: train_loss -0.8044\n",
      "2024-11-22 18:38:13.832999: val_loss -0.3527\n",
      "2024-11-22 18:38:13.842999: Pseudo dice [0.7111]\n",
      "2024-11-22 18:38:13.853000: Epoch time: 130.58 s\n",
      "2024-11-22 18:38:14.833014: \n",
      "2024-11-22 18:38:14.843014: Epoch 276\n",
      "2024-11-22 18:38:14.843014: Current learning rate: 0.00485\n",
      "2024-11-22 18:40:25.462054: train_loss -0.8067\n",
      "2024-11-22 18:40:25.482054: val_loss -0.5507\n",
      "2024-11-22 18:40:25.482054: Pseudo dice [0.7342]\n",
      "2024-11-22 18:40:25.492054: Epoch time: 130.63 s\n",
      "2024-11-22 18:40:26.483025: \n",
      "2024-11-22 18:40:26.483025: Epoch 277\n",
      "2024-11-22 18:40:26.493022: Current learning rate: 0.00484\n",
      "2024-11-22 18:42:37.030153: train_loss -0.8223\n",
      "2024-11-22 18:42:37.040152: val_loss -0.5696\n",
      "2024-11-22 18:42:37.050153: Pseudo dice [0.7429]\n",
      "2024-11-22 18:42:37.060153: Epoch time: 130.55 s\n",
      "2024-11-22 18:42:38.040166: \n",
      "2024-11-22 18:42:38.040166: Epoch 278\n",
      "2024-11-22 18:42:38.050166: Current learning rate: 0.00482\n",
      "2024-11-22 18:44:48.636129: train_loss -0.8119\n",
      "2024-11-22 18:44:48.646130: val_loss -0.5479\n",
      "2024-11-22 18:44:48.646130: Pseudo dice [0.7342]\n",
      "2024-11-22 18:44:48.656130: Epoch time: 130.6 s\n",
      "2024-11-22 18:44:48.656130: Yayy! New best EMA pseudo Dice: 0.7043\n",
      "2024-11-22 18:44:49.887647: \n",
      "2024-11-22 18:44:49.887647: Epoch 279\n",
      "2024-11-22 18:44:49.897646: Current learning rate: 0.0048\n",
      "2024-11-22 18:47:00.480542: train_loss -0.8196\n",
      "2024-11-22 18:47:00.500542: val_loss -0.3882\n",
      "2024-11-22 18:47:00.500542: Pseudo dice [0.6047]\n",
      "2024-11-22 18:47:00.510543: Epoch time: 130.59 s\n",
      "2024-11-22 18:47:01.680560: \n",
      "2024-11-22 18:47:01.680560: Epoch 280\n",
      "2024-11-22 18:47:01.690558: Current learning rate: 0.00478\n",
      "2024-11-22 18:49:12.249557: train_loss -0.7942\n",
      "2024-11-22 18:49:12.259557: val_loss -0.5054\n",
      "2024-11-22 18:49:12.269557: Pseudo dice [0.678]\n",
      "2024-11-22 18:49:12.269557: Epoch time: 130.57 s\n",
      "2024-11-22 18:49:13.259570: \n",
      "2024-11-22 18:49:13.269570: Epoch 281\n",
      "2024-11-22 18:49:13.269570: Current learning rate: 0.00476\n",
      "2024-11-22 18:51:23.857440: train_loss -0.7778\n",
      "2024-11-22 18:51:23.867441: val_loss -0.4821\n",
      "2024-11-22 18:51:23.867441: Pseudo dice [0.6951]\n",
      "2024-11-22 18:51:23.877442: Epoch time: 130.6 s\n",
      "2024-11-22 18:51:24.857779: \n",
      "2024-11-22 18:51:24.867779: Epoch 282\n",
      "2024-11-22 18:51:24.867779: Current learning rate: 0.00474\n",
      "2024-11-22 18:53:35.514508: train_loss -0.7851\n",
      "2024-11-22 18:53:35.524508: val_loss -0.6094\n",
      "2024-11-22 18:53:35.534508: Pseudo dice [0.7779]\n",
      "2024-11-22 18:53:35.544508: Epoch time: 130.66 s\n",
      "2024-11-22 18:53:36.524814: \n",
      "2024-11-22 18:53:36.534814: Epoch 283\n",
      "2024-11-22 18:53:36.534814: Current learning rate: 0.00472\n",
      "2024-11-22 18:55:47.184974: train_loss -0.8174\n",
      "2024-11-22 18:55:47.184974: val_loss -0.5101\n",
      "2024-11-22 18:55:47.194973: Pseudo dice [0.7057]\n",
      "2024-11-22 18:55:47.204974: Epoch time: 130.66 s\n",
      "2024-11-22 18:55:48.195294: \n",
      "2024-11-22 18:55:48.205294: Epoch 284\n",
      "2024-11-22 18:55:48.205294: Current learning rate: 0.0047\n",
      "2024-11-22 18:57:58.915087: train_loss -0.8229\n",
      "2024-11-22 18:57:58.925088: val_loss -0.4079\n",
      "2024-11-22 18:57:58.935088: Pseudo dice [0.6405]\n",
      "2024-11-22 18:57:58.935088: Epoch time: 130.72 s\n",
      "2024-11-22 18:57:59.915101: \n",
      "2024-11-22 18:57:59.925102: Epoch 285\n",
      "2024-11-22 18:57:59.925102: Current learning rate: 0.00468\n",
      "2024-11-22 19:00:10.525457: train_loss -0.816\n",
      "2024-11-22 19:00:10.535458: val_loss -0.2889\n",
      "2024-11-22 19:00:10.545458: Pseudo dice [0.6021]\n",
      "2024-11-22 19:00:10.545458: Epoch time: 130.61 s\n",
      "2024-11-22 19:00:11.534334: \n",
      "2024-11-22 19:00:11.539452: Epoch 286\n",
      "2024-11-22 19:00:11.543505: Current learning rate: 0.00466\n",
      "2024-11-22 19:02:22.218224: train_loss -0.7905\n",
      "2024-11-22 19:02:22.228225: val_loss -0.4129\n",
      "2024-11-22 19:02:22.238226: Pseudo dice [0.6768]\n",
      "2024-11-22 19:02:22.238226: Epoch time: 130.68 s\n",
      "2024-11-22 19:02:23.418243: \n",
      "2024-11-22 19:02:23.418243: Epoch 287\n",
      "2024-11-22 19:02:23.428241: Current learning rate: 0.00464\n",
      "2024-11-22 19:04:33.988539: train_loss -0.7903\n",
      "2024-11-22 19:04:33.998539: val_loss -0.419\n",
      "2024-11-22 19:04:34.008539: Pseudo dice [0.6741]\n",
      "2024-11-22 19:04:34.018539: Epoch time: 130.57 s\n",
      "2024-11-22 19:04:35.018553: \n",
      "2024-11-22 19:04:35.028553: Epoch 288\n",
      "2024-11-22 19:04:35.028553: Current learning rate: 0.00462\n",
      "2024-11-22 19:06:45.669187: train_loss -0.8104\n",
      "2024-11-22 19:06:45.679188: val_loss -0.5125\n",
      "2024-11-22 19:06:45.689188: Pseudo dice [0.7145]\n",
      "2024-11-22 19:06:45.689188: Epoch time: 130.65 s\n",
      "2024-11-22 19:06:46.689201: \n",
      "2024-11-22 19:06:46.699202: Epoch 289\n",
      "2024-11-22 19:06:46.699202: Current learning rate: 0.0046\n",
      "2024-11-22 19:08:57.259493: train_loss -0.7734\n",
      "2024-11-22 19:08:57.269492: val_loss -0.4998\n",
      "2024-11-22 19:08:57.279493: Pseudo dice [0.7104]\n",
      "2024-11-22 19:08:57.289494: Epoch time: 130.57 s\n",
      "2024-11-22 19:08:58.289507: \n",
      "2024-11-22 19:08:58.289507: Epoch 290\n",
      "2024-11-22 19:08:58.299506: Current learning rate: 0.00458\n",
      "2024-11-22 19:11:08.855065: train_loss -0.7635\n",
      "2024-11-22 19:11:08.865066: val_loss -0.4377\n",
      "2024-11-22 19:11:08.875065: Pseudo dice [0.7021]\n",
      "2024-11-22 19:11:08.875065: Epoch time: 130.57 s\n",
      "2024-11-22 19:11:09.885082: \n",
      "2024-11-22 19:11:09.885082: Epoch 291\n",
      "2024-11-22 19:11:09.885082: Current learning rate: 0.00456\n",
      "2024-11-22 19:13:20.533312: train_loss -0.7988\n",
      "2024-11-22 19:13:20.548015: val_loss -0.4373\n",
      "2024-11-22 19:13:20.595624: Pseudo dice [0.6902]\n",
      "2024-11-22 19:13:20.603629: Epoch time: 130.66 s\n",
      "2024-11-22 19:13:21.593648: \n",
      "2024-11-22 19:13:21.593648: Epoch 292\n",
      "2024-11-22 19:13:21.603645: Current learning rate: 0.00454\n",
      "2024-11-22 19:15:32.125325: train_loss -0.8206\n",
      "2024-11-22 19:15:32.135326: val_loss -0.5202\n",
      "2024-11-22 19:15:32.145326: Pseudo dice [0.7179]\n",
      "2024-11-22 19:15:32.145326: Epoch time: 130.53 s\n",
      "2024-11-22 19:15:33.155344: \n",
      "2024-11-22 19:15:33.155344: Epoch 293\n",
      "2024-11-22 19:15:33.165340: Current learning rate: 0.00452\n",
      "2024-11-22 19:17:43.626133: train_loss -0.8025\n",
      "2024-11-22 19:17:43.636134: val_loss -0.4479\n",
      "2024-11-22 19:17:43.646133: Pseudo dice [0.6649]\n",
      "2024-11-22 19:17:43.646133: Epoch time: 130.47 s\n",
      "2024-11-22 19:17:44.826481: \n",
      "2024-11-22 19:17:44.836481: Epoch 294\n",
      "2024-11-22 19:17:44.836481: Current learning rate: 0.0045\n",
      "2024-11-22 19:19:55.435405: train_loss -0.7982\n",
      "2024-11-22 19:19:55.445406: val_loss -0.4463\n",
      "2024-11-22 19:19:55.455405: Pseudo dice [0.6941]\n",
      "2024-11-22 19:19:55.465405: Epoch time: 130.61 s\n",
      "2024-11-22 19:19:56.465419: \n",
      "2024-11-22 19:19:56.475419: Epoch 295\n",
      "2024-11-22 19:19:56.475419: Current learning rate: 0.00448\n",
      "2024-11-22 19:22:07.026680: train_loss -0.7739\n",
      "2024-11-22 19:22:07.036680: val_loss -0.3755\n",
      "2024-11-22 19:22:07.046681: Pseudo dice [0.6204]\n",
      "2024-11-22 19:22:07.056681: Epoch time: 130.56 s\n",
      "2024-11-22 19:22:08.056695: \n",
      "2024-11-22 19:22:08.056695: Epoch 296\n",
      "2024-11-22 19:22:08.066694: Current learning rate: 0.00446\n",
      "2024-11-22 19:24:18.777285: train_loss -0.8041\n",
      "2024-11-22 19:24:18.787287: val_loss -0.3199\n",
      "2024-11-22 19:24:18.797288: Pseudo dice [0.6109]\n",
      "2024-11-22 19:24:18.797288: Epoch time: 130.72 s\n",
      "2024-11-22 19:24:19.807302: \n",
      "2024-11-22 19:24:19.807302: Epoch 297\n",
      "2024-11-22 19:24:19.807302: Current learning rate: 0.00444\n",
      "2024-11-22 19:26:30.474997: train_loss -0.799\n",
      "2024-11-22 19:26:30.484997: val_loss -0.372\n",
      "2024-11-22 19:26:30.484997: Pseudo dice [0.5968]\n",
      "2024-11-22 19:26:30.497197: Epoch time: 130.68 s\n",
      "2024-11-22 19:26:31.496059: \n",
      "2024-11-22 19:26:31.506058: Epoch 298\n",
      "2024-11-22 19:26:31.506058: Current learning rate: 0.00442\n",
      "2024-11-22 19:28:42.076543: train_loss -0.816\n",
      "2024-11-22 19:28:42.086545: val_loss -0.4209\n",
      "2024-11-22 19:28:42.096543: Pseudo dice [0.6744]\n",
      "2024-11-22 19:28:42.096543: Epoch time: 130.58 s\n",
      "2024-11-22 19:28:43.106557: \n",
      "2024-11-22 19:28:43.116557: Epoch 299\n",
      "2024-11-22 19:28:43.116557: Current learning rate: 0.0044\n",
      "2024-11-22 19:30:53.735914: train_loss -0.8178\n",
      "2024-11-22 19:30:53.745915: val_loss -0.4475\n",
      "2024-11-22 19:30:53.745915: Pseudo dice [0.6992]\n",
      "2024-11-22 19:30:53.755915: Epoch time: 130.63 s\n",
      "2024-11-22 19:30:55.006244: \n",
      "2024-11-22 19:30:55.006244: Epoch 300\n",
      "2024-11-22 19:30:55.016244: Current learning rate: 0.00438\n",
      "2024-11-22 19:33:05.552743: train_loss -0.8266\n",
      "2024-11-22 19:33:05.572744: val_loss -0.5521\n",
      "2024-11-22 19:33:05.582744: Pseudo dice [0.6962]\n",
      "2024-11-22 19:33:05.582744: Epoch time: 130.55 s\n",
      "2024-11-22 19:33:06.763855: \n",
      "2024-11-22 19:33:06.773855: Epoch 301\n",
      "2024-11-22 19:33:06.773855: Current learning rate: 0.00436\n",
      "2024-11-22 19:35:17.363348: train_loss -0.8192\n",
      "2024-11-22 19:35:17.373347: val_loss -0.5226\n",
      "2024-11-22 19:35:17.383348: Pseudo dice [0.706]\n",
      "2024-11-22 19:35:17.393348: Epoch time: 130.6 s\n",
      "2024-11-22 19:35:18.393361: \n",
      "2024-11-22 19:35:18.393361: Epoch 302\n",
      "2024-11-22 19:35:18.403361: Current learning rate: 0.00434\n",
      "2024-11-22 19:37:29.082983: train_loss -0.8159\n",
      "2024-11-22 19:37:29.092983: val_loss -0.4267\n",
      "2024-11-22 19:37:29.092983: Pseudo dice [0.6635]\n",
      "2024-11-22 19:37:29.102984: Epoch time: 130.69 s\n",
      "2024-11-22 19:37:30.104059: \n",
      "2024-11-22 19:37:30.114056: Epoch 303\n",
      "2024-11-22 19:37:30.114056: Current learning rate: 0.00432\n",
      "2024-11-22 19:39:40.725328: train_loss -0.8123\n",
      "2024-11-22 19:39:40.745329: val_loss -0.3338\n",
      "2024-11-22 19:39:40.745329: Pseudo dice [0.6689]\n",
      "2024-11-22 19:39:40.755329: Epoch time: 130.62 s\n",
      "2024-11-22 19:39:41.755475: \n",
      "2024-11-22 19:39:41.755475: Epoch 304\n",
      "2024-11-22 19:39:41.765475: Current learning rate: 0.0043\n",
      "2024-11-22 19:41:52.375746: train_loss -0.8217\n",
      "2024-11-22 19:41:52.385747: val_loss -0.4744\n",
      "2024-11-22 19:41:52.395747: Pseudo dice [0.7036]\n",
      "2024-11-22 19:41:52.395747: Epoch time: 130.62 s\n",
      "2024-11-22 19:41:53.395760: \n",
      "2024-11-22 19:41:53.405761: Epoch 305\n",
      "2024-11-22 19:41:53.405761: Current learning rate: 0.00429\n",
      "2024-11-22 19:44:03.993549: train_loss -0.819\n",
      "2024-11-22 19:44:04.003550: val_loss -0.3958\n",
      "2024-11-22 19:44:04.013549: Pseudo dice [0.7122]\n",
      "2024-11-22 19:44:04.023550: Epoch time: 130.6 s\n",
      "2024-11-22 19:44:05.023566: \n",
      "2024-11-22 19:44:05.023566: Epoch 306\n",
      "2024-11-22 19:44:05.033563: Current learning rate: 0.00427\n",
      "2024-11-22 19:46:15.632277: train_loss -0.7983\n",
      "2024-11-22 19:46:15.642277: val_loss -0.4203\n",
      "2024-11-22 19:46:15.652278: Pseudo dice [0.7283]\n",
      "2024-11-22 19:46:15.652278: Epoch time: 130.61 s\n",
      "2024-11-22 19:46:16.662744: \n",
      "2024-11-22 19:46:16.662744: Epoch 307\n",
      "2024-11-22 19:46:16.672744: Current learning rate: 0.00425\n",
      "2024-11-22 19:48:27.236876: train_loss -0.7857\n",
      "2024-11-22 19:48:27.246877: val_loss -0.3339\n",
      "2024-11-22 19:48:27.256876: Pseudo dice [0.5741]\n",
      "2024-11-22 19:48:27.256876: Epoch time: 130.57 s\n",
      "2024-11-22 19:48:28.266890: \n",
      "2024-11-22 19:48:28.276890: Epoch 308\n",
      "2024-11-22 19:48:28.276890: Current learning rate: 0.00423\n",
      "2024-11-22 19:50:38.768270: train_loss -0.8161\n",
      "2024-11-22 19:50:38.778269: val_loss -0.3736\n",
      "2024-11-22 19:50:38.778269: Pseudo dice [0.6643]\n",
      "2024-11-22 19:50:38.788270: Epoch time: 130.5 s\n",
      "2024-11-22 19:50:39.968286: \n",
      "2024-11-22 19:50:39.978286: Epoch 309\n",
      "2024-11-22 19:50:39.978286: Current learning rate: 0.00421\n",
      "2024-11-22 19:52:50.545922: train_loss -0.8278\n",
      "2024-11-22 19:52:50.555923: val_loss -0.3697\n",
      "2024-11-22 19:52:50.555923: Pseudo dice [0.6776]\n",
      "2024-11-22 19:52:50.565923: Epoch time: 130.58 s\n",
      "2024-11-22 19:52:51.567017: \n",
      "2024-11-22 19:52:51.577017: Epoch 310\n",
      "2024-11-22 19:52:51.577017: Current learning rate: 0.00419\n",
      "2024-11-22 19:55:02.107695: train_loss -0.8131\n",
      "2024-11-22 19:55:02.117697: val_loss -0.3717\n",
      "2024-11-22 19:55:02.127698: Pseudo dice [0.6565]\n",
      "2024-11-22 19:55:02.127698: Epoch time: 130.54 s\n",
      "2024-11-22 19:55:03.127711: \n",
      "2024-11-22 19:55:03.137710: Epoch 311\n",
      "2024-11-22 19:55:03.137710: Current learning rate: 0.00417\n",
      "2024-11-22 19:57:13.627625: train_loss -0.8167\n",
      "2024-11-22 19:57:13.637625: val_loss -0.5778\n",
      "2024-11-22 19:57:13.647626: Pseudo dice [0.7448]\n",
      "2024-11-22 19:57:13.657626: Epoch time: 130.5 s\n",
      "2024-11-22 19:57:14.657639: \n",
      "2024-11-22 19:57:14.667639: Epoch 312\n",
      "2024-11-22 19:57:14.667639: Current learning rate: 0.00415\n",
      "2024-11-22 19:59:25.289976: train_loss -0.8022\n",
      "2024-11-22 19:59:25.299975: val_loss -0.3349\n",
      "2024-11-22 19:59:25.299975: Pseudo dice [0.5549]\n",
      "2024-11-22 19:59:25.309975: Epoch time: 130.63 s\n",
      "2024-11-22 19:59:26.319990: \n",
      "2024-11-22 19:59:26.319990: Epoch 313\n",
      "2024-11-22 19:59:26.329990: Current learning rate: 0.00413\n",
      "2024-11-22 20:01:36.972787: train_loss -0.7772\n",
      "2024-11-22 20:01:36.982787: val_loss -0.5622\n",
      "2024-11-22 20:01:36.982787: Pseudo dice [0.7152]\n",
      "2024-11-22 20:01:36.992788: Epoch time: 130.65 s\n",
      "2024-11-22 20:01:38.002804: \n",
      "2024-11-22 20:01:38.002804: Epoch 314\n",
      "2024-11-22 20:01:38.012802: Current learning rate: 0.00411\n",
      "2024-11-22 20:03:48.564415: train_loss -0.8141\n",
      "2024-11-22 20:03:48.574415: val_loss -0.5675\n",
      "2024-11-22 20:03:48.584415: Pseudo dice [0.7373]\n",
      "2024-11-22 20:03:48.584415: Epoch time: 130.56 s\n",
      "2024-11-22 20:03:49.594715: \n",
      "2024-11-22 20:03:49.594715: Epoch 315\n",
      "2024-11-22 20:03:49.604715: Current learning rate: 0.00409\n",
      "2024-11-22 20:06:00.256071: train_loss -0.8176\n",
      "2024-11-22 20:06:00.266073: val_loss -0.4792\n",
      "2024-11-22 20:06:00.276073: Pseudo dice [0.6832]\n",
      "2024-11-22 20:06:00.276073: Epoch time: 130.66 s\n",
      "2024-11-22 20:06:01.446089: \n",
      "2024-11-22 20:06:01.456089: Epoch 316\n",
      "2024-11-22 20:06:01.466089: Current learning rate: 0.00407\n",
      "2024-11-22 20:08:12.057406: train_loss -0.8318\n",
      "2024-11-22 20:08:12.067405: val_loss -0.5408\n",
      "2024-11-22 20:08:12.067405: Pseudo dice [0.6764]\n",
      "2024-11-22 20:08:12.077406: Epoch time: 130.61 s\n",
      "2024-11-22 20:08:13.087423: \n",
      "2024-11-22 20:08:13.087423: Epoch 317\n",
      "2024-11-22 20:08:13.097420: Current learning rate: 0.00405\n",
      "2024-11-22 20:10:23.726464: train_loss -0.8359\n",
      "2024-11-22 20:10:23.746761: val_loss -0.5578\n",
      "2024-11-22 20:10:23.746761: Pseudo dice [0.7413]\n",
      "2024-11-22 20:10:23.756764: Epoch time: 130.64 s\n",
      "2024-11-22 20:10:24.766778: \n",
      "2024-11-22 20:10:24.766778: Epoch 318\n",
      "2024-11-22 20:10:24.766778: Current learning rate: 0.00403\n",
      "2024-11-22 20:12:35.359374: train_loss -0.8222\n",
      "2024-11-22 20:12:35.369375: val_loss -0.4439\n",
      "2024-11-22 20:12:35.379375: Pseudo dice [0.6609]\n",
      "2024-11-22 20:12:35.379375: Epoch time: 130.6 s\n",
      "2024-11-22 20:12:36.389388: \n",
      "2024-11-22 20:12:36.389388: Epoch 319\n",
      "2024-11-22 20:12:36.399389: Current learning rate: 0.00401\n",
      "2024-11-22 20:14:47.059018: train_loss -0.8134\n",
      "2024-11-22 20:14:47.069019: val_loss -0.4762\n",
      "2024-11-22 20:14:47.079020: Pseudo dice [0.697]\n",
      "2024-11-22 20:14:47.079020: Epoch time: 130.67 s\n",
      "2024-11-22 20:14:48.089033: \n",
      "2024-11-22 20:14:48.089033: Epoch 320\n",
      "2024-11-22 20:14:48.099034: Current learning rate: 0.00399\n",
      "2024-11-22 20:16:58.698268: train_loss -0.8304\n",
      "2024-11-22 20:16:58.708269: val_loss -0.2607\n",
      "2024-11-22 20:16:58.708269: Pseudo dice [0.6622]\n",
      "2024-11-22 20:16:58.718269: Epoch time: 130.61 s\n",
      "2024-11-22 20:16:59.718282: \n",
      "2024-11-22 20:16:59.728283: Epoch 321\n",
      "2024-11-22 20:16:59.728283: Current learning rate: 0.00397\n",
      "2024-11-22 20:19:10.337559: train_loss -0.8158\n",
      "2024-11-22 20:19:10.347558: val_loss -0.4334\n",
      "2024-11-22 20:19:10.357558: Pseudo dice [0.6784]\n",
      "2024-11-22 20:19:10.357558: Epoch time: 130.62 s\n",
      "2024-11-22 20:19:11.367573: \n",
      "2024-11-22 20:19:11.377573: Epoch 322\n",
      "2024-11-22 20:19:11.377573: Current learning rate: 0.00395\n",
      "2024-11-22 20:21:21.998119: train_loss -0.8099\n",
      "2024-11-22 20:21:22.008119: val_loss -0.4662\n",
      "2024-11-22 20:21:22.018121: Pseudo dice [0.673]\n",
      "2024-11-22 20:21:22.018121: Epoch time: 130.63 s\n",
      "2024-11-22 20:21:23.198137: \n",
      "2024-11-22 20:21:23.198137: Epoch 323\n",
      "2024-11-22 20:21:23.208136: Current learning rate: 0.00393\n",
      "2024-11-22 20:23:33.757189: train_loss -0.8191\n",
      "2024-11-22 20:23:33.767190: val_loss -0.4625\n",
      "2024-11-22 20:23:33.767190: Pseudo dice [0.6972]\n",
      "2024-11-22 20:23:33.777189: Epoch time: 130.56 s\n",
      "2024-11-22 20:23:34.777202: \n",
      "2024-11-22 20:23:34.787202: Epoch 324\n",
      "2024-11-22 20:23:34.787202: Current learning rate: 0.00391\n",
      "2024-11-22 20:25:45.450286: train_loss -0.8255\n",
      "2024-11-22 20:25:45.460286: val_loss -0.3522\n",
      "2024-11-22 20:25:45.470287: Pseudo dice [0.61]\n",
      "2024-11-22 20:25:45.480287: Epoch time: 130.67 s\n",
      "2024-11-22 20:25:46.490810: \n",
      "2024-11-22 20:25:46.490810: Epoch 325\n",
      "2024-11-22 20:25:46.500809: Current learning rate: 0.00389\n",
      "2024-11-22 20:27:57.082041: train_loss -0.8001\n",
      "2024-11-22 20:27:57.092041: val_loss -0.4567\n",
      "2024-11-22 20:27:57.102041: Pseudo dice [0.6858]\n",
      "2024-11-22 20:27:57.102041: Epoch time: 130.59 s\n",
      "2024-11-22 20:27:58.112983: \n",
      "2024-11-22 20:27:58.112983: Epoch 326\n",
      "2024-11-22 20:27:58.122983: Current learning rate: 0.00387\n",
      "2024-11-22 20:30:08.822815: train_loss -0.7898\n",
      "2024-11-22 20:30:08.822815: val_loss -0.5196\n",
      "2024-11-22 20:30:08.832815: Pseudo dice [0.7081]\n",
      "2024-11-22 20:30:08.842815: Epoch time: 130.71 s\n",
      "2024-11-22 20:30:09.843124: \n",
      "2024-11-22 20:30:09.853124: Epoch 327\n",
      "2024-11-22 20:30:09.853124: Current learning rate: 0.00385\n",
      "2024-11-22 20:32:20.527679: train_loss -0.8218\n",
      "2024-11-22 20:32:20.537679: val_loss -0.5362\n",
      "2024-11-22 20:32:20.537679: Pseudo dice [0.71]\n",
      "2024-11-22 20:32:20.547679: Epoch time: 130.68 s\n",
      "2024-11-22 20:32:21.557693: \n",
      "2024-11-22 20:32:21.557693: Epoch 328\n",
      "2024-11-22 20:32:21.567693: Current learning rate: 0.00383\n",
      "2024-11-22 20:34:32.168774: train_loss -0.8262\n",
      "2024-11-22 20:34:32.178775: val_loss -0.4111\n",
      "2024-11-22 20:34:32.188774: Pseudo dice [0.7191]\n",
      "2024-11-22 20:34:32.188774: Epoch time: 130.61 s\n",
      "2024-11-22 20:34:33.198788: \n",
      "2024-11-22 20:34:33.208788: Epoch 329\n",
      "2024-11-22 20:34:33.208788: Current learning rate: 0.00381\n",
      "2024-11-22 20:36:43.812181: train_loss -0.8\n",
      "2024-11-22 20:36:43.822180: val_loss -0.4822\n",
      "2024-11-22 20:36:43.822180: Pseudo dice [0.7228]\n",
      "2024-11-22 20:36:43.832181: Epoch time: 130.61 s\n",
      "2024-11-22 20:36:45.052905: \n",
      "2024-11-22 20:36:45.062905: Epoch 330\n",
      "2024-11-22 20:36:45.062905: Current learning rate: 0.00379\n",
      "2024-11-22 20:38:55.571045: train_loss -0.8169\n",
      "2024-11-22 20:38:55.581045: val_loss -0.5095\n",
      "2024-11-22 20:38:55.591046: Pseudo dice [0.6942]\n",
      "2024-11-22 20:38:55.601046: Epoch time: 130.52 s\n",
      "2024-11-22 20:38:56.601068: \n",
      "2024-11-22 20:38:56.611068: Epoch 331\n",
      "2024-11-22 20:38:56.611068: Current learning rate: 0.00377\n",
      "2024-11-22 20:41:07.122565: train_loss -0.8268\n",
      "2024-11-22 20:41:07.132565: val_loss -0.5894\n",
      "2024-11-22 20:41:07.132565: Pseudo dice [0.7548]\n",
      "2024-11-22 20:41:07.142566: Epoch time: 130.52 s\n",
      "2024-11-22 20:41:08.152586: \n",
      "2024-11-22 20:41:08.152586: Epoch 332\n",
      "2024-11-22 20:41:08.162587: Current learning rate: 0.00375\n",
      "2024-11-22 20:43:18.718360: train_loss -0.8061\n",
      "2024-11-22 20:43:18.728360: val_loss -0.4607\n",
      "2024-11-22 20:43:18.728360: Pseudo dice [0.733]\n",
      "2024-11-22 20:43:18.738361: Epoch time: 130.57 s\n",
      "2024-11-22 20:43:19.738383: \n",
      "2024-11-22 20:43:19.748383: Epoch 333\n",
      "2024-11-22 20:43:19.748383: Current learning rate: 0.00373\n",
      "2024-11-22 20:45:30.292020: train_loss -0.8148\n",
      "2024-11-22 20:45:30.302020: val_loss -0.4663\n",
      "2024-11-22 20:45:30.312020: Pseudo dice [0.6883]\n",
      "2024-11-22 20:45:30.312020: Epoch time: 130.55 s\n",
      "2024-11-22 20:45:31.322355: \n",
      "2024-11-22 20:45:31.322355: Epoch 334\n",
      "2024-11-22 20:45:31.332346: Current learning rate: 0.00371\n",
      "2024-11-22 20:47:41.946806: train_loss -0.8271\n",
      "2024-11-22 20:47:41.946806: val_loss -0.57\n",
      "2024-11-22 20:47:41.956806: Pseudo dice [0.7344]\n",
      "2024-11-22 20:47:41.966806: Epoch time: 130.62 s\n",
      "2024-11-22 20:47:42.986829: \n",
      "2024-11-22 20:47:42.986829: Epoch 335\n",
      "2024-11-22 20:47:42.996828: Current learning rate: 0.00369\n",
      "2024-11-22 20:49:53.536742: train_loss -0.824\n",
      "2024-11-22 20:49:53.546742: val_loss -0.5648\n",
      "2024-11-22 20:49:53.556743: Pseudo dice [0.7397]\n",
      "2024-11-22 20:49:53.556743: Epoch time: 130.55 s\n",
      "2024-11-22 20:49:53.566743: Yayy! New best EMA pseudo Dice: 0.7063\n",
      "2024-11-22 20:49:54.827216: \n",
      "2024-11-22 20:49:54.837215: Epoch 336\n",
      "2024-11-22 20:49:54.837215: Current learning rate: 0.00367\n",
      "2024-11-22 20:52:05.445725: train_loss -0.8008\n",
      "2024-11-22 20:52:05.455725: val_loss -0.4672\n",
      "2024-11-22 20:52:05.465726: Pseudo dice [0.6585]\n",
      "2024-11-22 20:52:05.465726: Epoch time: 130.62 s\n",
      "2024-11-22 20:52:06.666611: \n",
      "2024-11-22 20:52:06.676610: Epoch 337\n",
      "2024-11-22 20:52:06.676610: Current learning rate: 0.00365\n",
      "2024-11-22 20:54:17.312562: train_loss -0.8086\n",
      "2024-11-22 20:54:17.322564: val_loss -0.4563\n",
      "2024-11-22 20:54:17.332564: Pseudo dice [0.6615]\n",
      "2024-11-22 20:54:17.332564: Epoch time: 130.65 s\n",
      "2024-11-22 20:54:18.362577: \n",
      "2024-11-22 20:54:18.362577: Epoch 338\n",
      "2024-11-22 20:54:18.372578: Current learning rate: 0.00363\n",
      "2024-11-22 20:56:29.011781: train_loss -0.8136\n",
      "2024-11-22 20:56:29.021781: val_loss -0.5176\n",
      "2024-11-22 20:56:29.031781: Pseudo dice [0.7121]\n",
      "2024-11-22 20:56:29.031781: Epoch time: 130.65 s\n",
      "2024-11-22 20:56:30.061804: \n",
      "2024-11-22 20:56:30.061804: Epoch 339\n",
      "2024-11-22 20:56:30.061804: Current learning rate: 0.00361\n",
      "2024-11-22 20:58:40.645800: train_loss -0.8256\n",
      "2024-11-22 20:58:40.655801: val_loss -0.4427\n",
      "2024-11-22 20:58:40.655801: Pseudo dice [0.6895]\n",
      "2024-11-22 20:58:40.665801: Epoch time: 130.59 s\n",
      "2024-11-22 20:58:41.695814: \n",
      "2024-11-22 20:58:41.695814: Epoch 340\n",
      "2024-11-22 20:58:41.705816: Current learning rate: 0.00359\n",
      "2024-11-22 21:00:52.334235: train_loss -0.8156\n",
      "2024-11-22 21:00:52.344237: val_loss -0.5305\n",
      "2024-11-22 21:00:52.354236: Pseudo dice [0.7539]\n",
      "2024-11-22 21:00:52.354236: Epoch time: 130.64 s\n",
      "2024-11-22 21:00:53.384251: \n",
      "2024-11-22 21:00:53.384251: Epoch 341\n",
      "2024-11-22 21:00:53.394252: Current learning rate: 0.00357\n",
      "2024-11-22 21:03:03.923599: train_loss -0.8169\n",
      "2024-11-22 21:03:03.933599: val_loss -0.4423\n",
      "2024-11-22 21:03:03.943599: Pseudo dice [0.7052]\n",
      "2024-11-22 21:03:03.943599: Epoch time: 130.54 s\n",
      "2024-11-22 21:03:04.963969: \n",
      "2024-11-22 21:03:04.973968: Epoch 342\n",
      "2024-11-22 21:03:04.973968: Current learning rate: 0.00355\n",
      "2024-11-22 21:05:15.612452: train_loss -0.826\n",
      "2024-11-22 21:05:15.622452: val_loss -0.5201\n",
      "2024-11-22 21:05:15.622452: Pseudo dice [0.7]\n",
      "2024-11-22 21:05:15.632452: Epoch time: 130.65 s\n",
      "2024-11-22 21:05:16.652476: \n",
      "2024-11-22 21:05:16.652476: Epoch 343\n",
      "2024-11-22 21:05:16.662475: Current learning rate: 0.00353\n",
      "2024-11-22 21:07:27.160936: train_loss -0.8237\n",
      "2024-11-22 21:07:27.160936: val_loss -0.6093\n",
      "2024-11-22 21:07:27.170937: Pseudo dice [0.7696]\n",
      "2024-11-22 21:07:27.180936: Epoch time: 130.51 s\n",
      "2024-11-22 21:07:27.190937: Yayy! New best EMA pseudo Dice: 0.71\n",
      "2024-11-22 21:07:28.650964: \n",
      "2024-11-22 21:07:28.650964: Epoch 344\n",
      "2024-11-22 21:07:28.660956: Current learning rate: 0.00351\n",
      "2024-11-22 21:09:39.204097: train_loss -0.8134\n",
      "2024-11-22 21:09:39.214097: val_loss -0.4679\n",
      "2024-11-22 21:09:39.224097: Pseudo dice [0.6783]\n",
      "2024-11-22 21:09:39.234097: Epoch time: 130.55 s\n",
      "2024-11-22 21:09:40.254121: \n",
      "2024-11-22 21:09:40.254121: Epoch 345\n",
      "2024-11-22 21:09:40.264121: Current learning rate: 0.00349\n",
      "2024-11-22 21:11:50.905828: train_loss -0.8359\n",
      "2024-11-22 21:11:50.915829: val_loss -0.3391\n",
      "2024-11-22 21:11:50.925829: Pseudo dice [0.6134]\n",
      "2024-11-22 21:11:50.925829: Epoch time: 130.65 s\n",
      "2024-11-22 21:11:51.955843: \n",
      "2024-11-22 21:11:51.955843: Epoch 346\n",
      "2024-11-22 21:11:51.965851: Current learning rate: 0.00346\n",
      "2024-11-22 21:14:02.546656: train_loss -0.8235\n",
      "2024-11-22 21:14:02.546656: val_loss -0.4283\n",
      "2024-11-22 21:14:02.556656: Pseudo dice [0.6752]\n",
      "2024-11-22 21:14:02.566655: Epoch time: 130.59 s\n",
      "2024-11-22 21:14:03.586972: \n",
      "2024-11-22 21:14:03.596972: Epoch 347\n",
      "2024-11-22 21:14:03.596972: Current learning rate: 0.00344\n",
      "2024-11-22 21:16:14.204880: train_loss -0.8099\n",
      "2024-11-22 21:16:14.214881: val_loss -0.527\n",
      "2024-11-22 21:16:14.214881: Pseudo dice [0.6939]\n",
      "2024-11-22 21:16:14.224880: Epoch time: 130.62 s\n",
      "2024-11-22 21:16:15.254895: \n",
      "2024-11-22 21:16:15.254895: Epoch 348\n",
      "2024-11-22 21:16:15.264895: Current learning rate: 0.00342\n",
      "2024-11-22 21:18:25.764433: train_loss -0.8194\n",
      "2024-11-22 21:18:25.774435: val_loss -0.4102\n",
      "2024-11-22 21:18:25.784434: Pseudo dice [0.7102]\n",
      "2024-11-22 21:18:25.790439: Epoch time: 130.51 s\n",
      "2024-11-22 21:18:26.824461: \n",
      "2024-11-22 21:18:26.824461: Epoch 349\n",
      "2024-11-22 21:18:26.834459: Current learning rate: 0.0034\n",
      "2024-11-22 21:20:37.560604: train_loss -0.8205\n",
      "2024-11-22 21:20:37.570604: val_loss -0.3601\n",
      "2024-11-22 21:20:37.580604: Pseudo dice [0.6462]\n",
      "2024-11-22 21:20:37.589608: Epoch time: 130.74 s\n",
      "2024-11-22 21:20:38.900640: \n",
      "2024-11-22 21:20:38.910631: Epoch 350\n",
      "2024-11-22 21:20:38.910631: Current learning rate: 0.00338\n",
      "2024-11-22 21:22:49.589592: train_loss -0.7902\n",
      "2024-11-22 21:22:49.599592: val_loss -0.5112\n",
      "2024-11-22 21:22:49.599592: Pseudo dice [0.7144]\n",
      "2024-11-22 21:22:49.609592: Epoch time: 130.69 s\n",
      "2024-11-22 21:22:50.799618: \n",
      "2024-11-22 21:22:50.809617: Epoch 351\n",
      "2024-11-22 21:22:50.809617: Current learning rate: 0.00336\n",
      "2024-11-22 21:25:01.527300: train_loss -0.8107\n",
      "2024-11-22 21:25:01.537301: val_loss -0.4067\n",
      "2024-11-22 21:25:01.537301: Pseudo dice [0.6985]\n",
      "2024-11-22 21:25:01.547301: Epoch time: 130.73 s\n",
      "2024-11-22 21:25:02.577324: \n",
      "2024-11-22 21:25:02.577324: Epoch 352\n",
      "2024-11-22 21:25:02.587315: Current learning rate: 0.00334\n",
      "2024-11-22 21:27:13.284223: train_loss -0.8055\n",
      "2024-11-22 21:27:13.294223: val_loss -0.2684\n",
      "2024-11-22 21:27:13.304223: Pseudo dice [0.6416]\n",
      "2024-11-22 21:27:13.304223: Epoch time: 130.71 s\n",
      "2024-11-22 21:27:14.335461: \n",
      "2024-11-22 21:27:14.335461: Epoch 353\n",
      "2024-11-22 21:27:14.345462: Current learning rate: 0.00332\n",
      "2024-11-22 21:29:25.053514: train_loss -0.8204\n",
      "2024-11-22 21:29:25.063515: val_loss -0.4473\n",
      "2024-11-22 21:29:25.073514: Pseudo dice [0.6982]\n",
      "2024-11-22 21:29:25.073514: Epoch time: 130.72 s\n",
      "2024-11-22 21:29:26.113538: \n",
      "2024-11-22 21:29:26.113538: Epoch 354\n",
      "2024-11-22 21:29:26.123529: Current learning rate: 0.0033\n",
      "2024-11-22 21:31:36.783703: train_loss -0.8356\n",
      "2024-11-22 21:31:36.793702: val_loss -0.4706\n",
      "2024-11-22 21:31:36.803703: Pseudo dice [0.6924]\n",
      "2024-11-22 21:31:36.803703: Epoch time: 130.67 s\n",
      "2024-11-22 21:31:37.843718: \n",
      "2024-11-22 21:31:37.843718: Epoch 355\n",
      "2024-11-22 21:31:37.853718: Current learning rate: 0.00328\n",
      "2024-11-22 21:33:48.680459: train_loss -0.8117\n",
      "2024-11-22 21:33:48.690459: val_loss -0.4591\n",
      "2024-11-22 21:33:48.700459: Pseudo dice [0.6886]\n",
      "2024-11-22 21:33:48.700459: Epoch time: 130.85 s\n",
      "2024-11-22 21:33:49.731411: \n",
      "2024-11-22 21:33:49.731411: Epoch 356\n",
      "2024-11-22 21:33:49.741403: Current learning rate: 0.00326\n",
      "2024-11-22 21:36:00.468748: train_loss -0.8202\n",
      "2024-11-22 21:36:00.478748: val_loss -0.5318\n",
      "2024-11-22 21:36:00.488749: Pseudo dice [0.7155]\n",
      "2024-11-22 21:36:00.488749: Epoch time: 130.75 s\n",
      "2024-11-22 21:36:01.518771: \n",
      "2024-11-22 21:36:01.528763: Epoch 357\n",
      "2024-11-22 21:36:01.528763: Current learning rate: 0.00324\n",
      "2024-11-22 21:38:12.284428: train_loss -0.8371\n",
      "2024-11-22 21:38:12.294428: val_loss -0.5498\n",
      "2024-11-22 21:38:12.304429: Pseudo dice [0.7321]\n",
      "2024-11-22 21:38:12.304429: Epoch time: 130.77 s\n",
      "2024-11-22 21:38:13.534455: \n",
      "2024-11-22 21:38:13.544447: Epoch 358\n",
      "2024-11-22 21:38:13.544447: Current learning rate: 0.00322\n",
      "2024-11-22 21:40:24.334413: train_loss -0.8129\n",
      "2024-11-22 21:40:24.344415: val_loss -0.4085\n",
      "2024-11-22 21:40:24.354414: Pseudo dice [0.6735]\n",
      "2024-11-22 21:40:24.354414: Epoch time: 130.8 s\n",
      "2024-11-22 21:40:25.384431: \n",
      "2024-11-22 21:40:25.384431: Epoch 359\n",
      "2024-11-22 21:40:25.394429: Current learning rate: 0.0032\n",
      "2024-11-22 21:42:36.192423: train_loss -0.8388\n",
      "2024-11-22 21:42:36.202424: val_loss -0.5765\n",
      "2024-11-22 21:42:36.212422: Pseudo dice [0.7552]\n",
      "2024-11-22 21:42:36.212422: Epoch time: 130.81 s\n",
      "2024-11-22 21:42:37.242437: \n",
      "2024-11-22 21:42:37.252438: Epoch 360\n",
      "2024-11-22 21:42:37.252438: Current learning rate: 0.00318\n",
      "2024-11-22 21:44:47.999564: train_loss -0.8269\n",
      "2024-11-22 21:44:48.009564: val_loss -0.544\n",
      "2024-11-22 21:44:48.019565: Pseudo dice [0.6864]\n",
      "2024-11-22 21:44:48.019565: Epoch time: 130.76 s\n",
      "2024-11-22 21:44:49.049588: \n",
      "2024-11-22 21:44:49.049588: Epoch 361\n",
      "2024-11-22 21:44:49.059581: Current learning rate: 0.00316\n",
      "2024-11-22 21:46:59.767756: train_loss -0.8312\n",
      "2024-11-22 21:46:59.777757: val_loss -0.5515\n",
      "2024-11-22 21:46:59.787757: Pseudo dice [0.758]\n",
      "2024-11-22 21:46:59.797756: Epoch time: 130.72 s\n",
      "2024-11-22 21:47:00.827780: \n",
      "2024-11-22 21:47:00.827780: Epoch 362\n",
      "2024-11-22 21:47:00.837772: Current learning rate: 0.00314\n",
      "2024-11-22 21:49:11.494324: train_loss -0.8381\n",
      "2024-11-22 21:49:11.504323: val_loss -0.4531\n",
      "2024-11-22 21:49:11.504323: Pseudo dice [0.7029]\n",
      "2024-11-22 21:49:11.514324: Epoch time: 130.68 s\n",
      "2024-11-22 21:49:12.544347: \n",
      "2024-11-22 21:49:12.554340: Epoch 363\n",
      "2024-11-22 21:49:12.554340: Current learning rate: 0.00312\n",
      "2024-11-22 21:51:23.262162: train_loss -0.8502\n",
      "2024-11-22 21:51:23.272163: val_loss -0.4526\n",
      "2024-11-22 21:51:23.272163: Pseudo dice [0.7127]\n",
      "2024-11-22 21:51:23.282163: Epoch time: 130.72 s\n",
      "2024-11-22 21:51:24.312185: \n",
      "2024-11-22 21:51:24.322178: Epoch 364\n",
      "2024-11-22 21:51:24.322178: Current learning rate: 0.0031\n",
      "2024-11-22 21:53:35.047904: train_loss -0.8461\n",
      "2024-11-22 21:53:35.057905: val_loss -0.573\n",
      "2024-11-22 21:53:35.067905: Pseudo dice [0.7618]\n",
      "2024-11-22 21:53:35.067905: Epoch time: 130.74 s\n",
      "2024-11-22 21:53:35.077906: Yayy! New best EMA pseudo Dice: 0.7111\n",
      "2024-11-22 21:53:36.517938: \n",
      "2024-11-22 21:53:36.517938: Epoch 365\n",
      "2024-11-22 21:53:36.527934: Current learning rate: 0.00308\n",
      "2024-11-22 21:55:47.343408: train_loss -0.8476\n",
      "2024-11-22 21:55:47.343408: val_loss -0.4302\n",
      "2024-11-22 21:55:47.353408: Pseudo dice [0.6775]\n",
      "2024-11-22 21:55:47.363408: Epoch time: 130.83 s\n",
      "2024-11-22 21:55:48.393432: \n",
      "2024-11-22 21:55:48.393432: Epoch 366\n",
      "2024-11-22 21:55:48.403431: Current learning rate: 0.00306\n",
      "2024-11-22 21:57:59.149554: train_loss -0.8325\n",
      "2024-11-22 21:57:59.159554: val_loss -0.4772\n",
      "2024-11-22 21:57:59.169554: Pseudo dice [0.7187]\n",
      "2024-11-22 21:57:59.169554: Epoch time: 130.76 s\n",
      "2024-11-22 21:58:00.199577: \n",
      "2024-11-22 21:58:00.209577: Epoch 367\n",
      "2024-11-22 21:58:00.209577: Current learning rate: 0.00304\n",
      "2024-11-22 22:00:10.905122: train_loss -0.843\n",
      "2024-11-22 22:00:10.915123: val_loss -0.3923\n",
      "2024-11-22 22:00:10.925123: Pseudo dice [0.6884]\n",
      "2024-11-22 22:00:10.935124: Epoch time: 130.71 s\n",
      "2024-11-22 22:00:11.966059: \n",
      "2024-11-22 22:00:11.966059: Epoch 368\n",
      "2024-11-22 22:00:11.976059: Current learning rate: 0.00302\n",
      "2024-11-22 22:02:22.642940: train_loss -0.8514\n",
      "2024-11-22 22:02:22.662941: val_loss -0.5086\n",
      "2024-11-22 22:02:22.662941: Pseudo dice [0.7334]\n",
      "2024-11-22 22:02:22.672940: Epoch time: 130.69 s\n",
      "2024-11-22 22:02:23.702963: \n",
      "2024-11-22 22:02:23.712963: Epoch 369\n",
      "2024-11-22 22:02:23.712963: Current learning rate: 0.003\n",
      "2024-11-22 22:04:34.374495: train_loss -0.8272\n",
      "2024-11-22 22:04:34.384495: val_loss -0.5973\n",
      "2024-11-22 22:04:34.384495: Pseudo dice [0.7529]\n",
      "2024-11-22 22:04:34.394495: Epoch time: 130.67 s\n",
      "2024-11-22 22:04:34.394495: Yayy! New best EMA pseudo Dice: 0.7138\n",
      "2024-11-22 22:04:35.664522: \n",
      "2024-11-22 22:04:35.664522: Epoch 370\n",
      "2024-11-22 22:04:35.674522: Current learning rate: 0.00297\n",
      "2024-11-22 22:06:46.349918: train_loss -0.8386\n",
      "2024-11-22 22:06:46.359918: val_loss -0.3818\n",
      "2024-11-22 22:06:46.369919: Pseudo dice [0.652]\n",
      "2024-11-22 22:06:46.369919: Epoch time: 130.69 s\n",
      "2024-11-22 22:06:47.569944: \n",
      "2024-11-22 22:06:47.569944: Epoch 371\n",
      "2024-11-22 22:06:47.579934: Current learning rate: 0.00295\n",
      "2024-11-22 22:08:58.266330: train_loss -0.84\n",
      "2024-11-22 22:08:58.276332: val_loss -0.539\n",
      "2024-11-22 22:08:58.276332: Pseudo dice [0.7265]\n",
      "2024-11-22 22:08:58.286332: Epoch time: 130.71 s\n",
      "2024-11-22 22:08:59.316728: \n",
      "2024-11-22 22:08:59.326728: Epoch 372\n",
      "2024-11-22 22:08:59.326728: Current learning rate: 0.00293\n",
      "2024-11-22 22:11:10.066397: train_loss -0.8368\n",
      "2024-11-22 22:11:10.076398: val_loss -0.3763\n",
      "2024-11-22 22:11:10.086398: Pseudo dice [0.6536]\n",
      "2024-11-22 22:11:10.086398: Epoch time: 130.75 s\n",
      "2024-11-22 22:11:11.116421: \n",
      "2024-11-22 22:11:11.116421: Epoch 373\n",
      "2024-11-22 22:11:11.126420: Current learning rate: 0.00291\n",
      "2024-11-22 22:13:21.797407: train_loss -0.8424\n",
      "2024-11-22 22:13:21.807407: val_loss -0.4472\n",
      "2024-11-22 22:13:21.817407: Pseudo dice [0.6701]\n",
      "2024-11-22 22:13:21.817407: Epoch time: 130.68 s\n",
      "2024-11-22 22:13:22.879829: \n",
      "2024-11-22 22:13:22.889831: Epoch 374\n",
      "2024-11-22 22:13:22.889831: Current learning rate: 0.00289\n",
      "2024-11-22 22:15:33.555783: train_loss -0.8316\n",
      "2024-11-22 22:15:33.565783: val_loss -0.4602\n",
      "2024-11-22 22:15:33.575783: Pseudo dice [0.6873]\n",
      "2024-11-22 22:15:33.575783: Epoch time: 130.68 s\n",
      "2024-11-22 22:15:34.615808: \n",
      "2024-11-22 22:15:34.615808: Epoch 375\n",
      "2024-11-22 22:15:34.625798: Current learning rate: 0.00287\n",
      "2024-11-22 22:17:45.292037: train_loss -0.8088\n",
      "2024-11-22 22:17:45.302038: val_loss -0.5479\n",
      "2024-11-22 22:17:45.312038: Pseudo dice [0.7276]\n",
      "2024-11-22 22:17:45.312038: Epoch time: 130.68 s\n",
      "2024-11-22 22:17:46.342360: \n",
      "2024-11-22 22:17:46.352360: Epoch 376\n",
      "2024-11-22 22:17:46.352360: Current learning rate: 0.00285\n",
      "2024-11-22 22:19:57.114482: train_loss -0.8289\n",
      "2024-11-22 22:19:57.124483: val_loss -0.4601\n",
      "2024-11-22 22:19:57.124483: Pseudo dice [0.6748]\n",
      "2024-11-22 22:19:57.134483: Epoch time: 130.77 s\n",
      "2024-11-22 22:19:58.164508: \n",
      "2024-11-22 22:19:58.164508: Epoch 377\n",
      "2024-11-22 22:19:58.174499: Current learning rate: 0.00283\n",
      "2024-11-22 22:22:08.891187: train_loss -0.842\n",
      "2024-11-22 22:22:08.901188: val_loss -0.4106\n",
      "2024-11-22 22:22:08.911186: Pseudo dice [0.6396]\n",
      "2024-11-22 22:22:08.921188: Epoch time: 130.73 s\n",
      "2024-11-22 22:22:10.122020: \n",
      "2024-11-22 22:22:10.132013: Epoch 378\n",
      "2024-11-22 22:22:10.132013: Current learning rate: 0.00281\n",
      "2024-11-22 22:24:20.921508: train_loss -0.8422\n",
      "2024-11-22 22:24:20.931509: val_loss -0.4814\n",
      "2024-11-22 22:24:20.941508: Pseudo dice [0.7274]\n",
      "2024-11-22 22:24:20.941508: Epoch time: 130.8 s\n",
      "2024-11-22 22:24:21.981531: \n",
      "2024-11-22 22:24:21.991522: Epoch 379\n",
      "2024-11-22 22:24:21.991522: Current learning rate: 0.00279\n",
      "2024-11-22 22:26:32.752727: train_loss -0.843\n",
      "2024-11-22 22:26:32.762727: val_loss -0.5019\n",
      "2024-11-22 22:26:32.762727: Pseudo dice [0.7144]\n",
      "2024-11-22 22:26:32.772727: Epoch time: 130.77 s\n",
      "2024-11-22 22:26:33.802751: \n",
      "2024-11-22 22:26:33.802751: Epoch 380\n",
      "2024-11-22 22:26:33.812742: Current learning rate: 0.00277\n",
      "2024-11-22 22:28:44.553279: train_loss -0.8453\n",
      "2024-11-22 22:28:44.573279: val_loss -0.5136\n",
      "2024-11-22 22:28:44.573279: Pseudo dice [0.7042]\n",
      "2024-11-22 22:28:44.583280: Epoch time: 130.75 s\n",
      "2024-11-22 22:28:45.613303: \n",
      "2024-11-22 22:28:45.623293: Epoch 381\n",
      "2024-11-22 22:28:45.623293: Current learning rate: 0.00275\n",
      "2024-11-22 22:30:56.413125: train_loss -0.8538\n",
      "2024-11-22 22:30:56.423125: val_loss -0.5303\n",
      "2024-11-22 22:30:56.433125: Pseudo dice [0.7017]\n",
      "2024-11-22 22:30:56.433125: Epoch time: 130.8 s\n",
      "2024-11-22 22:30:57.483149: \n",
      "2024-11-22 22:30:57.483149: Epoch 382\n",
      "2024-11-22 22:30:57.483149: Current learning rate: 0.00273\n",
      "2024-11-22 22:33:08.189892: train_loss -0.8515\n",
      "2024-11-22 22:33:08.199892: val_loss -0.5604\n",
      "2024-11-22 22:33:08.209892: Pseudo dice [0.7252]\n",
      "2024-11-22 22:33:08.209892: Epoch time: 130.72 s\n",
      "2024-11-22 22:33:09.259916: \n",
      "2024-11-22 22:33:09.269915: Epoch 383\n",
      "2024-11-22 22:33:09.269915: Current learning rate: 0.00271\n",
      "2024-11-22 22:35:19.927608: train_loss -0.8213\n",
      "2024-11-22 22:35:19.937608: val_loss -0.5366\n",
      "2024-11-22 22:35:19.937608: Pseudo dice [0.7209]\n",
      "2024-11-22 22:35:19.947608: Epoch time: 130.67 s\n",
      "2024-11-22 22:35:20.987632: \n",
      "2024-11-22 22:35:20.997632: Epoch 384\n",
      "2024-11-22 22:35:20.997632: Current learning rate: 0.00268\n",
      "2024-11-22 22:37:31.686137: train_loss -0.8377\n",
      "2024-11-22 22:37:31.696137: val_loss -0.5263\n",
      "2024-11-22 22:37:31.706138: Pseudo dice [0.7423]\n",
      "2024-11-22 22:37:31.716137: Epoch time: 130.7 s\n",
      "2024-11-22 22:37:32.936165: \n",
      "2024-11-22 22:37:32.936165: Epoch 385\n",
      "2024-11-22 22:37:32.946163: Current learning rate: 0.00266\n",
      "2024-11-22 22:39:43.642992: train_loss -0.8147\n",
      "2024-11-22 22:39:43.652992: val_loss -0.5418\n",
      "2024-11-22 22:39:43.662992: Pseudo dice [0.7307]\n",
      "2024-11-22 22:39:43.662992: Epoch time: 130.71 s\n",
      "2024-11-22 22:39:44.703313: \n",
      "2024-11-22 22:39:44.713304: Epoch 386\n",
      "2024-11-22 22:39:44.713304: Current learning rate: 0.00264\n",
      "2024-11-22 22:41:55.473846: train_loss -0.775\n",
      "2024-11-22 22:41:55.483846: val_loss -0.4336\n",
      "2024-11-22 22:41:55.483846: Pseudo dice [0.6481]\n",
      "2024-11-22 22:41:55.493846: Epoch time: 130.77 s\n",
      "2024-11-22 22:41:56.543862: \n",
      "2024-11-22 22:41:56.553861: Epoch 387\n",
      "2024-11-22 22:41:56.553861: Current learning rate: 0.00262\n",
      "2024-11-22 22:44:07.315732: train_loss -0.8185\n",
      "2024-11-22 22:44:07.335732: val_loss -0.419\n",
      "2024-11-22 22:44:07.335732: Pseudo dice [0.6289]\n",
      "2024-11-22 22:44:07.345732: Epoch time: 130.77 s\n",
      "2024-11-22 22:44:08.395758: \n",
      "2024-11-22 22:44:08.395758: Epoch 388\n",
      "2024-11-22 22:44:08.405755: Current learning rate: 0.0026\n",
      "2024-11-22 22:46:19.058488: train_loss -0.7839\n",
      "2024-11-22 22:46:19.068489: val_loss -0.5768\n",
      "2024-11-22 22:46:19.078488: Pseudo dice [0.7524]\n",
      "2024-11-22 22:46:19.078488: Epoch time: 130.66 s\n",
      "2024-11-22 22:46:20.128814: \n",
      "2024-11-22 22:46:20.128814: Epoch 389\n",
      "2024-11-22 22:46:20.138819: Current learning rate: 0.00258\n",
      "2024-11-22 22:48:30.883837: train_loss -0.7916\n",
      "2024-11-22 22:48:30.893837: val_loss -0.404\n",
      "2024-11-22 22:48:30.903838: Pseudo dice [0.6266]\n",
      "2024-11-22 22:48:30.903838: Epoch time: 130.76 s\n",
      "2024-11-22 22:48:31.953861: \n",
      "2024-11-22 22:48:31.963851: Epoch 390\n",
      "2024-11-22 22:48:31.963851: Current learning rate: 0.00256\n",
      "2024-11-22 22:50:42.690665: train_loss -0.8273\n",
      "2024-11-22 22:50:42.710665: val_loss -0.5803\n",
      "2024-11-22 22:50:42.710665: Pseudo dice [0.759]\n",
      "2024-11-22 22:50:42.720665: Epoch time: 130.74 s\n",
      "2024-11-22 22:50:43.771048: \n",
      "2024-11-22 22:50:43.781038: Epoch 391\n",
      "2024-11-22 22:50:43.781038: Current learning rate: 0.00254\n",
      "2024-11-22 22:52:54.488437: train_loss -0.8339\n",
      "2024-11-22 22:52:54.498439: val_loss -0.5075\n",
      "2024-11-22 22:52:54.508438: Pseudo dice [0.7338]\n",
      "2024-11-22 22:52:54.508438: Epoch time: 130.72 s\n",
      "2024-11-22 22:52:55.728870: \n",
      "2024-11-22 22:52:55.738863: Epoch 392\n",
      "2024-11-22 22:52:55.738863: Current learning rate: 0.00252\n",
      "2024-11-22 22:55:06.444744: train_loss -0.843\n",
      "2024-11-22 22:55:06.444744: val_loss -0.5565\n",
      "2024-11-22 22:55:06.454745: Pseudo dice [0.7117]\n",
      "2024-11-22 22:55:06.464745: Epoch time: 130.72 s\n",
      "2024-11-22 22:55:07.505610: \n",
      "2024-11-22 22:55:07.515602: Epoch 393\n",
      "2024-11-22 22:55:07.515602: Current learning rate: 0.0025\n",
      "2024-11-22 22:57:18.285217: train_loss -0.83\n",
      "2024-11-22 22:57:18.295216: val_loss -0.4484\n",
      "2024-11-22 22:57:18.305218: Pseudo dice [0.6957]\n",
      "2024-11-22 22:57:18.315218: Epoch time: 130.78 s\n",
      "2024-11-22 22:57:19.355234: \n",
      "2024-11-22 22:57:19.355234: Epoch 394\n",
      "2024-11-22 22:57:19.365233: Current learning rate: 0.00248\n",
      "2024-11-22 22:59:30.032326: train_loss -0.8325\n",
      "2024-11-22 22:59:30.042325: val_loss -0.5345\n",
      "2024-11-22 22:59:30.052326: Pseudo dice [0.6892]\n",
      "2024-11-22 22:59:30.052326: Epoch time: 130.68 s\n",
      "2024-11-22 22:59:31.102606: \n",
      "2024-11-22 22:59:31.102606: Epoch 395\n",
      "2024-11-22 22:59:31.112606: Current learning rate: 0.00245\n",
      "2024-11-22 23:01:41.808907: train_loss -0.8217\n",
      "2024-11-22 23:01:41.818907: val_loss -0.5797\n",
      "2024-11-22 23:01:41.828907: Pseudo dice [0.7454]\n",
      "2024-11-22 23:01:41.828907: Epoch time: 130.71 s\n",
      "2024-11-22 23:01:42.878932: \n",
      "2024-11-22 23:01:42.878932: Epoch 396\n",
      "2024-11-22 23:01:42.888930: Current learning rate: 0.00243\n",
      "2024-11-22 23:03:53.598655: train_loss -0.826\n",
      "2024-11-22 23:03:53.618656: val_loss -0.5404\n",
      "2024-11-22 23:03:53.618656: Pseudo dice [0.7307]\n",
      "2024-11-22 23:03:53.628656: Epoch time: 130.72 s\n",
      "2024-11-22 23:03:54.678982: \n",
      "2024-11-22 23:03:54.678982: Epoch 397\n",
      "2024-11-22 23:03:54.678982: Current learning rate: 0.00241\n",
      "2024-11-22 23:06:05.448314: train_loss -0.8442\n",
      "2024-11-22 23:06:05.458314: val_loss -0.5013\n",
      "2024-11-22 23:06:05.458314: Pseudo dice [0.7087]\n",
      "2024-11-22 23:06:05.468315: Epoch time: 130.78 s\n",
      "2024-11-22 23:06:06.508337: \n",
      "2024-11-22 23:06:06.518328: Epoch 398\n",
      "2024-11-22 23:06:06.528329: Current learning rate: 0.00239\n",
      "2024-11-22 23:08:17.275827: train_loss -0.8494\n",
      "2024-11-22 23:08:17.285827: val_loss -0.542\n",
      "2024-11-22 23:08:17.295828: Pseudo dice [0.7278]\n",
      "2024-11-22 23:08:17.295828: Epoch time: 130.77 s\n",
      "2024-11-22 23:08:18.536176: \n",
      "2024-11-22 23:08:18.536176: Epoch 399\n",
      "2024-11-22 23:08:18.546164: Current learning rate: 0.00237\n",
      "2024-11-22 23:10:29.243877: train_loss -0.8471\n",
      "2024-11-22 23:10:29.253877: val_loss -0.4803\n",
      "2024-11-22 23:10:29.263877: Pseudo dice [0.6971]\n",
      "2024-11-22 23:10:29.263877: Epoch time: 130.71 s\n",
      "2024-11-22 23:10:30.564765: \n",
      "2024-11-22 23:10:30.564765: Epoch 400\n",
      "2024-11-22 23:10:30.574766: Current learning rate: 0.00235\n",
      "2024-11-22 23:12:41.354192: train_loss -0.8406\n",
      "2024-11-22 23:12:41.374193: val_loss -0.589\n",
      "2024-11-22 23:12:41.374193: Pseudo dice [0.7638]\n",
      "2024-11-22 23:12:41.384193: Epoch time: 130.79 s\n",
      "2024-11-22 23:12:41.384193: Yayy! New best EMA pseudo Dice: 0.715\n",
      "2024-11-22 23:12:42.675105: \n",
      "2024-11-22 23:12:42.685095: Epoch 401\n",
      "2024-11-22 23:12:42.685095: Current learning rate: 0.00233\n",
      "2024-11-22 23:14:53.431157: train_loss -0.8448\n",
      "2024-11-22 23:14:53.441158: val_loss -0.4884\n",
      "2024-11-22 23:14:53.451158: Pseudo dice [0.6893]\n",
      "2024-11-22 23:14:53.451158: Epoch time: 130.76 s\n",
      "2024-11-22 23:14:54.502441: \n",
      "2024-11-22 23:14:54.512432: Epoch 402\n",
      "2024-11-22 23:14:54.512432: Current learning rate: 0.00231\n",
      "2024-11-22 23:17:05.168705: train_loss -0.8484\n",
      "2024-11-22 23:17:05.178705: val_loss -0.5099\n",
      "2024-11-22 23:17:05.188705: Pseudo dice [0.7112]\n",
      "2024-11-22 23:17:05.198706: Epoch time: 130.67 s\n",
      "2024-11-22 23:17:06.238729: \n",
      "2024-11-22 23:17:06.248720: Epoch 403\n",
      "2024-11-22 23:17:06.248720: Current learning rate: 0.00229\n",
      "2024-11-22 23:19:16.971130: train_loss -0.8481\n",
      "2024-11-22 23:19:16.981130: val_loss -0.5646\n",
      "2024-11-22 23:19:16.991131: Pseudo dice [0.7484]\n",
      "2024-11-22 23:19:16.991131: Epoch time: 130.73 s\n",
      "2024-11-22 23:19:17.001131: Yayy! New best EMA pseudo Dice: 0.7159\n",
      "2024-11-22 23:19:18.291157: \n",
      "2024-11-22 23:19:18.301157: Epoch 404\n",
      "2024-11-22 23:19:18.301157: Current learning rate: 0.00226\n",
      "2024-11-22 23:21:28.958321: train_loss -0.8163\n",
      "2024-11-22 23:21:28.968321: val_loss -0.3347\n",
      "2024-11-22 23:21:28.968321: Pseudo dice [0.6752]\n",
      "2024-11-22 23:21:28.978322: Epoch time: 130.67 s\n",
      "2024-11-22 23:21:30.198653: \n",
      "2024-11-22 23:21:30.208652: Epoch 405\n",
      "2024-11-22 23:21:30.208652: Current learning rate: 0.00224\n",
      "2024-11-22 23:23:40.875520: train_loss -0.8143\n",
      "2024-11-22 23:23:40.885520: val_loss -0.39\n",
      "2024-11-22 23:23:40.895521: Pseudo dice [0.6318]\n",
      "2024-11-22 23:23:40.895521: Epoch time: 130.68 s\n",
      "2024-11-22 23:23:41.945544: \n",
      "2024-11-22 23:23:41.955544: Epoch 406\n",
      "2024-11-22 23:23:41.955544: Current learning rate: 0.00222\n",
      "2024-11-22 23:25:52.656876: train_loss -0.8241\n",
      "2024-11-22 23:25:52.666876: val_loss -0.4437\n",
      "2024-11-22 23:25:52.676876: Pseudo dice [0.7181]\n",
      "2024-11-22 23:25:52.686876: Epoch time: 130.71 s\n",
      "2024-11-22 23:25:53.727300: \n",
      "2024-11-22 23:25:53.737299: Epoch 407\n",
      "2024-11-22 23:25:53.737299: Current learning rate: 0.0022\n",
      "2024-11-22 23:28:04.425302: train_loss -0.8293\n",
      "2024-11-22 23:28:04.435302: val_loss -0.531\n",
      "2024-11-22 23:28:04.435302: Pseudo dice [0.7286]\n",
      "2024-11-22 23:28:04.445302: Epoch time: 130.7 s\n",
      "2024-11-22 23:28:05.495327: \n",
      "2024-11-22 23:28:05.495327: Epoch 408\n",
      "2024-11-22 23:28:05.505324: Current learning rate: 0.00218\n",
      "2024-11-22 23:30:16.151278: train_loss -0.8537\n",
      "2024-11-22 23:30:16.161279: val_loss -0.5049\n",
      "2024-11-22 23:30:16.161279: Pseudo dice [0.7045]\n",
      "2024-11-22 23:30:16.171279: Epoch time: 130.66 s\n",
      "2024-11-22 23:30:17.221302: \n",
      "2024-11-22 23:30:17.221302: Epoch 409\n",
      "2024-11-22 23:30:17.231301: Current learning rate: 0.00216\n",
      "2024-11-22 23:32:27.897507: train_loss -0.8507\n",
      "2024-11-22 23:32:27.907508: val_loss -0.5786\n",
      "2024-11-22 23:32:27.907508: Pseudo dice [0.7478]\n",
      "2024-11-22 23:32:27.917506: Epoch time: 130.69 s\n",
      "2024-11-22 23:32:28.967530: \n",
      "2024-11-22 23:32:28.967530: Epoch 410\n",
      "2024-11-22 23:32:28.977520: Current learning rate: 0.00214\n",
      "2024-11-22 23:34:39.731779: train_loss -0.8509\n",
      "2024-11-22 23:34:39.741779: val_loss -0.5362\n",
      "2024-11-22 23:34:39.751779: Pseudo dice [0.7305]\n",
      "2024-11-22 23:34:39.751779: Epoch time: 130.76 s\n",
      "2024-11-22 23:34:40.741802: \n",
      "2024-11-22 23:34:40.751793: Epoch 411\n",
      "2024-11-22 23:34:40.751793: Current learning rate: 0.00212\n",
      "2024-11-22 23:36:51.461546: train_loss -0.8368\n",
      "2024-11-22 23:36:51.471546: val_loss -0.5211\n",
      "2024-11-22 23:36:51.481547: Pseudo dice [0.7257]\n",
      "2024-11-22 23:36:51.491547: Epoch time: 130.72 s\n",
      "2024-11-22 23:36:52.661572: \n",
      "2024-11-22 23:36:52.671563: Epoch 412\n",
      "2024-11-22 23:36:52.671563: Current learning rate: 0.00209\n",
      "2024-11-22 23:39:03.497926: train_loss -0.8376\n",
      "2024-11-22 23:39:03.507926: val_loss -0.4417\n",
      "2024-11-22 23:39:03.507926: Pseudo dice [0.7043]\n",
      "2024-11-22 23:39:03.517926: Epoch time: 130.84 s\n",
      "2024-11-22 23:39:04.517941: \n",
      "2024-11-22 23:39:04.517941: Epoch 413\n",
      "2024-11-22 23:39:04.517941: Current learning rate: 0.00207\n",
      "2024-11-22 23:41:15.163259: train_loss -0.8494\n",
      "2024-11-22 23:41:15.173259: val_loss -0.3649\n",
      "2024-11-22 23:41:15.183259: Pseudo dice [0.66]\n",
      "2024-11-22 23:41:15.193259: Epoch time: 130.66 s\n",
      "2024-11-22 23:41:16.183285: \n",
      "2024-11-22 23:41:16.183285: Epoch 414\n",
      "2024-11-22 23:41:16.193274: Current learning rate: 0.00205\n",
      "2024-11-22 23:43:26.870134: train_loss -0.8471\n",
      "2024-11-22 23:43:26.880134: val_loss -0.4486\n",
      "2024-11-22 23:43:26.890135: Pseudo dice [0.695]\n",
      "2024-11-22 23:43:26.890135: Epoch time: 130.69 s\n",
      "2024-11-22 23:43:27.880157: \n",
      "2024-11-22 23:43:27.890149: Epoch 415\n",
      "2024-11-22 23:43:27.890149: Current learning rate: 0.00203\n",
      "2024-11-22 23:45:38.580764: train_loss -0.8531\n",
      "2024-11-22 23:45:38.590764: val_loss -0.4681\n",
      "2024-11-22 23:45:38.600765: Pseudo dice [0.6723]\n",
      "2024-11-22 23:45:38.610765: Epoch time: 130.7 s\n",
      "2024-11-22 23:45:39.601133: \n",
      "2024-11-22 23:45:39.601133: Epoch 416\n",
      "2024-11-22 23:45:39.601133: Current learning rate: 0.00201\n",
      "2024-11-22 23:47:50.367557: train_loss -0.839\n",
      "2024-11-22 23:47:50.377557: val_loss -0.4978\n",
      "2024-11-22 23:47:50.377557: Pseudo dice [0.7349]\n",
      "2024-11-22 23:47:50.387557: Epoch time: 130.78 s\n",
      "2024-11-22 23:47:51.377580: \n",
      "2024-11-22 23:47:51.387572: Epoch 417\n",
      "2024-11-22 23:47:51.387572: Current learning rate: 0.00199\n",
      "2024-11-22 23:50:02.133391: train_loss -0.8143\n",
      "2024-11-22 23:50:02.143391: val_loss -0.4819\n",
      "2024-11-22 23:50:02.143391: Pseudo dice [0.6906]\n",
      "2024-11-22 23:50:02.153391: Epoch time: 130.76 s\n",
      "2024-11-22 23:50:03.143414: \n",
      "2024-11-22 23:50:03.143414: Epoch 418\n",
      "2024-11-22 23:50:03.153413: Current learning rate: 0.00196\n",
      "2024-11-22 23:52:13.900657: train_loss -0.8519\n",
      "2024-11-22 23:52:13.910658: val_loss -0.5316\n",
      "2024-11-22 23:52:13.910658: Pseudo dice [0.7396]\n",
      "2024-11-22 23:52:13.920657: Epoch time: 130.76 s\n",
      "2024-11-22 23:52:14.910680: \n",
      "2024-11-22 23:52:14.920671: Epoch 419\n",
      "2024-11-22 23:52:14.920671: Current learning rate: 0.00194\n",
      "2024-11-22 23:54:25.725437: train_loss -0.8488\n",
      "2024-11-22 23:54:25.735437: val_loss -0.4501\n",
      "2024-11-22 23:54:25.745437: Pseudo dice [0.7164]\n",
      "2024-11-22 23:54:25.745437: Epoch time: 130.81 s\n",
      "2024-11-22 23:54:26.916735: \n",
      "2024-11-22 23:54:26.926726: Epoch 420\n",
      "2024-11-22 23:54:26.926726: Current learning rate: 0.00192\n",
      "2024-11-22 23:56:37.641171: train_loss -0.8507\n",
      "2024-11-22 23:56:37.651171: val_loss -0.4942\n",
      "2024-11-22 23:56:37.661171: Pseudo dice [0.7263]\n",
      "2024-11-22 23:56:37.661171: Epoch time: 130.72 s\n",
      "2024-11-22 23:56:38.651194: \n",
      "2024-11-22 23:56:38.661184: Epoch 421\n",
      "2024-11-22 23:56:38.661184: Current learning rate: 0.0019\n",
      "2024-11-22 23:58:49.377730: train_loss -0.855\n",
      "2024-11-22 23:58:49.387730: val_loss -0.4606\n",
      "2024-11-22 23:58:49.397730: Pseudo dice [0.7004]\n",
      "2024-11-22 23:58:49.397730: Epoch time: 130.73 s\n",
      "2024-11-22 23:58:50.387743: \n",
      "2024-11-22 23:58:50.397744: Epoch 422\n",
      "2024-11-22 23:58:50.397744: Current learning rate: 0.00188\n",
      "2024-11-23 00:01:01.117439: train_loss -0.8514\n",
      "2024-11-23 00:01:01.117439: val_loss -0.4625\n",
      "2024-11-23 00:01:01.127438: Pseudo dice [0.6905]\n",
      "2024-11-23 00:01:01.137438: Epoch time: 130.73 s\n",
      "2024-11-23 00:01:02.137452: \n",
      "2024-11-23 00:01:02.147453: Epoch 423\n",
      "2024-11-23 00:01:02.147453: Current learning rate: 0.00186\n",
      "2024-11-23 00:03:12.874441: train_loss -0.8529\n",
      "2024-11-23 00:03:12.884442: val_loss -0.4064\n",
      "2024-11-23 00:03:12.894441: Pseudo dice [0.6663]\n",
      "2024-11-23 00:03:12.904442: Epoch time: 130.74 s\n",
      "2024-11-23 00:03:13.894464: \n",
      "2024-11-23 00:03:13.894464: Epoch 424\n",
      "2024-11-23 00:03:13.904456: Current learning rate: 0.00184\n",
      "2024-11-23 00:05:24.642867: train_loss -0.8484\n",
      "2024-11-23 00:05:24.652867: val_loss -0.5562\n",
      "2024-11-23 00:05:24.662867: Pseudo dice [0.7376]\n",
      "2024-11-23 00:05:24.672867: Epoch time: 130.75 s\n",
      "2024-11-23 00:05:25.652889: \n",
      "2024-11-23 00:05:25.662882: Epoch 425\n",
      "2024-11-23 00:05:25.662882: Current learning rate: 0.00181\n",
      "2024-11-23 00:07:36.405619: train_loss -0.8532\n",
      "2024-11-23 00:07:36.414741: val_loss -0.4907\n",
      "2024-11-23 00:07:36.421840: Pseudo dice [0.7056]\n",
      "2024-11-23 00:07:36.422851: Epoch time: 130.75 s\n",
      "2024-11-23 00:07:37.400879: \n",
      "2024-11-23 00:07:37.410871: Epoch 426\n",
      "2024-11-23 00:07:37.410871: Current learning rate: 0.00179\n",
      "2024-11-23 00:09:48.441507: train_loss -0.8515\n",
      "2024-11-23 00:09:48.451507: val_loss -0.5069\n",
      "2024-11-23 00:09:48.461507: Pseudo dice [0.7596]\n",
      "2024-11-23 00:09:48.471507: Epoch time: 131.04 s\n",
      "2024-11-23 00:09:49.631534: \n",
      "2024-11-23 00:09:49.631534: Epoch 427\n",
      "2024-11-23 00:09:49.641525: Current learning rate: 0.00177\n",
      "2024-11-23 00:12:00.299414: train_loss -0.8525\n",
      "2024-11-23 00:12:00.309414: val_loss -0.4707\n",
      "2024-11-23 00:12:00.309414: Pseudo dice [0.7094]\n",
      "2024-11-23 00:12:00.319416: Epoch time: 130.67 s\n",
      "2024-11-23 00:12:01.299437: \n",
      "2024-11-23 00:12:01.299437: Epoch 428\n",
      "2024-11-23 00:12:01.299437: Current learning rate: 0.00175\n",
      "2024-11-23 00:14:12.073781: train_loss -0.8594\n",
      "2024-11-23 00:14:12.083780: val_loss -0.5343\n",
      "2024-11-23 00:14:12.093780: Pseudo dice [0.7173]\n",
      "2024-11-23 00:14:12.103780: Epoch time: 130.78 s\n",
      "2024-11-23 00:14:13.084323: \n",
      "2024-11-23 00:14:13.084323: Epoch 429\n",
      "2024-11-23 00:14:13.094311: Current learning rate: 0.00173\n",
      "2024-11-23 00:16:23.821120: train_loss -0.8557\n",
      "2024-11-23 00:16:23.831119: val_loss -0.5483\n",
      "2024-11-23 00:16:23.843409: Pseudo dice [0.7478]\n",
      "2024-11-23 00:16:23.844437: Epoch time: 130.74 s\n",
      "2024-11-23 00:16:23.851440: Yayy! New best EMA pseudo Dice: 0.716\n",
      "2024-11-23 00:16:25.082347: \n",
      "2024-11-23 00:16:25.092346: Epoch 430\n",
      "2024-11-23 00:16:25.092346: Current learning rate: 0.0017\n",
      "2024-11-23 00:18:35.828285: train_loss -0.8558\n",
      "2024-11-23 00:18:35.838286: val_loss -0.4994\n",
      "2024-11-23 00:18:35.848286: Pseudo dice [0.7559]\n",
      "2024-11-23 00:18:35.848286: Epoch time: 130.75 s\n",
      "2024-11-23 00:18:35.858286: Yayy! New best EMA pseudo Dice: 0.72\n",
      "2024-11-23 00:18:37.089214: \n",
      "2024-11-23 00:18:37.099206: Epoch 431\n",
      "2024-11-23 00:18:37.099206: Current learning rate: 0.00168\n",
      "2024-11-23 00:20:47.835965: train_loss -0.8581\n",
      "2024-11-23 00:20:47.845965: val_loss -0.4469\n",
      "2024-11-23 00:20:47.845965: Pseudo dice [0.7122]\n",
      "2024-11-23 00:20:47.855966: Epoch time: 130.75 s\n",
      "2024-11-23 00:20:48.836335: \n",
      "2024-11-23 00:20:48.846327: Epoch 432\n",
      "2024-11-23 00:20:48.846327: Current learning rate: 0.00166\n",
      "2024-11-23 00:22:59.512336: train_loss -0.8517\n",
      "2024-11-23 00:22:59.522337: val_loss -0.5688\n",
      "2024-11-23 00:22:59.532337: Pseudo dice [0.7494]\n",
      "2024-11-23 00:22:59.532337: Epoch time: 130.68 s\n",
      "2024-11-23 00:22:59.542337: Yayy! New best EMA pseudo Dice: 0.7223\n",
      "2024-11-23 00:23:00.772363: \n",
      "2024-11-23 00:23:00.782363: Epoch 433\n",
      "2024-11-23 00:23:00.782363: Current learning rate: 0.00164\n",
      "2024-11-23 00:25:11.490872: train_loss -0.8597\n",
      "2024-11-23 00:25:11.490872: val_loss -0.4797\n",
      "2024-11-23 00:25:11.500872: Pseudo dice [0.7064]\n",
      "2024-11-23 00:25:11.500872: Epoch time: 130.72 s\n",
      "2024-11-23 00:25:12.660888: \n",
      "2024-11-23 00:25:12.670888: Epoch 434\n",
      "2024-11-23 00:25:12.680888: Current learning rate: 0.00162\n",
      "2024-11-23 00:27:23.326517: train_loss -0.8514\n",
      "2024-11-23 00:27:23.336517: val_loss -0.5643\n",
      "2024-11-23 00:27:23.346517: Pseudo dice [0.7544]\n",
      "2024-11-23 00:27:23.346517: Epoch time: 130.67 s\n",
      "2024-11-23 00:27:23.356518: Yayy! New best EMA pseudo Dice: 0.724\n",
      "2024-11-23 00:27:24.577706: \n",
      "2024-11-23 00:27:24.587706: Epoch 435\n",
      "2024-11-23 00:27:24.587706: Current learning rate: 0.00159\n",
      "2024-11-23 00:29:35.373553: train_loss -0.8525\n",
      "2024-11-23 00:29:35.383553: val_loss -0.3532\n",
      "2024-11-23 00:29:35.383553: Pseudo dice [0.671]\n",
      "2024-11-23 00:29:35.393554: Epoch time: 130.8 s\n",
      "2024-11-23 00:29:36.373589: \n",
      "2024-11-23 00:29:36.373589: Epoch 436\n",
      "2024-11-23 00:29:36.383577: Current learning rate: 0.00157\n",
      "2024-11-23 00:31:47.082590: train_loss -0.856\n",
      "2024-11-23 00:31:47.092590: val_loss -0.5518\n",
      "2024-11-23 00:31:47.102591: Pseudo dice [0.7566]\n",
      "2024-11-23 00:31:47.102591: Epoch time: 130.71 s\n",
      "2024-11-23 00:31:48.092615: \n",
      "2024-11-23 00:31:48.092615: Epoch 437\n",
      "2024-11-23 00:31:48.102603: Current learning rate: 0.00155\n",
      "2024-11-23 00:33:58.812848: train_loss -0.8578\n",
      "2024-11-23 00:33:58.825141: val_loss -0.5202\n",
      "2024-11-23 00:33:58.825141: Pseudo dice [0.7143]\n",
      "2024-11-23 00:33:58.833146: Epoch time: 130.72 s\n",
      "2024-11-23 00:33:59.824140: \n",
      "2024-11-23 00:33:59.824140: Epoch 438\n",
      "2024-11-23 00:33:59.834132: Current learning rate: 0.00153\n",
      "2024-11-23 00:36:10.547031: train_loss -0.8561\n",
      "2024-11-23 00:36:10.557031: val_loss -0.5091\n",
      "2024-11-23 00:36:10.567032: Pseudo dice [0.7274]\n",
      "2024-11-23 00:36:10.567032: Epoch time: 130.73 s\n",
      "2024-11-23 00:36:11.547054: \n",
      "2024-11-23 00:36:11.557047: Epoch 439\n",
      "2024-11-23 00:36:11.557047: Current learning rate: 0.00151\n",
      "2024-11-23 00:38:22.251752: train_loss -0.8611\n",
      "2024-11-23 00:38:22.261753: val_loss -0.4934\n",
      "2024-11-23 00:38:22.271753: Pseudo dice [0.7332]\n",
      "2024-11-23 00:38:22.281752: Epoch time: 130.7 s\n",
      "2024-11-23 00:38:23.261775: \n",
      "2024-11-23 00:38:23.271767: Epoch 440\n",
      "2024-11-23 00:38:23.271767: Current learning rate: 0.00148\n",
      "2024-11-23 00:40:33.965511: train_loss -0.8534\n",
      "2024-11-23 00:40:33.975512: val_loss -0.6031\n",
      "2024-11-23 00:40:33.985512: Pseudo dice [0.7591]\n",
      "2024-11-23 00:40:33.985512: Epoch time: 130.7 s\n",
      "2024-11-23 00:40:33.995512: Yayy! New best EMA pseudo Dice: 0.727\n",
      "2024-11-23 00:40:35.216264: \n",
      "2024-11-23 00:40:35.226256: Epoch 441\n",
      "2024-11-23 00:40:35.226256: Current learning rate: 0.00146\n",
      "2024-11-23 00:42:45.900223: train_loss -0.8612\n",
      "2024-11-23 00:42:45.910223: val_loss -0.5685\n",
      "2024-11-23 00:42:45.910223: Pseudo dice [0.7343]\n",
      "2024-11-23 00:42:45.920223: Epoch time: 130.68 s\n",
      "2024-11-23 00:42:45.930223: Yayy! New best EMA pseudo Dice: 0.7277\n",
      "2024-11-23 00:42:47.320252: \n",
      "2024-11-23 00:42:47.330243: Epoch 442\n",
      "2024-11-23 00:42:47.330243: Current learning rate: 0.00144\n",
      "2024-11-23 00:44:58.077358: train_loss -0.8496\n",
      "2024-11-23 00:44:58.087359: val_loss -0.5221\n",
      "2024-11-23 00:44:58.097359: Pseudo dice [0.7328]\n",
      "2024-11-23 00:44:58.107359: Epoch time: 130.76 s\n",
      "2024-11-23 00:44:58.107359: Yayy! New best EMA pseudo Dice: 0.7282\n",
      "2024-11-23 00:44:59.347386: \n",
      "2024-11-23 00:44:59.347386: Epoch 443\n",
      "2024-11-23 00:44:59.357377: Current learning rate: 0.00142\n",
      "2024-11-23 00:47:10.035846: train_loss -0.8588\n",
      "2024-11-23 00:47:10.045847: val_loss -0.4499\n",
      "2024-11-23 00:47:10.045847: Pseudo dice [0.7235]\n",
      "2024-11-23 00:47:10.055847: Epoch time: 130.69 s\n",
      "2024-11-23 00:47:11.045870: \n",
      "2024-11-23 00:47:11.045870: Epoch 444\n",
      "2024-11-23 00:47:11.045870: Current learning rate: 0.00139\n",
      "2024-11-23 00:49:21.793514: train_loss -0.854\n",
      "2024-11-23 00:49:21.803515: val_loss -0.5025\n",
      "2024-11-23 00:49:21.803515: Pseudo dice [0.7079]\n",
      "2024-11-23 00:49:21.803515: Epoch time: 130.76 s\n",
      "2024-11-23 00:49:22.793539: \n",
      "2024-11-23 00:49:22.793539: Epoch 445\n",
      "2024-11-23 00:49:22.803530: Current learning rate: 0.00137\n",
      "2024-11-23 00:51:33.512236: train_loss -0.8576\n",
      "2024-11-23 00:51:33.522236: val_loss -0.5664\n",
      "2024-11-23 00:51:33.532237: Pseudo dice [0.7537]\n",
      "2024-11-23 00:51:33.542237: Epoch time: 130.72 s\n",
      "2024-11-23 00:51:33.542237: Yayy! New best EMA pseudo Dice: 0.7285\n",
      "2024-11-23 00:51:34.772538: \n",
      "2024-11-23 00:51:34.782529: Epoch 446\n",
      "2024-11-23 00:51:34.782529: Current learning rate: 0.00135\n",
      "2024-11-23 00:53:45.485949: train_loss -0.8586\n",
      "2024-11-23 00:53:45.495951: val_loss -0.4397\n",
      "2024-11-23 00:53:45.505950: Pseudo dice [0.7152]\n",
      "2024-11-23 00:53:45.505950: Epoch time: 130.71 s\n",
      "2024-11-23 00:53:46.496200: \n",
      "2024-11-23 00:53:46.496200: Epoch 447\n",
      "2024-11-23 00:53:46.506192: Current learning rate: 0.00133\n",
      "2024-11-23 00:55:57.204602: train_loss -0.8632\n",
      "2024-11-23 00:55:57.214602: val_loss -0.5268\n",
      "2024-11-23 00:55:57.224602: Pseudo dice [0.7383]\n",
      "2024-11-23 00:55:57.224602: Epoch time: 130.71 s\n",
      "2024-11-23 00:55:58.214617: \n",
      "2024-11-23 00:55:58.224617: Epoch 448\n",
      "2024-11-23 00:55:58.224617: Current learning rate: 0.0013\n",
      "2024-11-23 00:58:08.989189: train_loss -0.8623\n",
      "2024-11-23 00:58:08.999188: val_loss -0.4958\n",
      "2024-11-23 00:58:09.009190: Pseudo dice [0.7494]\n",
      "2024-11-23 00:58:09.019189: Epoch time: 130.77 s\n",
      "2024-11-23 00:58:09.019189: Yayy! New best EMA pseudo Dice: 0.7304\n",
      "2024-11-23 00:58:10.449218: \n",
      "2024-11-23 00:58:10.459210: Epoch 449\n",
      "2024-11-23 00:58:10.459210: Current learning rate: 0.00128\n",
      "2024-11-23 01:00:21.115484: train_loss -0.8585\n",
      "2024-11-23 01:00:21.125484: val_loss -0.5953\n",
      "2024-11-23 01:00:21.135485: Pseudo dice [0.7522]\n",
      "2024-11-23 01:00:21.135485: Epoch time: 130.67 s\n",
      "2024-11-23 01:00:21.395489: Yayy! New best EMA pseudo Dice: 0.7326\n",
      "2024-11-23 01:00:22.616512: \n",
      "2024-11-23 01:00:22.616512: Epoch 450\n",
      "2024-11-23 01:00:22.616512: Current learning rate: 0.00126\n",
      "2024-11-23 01:02:33.299814: train_loss -0.8605\n",
      "2024-11-23 01:02:33.309814: val_loss -0.5374\n",
      "2024-11-23 01:02:33.319814: Pseudo dice [0.7552]\n",
      "2024-11-23 01:02:33.319814: Epoch time: 130.69 s\n",
      "2024-11-23 01:02:33.329814: Yayy! New best EMA pseudo Dice: 0.7349\n",
      "2024-11-23 01:02:34.559832: \n",
      "2024-11-23 01:02:34.559832: Epoch 451\n",
      "2024-11-23 01:02:34.569832: Current learning rate: 0.00124\n",
      "2024-11-23 01:04:45.194657: train_loss -0.8627\n",
      "2024-11-23 01:04:45.204657: val_loss -0.544\n",
      "2024-11-23 01:04:45.214658: Pseudo dice [0.7374]\n",
      "2024-11-23 01:04:45.214658: Epoch time: 130.63 s\n",
      "2024-11-23 01:04:45.224658: Yayy! New best EMA pseudo Dice: 0.7351\n",
      "2024-11-23 01:04:46.455024: \n",
      "2024-11-23 01:04:46.465024: Epoch 452\n",
      "2024-11-23 01:04:46.465024: Current learning rate: 0.00121\n",
      "2024-11-23 01:06:57.255367: train_loss -0.8568\n",
      "2024-11-23 01:06:57.265367: val_loss -0.5467\n",
      "2024-11-23 01:06:57.275367: Pseudo dice [0.7403]\n",
      "2024-11-23 01:06:57.275367: Epoch time: 130.8 s\n",
      "2024-11-23 01:06:57.285367: Yayy! New best EMA pseudo Dice: 0.7356\n",
      "2024-11-23 01:06:58.515394: \n",
      "2024-11-23 01:06:58.515394: Epoch 453\n",
      "2024-11-23 01:06:58.525384: Current learning rate: 0.00119\n",
      "2024-11-23 01:09:09.227112: train_loss -0.8589\n",
      "2024-11-23 01:09:09.227112: val_loss -0.53\n",
      "2024-11-23 01:09:09.237112: Pseudo dice [0.7237]\n",
      "2024-11-23 01:09:09.247112: Epoch time: 130.71 s\n",
      "2024-11-23 01:09:10.227126: \n",
      "2024-11-23 01:09:10.237126: Epoch 454\n",
      "2024-11-23 01:09:10.237126: Current learning rate: 0.00117\n",
      "2024-11-23 01:11:20.906194: train_loss -0.8649\n",
      "2024-11-23 01:11:20.916195: val_loss -0.5854\n",
      "2024-11-23 01:11:20.926195: Pseudo dice [0.7512]\n",
      "2024-11-23 01:11:20.936195: Epoch time: 130.68 s\n",
      "2024-11-23 01:11:20.936195: Yayy! New best EMA pseudo Dice: 0.7361\n",
      "2024-11-23 01:11:22.176221: \n",
      "2024-11-23 01:11:22.176221: Epoch 455\n",
      "2024-11-23 01:11:22.186212: Current learning rate: 0.00115\n",
      "2024-11-23 01:13:32.846228: train_loss -0.8664\n",
      "2024-11-23 01:13:32.856228: val_loss -0.5837\n",
      "2024-11-23 01:13:32.866228: Pseudo dice [0.7663]\n",
      "2024-11-23 01:13:32.876228: Epoch time: 130.68 s\n",
      "2024-11-23 01:13:32.876228: Yayy! New best EMA pseudo Dice: 0.7391\n",
      "2024-11-23 01:13:34.285839: \n",
      "2024-11-23 01:13:34.285839: Epoch 456\n",
      "2024-11-23 01:13:34.295838: Current learning rate: 0.00112\n",
      "2024-11-23 01:15:45.014956: train_loss -0.8639\n",
      "2024-11-23 01:15:45.024958: val_loss -0.5716\n",
      "2024-11-23 01:15:45.034958: Pseudo dice [0.7546]\n",
      "2024-11-23 01:15:45.034958: Epoch time: 130.73 s\n",
      "2024-11-23 01:15:45.044958: Yayy! New best EMA pseudo Dice: 0.7407\n",
      "2024-11-23 01:15:46.285378: \n",
      "2024-11-23 01:15:46.285378: Epoch 457\n",
      "2024-11-23 01:15:46.295378: Current learning rate: 0.0011\n",
      "2024-11-23 01:17:56.985512: train_loss -0.8486\n",
      "2024-11-23 01:17:56.995511: val_loss -0.4815\n",
      "2024-11-23 01:17:57.005513: Pseudo dice [0.6974]\n",
      "2024-11-23 01:17:57.015513: Epoch time: 130.7 s\n",
      "2024-11-23 01:17:57.985526: \n",
      "2024-11-23 01:17:57.995526: Epoch 458\n",
      "2024-11-23 01:17:57.995526: Current learning rate: 0.00108\n",
      "2024-11-23 01:20:08.713547: train_loss -0.865\n",
      "2024-11-23 01:20:08.723547: val_loss -0.5389\n",
      "2024-11-23 01:20:08.723547: Pseudo dice [0.7217]\n",
      "2024-11-23 01:20:08.733547: Epoch time: 130.73 s\n",
      "2024-11-23 01:20:09.713857: \n",
      "2024-11-23 01:20:09.713857: Epoch 459\n",
      "2024-11-23 01:20:09.723857: Current learning rate: 0.00105\n",
      "2024-11-23 01:22:20.384288: train_loss -0.8643\n",
      "2024-11-23 01:22:20.404289: val_loss -0.5699\n",
      "2024-11-23 01:22:20.404289: Pseudo dice [0.7603]\n",
      "2024-11-23 01:22:20.414289: Epoch time: 130.67 s\n",
      "2024-11-23 01:22:21.398111: \n",
      "2024-11-23 01:22:21.403178: Epoch 460\n",
      "2024-11-23 01:22:21.407242: Current learning rate: 0.00103\n",
      "2024-11-23 01:24:32.014031: train_loss -0.8601\n",
      "2024-11-23 01:24:32.024030: val_loss -0.5136\n",
      "2024-11-23 01:24:32.024030: Pseudo dice [0.7123]\n",
      "2024-11-23 01:24:32.034031: Epoch time: 130.62 s\n",
      "2024-11-23 01:24:33.014045: \n",
      "2024-11-23 01:24:33.024044: Epoch 461\n",
      "2024-11-23 01:24:33.024044: Current learning rate: 0.00101\n",
      "2024-11-23 01:26:43.713832: train_loss -0.8659\n",
      "2024-11-23 01:26:43.733833: val_loss -0.47\n",
      "2024-11-23 01:26:43.733833: Pseudo dice [0.6981]\n",
      "2024-11-23 01:26:43.743833: Epoch time: 130.7 s\n",
      "2024-11-23 01:26:44.733846: \n",
      "2024-11-23 01:26:44.733846: Epoch 462\n",
      "2024-11-23 01:26:44.743855: Current learning rate: 0.00098\n",
      "2024-11-23 01:28:55.505505: train_loss -0.857\n",
      "2024-11-23 01:28:55.515505: val_loss -0.4579\n",
      "2024-11-23 01:28:55.525506: Pseudo dice [0.673]\n",
      "2024-11-23 01:28:55.535505: Epoch time: 130.77 s\n",
      "2024-11-23 01:28:56.695522: \n",
      "2024-11-23 01:28:56.695522: Epoch 463\n",
      "2024-11-23 01:28:56.705521: Current learning rate: 0.00096\n",
      "2024-11-23 01:31:07.398954: train_loss -0.8618\n",
      "2024-11-23 01:31:07.408955: val_loss -0.4801\n",
      "2024-11-23 01:31:07.418955: Pseudo dice [0.6748]\n",
      "2024-11-23 01:31:07.418955: Epoch time: 130.71 s\n",
      "2024-11-23 01:31:08.399165: \n",
      "2024-11-23 01:31:08.409165: Epoch 464\n",
      "2024-11-23 01:31:08.409165: Current learning rate: 0.00094\n",
      "2024-11-23 01:33:18.976509: train_loss -0.8695\n",
      "2024-11-23 01:33:18.996509: val_loss -0.4918\n",
      "2024-11-23 01:33:18.996509: Pseudo dice [0.6877]\n",
      "2024-11-23 01:33:19.006509: Epoch time: 130.58 s\n",
      "2024-11-23 01:33:19.987575: \n",
      "2024-11-23 01:33:19.997575: Epoch 465\n",
      "2024-11-23 01:33:19.997575: Current learning rate: 0.00091\n",
      "2024-11-23 01:35:30.726068: train_loss -0.8649\n",
      "2024-11-23 01:35:30.736068: val_loss -0.5275\n",
      "2024-11-23 01:35:30.746068: Pseudo dice [0.7039]\n",
      "2024-11-23 01:35:30.746068: Epoch time: 130.74 s\n",
      "2024-11-23 01:35:31.737014: \n",
      "2024-11-23 01:35:31.737014: Epoch 466\n",
      "2024-11-23 01:35:31.747013: Current learning rate: 0.00089\n",
      "2024-11-23 01:37:42.475963: train_loss -0.8558\n",
      "2024-11-23 01:37:42.485964: val_loss -0.5115\n",
      "2024-11-23 01:37:42.495965: Pseudo dice [0.6886]\n",
      "2024-11-23 01:37:42.495965: Epoch time: 130.74 s\n",
      "2024-11-23 01:37:43.485978: \n",
      "2024-11-23 01:37:43.485978: Epoch 467\n",
      "2024-11-23 01:37:43.495986: Current learning rate: 0.00087\n",
      "2024-11-23 01:39:54.234530: train_loss -0.8606\n",
      "2024-11-23 01:39:54.244530: val_loss -0.604\n",
      "2024-11-23 01:39:54.254530: Pseudo dice [0.7632]\n",
      "2024-11-23 01:39:54.254530: Epoch time: 130.76 s\n",
      "2024-11-23 01:39:55.234841: \n",
      "2024-11-23 01:39:55.244842: Epoch 468\n",
      "2024-11-23 01:39:55.244842: Current learning rate: 0.00084\n",
      "2024-11-23 01:42:06.004712: train_loss -0.8671\n",
      "2024-11-23 01:42:06.004712: val_loss -0.5088\n",
      "2024-11-23 01:42:06.014712: Pseudo dice [0.7311]\n",
      "2024-11-23 01:42:06.024713: Epoch time: 130.77 s\n",
      "2024-11-23 01:42:07.014728: \n",
      "2024-11-23 01:42:07.014728: Epoch 469\n",
      "2024-11-23 01:42:07.024726: Current learning rate: 0.00082\n",
      "2024-11-23 01:44:17.785348: train_loss -0.8621\n",
      "2024-11-23 01:44:17.795347: val_loss -0.5063\n",
      "2024-11-23 01:44:17.805347: Pseudo dice [0.7222]\n",
      "2024-11-23 01:44:17.805347: Epoch time: 130.78 s\n",
      "2024-11-23 01:44:18.795361: \n",
      "2024-11-23 01:44:18.795361: Epoch 470\n",
      "2024-11-23 01:44:18.795361: Current learning rate: 0.00079\n",
      "2024-11-23 01:46:29.548280: train_loss -0.8703\n",
      "2024-11-23 01:46:29.558280: val_loss -0.5518\n",
      "2024-11-23 01:46:29.568280: Pseudo dice [0.7547]\n",
      "2024-11-23 01:46:29.578280: Epoch time: 130.76 s\n",
      "2024-11-23 01:46:30.738297: \n",
      "2024-11-23 01:46:30.738297: Epoch 471\n",
      "2024-11-23 01:46:30.748297: Current learning rate: 0.00077\n",
      "2024-11-23 01:48:41.499629: train_loss -0.8698\n",
      "2024-11-23 01:48:41.509629: val_loss -0.5245\n",
      "2024-11-23 01:48:41.509629: Pseudo dice [0.7048]\n",
      "2024-11-23 01:48:41.519629: Epoch time: 130.76 s\n",
      "2024-11-23 01:48:42.499642: \n",
      "2024-11-23 01:48:42.509642: Epoch 472\n",
      "2024-11-23 01:48:42.509642: Current learning rate: 0.00075\n",
      "2024-11-23 01:50:53.261027: train_loss -0.8613\n",
      "2024-11-23 01:50:53.271027: val_loss -0.4895\n",
      "2024-11-23 01:50:53.271027: Pseudo dice [0.6907]\n",
      "2024-11-23 01:50:53.281027: Epoch time: 130.76 s\n",
      "2024-11-23 01:50:54.261328: \n",
      "2024-11-23 01:50:54.271328: Epoch 473\n",
      "2024-11-23 01:50:54.271328: Current learning rate: 0.00072\n",
      "2024-11-23 01:53:05.080265: train_loss -0.8588\n",
      "2024-11-23 01:53:05.090265: val_loss -0.5578\n",
      "2024-11-23 01:53:05.100265: Pseudo dice [0.7559]\n",
      "2024-11-23 01:53:05.100265: Epoch time: 130.82 s\n",
      "2024-11-23 01:53:06.090568: \n",
      "2024-11-23 01:53:06.090568: Epoch 474\n",
      "2024-11-23 01:53:06.100559: Current learning rate: 0.0007\n",
      "2024-11-23 01:55:16.795572: train_loss -0.8683\n",
      "2024-11-23 01:55:16.805572: val_loss -0.496\n",
      "2024-11-23 01:55:16.815572: Pseudo dice [0.717]\n",
      "2024-11-23 01:55:16.815572: Epoch time: 130.71 s\n",
      "2024-11-23 01:55:17.805596: \n",
      "2024-11-23 01:55:17.805596: Epoch 475\n",
      "2024-11-23 01:55:17.815586: Current learning rate: 0.00067\n",
      "2024-11-23 01:57:28.531070: train_loss -0.8712\n",
      "2024-11-23 01:57:28.541070: val_loss -0.5891\n",
      "2024-11-23 01:57:28.541070: Pseudo dice [0.7495]\n",
      "2024-11-23 01:57:28.551070: Epoch time: 130.73 s\n",
      "2024-11-23 01:57:29.531084: \n",
      "2024-11-23 01:57:29.531084: Epoch 476\n",
      "2024-11-23 01:57:29.541084: Current learning rate: 0.00065\n",
      "2024-11-23 01:59:40.218321: train_loss -0.8693\n",
      "2024-11-23 01:59:40.228322: val_loss -0.5826\n",
      "2024-11-23 01:59:40.228322: Pseudo dice [0.7517]\n",
      "2024-11-23 01:59:40.238322: Epoch time: 130.69 s\n",
      "2024-11-23 01:59:41.228347: \n",
      "2024-11-23 01:59:41.228347: Epoch 477\n",
      "2024-11-23 01:59:41.238336: Current learning rate: 0.00063\n",
      "2024-11-23 02:01:51.874899: train_loss -0.8624\n",
      "2024-11-23 02:01:51.884899: val_loss -0.4859\n",
      "2024-11-23 02:01:51.894899: Pseudo dice [0.7147]\n",
      "2024-11-23 02:01:51.894899: Epoch time: 130.65 s\n",
      "2024-11-23 02:01:52.894923: \n",
      "2024-11-23 02:01:52.894923: Epoch 478\n",
      "2024-11-23 02:01:52.904913: Current learning rate: 0.0006\n",
      "2024-11-23 02:04:03.579621: train_loss -0.8635\n",
      "2024-11-23 02:04:03.579621: val_loss -0.5637\n",
      "2024-11-23 02:04:03.589622: Pseudo dice [0.7537]\n",
      "2024-11-23 02:04:03.599622: Epoch time: 130.68 s\n",
      "2024-11-23 02:04:04.769937: \n",
      "2024-11-23 02:04:04.779928: Epoch 479\n",
      "2024-11-23 02:04:04.789928: Current learning rate: 0.00058\n",
      "2024-11-23 02:06:15.517491: train_loss -0.8625\n",
      "2024-11-23 02:06:15.527492: val_loss -0.5625\n",
      "2024-11-23 02:06:15.537492: Pseudo dice [0.7441]\n",
      "2024-11-23 02:06:15.537492: Epoch time: 130.75 s\n",
      "2024-11-23 02:06:16.547516: \n",
      "2024-11-23 02:06:16.547516: Epoch 480\n",
      "2024-11-23 02:06:16.557505: Current learning rate: 0.00055\n",
      "2024-11-23 02:08:27.311427: train_loss -0.8683\n",
      "2024-11-23 02:08:27.321427: val_loss -0.5678\n",
      "2024-11-23 02:08:27.331427: Pseudo dice [0.7402]\n",
      "2024-11-23 02:08:27.341429: Epoch time: 130.76 s\n",
      "2024-11-23 02:08:28.341450: \n",
      "2024-11-23 02:08:28.341450: Epoch 481\n",
      "2024-11-23 02:08:28.351442: Current learning rate: 0.00053\n",
      "2024-11-23 02:10:39.109449: train_loss -0.8616\n",
      "2024-11-23 02:10:39.119449: val_loss -0.6041\n",
      "2024-11-23 02:10:39.119449: Pseudo dice [0.7604]\n",
      "2024-11-23 02:10:39.129451: Epoch time: 130.77 s\n",
      "2024-11-23 02:10:40.129472: \n",
      "2024-11-23 02:10:40.139472: Epoch 482\n",
      "2024-11-23 02:10:40.139472: Current learning rate: 0.0005\n",
      "2024-11-23 02:12:50.823718: train_loss -0.8655\n",
      "2024-11-23 02:12:50.833719: val_loss -0.5163\n",
      "2024-11-23 02:12:50.843718: Pseudo dice [0.7076]\n",
      "2024-11-23 02:12:50.853719: Epoch time: 130.69 s\n",
      "2024-11-23 02:12:51.854252: \n",
      "2024-11-23 02:12:51.864252: Epoch 483\n",
      "2024-11-23 02:12:51.864252: Current learning rate: 0.00048\n",
      "2024-11-23 02:15:02.575843: train_loss -0.8708\n",
      "2024-11-23 02:15:02.585843: val_loss -0.6082\n",
      "2024-11-23 02:15:02.595843: Pseudo dice [0.7699]\n",
      "2024-11-23 02:15:02.605843: Epoch time: 130.72 s\n",
      "2024-11-23 02:15:03.605866: \n",
      "2024-11-23 02:15:03.615857: Epoch 484\n",
      "2024-11-23 02:15:03.615857: Current learning rate: 0.00045\n",
      "2024-11-23 02:17:14.331258: train_loss -0.8672\n",
      "2024-11-23 02:17:14.341258: val_loss -0.5515\n",
      "2024-11-23 02:17:14.351259: Pseudo dice [0.7271]\n",
      "2024-11-23 02:17:14.361259: Epoch time: 130.73 s\n",
      "2024-11-23 02:17:15.361273: \n",
      "2024-11-23 02:17:15.371273: Epoch 485\n",
      "2024-11-23 02:17:15.371273: Current learning rate: 0.00043\n",
      "2024-11-23 02:19:26.084621: train_loss -0.8674\n",
      "2024-11-23 02:19:26.094621: val_loss -0.5649\n",
      "2024-11-23 02:19:26.104621: Pseudo dice [0.7427]\n",
      "2024-11-23 02:19:26.104621: Epoch time: 130.72 s\n",
      "2024-11-23 02:19:27.285836: \n",
      "2024-11-23 02:19:27.285836: Epoch 486\n",
      "2024-11-23 02:19:27.295827: Current learning rate: 0.0004\n",
      "2024-11-23 02:21:38.051398: train_loss -0.8624\n",
      "2024-11-23 02:21:38.061398: val_loss -0.556\n",
      "2024-11-23 02:21:38.071397: Pseudo dice [0.7251]\n",
      "2024-11-23 02:21:38.081397: Epoch time: 130.78 s\n",
      "2024-11-23 02:21:39.081421: \n",
      "2024-11-23 02:21:39.091412: Epoch 487\n",
      "2024-11-23 02:21:39.091412: Current learning rate: 0.00037\n",
      "2024-11-23 02:23:49.835891: train_loss -0.8569\n",
      "2024-11-23 02:23:49.845890: val_loss -0.4347\n",
      "2024-11-23 02:23:49.845890: Pseudo dice [0.7053]\n",
      "2024-11-23 02:23:49.855891: Epoch time: 130.75 s\n",
      "2024-11-23 02:23:50.855913: \n",
      "2024-11-23 02:23:50.865913: Epoch 488\n",
      "2024-11-23 02:23:50.865913: Current learning rate: 0.00035\n",
      "2024-11-23 02:26:01.583119: train_loss -0.8593\n",
      "2024-11-23 02:26:01.593119: val_loss -0.573\n",
      "2024-11-23 02:26:01.593119: Pseudo dice [0.742]\n",
      "2024-11-23 02:26:01.603119: Epoch time: 130.73 s\n",
      "2024-11-23 02:26:02.623142: \n",
      "2024-11-23 02:26:02.623142: Epoch 489\n",
      "2024-11-23 02:26:02.633134: Current learning rate: 0.00032\n",
      "2024-11-23 02:28:13.311491: train_loss -0.8608\n",
      "2024-11-23 02:28:13.321491: val_loss -0.5262\n",
      "2024-11-23 02:28:13.331492: Pseudo dice [0.7486]\n",
      "2024-11-23 02:28:13.331492: Epoch time: 130.7 s\n",
      "2024-11-23 02:28:14.341845: \n",
      "2024-11-23 02:28:14.341845: Epoch 490\n",
      "2024-11-23 02:28:14.341845: Current learning rate: 0.0003\n",
      "2024-11-23 02:30:25.157231: train_loss -0.8637\n",
      "2024-11-23 02:30:25.167231: val_loss -0.5572\n",
      "2024-11-23 02:30:25.177232: Pseudo dice [0.7412]\n",
      "2024-11-23 02:30:25.177232: Epoch time: 130.83 s\n",
      "2024-11-23 02:30:26.187254: \n",
      "2024-11-23 02:30:26.197253: Epoch 491\n",
      "2024-11-23 02:30:26.197253: Current learning rate: 0.00027\n",
      "2024-11-23 02:32:36.940448: train_loss -0.866\n",
      "2024-11-23 02:32:36.950448: val_loss -0.5114\n",
      "2024-11-23 02:32:36.960449: Pseudo dice [0.7443]\n",
      "2024-11-23 02:32:36.960449: Epoch time: 130.75 s\n",
      "2024-11-23 02:32:37.960473: \n",
      "2024-11-23 02:32:37.960473: Epoch 492\n",
      "2024-11-23 02:32:37.970471: Current learning rate: 0.00024\n",
      "2024-11-23 02:34:48.748717: train_loss -0.8706\n",
      "2024-11-23 02:34:48.758717: val_loss -0.4827\n",
      "2024-11-23 02:34:48.768717: Pseudo dice [0.6751]\n",
      "2024-11-23 02:34:48.778717: Epoch time: 130.79 s\n",
      "2024-11-23 02:34:49.958733: \n",
      "2024-11-23 02:34:49.958733: Epoch 493\n",
      "2024-11-23 02:34:49.968733: Current learning rate: 0.00021\n",
      "2024-11-23 02:37:00.708026: train_loss -0.8697\n",
      "2024-11-23 02:37:00.718025: val_loss -0.5612\n",
      "2024-11-23 02:37:00.728026: Pseudo dice [0.7687]\n",
      "2024-11-23 02:37:00.738026: Epoch time: 130.75 s\n",
      "2024-11-23 02:37:01.738049: \n",
      "2024-11-23 02:37:01.748049: Epoch 494\n",
      "2024-11-23 02:37:01.748049: Current learning rate: 0.00019\n",
      "2024-11-23 02:39:12.496607: train_loss -0.8746\n",
      "2024-11-23 02:39:12.506607: val_loss -0.5147\n",
      "2024-11-23 02:39:12.516608: Pseudo dice [0.7184]\n",
      "2024-11-23 02:39:12.516608: Epoch time: 130.76 s\n",
      "2024-11-23 02:39:13.526622: \n",
      "2024-11-23 02:39:13.526622: Epoch 495\n",
      "2024-11-23 02:39:13.536622: Current learning rate: 0.00016\n",
      "2024-11-23 02:41:24.232933: train_loss -0.866\n",
      "2024-11-23 02:41:24.242933: val_loss -0.5683\n",
      "2024-11-23 02:41:24.252933: Pseudo dice [0.7489]\n",
      "2024-11-23 02:41:24.252933: Epoch time: 130.71 s\n",
      "2024-11-23 02:41:25.262957: \n",
      "2024-11-23 02:41:25.262957: Epoch 496\n",
      "2024-11-23 02:41:25.272957: Current learning rate: 0.00013\n",
      "2024-11-23 02:43:36.028134: train_loss -0.8671\n",
      "2024-11-23 02:43:36.038134: val_loss -0.5706\n",
      "2024-11-23 02:43:36.038134: Pseudo dice [0.7521]\n",
      "2024-11-23 02:43:36.048134: Epoch time: 130.77 s\n",
      "2024-11-23 02:43:37.048971: \n",
      "2024-11-23 02:43:37.058962: Epoch 497\n",
      "2024-11-23 02:43:37.058962: Current learning rate: 0.0001\n",
      "2024-11-23 02:45:47.715824: train_loss -0.867\n",
      "2024-11-23 02:45:47.725824: val_loss -0.474\n",
      "2024-11-23 02:45:47.735824: Pseudo dice [0.6905]\n",
      "2024-11-23 02:45:47.735824: Epoch time: 130.67 s\n",
      "2024-11-23 02:45:48.746191: \n",
      "2024-11-23 02:45:48.756191: Epoch 498\n",
      "2024-11-23 02:45:48.756191: Current learning rate: 7e-05\n",
      "2024-11-23 02:47:59.519597: train_loss -0.8703\n",
      "2024-11-23 02:47:59.529597: val_loss -0.5406\n",
      "2024-11-23 02:47:59.529597: Pseudo dice [0.7167]\n",
      "2024-11-23 02:47:59.539598: Epoch time: 130.77 s\n",
      "2024-11-23 02:48:00.540660: \n",
      "2024-11-23 02:48:00.550659: Epoch 499\n",
      "2024-11-23 02:48:00.550659: Current learning rate: 4e-05\n",
      "2024-11-23 02:50:11.196190: train_loss -0.8592\n",
      "2024-11-23 02:50:11.206190: val_loss -0.6212\n",
      "2024-11-23 02:50:11.206190: Pseudo dice [0.786]\n",
      "2024-11-23 02:50:11.216190: Epoch time: 130.66 s\n",
      "2024-11-23 02:50:12.696800: Training done.\n",
      "2024-11-23 02:50:12.817143: Using splits from existing split file: D:/Liver Segmentation Meena 2024/nnUNet_blastoma_2025/nnUNet_preprocessed\\Dataset007_Blastoma\\splits_final.json\n",
      "2024-11-23 02:50:12.837144: The split file contains 5 splits.\n",
      "2024-11-23 02:50:12.847144: Desired fold for training: 1\n",
      "2024-11-23 02:50:12.847144: This split has 19 training and 5 validation cases.\n",
      "2024-11-23 02:50:12.857144: predicting volume_1\n",
      "2024-11-23 02:50:12.867144: volume_1, shape torch.Size([1, 514, 561, 561]), rank 0\n",
      "2024-11-23 02:55:25.583493: predicting volume_12\n",
      "2024-11-23 02:55:25.663495: volume_12, shape torch.Size([1, 245, 441, 441]), rank 0\n",
      "2024-11-23 02:56:31.984414: predicting volume_38\n",
      "2024-11-23 02:56:32.014416: volume_38, shape torch.Size([1, 577, 485, 485]), rank 0\n",
      "2024-11-23 03:00:59.449401: predicting volume_39\n",
      "2024-11-23 03:00:59.509402: volume_39, shape torch.Size([1, 826, 494, 494]), rank 0\n",
      "2024-11-23 03:06:55.948842: predicting volume_40\n",
      "2024-11-23 03:06:56.028843: volume_40, shape torch.Size([1, 681, 455, 455]), rank 0\n",
      "2024-11-23 03:12:26.099567: Validation complete\n",
      "2024-11-23 03:12:26.109567: Mean Validation Dice:  0.5940212102535163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nnunetv2\\training\\nnUNetTrainer\\nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
      "C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "try:\n",
    "    !nnUNetv2_train 007 3d_fullres 1 -tr nnUNetTrainer\n",
    "except Exception as e:\n",
    "    print(f\"Error during training: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2024-11-25 21:24:50.011924: do_dummy_2d_data_aug: False\n",
      "2024-11-25 21:24:50.011924: Using splits from existing split file: D:/Liver Segmentation Meena 2024/nnUNet_blastoma_2025/nnUNet_preprocessed\\Dataset007_Blastoma\\splits_final.json\n",
      "2024-11-25 21:24:50.011924: The split file contains 5 splits.\n",
      "2024-11-25 21:24:50.022867: Desired fold for training: 3\n",
      "2024-11-25 21:24:50.022867: This split has 19 training and 5 validation cases.\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 3d_fullres\n",
      " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [569.5, 512.0, 512.0], 'spacing': [0.625, 0.4882810115814209, 0.4882810115814209], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset007_Blastoma', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.625, 0.4882810115814209, 0.4882810115814209], 'original_median_shape_after_transp': [471, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2609.056396484375, 'mean': 68.07295227050781, 'median': 66.0, 'min': -1028.0, 'percentile_00_5': -59.0, 'percentile_99_5': 248.0, 'std': 47.62541198730469}}} \n",
      "\n",
      "2024-11-25 21:24:59.124592: unpacking dataset...\n",
      "2024-11-25 21:24:59.454596: unpacking done...\n",
      "2024-11-25 21:24:59.475446: Unable to plot network architecture:\n",
      "2024-11-25 21:24:59.479486: No module named 'hiddenlayer'\n",
      "2024-11-25 21:24:59.501416: \n",
      "2024-11-25 21:24:59.510919: Epoch 0\n",
      "2024-11-25 21:24:59.510919: Current learning rate: 0.01\n",
      "2024-11-25 21:27:18.547610: train_loss 0.0658\n",
      "2024-11-25 21:27:18.557610: val_loss -0.0819\n",
      "2024-11-25 21:27:18.567611: Pseudo dice [0.5001]\n",
      "2024-11-25 21:27:18.567611: Epoch time: 139.05 s\n",
      "2024-11-25 21:27:18.577610: Yayy! New best EMA pseudo Dice: 0.5001\n",
      "2024-11-25 21:27:19.938264: \n",
      "2024-11-25 21:27:19.938264: Epoch 1\n",
      "2024-11-25 21:27:19.948263: Current learning rate: 0.00998\n",
      "2024-11-25 21:29:29.778493: train_loss -0.0938\n",
      "2024-11-25 21:29:29.778493: val_loss -0.2411\n",
      "2024-11-25 21:29:29.788493: Pseudo dice [0.57]\n",
      "2024-11-25 21:29:29.788493: Epoch time: 129.84 s\n",
      "2024-11-25 21:29:29.798493: Yayy! New best EMA pseudo Dice: 0.5071\n",
      "2024-11-25 21:29:31.014961: \n",
      "2024-11-25 21:29:31.014961: Epoch 2\n",
      "2024-11-25 21:29:31.024961: Current learning rate: 0.00996\n",
      "2024-11-25 21:31:40.818066: train_loss -0.1932\n",
      "2024-11-25 21:31:40.828067: val_loss -0.3381\n",
      "2024-11-25 21:31:40.838067: Pseudo dice [0.6523]\n",
      "2024-11-25 21:31:40.848067: Epoch time: 129.8 s\n",
      "2024-11-25 21:31:40.848067: Yayy! New best EMA pseudo Dice: 0.5216\n",
      "2024-11-25 21:31:42.092251: \n",
      "2024-11-25 21:31:42.102250: Epoch 3\n",
      "2024-11-25 21:31:42.102250: Current learning rate: 0.00995\n",
      "2024-11-25 21:33:51.974949: train_loss -0.1744\n",
      "2024-11-25 21:33:51.994948: val_loss -0.244\n",
      "2024-11-25 21:33:51.994948: Pseudo dice [0.6009]\n",
      "2024-11-25 21:33:52.004948: Epoch time: 129.88 s\n",
      "2024-11-25 21:33:52.004948: Yayy! New best EMA pseudo Dice: 0.5295\n",
      "2024-11-25 21:33:53.224974: \n",
      "2024-11-25 21:33:53.234974: Epoch 4\n",
      "2024-11-25 21:33:53.234974: Current learning rate: 0.00993\n",
      "2024-11-25 21:36:02.995273: train_loss -0.2116\n",
      "2024-11-25 21:36:03.005273: val_loss -0.2117\n",
      "2024-11-25 21:36:03.005273: Pseudo dice [0.5342]\n",
      "2024-11-25 21:36:03.015274: Epoch time: 129.77 s\n",
      "2024-11-25 21:36:03.015274: Yayy! New best EMA pseudo Dice: 0.53\n",
      "2024-11-25 21:36:04.275711: \n",
      "2024-11-25 21:36:04.275711: Epoch 5\n",
      "2024-11-25 21:36:04.275711: Current learning rate: 0.00991\n",
      "2024-11-25 21:38:14.082737: train_loss -0.2263\n",
      "2024-11-25 21:38:14.092737: val_loss -0.1559\n",
      "2024-11-25 21:38:14.102737: Pseudo dice [0.5538]\n",
      "2024-11-25 21:38:14.112738: Epoch time: 129.82 s\n",
      "2024-11-25 21:38:14.112738: Yayy! New best EMA pseudo Dice: 0.5324\n",
      "2024-11-25 21:38:15.312921: \n",
      "2024-11-25 21:38:15.322931: Epoch 6\n",
      "2024-11-25 21:38:15.322931: Current learning rate: 0.00989\n",
      "2024-11-25 21:40:25.089104: train_loss -0.2991\n",
      "2024-11-25 21:40:25.099105: val_loss -0.3269\n",
      "2024-11-25 21:40:25.099105: Pseudo dice [0.638]\n",
      "2024-11-25 21:40:25.109105: Epoch time: 129.78 s\n",
      "2024-11-25 21:40:25.109105: Yayy! New best EMA pseudo Dice: 0.543\n",
      "2024-11-25 21:40:26.499468: \n",
      "2024-11-25 21:40:26.499468: Epoch 7\n",
      "2024-11-25 21:40:26.499468: Current learning rate: 0.00987\n",
      "2024-11-25 21:42:36.346555: train_loss -0.3218\n",
      "2024-11-25 21:42:36.356555: val_loss -0.3914\n",
      "2024-11-25 21:42:36.356555: Pseudo dice [0.7058]\n",
      "2024-11-25 21:42:36.366555: Epoch time: 129.85 s\n",
      "2024-11-25 21:42:36.366555: Yayy! New best EMA pseudo Dice: 0.5592\n",
      "2024-11-25 21:42:37.593161: \n",
      "2024-11-25 21:42:37.603151: Epoch 8\n",
      "2024-11-25 21:42:37.603151: Current learning rate: 0.00986\n",
      "2024-11-25 21:44:47.419727: train_loss -0.3054\n",
      "2024-11-25 21:44:47.432023: val_loss -0.3981\n",
      "2024-11-25 21:44:47.440026: Pseudo dice [0.6846]\n",
      "2024-11-25 21:44:47.450029: Epoch time: 129.83 s\n",
      "2024-11-25 21:44:47.450029: Yayy! New best EMA pseudo Dice: 0.5718\n",
      "2024-11-25 21:44:48.680105: \n",
      "2024-11-25 21:44:48.690096: Epoch 9\n",
      "2024-11-25 21:44:48.690096: Current learning rate: 0.00984\n",
      "2024-11-25 21:46:58.506684: train_loss -0.341\n",
      "2024-11-25 21:46:58.516684: val_loss -0.3191\n",
      "2024-11-25 21:46:58.531580: Pseudo dice [0.6277]\n",
      "2024-11-25 21:46:58.538028: Epoch time: 129.83 s\n",
      "2024-11-25 21:46:58.544030: Yayy! New best EMA pseudo Dice: 0.5774\n",
      "2024-11-25 21:46:59.713571: \n",
      "2024-11-25 21:46:59.723562: Epoch 10\n",
      "2024-11-25 21:46:59.723562: Current learning rate: 0.00982\n",
      "2024-11-25 21:49:09.590702: train_loss -0.3757\n",
      "2024-11-25 21:49:09.600703: val_loss -0.3557\n",
      "2024-11-25 21:49:09.610702: Pseudo dice [0.6609]\n",
      "2024-11-25 21:49:09.610702: Epoch time: 129.88 s\n",
      "2024-11-25 21:49:09.620702: Yayy! New best EMA pseudo Dice: 0.5857\n",
      "2024-11-25 21:49:10.830728: \n",
      "2024-11-25 21:49:10.840728: Epoch 11\n",
      "2024-11-25 21:49:10.840728: Current learning rate: 0.0098\n",
      "2024-11-25 21:51:20.967708: train_loss -0.3371\n",
      "2024-11-25 21:51:20.977708: val_loss -0.1945\n",
      "2024-11-25 21:51:20.977708: Pseudo dice [0.604]\n",
      "2024-11-25 21:51:20.987708: Epoch time: 130.14 s\n",
      "2024-11-25 21:51:20.987708: Yayy! New best EMA pseudo Dice: 0.5876\n",
      "2024-11-25 21:51:22.197574: \n",
      "2024-11-25 21:51:22.207582: Epoch 12\n",
      "2024-11-25 21:51:22.207582: Current learning rate: 0.00978\n",
      "2024-11-25 21:53:36.620985: train_loss -0.3078\n",
      "2024-11-25 21:53:36.644991: val_loss -0.2711\n",
      "2024-11-25 21:53:36.650992: Pseudo dice [0.6218]\n",
      "2024-11-25 21:53:36.655994: Epoch time: 134.42 s\n",
      "2024-11-25 21:53:36.662995: Yayy! New best EMA pseudo Dice: 0.591\n",
      "2024-11-25 21:53:37.884696: \n",
      "2024-11-25 21:53:37.890697: Epoch 13\n",
      "2024-11-25 21:53:37.895698: Current learning rate: 0.00977\n",
      "2024-11-25 21:55:50.098342: train_loss -0.3771\n",
      "2024-11-25 21:55:50.108344: val_loss -0.373\n",
      "2024-11-25 21:55:50.115345: Pseudo dice [0.678]\n",
      "2024-11-25 21:55:50.122347: Epoch time: 132.21 s\n",
      "2024-11-25 21:55:50.127348: Yayy! New best EMA pseudo Dice: 0.5997\n",
      "2024-11-25 21:55:51.530664: \n",
      "2024-11-25 21:55:51.536665: Epoch 14\n",
      "2024-11-25 21:55:51.540666: Current learning rate: 0.00975\n",
      "2024-11-25 21:58:02.652512: train_loss -0.3915\n",
      "2024-11-25 21:58:02.662514: val_loss -0.1626\n",
      "2024-11-25 21:58:02.667515: Pseudo dice [0.5516]\n",
      "2024-11-25 21:58:02.673516: Epoch time: 131.12 s\n",
      "2024-11-25 21:58:03.652738: \n",
      "2024-11-25 21:58:03.659738: Epoch 15\n",
      "2024-11-25 21:58:03.664740: Current learning rate: 0.00973\n",
      "2024-11-25 22:00:14.314007: train_loss -0.4219\n",
      "2024-11-25 22:00:14.323008: val_loss -0.3839\n",
      "2024-11-25 22:00:14.329010: Pseudo dice [0.6598]\n",
      "2024-11-25 22:00:14.333011: Epoch time: 130.66 s\n",
      "2024-11-25 22:00:14.338012: Yayy! New best EMA pseudo Dice: 0.6014\n",
      "2024-11-25 22:00:15.581422: \n",
      "2024-11-25 22:00:15.587423: Epoch 16\n",
      "2024-11-25 22:00:15.592425: Current learning rate: 0.00971\n",
      "2024-11-25 22:02:26.080587: train_loss -0.4411\n",
      "2024-11-25 22:02:26.089590: val_loss -0.3713\n",
      "2024-11-25 22:02:26.095590: Pseudo dice [0.6682]\n",
      "2024-11-25 22:02:26.100592: Epoch time: 130.5 s\n",
      "2024-11-25 22:02:26.104593: Yayy! New best EMA pseudo Dice: 0.6081\n",
      "2024-11-25 22:02:27.354424: \n",
      "2024-11-25 22:02:27.360425: Epoch 17\n",
      "2024-11-25 22:02:27.364426: Current learning rate: 0.00969\n",
      "2024-11-25 22:04:37.540293: train_loss -0.4001\n",
      "2024-11-25 22:04:37.549296: val_loss -0.1101\n",
      "2024-11-25 22:04:37.555296: Pseudo dice [0.5496]\n",
      "2024-11-25 22:04:37.560297: Epoch time: 130.19 s\n",
      "2024-11-25 22:04:38.552521: \n",
      "2024-11-25 22:04:38.558523: Epoch 18\n",
      "2024-11-25 22:04:38.562523: Current learning rate: 0.00968\n",
      "2024-11-25 22:06:49.566072: train_loss -0.4147\n",
      "2024-11-25 22:06:49.587076: val_loss -0.3796\n",
      "2024-11-25 22:06:49.593077: Pseudo dice [0.7042]\n",
      "2024-11-25 22:06:49.600078: Epoch time: 131.01 s\n",
      "2024-11-25 22:06:49.605079: Yayy! New best EMA pseudo Dice: 0.6124\n",
      "2024-11-25 22:06:50.846698: \n",
      "2024-11-25 22:06:50.853700: Epoch 19\n",
      "2024-11-25 22:06:50.858700: Current learning rate: 0.00966\n",
      "2024-11-25 22:09:04.061311: train_loss -0.4317\n",
      "2024-11-25 22:09:04.070313: val_loss -0.2895\n",
      "2024-11-25 22:09:04.077315: Pseudo dice [0.6441]\n",
      "2024-11-25 22:09:04.084316: Epoch time: 133.22 s\n",
      "2024-11-25 22:09:04.090319: Yayy! New best EMA pseudo Dice: 0.6156\n",
      "2024-11-25 22:09:05.334632: \n",
      "2024-11-25 22:09:05.341635: Epoch 20\n",
      "2024-11-25 22:09:05.345636: Current learning rate: 0.00964\n",
      "2024-11-25 22:11:20.728340: train_loss -0.4386\n",
      "2024-11-25 22:11:20.735344: val_loss -0.3927\n",
      "2024-11-25 22:11:20.744346: Pseudo dice [0.7057]\n",
      "2024-11-25 22:11:20.749852: Epoch time: 135.39 s\n",
      "2024-11-25 22:11:20.756854: Yayy! New best EMA pseudo Dice: 0.6246\n",
      "2024-11-25 22:11:22.383323: \n",
      "2024-11-25 22:11:22.391325: Epoch 21\n",
      "2024-11-25 22:11:22.396326: Current learning rate: 0.00962\n",
      "2024-11-25 22:13:33.370371: train_loss -0.5032\n",
      "2024-11-25 22:13:33.390375: val_loss -0.3142\n",
      "2024-11-25 22:13:33.400373: Pseudo dice [0.6412]\n",
      "2024-11-25 22:13:33.400373: Epoch time: 130.99 s\n",
      "2024-11-25 22:13:33.410373: Yayy! New best EMA pseudo Dice: 0.6262\n",
      "2024-11-25 22:13:34.750392: \n",
      "2024-11-25 22:13:34.760391: Epoch 22\n",
      "2024-11-25 22:13:34.760391: Current learning rate: 0.0096\n",
      "2024-11-25 22:15:44.938162: train_loss -0.4796\n",
      "2024-11-25 22:15:44.958162: val_loss -0.4348\n",
      "2024-11-25 22:15:44.968162: Pseudo dice [0.7136]\n",
      "2024-11-25 22:15:44.968162: Epoch time: 130.19 s\n",
      "2024-11-25 22:15:44.978162: Yayy! New best EMA pseudo Dice: 0.635\n",
      "2024-11-25 22:15:46.358190: \n",
      "2024-11-25 22:15:46.368190: Epoch 23\n",
      "2024-11-25 22:15:46.368190: Current learning rate: 0.00959\n",
      "2024-11-25 22:17:56.220320: train_loss -0.4857\n",
      "2024-11-25 22:17:56.240320: val_loss -0.3064\n",
      "2024-11-25 22:17:56.240320: Pseudo dice [0.6408]\n",
      "2024-11-25 22:17:56.250320: Epoch time: 129.86 s\n",
      "2024-11-25 22:17:56.250320: Yayy! New best EMA pseudo Dice: 0.6356\n",
      "2024-11-25 22:17:57.620348: \n",
      "2024-11-25 22:17:57.630348: Epoch 24\n",
      "2024-11-25 22:17:57.630348: Current learning rate: 0.00957\n",
      "2024-11-25 22:20:07.472432: train_loss -0.4227\n",
      "2024-11-25 22:20:07.482432: val_loss -0.411\n",
      "2024-11-25 22:20:07.492432: Pseudo dice [0.7206]\n",
      "2024-11-25 22:20:07.502432: Epoch time: 129.85 s\n",
      "2024-11-25 22:20:07.512432: Yayy! New best EMA pseudo Dice: 0.6441\n",
      "2024-11-25 22:20:08.832461: \n",
      "2024-11-25 22:20:08.842462: Epoch 25\n",
      "2024-11-25 22:20:08.842462: Current learning rate: 0.00955\n",
      "2024-11-25 22:22:18.849391: train_loss -0.4808\n",
      "2024-11-25 22:22:18.869392: val_loss -0.2217\n",
      "2024-11-25 22:22:18.879390: Pseudo dice [0.5792]\n",
      "2024-11-25 22:22:18.879390: Epoch time: 130.02 s\n",
      "2024-11-25 22:22:19.979416: \n",
      "2024-11-25 22:22:19.989416: Epoch 26\n",
      "2024-11-25 22:22:19.989416: Current learning rate: 0.00953\n",
      "2024-11-25 22:24:29.910088: train_loss -0.4015\n",
      "2024-11-25 22:24:29.920089: val_loss -0.179\n",
      "2024-11-25 22:24:29.930088: Pseudo dice [0.6337]\n",
      "2024-11-25 22:24:29.940089: Epoch time: 129.93 s\n",
      "2024-11-25 22:24:31.010113: \n",
      "2024-11-25 22:24:31.020103: Epoch 27\n",
      "2024-11-25 22:24:31.020103: Current learning rate: 0.00951\n",
      "2024-11-25 22:26:40.891260: train_loss -0.4418\n",
      "2024-11-25 22:26:40.901260: val_loss -0.4255\n",
      "2024-11-25 22:26:40.911260: Pseudo dice [0.6877]\n",
      "2024-11-25 22:26:40.911260: Epoch time: 129.88 s\n",
      "2024-11-25 22:26:41.981297: \n",
      "2024-11-25 22:26:41.981297: Epoch 28\n",
      "2024-11-25 22:26:41.991297: Current learning rate: 0.00949\n",
      "2024-11-25 22:28:51.862853: train_loss -0.5031\n",
      "2024-11-25 22:28:51.872853: val_loss -0.3148\n",
      "2024-11-25 22:28:51.882853: Pseudo dice [0.6469]\n",
      "2024-11-25 22:28:51.892853: Epoch time: 129.88 s\n",
      "2024-11-25 22:28:53.142871: \n",
      "2024-11-25 22:28:53.152871: Epoch 29\n",
      "2024-11-25 22:28:53.152871: Current learning rate: 0.00948\n",
      "2024-11-25 22:31:03.134553: train_loss -0.5083\n",
      "2024-11-25 22:31:03.154554: val_loss -0.3744\n",
      "2024-11-25 22:31:03.164554: Pseudo dice [0.6709]\n",
      "2024-11-25 22:31:03.174553: Epoch time: 129.99 s\n",
      "2024-11-25 22:31:03.174553: Yayy! New best EMA pseudo Dice: 0.6455\n",
      "2024-11-25 22:31:04.484581: \n",
      "2024-11-25 22:31:04.484581: Epoch 30\n",
      "2024-11-25 22:31:04.494581: Current learning rate: 0.00946\n",
      "2024-11-25 22:33:14.326129: train_loss -0.5415\n",
      "2024-11-25 22:33:14.336129: val_loss -0.3918\n",
      "2024-11-25 22:33:14.346129: Pseudo dice [0.6868]\n",
      "2024-11-25 22:33:14.356129: Epoch time: 129.84 s\n",
      "2024-11-25 22:33:14.356129: Yayy! New best EMA pseudo Dice: 0.6497\n",
      "2024-11-25 22:33:15.646156: \n",
      "2024-11-25 22:33:15.656156: Epoch 31\n",
      "2024-11-25 22:33:15.656156: Current learning rate: 0.00944\n",
      "2024-11-25 22:35:25.518728: train_loss -0.5318\n",
      "2024-11-25 22:35:25.538728: val_loss -0.3408\n",
      "2024-11-25 22:35:25.538728: Pseudo dice [0.664]\n",
      "2024-11-25 22:35:25.548728: Epoch time: 129.87 s\n",
      "2024-11-25 22:35:25.558728: Yayy! New best EMA pseudo Dice: 0.6511\n",
      "2024-11-25 22:35:26.878756: \n",
      "2024-11-25 22:35:26.888756: Epoch 32\n",
      "2024-11-25 22:35:26.888756: Current learning rate: 0.00942\n",
      "2024-11-25 22:37:36.701258: train_loss -0.5119\n",
      "2024-11-25 22:37:36.721259: val_loss -0.3414\n",
      "2024-11-25 22:37:36.721259: Pseudo dice [0.6948]\n",
      "2024-11-25 22:37:36.731259: Epoch time: 129.82 s\n",
      "2024-11-25 22:37:36.731259: Yayy! New best EMA pseudo Dice: 0.6555\n",
      "2024-11-25 22:37:38.041287: \n",
      "2024-11-25 22:37:38.041287: Epoch 33\n",
      "2024-11-25 22:37:38.051287: Current learning rate: 0.0094\n",
      "2024-11-25 22:39:48.073021: train_loss -0.4697\n",
      "2024-11-25 22:39:48.083021: val_loss -0.3135\n",
      "2024-11-25 22:39:48.093021: Pseudo dice [0.6764]\n",
      "2024-11-25 22:39:48.093021: Epoch time: 130.04 s\n",
      "2024-11-25 22:39:48.103022: Yayy! New best EMA pseudo Dice: 0.6576\n",
      "2024-11-25 22:39:49.473041: \n",
      "2024-11-25 22:39:49.483041: Epoch 34\n",
      "2024-11-25 22:39:49.483041: Current learning rate: 0.00939\n",
      "2024-11-25 22:41:59.315998: train_loss -0.4992\n",
      "2024-11-25 22:41:59.325998: val_loss -0.3022\n",
      "2024-11-25 22:41:59.335998: Pseudo dice [0.6552]\n",
      "2024-11-25 22:41:59.345998: Epoch time: 129.84 s\n",
      "2024-11-25 22:42:00.416023: \n",
      "2024-11-25 22:42:00.426023: Epoch 35\n",
      "2024-11-25 22:42:00.426023: Current learning rate: 0.00937\n",
      "2024-11-25 22:44:10.297110: train_loss -0.5385\n",
      "2024-11-25 22:44:10.307110: val_loss -0.3221\n",
      "2024-11-25 22:44:10.317110: Pseudo dice [0.6692]\n",
      "2024-11-25 22:44:10.327111: Epoch time: 129.88 s\n",
      "2024-11-25 22:44:10.327111: Yayy! New best EMA pseudo Dice: 0.6585\n",
      "2024-11-25 22:44:11.837141: \n",
      "2024-11-25 22:44:11.847141: Epoch 36\n",
      "2024-11-25 22:44:11.847141: Current learning rate: 0.00935\n",
      "2024-11-25 22:46:21.769848: train_loss -0.505\n",
      "2024-11-25 22:46:21.779848: val_loss -0.2777\n",
      "2024-11-25 22:46:21.779848: Pseudo dice [0.6458]\n",
      "2024-11-25 22:46:21.789849: Epoch time: 129.93 s\n",
      "2024-11-25 22:46:22.879873: \n",
      "2024-11-25 22:46:22.889873: Epoch 37\n",
      "2024-11-25 22:46:22.899873: Current learning rate: 0.00933\n",
      "2024-11-25 22:48:33.071002: train_loss -0.518\n",
      "2024-11-25 22:48:33.081002: val_loss -0.2286\n",
      "2024-11-25 22:48:33.081002: Pseudo dice [0.6261]\n",
      "2024-11-25 22:48:33.091003: Epoch time: 130.19 s\n",
      "2024-11-25 22:48:34.161028: \n",
      "2024-11-25 22:48:34.171030: Epoch 38\n",
      "2024-11-25 22:48:34.171030: Current learning rate: 0.00931\n",
      "2024-11-25 22:50:44.053864: train_loss -0.5245\n",
      "2024-11-25 22:50:44.063864: val_loss -0.382\n",
      "2024-11-25 22:50:44.073864: Pseudo dice [0.7076]\n",
      "2024-11-25 22:50:44.073864: Epoch time: 129.89 s\n",
      "2024-11-25 22:50:44.083864: Yayy! New best EMA pseudo Dice: 0.6595\n",
      "2024-11-25 22:50:45.413892: \n",
      "2024-11-25 22:50:45.423892: Epoch 39\n",
      "2024-11-25 22:50:45.423892: Current learning rate: 0.0093\n",
      "2024-11-25 22:52:55.246923: train_loss -0.5293\n",
      "2024-11-25 22:52:55.256923: val_loss -0.3835\n",
      "2024-11-25 22:52:55.266923: Pseudo dice [0.698]\n",
      "2024-11-25 22:52:55.266923: Epoch time: 129.83 s\n",
      "2024-11-25 22:52:55.276923: Yayy! New best EMA pseudo Dice: 0.6633\n",
      "2024-11-25 22:52:56.626951: \n",
      "2024-11-25 22:52:56.636951: Epoch 40\n",
      "2024-11-25 22:52:56.636951: Current learning rate: 0.00928\n",
      "2024-11-25 22:55:06.589877: train_loss -0.5701\n",
      "2024-11-25 22:55:06.609878: val_loss -0.3947\n",
      "2024-11-25 22:55:06.619878: Pseudo dice [0.6984]\n",
      "2024-11-25 22:55:06.629878: Epoch time: 129.96 s\n",
      "2024-11-25 22:55:06.629878: Yayy! New best EMA pseudo Dice: 0.6668\n",
      "2024-11-25 22:55:07.989908: \n",
      "2024-11-25 22:55:07.999906: Epoch 41\n",
      "2024-11-25 22:55:07.999906: Current learning rate: 0.00926\n",
      "2024-11-25 22:57:17.872672: train_loss -0.5004\n",
      "2024-11-25 22:57:17.882672: val_loss -0.2765\n",
      "2024-11-25 22:57:17.892672: Pseudo dice [0.6539]\n",
      "2024-11-25 22:57:17.892672: Epoch time: 129.88 s\n",
      "2024-11-25 22:57:18.962200: \n",
      "2024-11-25 22:57:18.972201: Epoch 42\n",
      "2024-11-25 22:57:18.972201: Current learning rate: 0.00924\n",
      "2024-11-25 22:59:28.878593: train_loss -0.5621\n",
      "2024-11-25 22:59:28.888593: val_loss -0.2365\n",
      "2024-11-25 22:59:28.898594: Pseudo dice [0.6683]\n",
      "2024-11-25 22:59:28.898594: Epoch time: 129.92 s\n",
      "2024-11-25 22:59:30.078620: \n",
      "2024-11-25 22:59:30.088620: Epoch 43\n",
      "2024-11-25 22:59:30.098620: Current learning rate: 0.00922\n",
      "2024-11-25 23:01:39.953427: train_loss -0.5619\n",
      "2024-11-25 23:01:39.963428: val_loss -0.1498\n",
      "2024-11-25 23:01:39.963428: Pseudo dice [0.5753]\n",
      "2024-11-25 23:01:39.973428: Epoch time: 129.87 s\n",
      "2024-11-25 23:01:41.003451: \n",
      "2024-11-25 23:01:41.013451: Epoch 44\n",
      "2024-11-25 23:01:41.013451: Current learning rate: 0.0092\n",
      "2024-11-25 23:03:50.879602: train_loss -0.5799\n",
      "2024-11-25 23:03:50.889602: val_loss -0.4671\n",
      "2024-11-25 23:03:50.899603: Pseudo dice [0.7198]\n",
      "2024-11-25 23:03:50.909603: Epoch time: 129.88 s\n",
      "2024-11-25 23:03:51.979628: \n",
      "2024-11-25 23:03:51.989628: Epoch 45\n",
      "2024-11-25 23:03:51.989628: Current learning rate: 0.00919\n",
      "2024-11-25 23:06:01.793760: train_loss -0.5475\n",
      "2024-11-25 23:06:01.803760: val_loss -0.4345\n",
      "2024-11-25 23:06:01.813761: Pseudo dice [0.7308]\n",
      "2024-11-25 23:06:01.813761: Epoch time: 129.81 s\n",
      "2024-11-25 23:06:01.823760: Yayy! New best EMA pseudo Dice: 0.6698\n",
      "2024-11-25 23:06:03.163790: \n",
      "2024-11-25 23:06:03.163790: Epoch 46\n",
      "2024-11-25 23:06:03.173790: Current learning rate: 0.00917\n",
      "2024-11-25 23:08:12.957989: train_loss -0.5323\n",
      "2024-11-25 23:08:12.967990: val_loss -0.1765\n",
      "2024-11-25 23:08:12.967990: Pseudo dice [0.5882]\n",
      "2024-11-25 23:08:12.977990: Epoch time: 129.79 s\n",
      "2024-11-25 23:08:14.068005: \n",
      "2024-11-25 23:08:14.078006: Epoch 47\n",
      "2024-11-25 23:08:14.078006: Current learning rate: 0.00915\n",
      "2024-11-25 23:10:23.804251: train_loss -0.5628\n",
      "2024-11-25 23:10:23.814251: val_loss -0.3374\n",
      "2024-11-25 23:10:23.814251: Pseudo dice [0.6781]\n",
      "2024-11-25 23:10:23.824252: Epoch time: 129.74 s\n",
      "2024-11-25 23:10:24.914277: \n",
      "2024-11-25 23:10:24.924277: Epoch 48\n",
      "2024-11-25 23:10:24.924277: Current learning rate: 0.00913\n",
      "2024-11-25 23:12:34.881026: train_loss -0.5947\n",
      "2024-11-25 23:12:34.891026: val_loss -0.3319\n",
      "2024-11-25 23:12:34.901026: Pseudo dice [0.6757]\n",
      "2024-11-25 23:12:34.911027: Epoch time: 129.97 s\n",
      "2024-11-25 23:12:36.021052: \n",
      "2024-11-25 23:12:36.031053: Epoch 49\n",
      "2024-11-25 23:12:36.041053: Current learning rate: 0.00911\n",
      "2024-11-25 23:14:45.822152: train_loss -0.5438\n",
      "2024-11-25 23:14:45.832152: val_loss -0.4657\n",
      "2024-11-25 23:14:45.832152: Pseudo dice [0.7439]\n",
      "2024-11-25 23:14:45.842152: Epoch time: 129.8 s\n",
      "2024-11-25 23:14:46.102156: Yayy! New best EMA pseudo Dice: 0.6725\n",
      "2024-11-25 23:14:47.602186: \n",
      "2024-11-25 23:14:47.612187: Epoch 50\n",
      "2024-11-25 23:14:47.612187: Current learning rate: 0.0091\n",
      "2024-11-25 23:16:57.477097: train_loss -0.6253\n",
      "2024-11-25 23:16:57.487097: val_loss -0.3563\n",
      "2024-11-25 23:16:57.497097: Pseudo dice [0.684]\n",
      "2024-11-25 23:16:57.497097: Epoch time: 129.87 s\n",
      "2024-11-25 23:16:57.507097: Yayy! New best EMA pseudo Dice: 0.6737\n",
      "2024-11-25 23:16:58.877117: \n",
      "2024-11-25 23:16:58.887117: Epoch 51\n",
      "2024-11-25 23:16:58.887117: Current learning rate: 0.00908\n",
      "2024-11-25 23:19:08.768108: train_loss -0.6009\n",
      "2024-11-25 23:19:08.778109: val_loss -0.3097\n",
      "2024-11-25 23:19:08.788109: Pseudo dice [0.6527]\n",
      "2024-11-25 23:19:08.788109: Epoch time: 129.89 s\n",
      "2024-11-25 23:19:09.908134: \n",
      "2024-11-25 23:19:09.918134: Epoch 52\n",
      "2024-11-25 23:19:09.918134: Current learning rate: 0.00906\n",
      "2024-11-25 23:21:19.753097: train_loss -0.6352\n",
      "2024-11-25 23:21:19.763097: val_loss -0.3058\n",
      "2024-11-25 23:21:19.763097: Pseudo dice [0.6742]\n",
      "2024-11-25 23:21:19.773098: Epoch time: 129.84 s\n",
      "2024-11-25 23:21:20.884167: \n",
      "2024-11-25 23:21:20.884167: Epoch 53\n",
      "2024-11-25 23:21:20.894168: Current learning rate: 0.00904\n",
      "2024-11-25 23:23:30.668036: train_loss -0.6579\n",
      "2024-11-25 23:23:30.678036: val_loss -0.5119\n",
      "2024-11-25 23:23:30.688037: Pseudo dice [0.7608]\n",
      "2024-11-25 23:23:30.698037: Epoch time: 129.78 s\n",
      "2024-11-25 23:23:30.698037: Yayy! New best EMA pseudo Dice: 0.6807\n",
      "2024-11-25 23:23:31.998065: \n",
      "2024-11-25 23:23:31.998065: Epoch 54\n",
      "2024-11-25 23:23:32.008054: Current learning rate: 0.00902\n",
      "2024-11-25 23:25:41.813940: train_loss -0.5868\n",
      "2024-11-25 23:25:41.813940: val_loss -0.2981\n",
      "2024-11-25 23:25:41.823940: Pseudo dice [0.6556]\n",
      "2024-11-25 23:25:41.833940: Epoch time: 129.83 s\n",
      "2024-11-25 23:25:42.854170: \n",
      "2024-11-25 23:25:42.854170: Epoch 55\n",
      "2024-11-25 23:25:42.864171: Current learning rate: 0.009\n",
      "2024-11-25 23:27:52.783474: train_loss -0.5416\n",
      "2024-11-25 23:27:52.793475: val_loss -0.3662\n",
      "2024-11-25 23:27:52.793475: Pseudo dice [0.683]\n",
      "2024-11-25 23:27:52.803475: Epoch time: 129.94 s\n",
      "2024-11-25 23:27:53.873995: \n",
      "2024-11-25 23:27:53.873995: Epoch 56\n",
      "2024-11-25 23:27:53.883995: Current learning rate: 0.00899\n",
      "2024-11-25 23:30:03.314825: train_loss -0.6237\n",
      "2024-11-25 23:30:03.324825: val_loss -0.3884\n",
      "2024-11-25 23:30:03.324825: Pseudo dice [0.6976]\n",
      "2024-11-25 23:30:03.334825: Epoch time: 129.45 s\n",
      "2024-11-25 23:30:04.414850: \n",
      "2024-11-25 23:30:04.424851: Epoch 57\n",
      "2024-11-25 23:30:04.424851: Current learning rate: 0.00897\n",
      "2024-11-25 23:32:13.747119: train_loss -0.5988\n",
      "2024-11-25 23:32:13.757119: val_loss -0.4812\n",
      "2024-11-25 23:32:13.767120: Pseudo dice [0.7477]\n",
      "2024-11-25 23:32:13.767120: Epoch time: 129.33 s\n",
      "2024-11-25 23:32:13.777120: Yayy! New best EMA pseudo Dice: 0.6873\n",
      "2024-11-25 23:32:15.197148: \n",
      "2024-11-25 23:32:15.207149: Epoch 58\n",
      "2024-11-25 23:32:15.207149: Current learning rate: 0.00895\n",
      "2024-11-25 23:34:24.515369: train_loss -0.5878\n",
      "2024-11-25 23:34:24.525369: val_loss -0.3491\n",
      "2024-11-25 23:34:24.525369: Pseudo dice [0.6781]\n",
      "2024-11-25 23:34:24.525369: Epoch time: 129.32 s\n",
      "2024-11-25 23:34:25.545392: \n",
      "2024-11-25 23:34:25.555393: Epoch 59\n",
      "2024-11-25 23:34:25.555393: Current learning rate: 0.00893\n",
      "2024-11-25 23:36:35.050498: train_loss -0.5915\n",
      "2024-11-25 23:36:35.060498: val_loss -0.4628\n",
      "2024-11-25 23:36:35.070498: Pseudo dice [0.7533]\n",
      "2024-11-25 23:36:35.070498: Epoch time: 129.51 s\n",
      "2024-11-25 23:36:35.080498: Yayy! New best EMA pseudo Dice: 0.6931\n",
      "2024-11-25 23:36:36.291722: \n",
      "2024-11-25 23:36:36.301722: Epoch 60\n",
      "2024-11-25 23:36:36.301722: Current learning rate: 0.00891\n",
      "2024-11-25 23:38:45.608261: train_loss -0.56\n",
      "2024-11-25 23:38:45.618262: val_loss -0.4538\n",
      "2024-11-25 23:38:45.628262: Pseudo dice [0.7306]\n",
      "2024-11-25 23:38:45.628262: Epoch time: 129.32 s\n",
      "2024-11-25 23:38:45.638262: Yayy! New best EMA pseudo Dice: 0.6968\n",
      "2024-11-25 23:38:46.858287: \n",
      "2024-11-25 23:38:46.858287: Epoch 61\n",
      "2024-11-25 23:38:46.868287: Current learning rate: 0.00889\n",
      "2024-11-25 23:40:56.117472: train_loss -0.6198\n",
      "2024-11-25 23:40:56.127472: val_loss -0.4332\n",
      "2024-11-25 23:40:56.137472: Pseudo dice [0.7271]\n",
      "2024-11-25 23:40:56.137472: Epoch time: 129.26 s\n",
      "2024-11-25 23:40:56.147472: Yayy! New best EMA pseudo Dice: 0.6998\n",
      "2024-11-25 23:40:57.358429: \n",
      "2024-11-25 23:40:57.368428: Epoch 62\n",
      "2024-11-25 23:40:57.368428: Current learning rate: 0.00888\n",
      "2024-11-25 23:43:06.632174: train_loss -0.636\n",
      "2024-11-25 23:43:06.642174: val_loss 0.0737\n",
      "2024-11-25 23:43:06.652174: Pseudo dice [0.4455]\n",
      "2024-11-25 23:43:06.652174: Epoch time: 129.27 s\n",
      "2024-11-25 23:43:07.633125: \n",
      "2024-11-25 23:43:07.643125: Epoch 63\n",
      "2024-11-25 23:43:07.643125: Current learning rate: 0.00886\n",
      "2024-11-25 23:45:17.209625: train_loss -0.5782\n",
      "2024-11-25 23:45:17.209625: val_loss -0.4912\n",
      "2024-11-25 23:45:17.219626: Pseudo dice [0.759]\n",
      "2024-11-25 23:45:17.229626: Epoch time: 129.58 s\n",
      "2024-11-25 23:45:18.199649: \n",
      "2024-11-25 23:45:18.209649: Epoch 64\n",
      "2024-11-25 23:45:18.209649: Current learning rate: 0.00884\n",
      "2024-11-25 23:47:27.485042: train_loss -0.6431\n",
      "2024-11-25 23:47:27.495042: val_loss -0.234\n",
      "2024-11-25 23:47:27.505043: Pseudo dice [0.647]\n",
      "2024-11-25 23:47:27.505043: Epoch time: 129.29 s\n",
      "2024-11-25 23:47:28.655475: \n",
      "2024-11-25 23:47:28.665475: Epoch 65\n",
      "2024-11-25 23:47:28.665475: Current learning rate: 0.00882\n",
      "2024-11-25 23:49:37.888496: train_loss -0.6258\n",
      "2024-11-25 23:49:37.888496: val_loss -0.3689\n",
      "2024-11-25 23:49:37.898496: Pseudo dice [0.7018]\n",
      "2024-11-25 23:49:37.908496: Epoch time: 129.23 s\n",
      "2024-11-25 23:49:38.888520: \n",
      "2024-11-25 23:49:38.888520: Epoch 66\n",
      "2024-11-25 23:49:38.888520: Current learning rate: 0.0088\n",
      "2024-11-25 23:51:48.165719: train_loss -0.5975\n",
      "2024-11-25 23:51:48.175720: val_loss -0.5086\n",
      "2024-11-25 23:51:48.175720: Pseudo dice [0.7634]\n",
      "2024-11-25 23:51:48.175720: Epoch time: 129.29 s\n",
      "2024-11-25 23:51:49.165742: \n",
      "2024-11-25 23:51:49.175741: Epoch 67\n",
      "2024-11-25 23:51:49.175741: Current learning rate: 0.00879\n",
      "2024-11-25 23:53:58.731993: train_loss -0.6156\n",
      "2024-11-25 23:53:58.741993: val_loss -0.3964\n",
      "2024-11-25 23:53:58.751993: Pseudo dice [0.7463]\n",
      "2024-11-25 23:53:58.751993: Epoch time: 129.57 s\n",
      "2024-11-25 23:53:59.752016: \n",
      "2024-11-25 23:53:59.752016: Epoch 68\n",
      "2024-11-25 23:53:59.762015: Current learning rate: 0.00877\n",
      "2024-11-25 23:56:09.048006: train_loss -0.6318\n",
      "2024-11-25 23:56:09.058007: val_loss -0.4065\n",
      "2024-11-25 23:56:09.058007: Pseudo dice [0.7068]\n",
      "2024-11-25 23:56:09.068007: Epoch time: 129.31 s\n",
      "2024-11-25 23:56:10.068031: \n",
      "2024-11-25 23:56:10.068031: Epoch 69\n",
      "2024-11-25 23:56:10.078029: Current learning rate: 0.00875\n",
      "2024-11-25 23:58:19.340749: train_loss -0.6182\n",
      "2024-11-25 23:58:19.350750: val_loss -0.0158\n",
      "2024-11-25 23:58:19.360749: Pseudo dice [0.5372]\n",
      "2024-11-25 23:58:19.360749: Epoch time: 129.27 s\n",
      "2024-11-25 23:58:20.360772: \n",
      "2024-11-25 23:58:20.370771: Epoch 70\n",
      "2024-11-25 23:58:20.370771: Current learning rate: 0.00873\n",
      "2024-11-26 00:00:29.793380: train_loss -0.5975\n",
      "2024-11-26 00:00:29.803380: val_loss -0.3976\n",
      "2024-11-26 00:00:29.813380: Pseudo dice [0.6878]\n",
      "2024-11-26 00:00:29.813380: Epoch time: 129.43 s\n",
      "2024-11-26 00:00:30.823403: \n",
      "2024-11-26 00:00:30.823403: Epoch 71\n",
      "2024-11-26 00:00:30.833403: Current learning rate: 0.00871\n",
      "2024-11-26 00:02:40.067342: train_loss -0.6087\n",
      "2024-11-26 00:02:40.077342: val_loss -0.4148\n",
      "2024-11-26 00:02:40.087342: Pseudo dice [0.7355]\n",
      "2024-11-26 00:02:40.087342: Epoch time: 129.25 s\n",
      "2024-11-26 00:02:41.257367: \n",
      "2024-11-26 00:02:41.257367: Epoch 72\n",
      "2024-11-26 00:02:41.267368: Current learning rate: 0.00869\n",
      "2024-11-26 00:04:50.492287: train_loss -0.5575\n",
      "2024-11-26 00:04:50.502288: val_loss -0.4535\n",
      "2024-11-26 00:04:50.512288: Pseudo dice [0.7542]\n",
      "2024-11-26 00:04:50.512288: Epoch time: 129.23 s\n",
      "2024-11-26 00:04:51.512311: \n",
      "2024-11-26 00:04:51.522311: Epoch 73\n",
      "2024-11-26 00:04:51.522311: Current learning rate: 0.00868\n",
      "2024-11-26 00:07:00.748422: train_loss -0.5638\n",
      "2024-11-26 00:07:00.758422: val_loss -0.3234\n",
      "2024-11-26 00:07:00.758422: Pseudo dice [0.7075]\n",
      "2024-11-26 00:07:00.768422: Epoch time: 129.24 s\n",
      "2024-11-26 00:07:01.768446: \n",
      "2024-11-26 00:07:01.778445: Epoch 74\n",
      "2024-11-26 00:07:01.778445: Current learning rate: 0.00866\n",
      "2024-11-26 00:09:11.123477: train_loss -0.5824\n",
      "2024-11-26 00:09:11.133478: val_loss -0.2522\n",
      "2024-11-26 00:09:11.133478: Pseudo dice [0.6264]\n",
      "2024-11-26 00:09:11.143478: Epoch time: 129.36 s\n",
      "2024-11-26 00:09:12.153852: \n",
      "2024-11-26 00:09:12.163851: Epoch 75\n",
      "2024-11-26 00:09:12.163851: Current learning rate: 0.00864\n",
      "2024-11-26 00:11:21.381121: train_loss -0.6272\n",
      "2024-11-26 00:11:21.391122: val_loss -0.1896\n",
      "2024-11-26 00:11:21.391122: Pseudo dice [0.6496]\n",
      "2024-11-26 00:11:21.401122: Epoch time: 129.23 s\n",
      "2024-11-26 00:11:22.401437: \n",
      "2024-11-26 00:11:22.401437: Epoch 76\n",
      "2024-11-26 00:11:22.411437: Current learning rate: 0.00862\n",
      "2024-11-26 00:13:31.658244: train_loss -0.639\n",
      "2024-11-26 00:13:31.668244: val_loss -0.4188\n",
      "2024-11-26 00:13:31.668244: Pseudo dice [0.7097]\n",
      "2024-11-26 00:13:31.678245: Epoch time: 129.26 s\n",
      "2024-11-26 00:13:32.679251: \n",
      "2024-11-26 00:13:32.679251: Epoch 77\n",
      "2024-11-26 00:13:32.689250: Current learning rate: 0.0086\n",
      "2024-11-26 00:15:41.965152: train_loss -0.6199\n",
      "2024-11-26 00:15:41.975152: val_loss -0.2133\n",
      "2024-11-26 00:15:41.985152: Pseudo dice [0.5875]\n",
      "2024-11-26 00:15:41.995152: Epoch time: 129.29 s\n",
      "2024-11-26 00:15:43.005176: \n",
      "2024-11-26 00:15:43.015175: Epoch 78\n",
      "2024-11-26 00:15:43.015175: Current learning rate: 0.00858\n",
      "2024-11-26 00:17:52.357125: train_loss -0.6142\n",
      "2024-11-26 00:17:52.367125: val_loss -0.4146\n",
      "2024-11-26 00:17:52.367125: Pseudo dice [0.7007]\n",
      "2024-11-26 00:17:52.377125: Epoch time: 129.35 s\n",
      "2024-11-26 00:17:53.567445: \n",
      "2024-11-26 00:17:53.567445: Epoch 79\n",
      "2024-11-26 00:17:53.577444: Current learning rate: 0.00857\n",
      "2024-11-26 00:20:02.852529: train_loss -0.6116\n",
      "2024-11-26 00:20:02.862529: val_loss -0.4976\n",
      "2024-11-26 00:20:02.872529: Pseudo dice [0.7581]\n",
      "2024-11-26 00:20:02.882529: Epoch time: 129.29 s\n",
      "2024-11-26 00:20:03.892551: \n",
      "2024-11-26 00:20:03.902551: Epoch 80\n",
      "2024-11-26 00:20:03.902551: Current learning rate: 0.00855\n",
      "2024-11-26 00:22:14.664525: train_loss -0.646\n",
      "2024-11-26 00:22:14.675999: val_loss -0.3371\n",
      "2024-11-26 00:22:14.682000: Pseudo dice [0.706]\n",
      "2024-11-26 00:22:14.684477: Epoch time: 130.77 s\n",
      "2024-11-26 00:22:15.739262: \n",
      "2024-11-26 00:22:15.745273: Epoch 81\n",
      "2024-11-26 00:22:15.750273: Current learning rate: 0.00853\n",
      "2024-11-26 00:24:29.657944: train_loss -0.651\n",
      "2024-11-26 00:24:29.664811: val_loss -0.3129\n",
      "2024-11-26 00:24:29.674809: Pseudo dice [0.6832]\n",
      "2024-11-26 00:24:29.681647: Epoch time: 133.92 s\n",
      "2024-11-26 00:24:30.714753: \n",
      "2024-11-26 00:24:30.714753: Epoch 82\n",
      "2024-11-26 00:24:30.724752: Current learning rate: 0.00851\n",
      "2024-11-26 00:26:44.613499: train_loss -0.6551\n",
      "2024-11-26 00:26:44.623526: val_loss -0.3453\n",
      "2024-11-26 00:26:44.630423: Pseudo dice [0.6813]\n",
      "2024-11-26 00:26:44.630423: Epoch time: 133.9 s\n",
      "2024-11-26 00:26:45.613330: \n",
      "2024-11-26 00:26:45.623351: Epoch 83\n",
      "2024-11-26 00:26:45.629928: Current learning rate: 0.00849\n",
      "2024-11-26 00:28:59.558660: train_loss -0.639\n",
      "2024-11-26 00:28:59.568659: val_loss -0.2771\n",
      "2024-11-26 00:28:59.575049: Pseudo dice [0.6535]\n",
      "2024-11-26 00:28:59.575049: Epoch time: 133.95 s\n",
      "2024-11-26 00:29:00.575068: \n",
      "2024-11-26 00:29:00.575068: Epoch 84\n",
      "2024-11-26 00:29:00.585067: Current learning rate: 0.00847\n",
      "2024-11-26 00:31:14.922094: train_loss -0.6348\n",
      "2024-11-26 00:31:14.940759: val_loss -0.3156\n",
      "2024-11-26 00:31:14.950777: Pseudo dice [0.6991]\n",
      "2024-11-26 00:31:14.957389: Epoch time: 134.35 s\n",
      "2024-11-26 00:31:16.131893: \n",
      "2024-11-26 00:31:16.138493: Epoch 85\n",
      "2024-11-26 00:31:16.138493: Current learning rate: 0.00846\n",
      "2024-11-26 00:33:30.078985: train_loss -0.6556\n",
      "2024-11-26 00:33:30.085319: val_loss -0.451\n",
      "2024-11-26 00:33:30.095318: Pseudo dice [0.7171]\n",
      "2024-11-26 00:33:30.101893: Epoch time: 133.95 s\n",
      "2024-11-26 00:33:31.085354: \n",
      "2024-11-26 00:33:31.095353: Epoch 86\n",
      "2024-11-26 00:33:31.101998: Current learning rate: 0.00844\n",
      "2024-11-26 00:35:45.060753: train_loss -0.5878\n",
      "2024-11-26 00:35:45.067654: val_loss -0.3678\n",
      "2024-11-26 00:35:45.077694: Pseudo dice [0.7192]\n",
      "2024-11-26 00:35:45.084009: Epoch time: 133.98 s\n",
      "2024-11-26 00:35:46.077068: \n",
      "2024-11-26 00:35:46.083592: Epoch 87\n",
      "2024-11-26 00:35:46.083744: Current learning rate: 0.00842\n",
      "2024-11-26 00:37:58.675736: train_loss -0.6378\n",
      "2024-11-26 00:37:58.685736: val_loss -0.3519\n",
      "2024-11-26 00:37:58.685736: Pseudo dice [0.7023]\n",
      "2024-11-26 00:37:58.695737: Epoch time: 132.61 s\n",
      "2024-11-26 00:37:59.664485: \n",
      "2024-11-26 00:37:59.671486: Epoch 88\n",
      "2024-11-26 00:37:59.682115: Current learning rate: 0.0084\n",
      "2024-11-26 00:40:10.928037: train_loss -0.6277\n",
      "2024-11-26 00:40:10.938060: val_loss -0.4921\n",
      "2024-11-26 00:40:10.943515: Pseudo dice [0.7546]\n",
      "2024-11-26 00:40:10.944502: Epoch time: 131.26 s\n",
      "2024-11-26 00:40:11.909508: \n",
      "2024-11-26 00:40:11.910362: Epoch 89\n",
      "2024-11-26 00:40:11.920379: Current learning rate: 0.00838\n",
      "2024-11-26 00:42:23.124112: train_loss -0.6764\n",
      "2024-11-26 00:42:23.134153: val_loss -0.4974\n",
      "2024-11-26 00:42:23.140376: Pseudo dice [0.7416]\n",
      "2024-11-26 00:42:23.141675: Epoch time: 131.22 s\n",
      "2024-11-26 00:42:23.151703: Yayy! New best EMA pseudo Dice: 0.7034\n",
      "2024-11-26 00:42:24.361866: \n",
      "2024-11-26 00:42:24.368868: Epoch 90\n",
      "2024-11-26 00:42:24.372706: Current learning rate: 0.00836\n",
      "2024-11-26 00:44:35.576235: train_loss -0.6366\n",
      "2024-11-26 00:44:35.586235: val_loss -0.2371\n",
      "2024-11-26 00:44:35.596236: Pseudo dice [0.6349]\n",
      "2024-11-26 00:44:35.596236: Epoch time: 131.22 s\n",
      "2024-11-26 00:44:36.566108: \n",
      "2024-11-26 00:44:36.576108: Epoch 91\n",
      "2024-11-26 00:44:36.576108: Current learning rate: 0.00835\n",
      "2024-11-26 00:46:47.811097: train_loss -0.6714\n",
      "2024-11-26 00:46:47.818438: val_loss -0.4353\n",
      "2024-11-26 00:46:47.828479: Pseudo dice [0.7256]\n",
      "2024-11-26 00:46:47.834719: Epoch time: 131.24 s\n",
      "2024-11-26 00:46:48.801710: \n",
      "2024-11-26 00:46:48.801710: Epoch 92\n",
      "2024-11-26 00:46:48.811709: Current learning rate: 0.00833\n",
      "2024-11-26 00:49:00.147855: train_loss -0.6328\n",
      "2024-11-26 00:49:00.157884: val_loss -0.5119\n",
      "2024-11-26 00:49:00.164730: Pseudo dice [0.7777]\n",
      "2024-11-26 00:49:00.164730: Epoch time: 131.35 s\n",
      "2024-11-26 00:49:00.164730: Yayy! New best EMA pseudo Dice: 0.7073\n",
      "2024-11-26 00:49:01.564409: \n",
      "2024-11-26 00:49:01.574445: Epoch 93\n",
      "2024-11-26 00:49:01.581119: Current learning rate: 0.00831\n",
      "2024-11-26 00:51:12.810040: train_loss -0.6602\n",
      "2024-11-26 00:51:12.820042: val_loss -0.3394\n",
      "2024-11-26 00:51:12.820042: Pseudo dice [0.6476]\n",
      "2024-11-26 00:51:12.830041: Epoch time: 131.25 s\n",
      "2024-11-26 00:51:13.783346: \n",
      "2024-11-26 00:51:13.793345: Epoch 94\n",
      "2024-11-26 00:51:13.803346: Current learning rate: 0.00829\n",
      "2024-11-26 00:53:25.050239: train_loss -0.6509\n",
      "2024-11-26 00:53:25.060239: val_loss -0.5243\n",
      "2024-11-26 00:53:25.070240: Pseudo dice [0.7667]\n",
      "2024-11-26 00:53:25.070240: Epoch time: 131.27 s\n",
      "2024-11-26 00:53:25.080240: Yayy! New best EMA pseudo Dice: 0.7078\n",
      "2024-11-26 00:53:26.292309: \n",
      "2024-11-26 00:53:26.292309: Epoch 95\n",
      "2024-11-26 00:53:26.302327: Current learning rate: 0.00827\n",
      "2024-11-26 00:55:37.503922: train_loss -0.6943\n",
      "2024-11-26 00:55:37.520399: val_loss -0.4623\n",
      "2024-11-26 00:55:37.520399: Pseudo dice [0.7373]\n",
      "2024-11-26 00:55:37.530416: Epoch time: 131.21 s\n",
      "2024-11-26 00:55:37.537142: Yayy! New best EMA pseudo Dice: 0.7108\n",
      "2024-11-26 00:55:38.747117: \n",
      "2024-11-26 00:55:38.747117: Epoch 96\n",
      "2024-11-26 00:55:38.757118: Current learning rate: 0.00825\n",
      "2024-11-26 00:57:49.997278: train_loss -0.6558\n",
      "2024-11-26 00:57:50.007279: val_loss -0.3626\n",
      "2024-11-26 00:57:50.017341: Pseudo dice [0.6927]\n",
      "2024-11-26 00:57:50.027387: Epoch time: 131.26 s\n",
      "2024-11-26 00:57:51.010696: \n",
      "2024-11-26 00:57:51.020696: Epoch 97\n",
      "2024-11-26 00:57:51.020696: Current learning rate: 0.00824\n",
      "2024-11-26 01:00:02.314174: train_loss -0.6831\n",
      "2024-11-26 01:00:02.324174: val_loss -0.4172\n",
      "2024-11-26 01:00:02.334174: Pseudo dice [0.724]\n",
      "2024-11-26 01:00:02.344175: Epoch time: 131.3 s\n",
      "2024-11-26 01:00:03.314199: \n",
      "2024-11-26 01:00:03.326484: Epoch 98\n",
      "2024-11-26 01:00:03.330755: Current learning rate: 0.00822\n",
      "2024-11-26 01:02:14.579404: train_loss -0.6744\n",
      "2024-11-26 01:02:14.594417: val_loss -0.4762\n",
      "2024-11-26 01:02:14.596829: Pseudo dice [0.7543]\n",
      "2024-11-26 01:02:14.606868: Epoch time: 131.27 s\n",
      "2024-11-26 01:02:14.615511: Yayy! New best EMA pseudo Dice: 0.7149\n",
      "2024-11-26 01:02:15.837721: \n",
      "2024-11-26 01:02:15.837721: Epoch 99\n",
      "2024-11-26 01:02:15.847721: Current learning rate: 0.0082\n",
      "2024-11-26 01:04:27.163859: train_loss -0.6606\n",
      "2024-11-26 01:04:27.172862: val_loss -0.5285\n",
      "2024-11-26 01:04:27.179555: Pseudo dice [0.7676]\n",
      "2024-11-26 01:04:27.186557: Epoch time: 131.34 s\n",
      "2024-11-26 01:04:27.419251: Yayy! New best EMA pseudo Dice: 0.7201\n",
      "2024-11-26 01:04:28.860621: \n",
      "2024-11-26 01:04:28.870621: Epoch 100\n",
      "2024-11-26 01:04:28.870621: Current learning rate: 0.00818\n",
      "2024-11-26 01:06:40.202344: train_loss -0.6957\n",
      "2024-11-26 01:06:40.212344: val_loss -0.34\n",
      "2024-11-26 01:06:40.222344: Pseudo dice [0.6754]\n",
      "2024-11-26 01:06:40.222344: Epoch time: 131.34 s\n",
      "2024-11-26 01:06:41.207227: \n",
      "2024-11-26 01:06:41.217275: Epoch 101\n",
      "2024-11-26 01:06:41.222499: Current learning rate: 0.00816\n",
      "2024-11-26 01:08:52.471593: train_loss -0.6551\n",
      "2024-11-26 01:08:52.484924: val_loss -0.4254\n",
      "2024-11-26 01:08:52.484924: Pseudo dice [0.7321]\n",
      "2024-11-26 01:08:52.494940: Epoch time: 131.27 s\n",
      "2024-11-26 01:08:53.484908: \n",
      "2024-11-26 01:08:53.484908: Epoch 102\n",
      "2024-11-26 01:08:53.494906: Current learning rate: 0.00814\n",
      "2024-11-26 01:11:04.748509: train_loss -0.6525\n",
      "2024-11-26 01:11:04.758508: val_loss -0.4497\n",
      "2024-11-26 01:11:04.768510: Pseudo dice [0.7305]\n",
      "2024-11-26 01:11:04.768510: Epoch time: 131.26 s\n",
      "2024-11-26 01:11:05.767603: \n",
      "2024-11-26 01:11:05.783801: Epoch 103\n",
      "2024-11-26 01:11:05.783801: Current learning rate: 0.00813\n",
      "2024-11-26 01:13:17.045359: train_loss -0.6516\n",
      "2024-11-26 01:13:17.055358: val_loss -0.5082\n",
      "2024-11-26 01:13:17.065359: Pseudo dice [0.7534]\n",
      "2024-11-26 01:13:17.075359: Epoch time: 131.28 s\n",
      "2024-11-26 01:13:17.075359: Yayy! New best EMA pseudo Dice: 0.7221\n",
      "2024-11-26 01:13:18.314065: \n",
      "2024-11-26 01:13:18.314065: Epoch 104\n",
      "2024-11-26 01:13:18.324361: Current learning rate: 0.00811\n",
      "2024-11-26 01:15:29.520405: train_loss -0.6562\n",
      "2024-11-26 01:15:29.528643: val_loss -0.4894\n",
      "2024-11-26 01:15:29.538673: Pseudo dice [0.7606]\n",
      "2024-11-26 01:15:29.546278: Epoch time: 131.21 s\n",
      "2024-11-26 01:15:29.550935: Yayy! New best EMA pseudo Dice: 0.726\n",
      "2024-11-26 01:15:30.776754: \n",
      "2024-11-26 01:15:30.792201: Epoch 105\n",
      "2024-11-26 01:15:30.793524: Current learning rate: 0.00809\n",
      "2024-11-26 01:17:42.024942: train_loss -0.6934\n",
      "2024-11-26 01:17:42.024942: val_loss -0.511\n",
      "2024-11-26 01:17:42.041704: Pseudo dice [0.7742]\n",
      "2024-11-26 01:17:42.041704: Epoch time: 131.25 s\n",
      "2024-11-26 01:17:42.051722: Yayy! New best EMA pseudo Dice: 0.7308\n",
      "2024-11-26 01:17:43.295897: \n",
      "2024-11-26 01:17:43.301899: Epoch 106\n",
      "2024-11-26 01:17:43.307709: Current learning rate: 0.00807\n",
      "2024-11-26 01:19:54.539327: train_loss -0.6496\n",
      "2024-11-26 01:19:54.549327: val_loss -0.3474\n",
      "2024-11-26 01:19:54.559326: Pseudo dice [0.677]\n",
      "2024-11-26 01:19:54.569326: Epoch time: 131.24 s\n",
      "2024-11-26 01:19:55.759177: \n",
      "2024-11-26 01:19:55.769178: Epoch 107\n",
      "2024-11-26 01:19:55.769178: Current learning rate: 0.00805\n",
      "2024-11-26 01:22:06.982872: train_loss -0.6839\n",
      "2024-11-26 01:22:06.992872: val_loss -0.5276\n",
      "2024-11-26 01:22:06.992872: Pseudo dice [0.7611]\n",
      "2024-11-26 01:22:07.002874: Epoch time: 131.22 s\n",
      "2024-11-26 01:22:07.979410: \n",
      "2024-11-26 01:22:07.989410: Epoch 108\n",
      "2024-11-26 01:22:07.989410: Current learning rate: 0.00803\n",
      "2024-11-26 01:24:19.231217: train_loss -0.7164\n",
      "2024-11-26 01:24:19.240761: val_loss -0.5027\n",
      "2024-11-26 01:24:19.250412: Pseudo dice [0.7526]\n",
      "2024-11-26 01:24:19.258414: Epoch time: 131.25 s\n",
      "2024-11-26 01:24:19.265137: Yayy! New best EMA pseudo Dice: 0.7313\n",
      "2024-11-26 01:24:20.496281: \n",
      "2024-11-26 01:24:20.506281: Epoch 109\n",
      "2024-11-26 01:24:20.506281: Current learning rate: 0.00801\n",
      "2024-11-26 01:26:31.753271: train_loss -0.6765\n",
      "2024-11-26 01:26:31.753271: val_loss -0.3505\n",
      "2024-11-26 01:26:31.763272: Pseudo dice [0.6882]\n",
      "2024-11-26 01:26:31.773272: Epoch time: 131.26 s\n",
      "2024-11-26 01:26:32.756459: \n",
      "2024-11-26 01:26:32.766460: Epoch 110\n",
      "2024-11-26 01:26:32.766460: Current learning rate: 0.008\n",
      "2024-11-26 01:28:43.963220: train_loss -0.6629\n",
      "2024-11-26 01:28:43.979238: val_loss -0.4647\n",
      "2024-11-26 01:28:43.985239: Pseudo dice [0.7458]\n",
      "2024-11-26 01:28:43.991058: Epoch time: 131.21 s\n",
      "2024-11-26 01:28:44.991879: \n",
      "2024-11-26 01:28:45.006708: Epoch 111\n",
      "2024-11-26 01:28:45.009307: Current learning rate: 0.00798\n",
      "2024-11-26 01:30:56.293278: train_loss -0.6721\n",
      "2024-11-26 01:30:56.301280: val_loss -0.1994\n",
      "2024-11-26 01:30:56.310312: Pseudo dice [0.6517]\n",
      "2024-11-26 01:30:56.315312: Epoch time: 131.3 s\n",
      "2024-11-26 01:30:57.297180: \n",
      "2024-11-26 01:30:57.304181: Epoch 112\n",
      "2024-11-26 01:30:57.308228: Current learning rate: 0.00796\n",
      "2024-11-26 01:33:06.629189: train_loss -0.6922\n",
      "2024-11-26 01:33:06.636694: val_loss -0.4412\n",
      "2024-11-26 01:33:06.641694: Pseudo dice [0.713]\n",
      "2024-11-26 01:33:06.648696: Epoch time: 129.33 s\n",
      "2024-11-26 01:33:07.623871: \n",
      "2024-11-26 01:33:07.630873: Epoch 113\n",
      "2024-11-26 01:33:07.635355: Current learning rate: 0.00794\n",
      "2024-11-26 01:35:17.010322: train_loss -0.6949\n",
      "2024-11-26 01:35:17.020034: val_loss -0.5588\n",
      "2024-11-26 01:35:17.025034: Pseudo dice [0.7887]\n",
      "2024-11-26 01:35:17.031672: Epoch time: 129.39 s\n",
      "2024-11-26 01:35:18.179959: \n",
      "2024-11-26 01:35:18.186493: Epoch 114\n",
      "2024-11-26 01:35:18.190493: Current learning rate: 0.00792\n",
      "2024-11-26 01:37:27.483700: train_loss -0.6704\n",
      "2024-11-26 01:37:27.492701: val_loss -0.4677\n",
      "2024-11-26 01:37:27.499310: Pseudo dice [0.73]\n",
      "2024-11-26 01:37:27.503311: Epoch time: 129.3 s\n",
      "2024-11-26 01:37:28.469867: \n",
      "2024-11-26 01:37:28.475869: Epoch 115\n",
      "2024-11-26 01:37:28.480059: Current learning rate: 0.0079\n",
      "2024-11-26 01:39:37.796176: train_loss -0.7228\n",
      "2024-11-26 01:39:37.804178: val_loss -0.4659\n",
      "2024-11-26 01:39:37.809919: Pseudo dice [0.7381]\n",
      "2024-11-26 01:39:37.815920: Epoch time: 129.33 s\n",
      "2024-11-26 01:39:38.817681: \n",
      "2024-11-26 01:39:38.828651: Epoch 116\n",
      "2024-11-26 01:39:38.831652: Current learning rate: 0.00789\n",
      "2024-11-26 01:41:48.226904: train_loss -0.7021\n",
      "2024-11-26 01:41:48.226904: val_loss -0.5096\n",
      "2024-11-26 01:41:48.236903: Pseudo dice [0.764]\n",
      "2024-11-26 01:41:48.246904: Epoch time: 129.41 s\n",
      "2024-11-26 01:41:48.253280: Yayy! New best EMA pseudo Dice: 0.7321\n",
      "2024-11-26 01:41:49.526460: \n",
      "2024-11-26 01:41:49.533581: Epoch 117\n",
      "2024-11-26 01:41:49.538582: Current learning rate: 0.00787\n",
      "2024-11-26 01:44:01.592589: train_loss -0.7239\n",
      "2024-11-26 01:44:01.602160: val_loss -0.4905\n",
      "2024-11-26 01:44:01.608666: Pseudo dice [0.7442]\n",
      "2024-11-26 01:44:01.616201: Epoch time: 132.07 s\n",
      "2024-11-26 01:44:01.621203: Yayy! New best EMA pseudo Dice: 0.7333\n",
      "2024-11-26 01:44:02.856026: \n",
      "2024-11-26 01:44:02.863026: Epoch 118\n",
      "2024-11-26 01:44:02.867541: Current learning rate: 0.00785\n",
      "2024-11-26 01:46:14.471012: train_loss -0.6678\n",
      "2024-11-26 01:46:14.478517: val_loss -0.427\n",
      "2024-11-26 01:46:14.484351: Pseudo dice [0.704]\n",
      "2024-11-26 01:46:14.490433: Epoch time: 131.62 s\n",
      "2024-11-26 01:46:15.486623: \n",
      "2024-11-26 01:46:15.493133: Epoch 119\n",
      "2024-11-26 01:46:15.498135: Current learning rate: 0.00783\n",
      "2024-11-26 01:48:29.277477: train_loss -0.6225\n",
      "2024-11-26 01:48:29.287289: val_loss -0.4987\n",
      "2024-11-26 01:48:29.293038: Pseudo dice [0.7728]\n",
      "2024-11-26 01:48:29.298039: Epoch time: 133.79 s\n",
      "2024-11-26 01:48:29.306549: Yayy! New best EMA pseudo Dice: 0.7346\n",
      "2024-11-26 01:48:30.539142: \n",
      "2024-11-26 01:48:30.547162: Epoch 120\n",
      "2024-11-26 01:48:30.552121: Current learning rate: 0.00781\n",
      "2024-11-26 01:50:43.882541: train_loss -0.6391\n",
      "2024-11-26 01:50:43.882541: val_loss -0.444\n",
      "2024-11-26 01:50:43.892541: Pseudo dice [0.7295]\n",
      "2024-11-26 01:50:43.902542: Epoch time: 133.34 s\n",
      "2024-11-26 01:50:45.072559: \n",
      "2024-11-26 01:50:45.082557: Epoch 121\n",
      "2024-11-26 01:50:45.082557: Current learning rate: 0.00779\n",
      "2024-11-26 01:52:56.751426: train_loss -0.7068\n",
      "2024-11-26 01:52:56.759942: val_loss -0.3719\n",
      "2024-11-26 01:52:56.765447: Pseudo dice [0.6854]\n",
      "2024-11-26 01:52:56.769449: Epoch time: 131.68 s\n",
      "2024-11-26 01:52:57.752476: \n",
      "2024-11-26 01:52:57.758375: Epoch 122\n",
      "2024-11-26 01:52:57.763859: Current learning rate: 0.00777\n",
      "2024-11-26 01:55:08.849426: train_loss -0.6884\n",
      "2024-11-26 01:55:08.858428: val_loss -0.5516\n",
      "2024-11-26 01:55:08.866504: Pseudo dice [0.7715]\n",
      "2024-11-26 01:55:08.871504: Epoch time: 131.1 s\n",
      "2024-11-26 01:55:09.860451: \n",
      "2024-11-26 01:55:09.867502: Epoch 123\n",
      "2024-11-26 01:55:09.871503: Current learning rate: 0.00776\n",
      "2024-11-26 01:57:19.208285: train_loss -0.6982\n",
      "2024-11-26 01:57:19.217550: val_loss -0.4658\n",
      "2024-11-26 01:57:19.225549: Pseudo dice [0.7686]\n",
      "2024-11-26 01:57:19.230550: Epoch time: 129.35 s\n",
      "2024-11-26 01:57:19.234587: Yayy! New best EMA pseudo Dice: 0.737\n",
      "2024-11-26 01:57:20.465724: \n",
      "2024-11-26 01:57:20.472726: Epoch 124\n",
      "2024-11-26 01:57:20.477728: Current learning rate: 0.00774\n",
      "2024-11-26 01:59:31.574079: train_loss -0.704\n",
      "2024-11-26 01:59:31.579770: val_loss -0.3756\n",
      "2024-11-26 01:59:31.590180: Pseudo dice [0.723]\n",
      "2024-11-26 01:59:31.596480: Epoch time: 131.11 s\n",
      "2024-11-26 01:59:32.620815: \n",
      "2024-11-26 01:59:32.628957: Epoch 125\n",
      "2024-11-26 01:59:32.634183: Current learning rate: 0.00772\n",
      "2024-11-26 02:01:42.859195: train_loss -0.6905\n",
      "2024-11-26 02:01:42.868235: val_loss -0.3246\n",
      "2024-11-26 02:01:42.875238: Pseudo dice [0.6518]\n",
      "2024-11-26 02:01:42.880239: Epoch time: 130.24 s\n",
      "2024-11-26 02:01:43.867506: \n",
      "2024-11-26 02:01:43.874508: Epoch 126\n",
      "2024-11-26 02:01:43.878509: Current learning rate: 0.0077\n",
      "2024-11-26 02:03:53.168320: train_loss -0.7319\n",
      "2024-11-26 02:03:53.176572: val_loss -0.5301\n",
      "2024-11-26 02:03:53.183648: Pseudo dice [0.7776]\n",
      "2024-11-26 02:03:53.187781: Epoch time: 129.3 s\n",
      "2024-11-26 02:03:54.167110: \n",
      "2024-11-26 02:03:54.172112: Epoch 127\n",
      "2024-11-26 02:03:54.176113: Current learning rate: 0.00768\n",
      "2024-11-26 02:06:03.466000: train_loss -0.7184\n",
      "2024-11-26 02:06:03.475002: val_loss -0.3775\n",
      "2024-11-26 02:06:03.479002: Pseudo dice [0.7036]\n",
      "2024-11-26 02:06:03.484003: Epoch time: 129.3 s\n",
      "2024-11-26 02:06:04.639686: \n",
      "2024-11-26 02:06:04.646687: Epoch 128\n",
      "2024-11-26 02:06:04.650914: Current learning rate: 0.00766\n",
      "2024-11-26 02:08:13.927912: train_loss -0.7182\n",
      "2024-11-26 02:08:13.936966: val_loss -0.496\n",
      "2024-11-26 02:08:13.944010: Pseudo dice [0.766]\n",
      "2024-11-26 02:08:13.949012: Epoch time: 129.29 s\n",
      "2024-11-26 02:08:14.935019: \n",
      "2024-11-26 02:08:14.942055: Epoch 129\n",
      "2024-11-26 02:08:14.945055: Current learning rate: 0.00764\n",
      "2024-11-26 02:10:24.247320: train_loss -0.6815\n",
      "2024-11-26 02:10:24.256321: val_loss -0.4487\n",
      "2024-11-26 02:10:24.261368: Pseudo dice [0.728]\n",
      "2024-11-26 02:10:24.269412: Epoch time: 129.31 s\n",
      "2024-11-26 02:10:25.248460: \n",
      "2024-11-26 02:10:25.254262: Epoch 130\n",
      "2024-11-26 02:10:25.260308: Current learning rate: 0.00763\n",
      "2024-11-26 02:12:34.558298: train_loss -0.6963\n",
      "2024-11-26 02:12:34.567364: val_loss -0.4849\n",
      "2024-11-26 02:12:34.572366: Pseudo dice [0.7614]\n",
      "2024-11-26 02:12:34.576367: Epoch time: 129.31 s\n",
      "2024-11-26 02:12:35.551655: \n",
      "2024-11-26 02:12:35.557656: Epoch 131\n",
      "2024-11-26 02:12:35.560701: Current learning rate: 0.00761\n",
      "2024-11-26 02:14:44.812034: train_loss -0.7021\n",
      "2024-11-26 02:14:44.822163: val_loss -0.4743\n",
      "2024-11-26 02:14:44.831163: Pseudo dice [0.7359]\n",
      "2024-11-26 02:14:44.836214: Epoch time: 129.26 s\n",
      "2024-11-26 02:14:45.825061: \n",
      "2024-11-26 02:14:45.831063: Epoch 132\n",
      "2024-11-26 02:14:45.835113: Current learning rate: 0.00759\n",
      "2024-11-26 02:16:55.133319: train_loss -0.687\n",
      "2024-11-26 02:16:55.140401: val_loss -0.6045\n",
      "2024-11-26 02:16:55.147402: Pseudo dice [0.8036]\n",
      "2024-11-26 02:16:55.152403: Epoch time: 129.31 s\n",
      "2024-11-26 02:16:55.158406: Yayy! New best EMA pseudo Dice: 0.7423\n",
      "2024-11-26 02:16:56.385639: \n",
      "2024-11-26 02:16:56.390687: Epoch 133\n",
      "2024-11-26 02:16:56.395688: Current learning rate: 0.00757\n",
      "2024-11-26 02:19:05.649892: train_loss -0.6569\n",
      "2024-11-26 02:19:05.658894: val_loss -0.3834\n",
      "2024-11-26 02:19:05.664978: Pseudo dice [0.7079]\n",
      "2024-11-26 02:19:05.670979: Epoch time: 129.27 s\n",
      "2024-11-26 02:19:06.659113: \n",
      "2024-11-26 02:19:06.665675: Epoch 134\n",
      "2024-11-26 02:19:06.669666: Current learning rate: 0.00755\n",
      "2024-11-26 02:21:16.041343: train_loss -0.697\n",
      "2024-11-26 02:21:16.051343: val_loss -0.3756\n",
      "2024-11-26 02:21:16.061344: Pseudo dice [0.6926]\n",
      "2024-11-26 02:21:16.061344: Epoch time: 129.38 s\n",
      "2024-11-26 02:21:17.237997: \n",
      "2024-11-26 02:21:17.247989: Epoch 135\n",
      "2024-11-26 02:21:17.247989: Current learning rate: 0.00753\n",
      "2024-11-26 02:23:26.575120: train_loss -0.7075\n",
      "2024-11-26 02:23:26.578744: val_loss -0.4819\n",
      "2024-11-26 02:23:26.588248: Pseudo dice [0.7409]\n",
      "2024-11-26 02:23:26.588248: Epoch time: 129.34 s\n",
      "2024-11-26 02:23:27.598224: \n",
      "2024-11-26 02:23:27.608225: Epoch 136\n",
      "2024-11-26 02:23:27.608225: Current learning rate: 0.00751\n",
      "2024-11-26 02:25:36.962329: train_loss -0.724\n",
      "2024-11-26 02:25:36.972329: val_loss -0.45\n",
      "2024-11-26 02:25:36.982330: Pseudo dice [0.7471]\n",
      "2024-11-26 02:25:36.982330: Epoch time: 129.36 s\n",
      "2024-11-26 02:25:38.001812: \n",
      "2024-11-26 02:25:38.001812: Epoch 137\n",
      "2024-11-26 02:25:38.011812: Current learning rate: 0.0075\n",
      "2024-11-26 02:27:47.338757: train_loss -0.7241\n",
      "2024-11-26 02:27:47.348757: val_loss -0.3208\n",
      "2024-11-26 02:27:47.358757: Pseudo dice [0.6805]\n",
      "2024-11-26 02:27:47.358757: Epoch time: 129.34 s\n",
      "2024-11-26 02:27:48.372046: \n",
      "2024-11-26 02:27:48.382046: Epoch 138\n",
      "2024-11-26 02:27:48.382046: Current learning rate: 0.00748\n",
      "2024-11-26 02:29:57.778959: train_loss -0.6882\n",
      "2024-11-26 02:29:57.788962: val_loss -0.221\n",
      "2024-11-26 02:29:57.788962: Pseudo dice [0.6046]\n",
      "2024-11-26 02:29:57.798962: Epoch time: 129.41 s\n",
      "2024-11-26 02:29:58.811156: \n",
      "2024-11-26 02:29:58.817156: Epoch 139\n",
      "2024-11-26 02:29:58.821516: Current learning rate: 0.00746\n",
      "2024-11-26 02:32:08.912544: train_loss -0.6566\n",
      "2024-11-26 02:32:08.922544: val_loss -0.4758\n",
      "2024-11-26 02:32:08.922544: Pseudo dice [0.7323]\n",
      "2024-11-26 02:32:08.932545: Epoch time: 130.1 s\n",
      "2024-11-26 02:32:09.945871: \n",
      "2024-11-26 02:32:09.945871: Epoch 140\n",
      "2024-11-26 02:32:09.955872: Current learning rate: 0.00744\n",
      "2024-11-26 02:34:21.206972: train_loss -0.7053\n",
      "2024-11-26 02:34:21.213535: val_loss -0.292\n",
      "2024-11-26 02:34:21.223533: Pseudo dice [0.6504]\n",
      "2024-11-26 02:34:21.230201: Epoch time: 131.26 s\n",
      "2024-11-26 02:34:22.246821: \n",
      "2024-11-26 02:34:22.256819: Epoch 141\n",
      "2024-11-26 02:34:22.256819: Current learning rate: 0.00742\n",
      "2024-11-26 02:36:34.814572: train_loss -0.6627\n",
      "2024-11-26 02:36:34.839892: val_loss -0.3441\n",
      "2024-11-26 02:36:34.847563: Pseudo dice [0.6804]\n",
      "2024-11-26 02:36:34.853564: Epoch time: 132.57 s\n",
      "2024-11-26 02:36:36.154229: \n",
      "2024-11-26 02:36:36.162232: Epoch 142\n",
      "2024-11-26 02:36:36.169233: Current learning rate: 0.0074\n",
      "2024-11-26 02:38:46.802195: train_loss -0.6833\n",
      "2024-11-26 02:38:46.818620: val_loss -0.3963\n",
      "2024-11-26 02:38:46.825263: Pseudo dice [0.7118]\n",
      "2024-11-26 02:38:46.825263: Epoch time: 130.65 s\n",
      "2024-11-26 02:38:47.873078: \n",
      "2024-11-26 02:38:47.883078: Epoch 143\n",
      "2024-11-26 02:38:47.883078: Current learning rate: 0.00738\n",
      "2024-11-26 02:40:58.010481: train_loss -0.7017\n",
      "2024-11-26 02:40:58.020483: val_loss -0.4916\n",
      "2024-11-26 02:40:58.030482: Pseudo dice [0.743]\n",
      "2024-11-26 02:40:58.030482: Epoch time: 130.14 s\n",
      "2024-11-26 02:40:59.039982: \n",
      "2024-11-26 02:40:59.049982: Epoch 144\n",
      "2024-11-26 02:40:59.049982: Current learning rate: 0.00737\n",
      "2024-11-26 02:43:09.048418: train_loss -0.693\n",
      "2024-11-26 02:43:09.057453: val_loss -0.4678\n",
      "2024-11-26 02:43:09.063946: Pseudo dice [0.7353]\n",
      "2024-11-26 02:43:09.069472: Epoch time: 130.01 s\n",
      "2024-11-26 02:43:10.070449: \n",
      "2024-11-26 02:43:10.080449: Epoch 145\n",
      "2024-11-26 02:43:10.080449: Current learning rate: 0.00735\n",
      "2024-11-26 02:45:21.782766: train_loss -0.6797\n",
      "2024-11-26 02:45:21.798679: val_loss -0.5128\n",
      "2024-11-26 02:45:21.801263: Pseudo dice [0.7636]\n",
      "2024-11-26 02:45:21.810766: Epoch time: 131.71 s\n",
      "2024-11-26 02:45:22.831747: \n",
      "2024-11-26 02:45:22.841250: Epoch 146\n",
      "2024-11-26 02:45:22.848377: Current learning rate: 0.00733\n",
      "2024-11-26 02:47:35.862461: train_loss -0.7146\n",
      "2024-11-26 02:47:35.872459: val_loss -0.4529\n",
      "2024-11-26 02:47:35.878559: Pseudo dice [0.7094]\n",
      "2024-11-26 02:47:35.888063: Epoch time: 133.03 s\n",
      "2024-11-26 02:47:36.895820: \n",
      "2024-11-26 02:47:36.905819: Epoch 147\n",
      "2024-11-26 02:47:36.912117: Current learning rate: 0.00731\n",
      "2024-11-26 02:49:46.755169: train_loss -0.714\n",
      "2024-11-26 02:49:46.765170: val_loss -0.4213\n",
      "2024-11-26 02:49:46.775170: Pseudo dice [0.7007]\n",
      "2024-11-26 02:49:46.775170: Epoch time: 129.86 s\n",
      "2024-11-26 02:49:47.961830: \n",
      "2024-11-26 02:49:47.974151: Epoch 148\n",
      "2024-11-26 02:49:47.974151: Current learning rate: 0.00729\n",
      "2024-11-26 02:51:57.485460: train_loss -0.7001\n",
      "2024-11-26 02:51:57.495459: val_loss -0.3505\n",
      "2024-11-26 02:51:57.505461: Pseudo dice [0.7011]\n",
      "2024-11-26 02:51:57.505461: Epoch time: 129.52 s\n",
      "2024-11-26 02:51:58.521009: \n",
      "2024-11-26 02:51:58.531009: Epoch 149\n",
      "2024-11-26 02:51:58.531009: Current learning rate: 0.00727\n",
      "2024-11-26 02:54:08.062259: train_loss -0.7493\n",
      "2024-11-26 02:54:08.072260: val_loss -0.5213\n",
      "2024-11-26 02:54:08.072260: Pseudo dice [0.7684]\n",
      "2024-11-26 02:54:08.082261: Epoch time: 129.54 s\n",
      "2024-11-26 02:54:09.312261: \n",
      "2024-11-26 02:54:09.322261: Epoch 150\n",
      "2024-11-26 02:54:09.322261: Current learning rate: 0.00725\n",
      "2024-11-26 02:56:18.834048: train_loss -0.7468\n",
      "2024-11-26 02:56:18.844087: val_loss -0.4144\n",
      "2024-11-26 02:56:18.850212: Pseudo dice [0.7231]\n",
      "2024-11-26 02:56:18.850212: Epoch time: 129.52 s\n",
      "2024-11-26 02:56:19.842452: \n",
      "2024-11-26 02:56:19.852452: Epoch 151\n",
      "2024-11-26 02:56:19.852452: Current learning rate: 0.00724\n",
      "2024-11-26 02:58:29.379426: train_loss -0.745\n",
      "2024-11-26 02:58:29.389450: val_loss -0.4039\n",
      "2024-11-26 02:58:29.399450: Pseudo dice [0.7284]\n",
      "2024-11-26 02:58:29.399450: Epoch time: 129.54 s\n",
      "2024-11-26 02:58:30.402743: \n",
      "2024-11-26 02:58:30.416234: Epoch 152\n",
      "2024-11-26 02:58:30.420235: Current learning rate: 0.00722\n",
      "2024-11-26 03:00:39.971939: train_loss -0.77\n",
      "2024-11-26 03:00:39.981941: val_loss -0.1551\n",
      "2024-11-26 03:00:39.991940: Pseudo dice [0.5935]\n",
      "2024-11-26 03:00:39.991940: Epoch time: 129.57 s\n",
      "2024-11-26 03:00:40.999645: \n",
      "2024-11-26 03:00:40.999645: Epoch 153\n",
      "2024-11-26 03:00:41.009644: Current learning rate: 0.0072\n",
      "2024-11-26 03:02:50.496579: train_loss -0.7648\n",
      "2024-11-26 03:02:50.506579: val_loss -0.4343\n",
      "2024-11-26 03:02:50.506579: Pseudo dice [0.7275]\n",
      "2024-11-26 03:02:50.516579: Epoch time: 129.5 s\n",
      "2024-11-26 03:02:51.533196: \n",
      "2024-11-26 03:02:51.543196: Epoch 154\n",
      "2024-11-26 03:02:51.543196: Current learning rate: 0.00718\n",
      "2024-11-26 03:05:01.070617: train_loss -0.7275\n",
      "2024-11-26 03:05:01.079620: val_loss -0.2763\n",
      "2024-11-26 03:05:01.086269: Pseudo dice [0.6494]\n",
      "2024-11-26 03:05:01.086269: Epoch time: 129.54 s\n",
      "2024-11-26 03:05:02.103381: \n",
      "2024-11-26 03:05:02.103381: Epoch 155\n",
      "2024-11-26 03:05:02.113381: Current learning rate: 0.00716\n",
      "2024-11-26 03:07:11.587754: train_loss -0.7244\n",
      "2024-11-26 03:07:11.597755: val_loss -0.4436\n",
      "2024-11-26 03:07:11.597755: Pseudo dice [0.7255]\n",
      "2024-11-26 03:07:11.607754: Epoch time: 129.48 s\n",
      "2024-11-26 03:07:12.801241: \n",
      "2024-11-26 03:07:12.801241: Epoch 156\n",
      "2024-11-26 03:07:12.811282: Current learning rate: 0.00714\n",
      "2024-11-26 03:09:22.289534: train_loss -0.7131\n",
      "2024-11-26 03:09:22.299536: val_loss -0.4043\n",
      "2024-11-26 03:09:22.309536: Pseudo dice [0.7234]\n",
      "2024-11-26 03:09:22.319536: Epoch time: 129.49 s\n",
      "2024-11-26 03:09:23.337228: \n",
      "2024-11-26 03:09:23.347228: Epoch 157\n",
      "2024-11-26 03:09:23.347228: Current learning rate: 0.00712\n",
      "2024-11-26 03:11:32.814205: train_loss -0.7384\n",
      "2024-11-26 03:11:32.824205: val_loss -0.4552\n",
      "2024-11-26 03:11:32.834206: Pseudo dice [0.7483]\n",
      "2024-11-26 03:11:32.834206: Epoch time: 129.48 s\n",
      "2024-11-26 03:11:33.853569: \n",
      "2024-11-26 03:11:33.863569: Epoch 158\n",
      "2024-11-26 03:11:33.863569: Current learning rate: 0.0071\n",
      "2024-11-26 03:13:43.403395: train_loss -0.7258\n",
      "2024-11-26 03:13:43.403395: val_loss -0.5411\n",
      "2024-11-26 03:13:43.413395: Pseudo dice [0.7791]\n",
      "2024-11-26 03:13:43.423395: Epoch time: 129.55 s\n",
      "2024-11-26 03:13:44.440988: \n",
      "2024-11-26 03:13:44.450989: Epoch 159\n",
      "2024-11-26 03:13:44.450989: Current learning rate: 0.00709\n",
      "2024-11-26 03:15:53.957972: train_loss -0.734\n",
      "2024-11-26 03:15:53.957972: val_loss -0.4789\n",
      "2024-11-26 03:15:53.967972: Pseudo dice [0.7599]\n",
      "2024-11-26 03:15:53.977973: Epoch time: 129.52 s\n",
      "2024-11-26 03:15:54.997900: \n",
      "2024-11-26 03:15:54.997900: Epoch 160\n",
      "2024-11-26 03:15:55.007900: Current learning rate: 0.00707\n",
      "2024-11-26 03:18:04.487224: train_loss -0.7356\n",
      "2024-11-26 03:18:04.497223: val_loss -0.4831\n",
      "2024-11-26 03:18:04.507223: Pseudo dice [0.7374]\n",
      "2024-11-26 03:18:04.507223: Epoch time: 129.5 s\n",
      "2024-11-26 03:18:05.525796: \n",
      "2024-11-26 03:18:05.535796: Epoch 161\n",
      "2024-11-26 03:18:05.535796: Current learning rate: 0.00705\n",
      "2024-11-26 03:20:15.048409: train_loss -0.7341\n",
      "2024-11-26 03:20:15.058409: val_loss -0.4387\n",
      "2024-11-26 03:20:15.068409: Pseudo dice [0.7119]\n",
      "2024-11-26 03:20:15.068409: Epoch time: 129.52 s\n",
      "2024-11-26 03:20:16.264528: \n",
      "2024-11-26 03:20:16.274032: Epoch 162\n",
      "2024-11-26 03:20:16.274032: Current learning rate: 0.00703\n",
      "2024-11-26 03:22:25.795667: train_loss -0.7114\n",
      "2024-11-26 03:22:25.805667: val_loss -0.4951\n",
      "2024-11-26 03:22:25.805667: Pseudo dice [0.7596]\n",
      "2024-11-26 03:22:25.815667: Epoch time: 129.53 s\n",
      "2024-11-26 03:22:26.828650: \n",
      "2024-11-26 03:22:26.838649: Epoch 163\n",
      "2024-11-26 03:22:26.848650: Current learning rate: 0.00701\n",
      "2024-11-26 03:24:36.358924: train_loss -0.7164\n",
      "2024-11-26 03:24:36.368925: val_loss -0.294\n",
      "2024-11-26 03:24:36.378925: Pseudo dice [0.6823]\n",
      "2024-11-26 03:24:36.378925: Epoch time: 129.53 s\n",
      "2024-11-26 03:24:37.405488: \n",
      "2024-11-26 03:24:37.405488: Epoch 164\n",
      "2024-11-26 03:24:37.415489: Current learning rate: 0.00699\n",
      "2024-11-26 03:26:46.892480: train_loss -0.7105\n",
      "2024-11-26 03:26:46.902480: val_loss -0.2687\n",
      "2024-11-26 03:26:46.912481: Pseudo dice [0.6697]\n",
      "2024-11-26 03:26:46.912481: Epoch time: 129.49 s\n",
      "2024-11-26 03:26:47.909112: \n",
      "2024-11-26 03:26:47.909112: Epoch 165\n",
      "2024-11-26 03:26:47.919111: Current learning rate: 0.00697\n",
      "2024-11-26 03:28:57.449158: train_loss -0.6942\n",
      "2024-11-26 03:28:57.459159: val_loss -0.4833\n",
      "2024-11-26 03:28:57.459159: Pseudo dice [0.7623]\n",
      "2024-11-26 03:28:57.469160: Epoch time: 129.55 s\n",
      "2024-11-26 03:28:58.458290: \n",
      "2024-11-26 03:28:58.468290: Epoch 166\n",
      "2024-11-26 03:28:58.468290: Current learning rate: 0.00696\n",
      "2024-11-26 03:31:07.989621: train_loss -0.7293\n",
      "2024-11-26 03:31:07.999621: val_loss -0.3723\n",
      "2024-11-26 03:31:08.009621: Pseudo dice [0.675]\n",
      "2024-11-26 03:31:08.009621: Epoch time: 129.53 s\n",
      "2024-11-26 03:31:08.996238: \n",
      "2024-11-26 03:31:09.006238: Epoch 167\n",
      "2024-11-26 03:31:09.006238: Current learning rate: 0.00694\n",
      "2024-11-26 03:33:18.489916: train_loss -0.7316\n",
      "2024-11-26 03:33:18.489916: val_loss -0.5793\n",
      "2024-11-26 03:33:18.499918: Pseudo dice [0.7944]\n",
      "2024-11-26 03:33:18.509917: Epoch time: 129.49 s\n",
      "2024-11-26 03:33:19.506449: \n",
      "2024-11-26 03:33:19.516449: Epoch 168\n",
      "2024-11-26 03:33:19.516449: Current learning rate: 0.00692\n",
      "2024-11-26 03:35:29.023392: train_loss -0.7483\n",
      "2024-11-26 03:35:29.033393: val_loss -0.4897\n",
      "2024-11-26 03:35:29.033393: Pseudo dice [0.773]\n",
      "2024-11-26 03:35:29.033393: Epoch time: 129.52 s\n",
      "2024-11-26 03:35:30.210074: \n",
      "2024-11-26 03:35:30.220074: Epoch 169\n",
      "2024-11-26 03:35:30.220074: Current learning rate: 0.0069\n",
      "2024-11-26 03:37:39.690295: train_loss -0.759\n",
      "2024-11-26 03:37:39.700295: val_loss -0.0901\n",
      "2024-11-26 03:37:39.710296: Pseudo dice [0.5437]\n",
      "2024-11-26 03:37:39.710296: Epoch time: 129.48 s\n",
      "2024-11-26 03:37:40.716926: \n",
      "2024-11-26 03:37:40.726926: Epoch 170\n",
      "2024-11-26 03:37:40.726926: Current learning rate: 0.00688\n",
      "2024-11-26 03:39:50.233883: train_loss -0.7214\n",
      "2024-11-26 03:39:50.233883: val_loss -0.2646\n",
      "2024-11-26 03:39:50.243884: Pseudo dice [0.5973]\n",
      "2024-11-26 03:39:50.243884: Epoch time: 129.52 s\n",
      "2024-11-26 03:39:51.260242: \n",
      "2024-11-26 03:39:51.266343: Epoch 171\n",
      "2024-11-26 03:39:51.272438: Current learning rate: 0.00686\n",
      "2024-11-26 03:42:00.776597: train_loss -0.727\n",
      "2024-11-26 03:42:00.785058: val_loss -0.5573\n",
      "2024-11-26 03:42:00.785058: Pseudo dice [0.7899]\n",
      "2024-11-26 03:42:00.794610: Epoch time: 129.52 s\n",
      "2024-11-26 03:42:01.800749: \n",
      "2024-11-26 03:42:01.800749: Epoch 172\n",
      "2024-11-26 03:42:01.810748: Current learning rate: 0.00684\n",
      "2024-11-26 03:44:11.367673: train_loss -0.7493\n",
      "2024-11-26 03:44:11.377674: val_loss -0.5385\n",
      "2024-11-26 03:44:11.387674: Pseudo dice [0.7669]\n",
      "2024-11-26 03:44:11.387674: Epoch time: 129.57 s\n",
      "2024-11-26 03:44:12.400946: \n",
      "2024-11-26 03:44:12.410946: Epoch 173\n",
      "2024-11-26 03:44:12.410946: Current learning rate: 0.00682\n",
      "2024-11-26 03:46:21.872587: train_loss -0.7567\n",
      "2024-11-26 03:46:21.878994: val_loss -0.4351\n",
      "2024-11-26 03:46:21.889041: Pseudo dice [0.7288]\n",
      "2024-11-26 03:46:21.895755: Epoch time: 129.47 s\n",
      "2024-11-26 03:46:22.897842: \n",
      "2024-11-26 03:46:22.907842: Epoch 174\n",
      "2024-11-26 03:46:22.907842: Current learning rate: 0.0068\n",
      "2024-11-26 03:48:32.458137: train_loss -0.7139\n",
      "2024-11-26 03:48:32.468138: val_loss -0.4136\n",
      "2024-11-26 03:48:32.468138: Pseudo dice [0.7303]\n",
      "2024-11-26 03:48:32.478137: Epoch time: 129.56 s\n",
      "2024-11-26 03:48:33.484781: \n",
      "2024-11-26 03:48:33.494781: Epoch 175\n",
      "2024-11-26 03:48:33.494781: Current learning rate: 0.00679\n",
      "2024-11-26 03:50:44.138125: train_loss -0.7259\n",
      "2024-11-26 03:50:44.138125: val_loss -0.4588\n",
      "2024-11-26 03:50:44.148124: Pseudo dice [0.748]\n",
      "2024-11-26 03:50:44.154693: Epoch time: 130.65 s\n",
      "2024-11-26 03:50:45.398029: \n",
      "2024-11-26 03:50:45.406059: Epoch 176\n",
      "2024-11-26 03:50:45.406059: Current learning rate: 0.00677\n",
      "2024-11-26 03:52:56.598796: train_loss -0.7329\n",
      "2024-11-26 03:52:56.601596: val_loss -0.5757\n",
      "2024-11-26 03:52:56.611100: Pseudo dice [0.7865]\n",
      "2024-11-26 03:52:56.618179: Epoch time: 131.2 s\n",
      "2024-11-26 03:52:57.694678: \n",
      "2024-11-26 03:52:57.701583: Epoch 177\n",
      "2024-11-26 03:52:57.701583: Current learning rate: 0.00675\n",
      "2024-11-26 03:55:08.641745: train_loss -0.7059\n",
      "2024-11-26 03:55:08.650621: val_loss -0.5034\n",
      "2024-11-26 03:55:08.650621: Pseudo dice [0.7698]\n",
      "2024-11-26 03:55:08.664929: Epoch time: 130.95 s\n",
      "2024-11-26 03:55:09.698090: \n",
      "2024-11-26 03:55:09.698352: Epoch 178\n",
      "2024-11-26 03:55:09.708351: Current learning rate: 0.00673\n",
      "2024-11-26 03:57:20.688618: train_loss -0.7074\n",
      "2024-11-26 03:57:20.695286: val_loss -0.505\n",
      "2024-11-26 03:57:20.705284: Pseudo dice [0.7562]\n",
      "2024-11-26 03:57:20.712006: Epoch time: 131.0 s\n",
      "2024-11-26 03:57:21.745179: \n",
      "2024-11-26 03:57:21.761864: Epoch 179\n",
      "2024-11-26 03:57:21.761864: Current learning rate: 0.00671\n",
      "2024-11-26 03:59:32.958767: train_loss -0.7463\n",
      "2024-11-26 03:59:32.976135: val_loss -0.538\n",
      "2024-11-26 03:59:32.986567: Pseudo dice [0.7833]\n",
      "2024-11-26 03:59:32.991811: Epoch time: 131.21 s\n",
      "2024-11-26 03:59:34.131246: \n",
      "2024-11-26 03:59:34.138247: Epoch 180\n",
      "2024-11-26 03:59:34.142805: Current learning rate: 0.00669\n",
      "2024-11-26 04:01:45.089024: train_loss -0.7121\n",
      "2024-11-26 04:01:45.099023: val_loss -0.4524\n",
      "2024-11-26 04:01:45.105646: Pseudo dice [0.7453]\n",
      "2024-11-26 04:01:45.105646: Epoch time: 130.96 s\n",
      "2024-11-26 04:01:46.182290: \n",
      "2024-11-26 04:01:46.188905: Epoch 181\n",
      "2024-11-26 04:01:46.188905: Current learning rate: 0.00667\n",
      "2024-11-26 04:03:57.452452: train_loss -0.7525\n",
      "2024-11-26 04:03:57.462449: val_loss -0.3649\n",
      "2024-11-26 04:03:57.469197: Pseudo dice [0.7131]\n",
      "2024-11-26 04:03:57.479196: Epoch time: 131.27 s\n",
      "2024-11-26 04:03:58.552401: \n",
      "2024-11-26 04:03:58.568824: Epoch 182\n",
      "2024-11-26 04:03:58.569090: Current learning rate: 0.00665\n",
      "2024-11-26 04:06:09.608819: train_loss -0.7525\n",
      "2024-11-26 04:06:09.619530: val_loss -0.4611\n",
      "2024-11-26 04:06:09.627532: Pseudo dice [0.7419]\n",
      "2024-11-26 04:06:09.632533: Epoch time: 131.06 s\n",
      "2024-11-26 04:06:10.944413: \n",
      "2024-11-26 04:06:10.949409: Epoch 183\n",
      "2024-11-26 04:06:10.959409: Current learning rate: 0.00664\n",
      "2024-11-26 04:08:23.067781: train_loss -0.745\n",
      "2024-11-26 04:08:23.079405: val_loss -0.5219\n",
      "2024-11-26 04:08:23.081874: Pseudo dice [0.7789]\n",
      "2024-11-26 04:08:23.091911: Epoch time: 132.12 s\n",
      "2024-11-26 04:08:24.131981: \n",
      "2024-11-26 04:08:24.138983: Epoch 184\n",
      "2024-11-26 04:08:24.144984: Current learning rate: 0.00662\n",
      "2024-11-26 04:10:37.200428: train_loss -0.7442\n",
      "2024-11-26 04:10:37.220429: val_loss -0.3994\n",
      "2024-11-26 04:10:37.220429: Pseudo dice [0.7018]\n",
      "2024-11-26 04:10:37.220429: Epoch time: 133.07 s\n",
      "2024-11-26 04:10:38.240443: \n",
      "2024-11-26 04:10:38.250442: Epoch 185\n",
      "2024-11-26 04:10:38.260443: Current learning rate: 0.0066\n",
      "2024-11-26 04:12:47.643595: train_loss -0.7569\n",
      "2024-11-26 04:12:47.653595: val_loss -0.2521\n",
      "2024-11-26 04:12:47.663595: Pseudo dice [0.6843]\n",
      "2024-11-26 04:12:47.673595: Epoch time: 129.4 s\n",
      "2024-11-26 04:12:48.683609: \n",
      "2024-11-26 04:12:48.693608: Epoch 186\n",
      "2024-11-26 04:12:48.693608: Current learning rate: 0.00658\n",
      "2024-11-26 04:14:58.113849: train_loss -0.7736\n",
      "2024-11-26 04:14:58.123849: val_loss -0.4981\n",
      "2024-11-26 04:14:58.133849: Pseudo dice [0.7592]\n",
      "2024-11-26 04:14:58.133849: Epoch time: 129.43 s\n",
      "2024-11-26 04:14:59.144753: \n",
      "2024-11-26 04:14:59.154745: Epoch 187\n",
      "2024-11-26 04:14:59.164745: Current learning rate: 0.00656\n",
      "2024-11-26 04:17:08.512507: train_loss -0.7359\n",
      "2024-11-26 04:17:08.522507: val_loss -0.4718\n",
      "2024-11-26 04:17:08.532507: Pseudo dice [0.7456]\n",
      "2024-11-26 04:17:08.532507: Epoch time: 129.37 s\n",
      "2024-11-26 04:17:09.542531: \n",
      "2024-11-26 04:17:09.552529: Epoch 188\n",
      "2024-11-26 04:17:09.552529: Current learning rate: 0.00654\n",
      "2024-11-26 04:19:18.999361: train_loss -0.7206\n",
      "2024-11-26 04:19:19.009360: val_loss -0.3197\n",
      "2024-11-26 04:19:19.019361: Pseudo dice [0.6561]\n",
      "2024-11-26 04:19:19.029362: Epoch time: 129.46 s\n",
      "2024-11-26 04:19:20.039375: \n",
      "2024-11-26 04:19:20.039375: Epoch 189\n",
      "2024-11-26 04:19:20.049377: Current learning rate: 0.00652\n",
      "2024-11-26 04:21:29.534697: train_loss -0.7411\n",
      "2024-11-26 04:21:29.544697: val_loss -0.4163\n",
      "2024-11-26 04:21:29.554697: Pseudo dice [0.711]\n",
      "2024-11-26 04:21:29.554697: Epoch time: 129.5 s\n",
      "2024-11-26 04:21:30.744723: \n",
      "2024-11-26 04:21:30.754722: Epoch 190\n",
      "2024-11-26 04:21:30.754722: Current learning rate: 0.0065\n",
      "2024-11-26 04:23:40.136291: train_loss -0.7405\n",
      "2024-11-26 04:23:40.146291: val_loss -0.3337\n",
      "2024-11-26 04:23:40.146291: Pseudo dice [0.6577]\n",
      "2024-11-26 04:23:40.156291: Epoch time: 129.39 s\n",
      "2024-11-26 04:23:41.176306: \n",
      "2024-11-26 04:23:41.176306: Epoch 191\n",
      "2024-11-26 04:23:41.186314: Current learning rate: 0.00648\n",
      "2024-11-26 04:25:50.534066: train_loss -0.734\n",
      "2024-11-26 04:25:50.544067: val_loss -0.4378\n",
      "2024-11-26 04:25:50.554067: Pseudo dice [0.7313]\n",
      "2024-11-26 04:25:50.554067: Epoch time: 129.36 s\n",
      "2024-11-26 04:25:51.594080: \n",
      "2024-11-26 04:25:51.604081: Epoch 192\n",
      "2024-11-26 04:25:51.604081: Current learning rate: 0.00647\n",
      "2024-11-26 04:28:00.970793: train_loss -0.7468\n",
      "2024-11-26 04:28:00.980794: val_loss -0.5125\n",
      "2024-11-26 04:28:00.980794: Pseudo dice [0.7428]\n",
      "2024-11-26 04:28:00.990794: Epoch time: 129.38 s\n",
      "2024-11-26 04:28:02.020807: \n",
      "2024-11-26 04:28:02.020807: Epoch 193\n",
      "2024-11-26 04:28:02.030807: Current learning rate: 0.00645\n",
      "2024-11-26 04:30:11.403821: train_loss -0.72\n",
      "2024-11-26 04:30:11.413821: val_loss -0.4708\n",
      "2024-11-26 04:30:11.423821: Pseudo dice [0.7367]\n",
      "2024-11-26 04:30:11.423821: Epoch time: 129.39 s\n",
      "2024-11-26 04:30:12.463844: \n",
      "2024-11-26 04:30:12.473836: Epoch 194\n",
      "2024-11-26 04:30:12.473836: Current learning rate: 0.00643\n",
      "2024-11-26 04:32:21.830186: train_loss -0.7578\n",
      "2024-11-26 04:32:21.840186: val_loss -0.4943\n",
      "2024-11-26 04:32:21.840186: Pseudo dice [0.7657]\n",
      "2024-11-26 04:32:21.850187: Epoch time: 129.37 s\n",
      "2024-11-26 04:32:22.880201: \n",
      "2024-11-26 04:32:22.880201: Epoch 195\n",
      "2024-11-26 04:32:22.890202: Current learning rate: 0.00641\n",
      "2024-11-26 04:34:32.239801: train_loss -0.721\n",
      "2024-11-26 04:34:32.249801: val_loss -0.5523\n",
      "2024-11-26 04:34:32.259801: Pseudo dice [0.767]\n",
      "2024-11-26 04:34:32.269801: Epoch time: 129.36 s\n",
      "2024-11-26 04:34:33.289816: \n",
      "2024-11-26 04:34:33.299816: Epoch 196\n",
      "2024-11-26 04:34:33.299816: Current learning rate: 0.00639\n",
      "2024-11-26 04:36:42.670754: train_loss -0.729\n",
      "2024-11-26 04:36:42.680754: val_loss -0.556\n",
      "2024-11-26 04:36:42.680754: Pseudo dice [0.7952]\n",
      "2024-11-26 04:36:42.690755: Epoch time: 129.38 s\n",
      "2024-11-26 04:36:43.900780: \n",
      "2024-11-26 04:36:43.910779: Epoch 197\n",
      "2024-11-26 04:36:43.920772: Current learning rate: 0.00637\n",
      "2024-11-26 04:38:53.253772: train_loss -0.7649\n",
      "2024-11-26 04:38:53.263773: val_loss -0.5426\n",
      "2024-11-26 04:38:53.273772: Pseudo dice [0.7746]\n",
      "2024-11-26 04:38:53.273772: Epoch time: 129.35 s\n",
      "2024-11-26 04:38:54.313786: \n",
      "2024-11-26 04:38:54.313786: Epoch 198\n",
      "2024-11-26 04:38:54.323789: Current learning rate: 0.00635\n",
      "2024-11-26 04:41:03.656347: train_loss -0.7473\n",
      "2024-11-26 04:41:03.666348: val_loss -0.4644\n",
      "2024-11-26 04:41:03.666348: Pseudo dice [0.7256]\n",
      "2024-11-26 04:41:03.676348: Epoch time: 129.34 s\n",
      "2024-11-26 04:41:04.706688: \n",
      "2024-11-26 04:41:04.706688: Epoch 199\n",
      "2024-11-26 04:41:04.716681: Current learning rate: 0.00633\n",
      "2024-11-26 04:43:14.079579: train_loss -0.7635\n",
      "2024-11-26 04:43:14.089579: val_loss -0.5081\n",
      "2024-11-26 04:43:14.099579: Pseudo dice [0.7655]\n",
      "2024-11-26 04:43:14.099579: Epoch time: 129.37 s\n",
      "2024-11-26 04:43:14.359583: Yayy! New best EMA pseudo Dice: 0.743\n",
      "2024-11-26 04:43:15.609600: \n",
      "2024-11-26 04:43:15.609600: Epoch 200\n",
      "2024-11-26 04:43:15.619600: Current learning rate: 0.00631\n",
      "2024-11-26 04:45:25.017915: train_loss -0.7692\n",
      "2024-11-26 04:45:25.017915: val_loss -0.4336\n",
      "2024-11-26 04:45:25.027915: Pseudo dice [0.748]\n",
      "2024-11-26 04:45:25.037917: Epoch time: 129.41 s\n",
      "2024-11-26 04:45:25.037917: Yayy! New best EMA pseudo Dice: 0.7435\n",
      "2024-11-26 04:45:26.317943: \n",
      "2024-11-26 04:45:26.327935: Epoch 201\n",
      "2024-11-26 04:45:26.327935: Current learning rate: 0.0063\n",
      "2024-11-26 04:47:35.690503: train_loss -0.7467\n",
      "2024-11-26 04:47:35.700504: val_loss -0.3455\n",
      "2024-11-26 04:47:35.710504: Pseudo dice [0.6854]\n",
      "2024-11-26 04:47:35.720504: Epoch time: 129.37 s\n",
      "2024-11-26 04:47:36.750527: \n",
      "2024-11-26 04:47:36.760518: Epoch 202\n",
      "2024-11-26 04:47:36.760518: Current learning rate: 0.00628\n",
      "2024-11-26 04:49:46.200276: train_loss -0.7205\n",
      "2024-11-26 04:49:46.210276: val_loss -0.4493\n",
      "2024-11-26 04:49:46.220277: Pseudo dice [0.7574]\n",
      "2024-11-26 04:49:46.220277: Epoch time: 129.45 s\n",
      "2024-11-26 04:49:47.250299: \n",
      "2024-11-26 04:49:47.260298: Epoch 203\n",
      "2024-11-26 04:49:47.260298: Current learning rate: 0.00626\n",
      "2024-11-26 04:51:56.682263: train_loss -0.7216\n",
      "2024-11-26 04:51:56.692264: val_loss -0.337\n",
      "2024-11-26 04:51:56.702264: Pseudo dice [0.6889]\n",
      "2024-11-26 04:51:56.712266: Epoch time: 129.43 s\n",
      "2024-11-26 04:51:57.922640: \n",
      "2024-11-26 04:51:57.932631: Epoch 204\n",
      "2024-11-26 04:51:57.932631: Current learning rate: 0.00624\n",
      "2024-11-26 04:54:07.301625: train_loss -0.76\n",
      "2024-11-26 04:54:07.311625: val_loss -0.424\n",
      "2024-11-26 04:54:07.321625: Pseudo dice [0.7149]\n",
      "2024-11-26 04:54:07.331625: Epoch time: 129.38 s\n",
      "2024-11-26 04:54:08.361639: \n",
      "2024-11-26 04:54:08.371648: Epoch 205\n",
      "2024-11-26 04:54:08.371648: Current learning rate: 0.00622\n",
      "2024-11-26 04:56:17.750005: train_loss -0.6855\n",
      "2024-11-26 04:56:17.750005: val_loss -0.3862\n",
      "2024-11-26 04:56:17.760006: Pseudo dice [0.7046]\n",
      "2024-11-26 04:56:17.760006: Epoch time: 129.39 s\n",
      "2024-11-26 04:56:18.760317: \n",
      "2024-11-26 04:56:18.760317: Epoch 206\n",
      "2024-11-26 04:56:18.770319: Current learning rate: 0.0062\n",
      "2024-11-26 04:58:28.143758: train_loss -0.7607\n",
      "2024-11-26 04:58:28.153760: val_loss -0.4916\n",
      "2024-11-26 04:58:28.153760: Pseudo dice [0.756]\n",
      "2024-11-26 04:58:28.163760: Epoch time: 129.38 s\n",
      "2024-11-26 04:58:29.144720: \n",
      "2024-11-26 04:58:29.144720: Epoch 207\n",
      "2024-11-26 04:58:29.154721: Current learning rate: 0.00618\n",
      "2024-11-26 05:00:38.493508: train_loss -0.7598\n",
      "2024-11-26 05:00:38.503508: val_loss -0.3933\n",
      "2024-11-26 05:00:38.513508: Pseudo dice [0.7447]\n",
      "2024-11-26 05:00:38.523508: Epoch time: 129.35 s\n",
      "2024-11-26 05:00:39.503522: \n",
      "2024-11-26 05:00:39.513522: Epoch 208\n",
      "2024-11-26 05:00:39.513522: Current learning rate: 0.00616\n",
      "2024-11-26 05:02:48.855858: train_loss -0.7577\n",
      "2024-11-26 05:02:48.865858: val_loss -0.2802\n",
      "2024-11-26 05:02:48.875858: Pseudo dice [0.6236]\n",
      "2024-11-26 05:02:48.885858: Epoch time: 129.35 s\n",
      "2024-11-26 05:02:49.845880: \n",
      "2024-11-26 05:02:49.855879: Epoch 209\n",
      "2024-11-26 05:02:49.855879: Current learning rate: 0.00614\n",
      "2024-11-26 05:04:59.284214: train_loss -0.708\n",
      "2024-11-26 05:04:59.294214: val_loss -0.4569\n",
      "2024-11-26 05:04:59.304214: Pseudo dice [0.7043]\n",
      "2024-11-26 05:04:59.314214: Epoch time: 129.44 s\n",
      "2024-11-26 05:05:00.284227: \n",
      "2024-11-26 05:05:00.294227: Epoch 210\n",
      "2024-11-26 05:05:00.304228: Current learning rate: 0.00612\n",
      "2024-11-26 05:07:09.656483: train_loss -0.7885\n",
      "2024-11-26 05:07:09.666483: val_loss -0.5468\n",
      "2024-11-26 05:07:09.676483: Pseudo dice [0.7732]\n",
      "2024-11-26 05:07:09.686483: Epoch time: 129.37 s\n",
      "2024-11-26 05:07:10.846500: \n",
      "2024-11-26 05:07:10.856500: Epoch 211\n",
      "2024-11-26 05:07:10.856500: Current learning rate: 0.00611\n",
      "2024-11-26 05:09:20.235100: train_loss -0.7527\n",
      "2024-11-26 05:09:20.245100: val_loss -0.3377\n",
      "2024-11-26 05:09:20.255100: Pseudo dice [0.665]\n",
      "2024-11-26 05:09:20.255100: Epoch time: 129.39 s\n",
      "2024-11-26 05:09:21.245123: \n",
      "2024-11-26 05:09:21.255122: Epoch 212\n",
      "2024-11-26 05:09:21.255122: Current learning rate: 0.00609\n",
      "2024-11-26 05:11:30.604029: train_loss -0.7553\n",
      "2024-11-26 05:11:30.614029: val_loss -0.5787\n",
      "2024-11-26 05:11:30.614029: Pseudo dice [0.8077]\n",
      "2024-11-26 05:11:30.624029: Epoch time: 129.36 s\n",
      "2024-11-26 05:11:31.594052: \n",
      "2024-11-26 05:11:31.604051: Epoch 213\n",
      "2024-11-26 05:11:31.604051: Current learning rate: 0.00607\n",
      "2024-11-26 05:13:40.899497: train_loss -0.7654\n",
      "2024-11-26 05:13:40.909497: val_loss -0.4047\n",
      "2024-11-26 05:13:40.919498: Pseudo dice [0.7193]\n",
      "2024-11-26 05:13:40.919498: Epoch time: 129.31 s\n",
      "2024-11-26 05:13:41.899510: \n",
      "2024-11-26 05:13:41.899510: Epoch 214\n",
      "2024-11-26 05:13:41.899510: Current learning rate: 0.00605\n",
      "2024-11-26 05:15:51.193779: train_loss -0.7766\n",
      "2024-11-26 05:15:51.203780: val_loss -0.5555\n",
      "2024-11-26 05:15:51.213780: Pseudo dice [0.7862]\n",
      "2024-11-26 05:15:51.213780: Epoch time: 129.3 s\n",
      "2024-11-26 05:15:52.193793: \n",
      "2024-11-26 05:15:52.193793: Epoch 215\n",
      "2024-11-26 05:15:52.193793: Current learning rate: 0.00603\n",
      "2024-11-26 05:18:01.527996: train_loss -0.7525\n",
      "2024-11-26 05:18:01.527996: val_loss -0.502\n",
      "2024-11-26 05:18:01.537996: Pseudo dice [0.7437]\n",
      "2024-11-26 05:18:01.537996: Epoch time: 129.34 s\n",
      "2024-11-26 05:18:02.508010: \n",
      "2024-11-26 05:18:02.518010: Epoch 216\n",
      "2024-11-26 05:18:02.518010: Current learning rate: 0.00601\n",
      "2024-11-26 05:20:11.783382: train_loss -0.7965\n",
      "2024-11-26 05:20:11.793383: val_loss -0.3802\n",
      "2024-11-26 05:20:11.793383: Pseudo dice [0.6987]\n",
      "2024-11-26 05:20:11.793383: Epoch time: 129.28 s\n",
      "2024-11-26 05:20:12.773406: \n",
      "2024-11-26 05:20:12.783405: Epoch 217\n",
      "2024-11-26 05:20:12.783405: Current learning rate: 0.00599\n",
      "2024-11-26 05:22:22.110709: train_loss -0.76\n",
      "2024-11-26 05:22:22.110709: val_loss -0.5466\n",
      "2024-11-26 05:22:22.120709: Pseudo dice [0.7859]\n",
      "2024-11-26 05:22:22.130709: Epoch time: 129.34 s\n",
      "2024-11-26 05:22:23.280885: \n",
      "2024-11-26 05:22:23.280885: Epoch 218\n",
      "2024-11-26 05:22:23.290886: Current learning rate: 0.00597\n",
      "2024-11-26 05:24:32.626036: train_loss -0.7516\n",
      "2024-11-26 05:24:32.626036: val_loss -0.3224\n",
      "2024-11-26 05:24:32.636036: Pseudo dice [0.6538]\n",
      "2024-11-26 05:24:32.646036: Epoch time: 129.36 s\n",
      "2024-11-26 05:24:33.606966: \n",
      "2024-11-26 05:24:33.616965: Epoch 219\n",
      "2024-11-26 05:24:33.616965: Current learning rate: 0.00595\n",
      "2024-11-26 05:26:42.931288: train_loss -0.7335\n",
      "2024-11-26 05:26:42.941288: val_loss -0.5288\n",
      "2024-11-26 05:26:42.951288: Pseudo dice [0.7704]\n",
      "2024-11-26 05:26:42.951288: Epoch time: 129.32 s\n",
      "2024-11-26 05:26:43.921310: \n",
      "2024-11-26 05:26:43.931309: Epoch 220\n",
      "2024-11-26 05:26:43.931309: Current learning rate: 0.00593\n",
      "2024-11-26 05:28:53.250088: train_loss -0.7501\n",
      "2024-11-26 05:28:53.250088: val_loss -0.5011\n",
      "2024-11-26 05:28:53.260088: Pseudo dice [0.7661]\n",
      "2024-11-26 05:28:53.270088: Epoch time: 129.33 s\n",
      "2024-11-26 05:28:54.240102: \n",
      "2024-11-26 05:28:54.250102: Epoch 221\n",
      "2024-11-26 05:28:54.250102: Current learning rate: 0.00592\n",
      "2024-11-26 05:31:03.632249: train_loss -0.7284\n",
      "2024-11-26 05:31:03.642249: val_loss -0.5515\n",
      "2024-11-26 05:31:03.652249: Pseudo dice [0.7865]\n",
      "2024-11-26 05:31:03.652249: Epoch time: 129.39 s\n",
      "2024-11-26 05:31:04.622272: \n",
      "2024-11-26 05:31:04.632272: Epoch 222\n",
      "2024-11-26 05:31:04.632272: Current learning rate: 0.0059\n",
      "2024-11-26 05:33:14.005597: train_loss -0.7367\n",
      "2024-11-26 05:33:14.015598: val_loss -0.4128\n",
      "2024-11-26 05:33:14.025597: Pseudo dice [0.7062]\n",
      "2024-11-26 05:33:14.035598: Epoch time: 129.38 s\n",
      "2024-11-26 05:33:14.995618: \n",
      "2024-11-26 05:33:14.995618: Epoch 223\n",
      "2024-11-26 05:33:14.995618: Current learning rate: 0.00588\n",
      "2024-11-26 05:35:24.351812: train_loss -0.7277\n",
      "2024-11-26 05:35:24.361812: val_loss -0.5383\n",
      "2024-11-26 05:35:24.371812: Pseudo dice [0.7663]\n",
      "2024-11-26 05:35:24.381814: Epoch time: 129.37 s\n",
      "2024-11-26 05:35:25.341826: \n",
      "2024-11-26 05:35:25.341826: Epoch 224\n",
      "2024-11-26 05:35:25.351835: Current learning rate: 0.00586\n",
      "2024-11-26 05:37:34.710130: train_loss -0.7659\n",
      "2024-11-26 05:37:34.720131: val_loss -0.3198\n",
      "2024-11-26 05:37:34.730131: Pseudo dice [0.6528]\n",
      "2024-11-26 05:37:34.730131: Epoch time: 129.37 s\n",
      "2024-11-26 05:37:35.700144: \n",
      "2024-11-26 05:37:35.700144: Epoch 225\n",
      "2024-11-26 05:37:35.710152: Current learning rate: 0.00584\n",
      "2024-11-26 05:39:45.063627: train_loss -0.7536\n",
      "2024-11-26 05:39:45.073627: val_loss -0.4077\n",
      "2024-11-26 05:39:45.073627: Pseudo dice [0.6968]\n",
      "2024-11-26 05:39:45.083627: Epoch time: 129.36 s\n",
      "2024-11-26 05:39:46.233642: \n",
      "2024-11-26 05:39:46.233642: Epoch 226\n",
      "2024-11-26 05:39:46.243651: Current learning rate: 0.00582\n",
      "2024-11-26 05:41:55.636344: train_loss -0.7456\n",
      "2024-11-26 05:41:55.646344: val_loss -0.4284\n",
      "2024-11-26 05:41:55.656344: Pseudo dice [0.7097]\n",
      "2024-11-26 05:41:55.666344: Epoch time: 129.4 s\n",
      "2024-11-26 05:41:56.626653: \n",
      "2024-11-26 05:41:56.636652: Epoch 227\n",
      "2024-11-26 05:41:56.636652: Current learning rate: 0.0058\n",
      "2024-11-26 05:44:05.986283: train_loss -0.7367\n",
      "2024-11-26 05:44:05.996282: val_loss -0.4483\n",
      "2024-11-26 05:44:05.996282: Pseudo dice [0.7355]\n",
      "2024-11-26 05:44:06.006282: Epoch time: 129.36 s\n",
      "2024-11-26 05:44:06.976305: \n",
      "2024-11-26 05:44:06.976305: Epoch 228\n",
      "2024-11-26 05:44:06.986305: Current learning rate: 0.00578\n",
      "2024-11-26 05:46:16.386647: train_loss -0.7531\n",
      "2024-11-26 05:46:16.396648: val_loss -0.5443\n",
      "2024-11-26 05:46:16.406647: Pseudo dice [0.7713]\n",
      "2024-11-26 05:46:16.406647: Epoch time: 129.41 s\n",
      "2024-11-26 05:46:17.376678: \n",
      "2024-11-26 05:46:17.386678: Epoch 229\n",
      "2024-11-26 05:46:17.386678: Current learning rate: 0.00576\n",
      "2024-11-26 05:48:26.784559: train_loss -0.7653\n",
      "2024-11-26 05:48:26.784559: val_loss -0.497\n",
      "2024-11-26 05:48:26.794559: Pseudo dice [0.7561]\n",
      "2024-11-26 05:48:26.804560: Epoch time: 129.41 s\n",
      "2024-11-26 05:48:27.765211: \n",
      "2024-11-26 05:48:27.765211: Epoch 230\n",
      "2024-11-26 05:48:27.775219: Current learning rate: 0.00574\n",
      "2024-11-26 05:50:37.188448: train_loss -0.757\n",
      "2024-11-26 05:50:37.198448: val_loss -0.1867\n",
      "2024-11-26 05:50:37.208449: Pseudo dice [0.5661]\n",
      "2024-11-26 05:50:37.208449: Epoch time: 129.42 s\n",
      "2024-11-26 05:50:38.177714: \n",
      "2024-11-26 05:50:38.181763: Epoch 231\n",
      "2024-11-26 05:50:38.181763: Current learning rate: 0.00572\n",
      "2024-11-26 05:52:47.546517: train_loss -0.7522\n",
      "2024-11-26 05:52:47.556518: val_loss -0.5999\n",
      "2024-11-26 05:52:47.566518: Pseudo dice [0.8072]\n",
      "2024-11-26 05:52:47.566518: Epoch time: 129.37 s\n",
      "2024-11-26 05:52:48.536531: \n",
      "2024-11-26 05:52:48.536531: Epoch 232\n",
      "2024-11-26 05:52:48.546539: Current learning rate: 0.0057\n",
      "2024-11-26 05:54:57.911239: train_loss -0.7777\n",
      "2024-11-26 05:54:57.921241: val_loss -0.5278\n",
      "2024-11-26 05:54:57.921241: Pseudo dice [0.7653]\n",
      "2024-11-26 05:54:57.931241: Epoch time: 129.37 s\n",
      "2024-11-26 05:54:58.891601: \n",
      "2024-11-26 05:54:58.901601: Epoch 233\n",
      "2024-11-26 05:54:58.901601: Current learning rate: 0.00569\n",
      "2024-11-26 05:57:08.329537: train_loss -0.7574\n",
      "2024-11-26 05:57:08.339538: val_loss -0.4963\n",
      "2024-11-26 05:57:08.349538: Pseudo dice [0.7564]\n",
      "2024-11-26 05:57:08.349538: Epoch time: 129.44 s\n",
      "2024-11-26 05:57:09.319559: \n",
      "2024-11-26 05:57:09.329552: Epoch 234\n",
      "2024-11-26 05:57:09.329552: Current learning rate: 0.00567\n",
      "2024-11-26 05:59:20.914897: train_loss -0.7812\n",
      "2024-11-26 05:59:20.924897: val_loss -0.2746\n",
      "2024-11-26 05:59:20.934898: Pseudo dice [0.6479]\n",
      "2024-11-26 05:59:20.944898: Epoch time: 131.6 s\n",
      "2024-11-26 05:59:21.904920: \n",
      "2024-11-26 05:59:21.914912: Epoch 235\n",
      "2024-11-26 05:59:21.914912: Current learning rate: 0.00565\n",
      "2024-11-26 06:01:31.271094: train_loss -0.7826\n",
      "2024-11-26 06:01:31.281093: val_loss -0.2408\n",
      "2024-11-26 06:01:31.291094: Pseudo dice [0.5997]\n",
      "2024-11-26 06:01:31.301094: Epoch time: 129.37 s\n",
      "2024-11-26 06:01:32.261115: \n",
      "2024-11-26 06:01:32.271108: Epoch 236\n",
      "2024-11-26 06:01:32.271108: Current learning rate: 0.00563\n",
      "2024-11-26 06:03:41.623717: train_loss -0.7711\n",
      "2024-11-26 06:03:41.633717: val_loss -0.5057\n",
      "2024-11-26 06:03:41.633717: Pseudo dice [0.7437]\n",
      "2024-11-26 06:03:41.643719: Epoch time: 129.36 s\n",
      "2024-11-26 06:03:42.614066: \n",
      "2024-11-26 06:03:42.614066: Epoch 237\n",
      "2024-11-26 06:03:42.624074: Current learning rate: 0.00561\n",
      "2024-11-26 06:05:51.967532: train_loss -0.7723\n",
      "2024-11-26 06:05:51.977533: val_loss -0.5796\n",
      "2024-11-26 06:05:51.977533: Pseudo dice [0.789]\n",
      "2024-11-26 06:05:51.987533: Epoch time: 129.35 s\n",
      "2024-11-26 06:05:52.957555: \n",
      "2024-11-26 06:05:52.967554: Epoch 238\n",
      "2024-11-26 06:05:52.967554: Current learning rate: 0.00559\n",
      "2024-11-26 06:08:02.341456: train_loss -0.7727\n",
      "2024-11-26 06:08:02.351455: val_loss -0.5294\n",
      "2024-11-26 06:08:02.361456: Pseudo dice [0.7864]\n",
      "2024-11-26 06:08:02.371457: Epoch time: 129.38 s\n",
      "2024-11-26 06:08:03.331478: \n",
      "2024-11-26 06:08:03.341477: Epoch 239\n",
      "2024-11-26 06:08:03.341477: Current learning rate: 0.00557\n",
      "2024-11-26 06:10:12.719419: train_loss -0.7695\n",
      "2024-11-26 06:10:12.729418: val_loss -0.497\n",
      "2024-11-26 06:10:12.739419: Pseudo dice [0.7707]\n",
      "2024-11-26 06:10:12.739419: Epoch time: 129.39 s\n",
      "2024-11-26 06:10:13.720277: \n",
      "2024-11-26 06:10:13.730276: Epoch 240\n",
      "2024-11-26 06:10:13.730276: Current learning rate: 0.00555\n",
      "2024-11-26 06:12:23.099516: train_loss -0.7372\n",
      "2024-11-26 06:12:23.099516: val_loss -0.5725\n",
      "2024-11-26 06:12:23.109517: Pseudo dice [0.7917]\n",
      "2024-11-26 06:12:23.109517: Epoch time: 129.38 s\n",
      "2024-11-26 06:12:24.269838: \n",
      "2024-11-26 06:12:24.269838: Epoch 241\n",
      "2024-11-26 06:12:24.279838: Current learning rate: 0.00553\n",
      "2024-11-26 06:14:33.648378: train_loss -0.7734\n",
      "2024-11-26 06:14:33.658378: val_loss -0.5532\n",
      "2024-11-26 06:14:33.658378: Pseudo dice [0.7723]\n",
      "2024-11-26 06:14:33.668378: Epoch time: 129.38 s\n",
      "2024-11-26 06:14:34.648401: \n",
      "2024-11-26 06:14:34.648401: Epoch 242\n",
      "2024-11-26 06:14:34.658401: Current learning rate: 0.00551\n",
      "2024-11-26 06:16:49.495653: train_loss -0.7622\n",
      "2024-11-26 06:16:49.503654: val_loss -0.5334\n",
      "2024-11-26 06:16:49.511656: Pseudo dice [0.7891]\n",
      "2024-11-26 06:16:49.517656: Epoch time: 134.85 s\n",
      "2024-11-26 06:16:49.523658: Yayy! New best EMA pseudo Dice: 0.7469\n",
      "2024-11-26 06:16:50.819932: \n",
      "2024-11-26 06:16:50.827932: Epoch 243\n",
      "2024-11-26 06:16:50.832934: Current learning rate: 0.00549\n",
      "2024-11-26 06:19:01.635977: train_loss -0.7801\n",
      "2024-11-26 06:19:01.643977: val_loss -0.4372\n",
      "2024-11-26 06:19:01.651979: Pseudo dice [0.7316]\n",
      "2024-11-26 06:19:01.657982: Epoch time: 130.82 s\n",
      "2024-11-26 06:19:02.655818: \n",
      "2024-11-26 06:19:02.662820: Epoch 244\n",
      "2024-11-26 06:19:02.666821: Current learning rate: 0.00547\n",
      "2024-11-26 06:21:13.359266: train_loss -0.7731\n",
      "2024-11-26 06:21:13.368268: val_loss -0.4561\n",
      "2024-11-26 06:21:13.374270: Pseudo dice [0.7243]\n",
      "2024-11-26 06:21:13.381272: Epoch time: 130.7 s\n",
      "2024-11-26 06:21:14.362493: \n",
      "2024-11-26 06:21:14.368494: Epoch 245\n",
      "2024-11-26 06:21:14.374495: Current learning rate: 0.00546\n",
      "2024-11-26 06:23:23.705627: train_loss -0.7266\n",
      "2024-11-26 06:23:23.714629: val_loss -0.4865\n",
      "2024-11-26 06:23:23.723631: Pseudo dice [0.7636]\n",
      "2024-11-26 06:23:23.728633: Epoch time: 129.34 s\n",
      "2024-11-26 06:23:24.706852: \n",
      "2024-11-26 06:23:24.712853: Epoch 246\n",
      "2024-11-26 06:23:24.716855: Current learning rate: 0.00544\n",
      "2024-11-26 06:25:34.122576: train_loss -0.7697\n",
      "2024-11-26 06:25:34.129577: val_loss -0.522\n",
      "2024-11-26 06:25:34.137579: Pseudo dice [0.7732]\n",
      "2024-11-26 06:25:34.144581: Epoch time: 129.42 s\n",
      "2024-11-26 06:25:34.149582: Yayy! New best EMA pseudo Dice: 0.7481\n",
      "2024-11-26 06:25:35.373745: \n",
      "2024-11-26 06:25:35.380746: Epoch 247\n",
      "2024-11-26 06:25:35.383747: Current learning rate: 0.00542\n",
      "2024-11-26 06:27:44.758504: train_loss -0.7688\n",
      "2024-11-26 06:27:44.767505: val_loss -0.4494\n",
      "2024-11-26 06:27:44.773505: Pseudo dice [0.7352]\n",
      "2024-11-26 06:27:44.778507: Epoch time: 129.39 s\n",
      "2024-11-26 06:27:45.755727: \n",
      "2024-11-26 06:27:45.761729: Epoch 248\n",
      "2024-11-26 06:27:45.765729: Current learning rate: 0.0054\n",
      "2024-11-26 06:29:55.014252: train_loss -0.7816\n",
      "2024-11-26 06:29:55.023254: val_loss -0.3711\n",
      "2024-11-26 06:29:55.029255: Pseudo dice [0.7138]\n",
      "2024-11-26 06:29:55.035257: Epoch time: 129.26 s\n",
      "2024-11-26 06:29:56.212523: \n",
      "2024-11-26 06:29:56.218524: Epoch 249\n",
      "2024-11-26 06:29:56.222524: Current learning rate: 0.00538\n",
      "2024-11-26 06:32:05.522819: train_loss -0.7718\n",
      "2024-11-26 06:32:05.531821: val_loss -0.4675\n",
      "2024-11-26 06:32:05.539823: Pseudo dice [0.7498]\n",
      "2024-11-26 06:32:05.545825: Epoch time: 129.31 s\n",
      "2024-11-26 06:32:06.751262: \n",
      "2024-11-26 06:32:06.757264: Epoch 250\n",
      "2024-11-26 06:32:06.761264: Current learning rate: 0.00536\n",
      "2024-11-26 06:34:16.050584: train_loss -0.793\n",
      "2024-11-26 06:34:16.059586: val_loss -0.4881\n",
      "2024-11-26 06:34:16.064587: Pseudo dice [0.7278]\n",
      "2024-11-26 06:34:16.070588: Epoch time: 129.3 s\n",
      "2024-11-26 06:34:17.051808: \n",
      "2024-11-26 06:34:17.057811: Epoch 251\n",
      "2024-11-26 06:34:17.062811: Current learning rate: 0.00534\n",
      "2024-11-26 06:36:26.360131: train_loss -0.7495\n",
      "2024-11-26 06:36:26.369133: val_loss -0.5285\n",
      "2024-11-26 06:36:26.377134: Pseudo dice [0.7746]\n",
      "2024-11-26 06:36:26.383136: Epoch time: 129.31 s\n",
      "2024-11-26 06:36:27.358355: \n",
      "2024-11-26 06:36:27.365357: Epoch 252\n",
      "2024-11-26 06:36:27.369357: Current learning rate: 0.00532\n",
      "2024-11-26 06:38:36.724937: train_loss -0.774\n",
      "2024-11-26 06:38:36.733940: val_loss -0.4108\n",
      "2024-11-26 06:38:36.738940: Pseudo dice [0.7085]\n",
      "2024-11-26 06:38:36.745942: Epoch time: 129.37 s\n",
      "2024-11-26 06:38:37.726163: \n",
      "2024-11-26 06:38:37.732164: Epoch 253\n",
      "2024-11-26 06:38:37.736165: Current learning rate: 0.0053\n",
      "2024-11-26 06:40:47.107267: train_loss -0.7849\n",
      "2024-11-26 06:40:47.116270: val_loss -0.2441\n",
      "2024-11-26 06:40:47.120270: Pseudo dice [0.6327]\n",
      "2024-11-26 06:40:47.125271: Epoch time: 129.38 s\n",
      "2024-11-26 06:40:48.108493: \n",
      "2024-11-26 06:40:48.114494: Epoch 254\n",
      "2024-11-26 06:40:48.118495: Current learning rate: 0.00528\n",
      "2024-11-26 06:42:57.591749: train_loss -0.7484\n",
      "2024-11-26 06:42:57.599750: val_loss -0.522\n",
      "2024-11-26 06:42:57.604752: Pseudo dice [0.759]\n",
      "2024-11-26 06:42:57.608752: Epoch time: 129.48 s\n",
      "2024-11-26 06:42:58.582971: \n",
      "2024-11-26 06:42:58.588973: Epoch 255\n",
      "2024-11-26 06:42:58.592974: Current learning rate: 0.00526\n",
      "2024-11-26 06:45:08.224287: train_loss -0.7524\n",
      "2024-11-26 06:45:08.233289: val_loss -0.449\n",
      "2024-11-26 06:45:08.237290: Pseudo dice [0.7319]\n",
      "2024-11-26 06:45:08.241291: Epoch time: 129.64 s\n",
      "2024-11-26 06:45:09.394387: \n",
      "2024-11-26 06:45:09.400388: Epoch 256\n",
      "2024-11-26 06:45:09.404389: Current learning rate: 0.00524\n",
      "2024-11-26 06:47:19.082646: train_loss -0.7739\n",
      "2024-11-26 06:47:19.091649: val_loss -0.4833\n",
      "2024-11-26 06:47:19.096649: Pseudo dice [0.747]\n",
      "2024-11-26 06:47:19.100650: Epoch time: 129.69 s\n",
      "2024-11-26 06:47:20.078870: \n",
      "2024-11-26 06:47:20.084871: Epoch 257\n",
      "2024-11-26 06:47:20.088872: Current learning rate: 0.00522\n",
      "2024-11-26 06:49:29.874010: train_loss -0.7815\n",
      "2024-11-26 06:49:29.881012: val_loss -0.4535\n",
      "2024-11-26 06:49:29.888013: Pseudo dice [0.7154]\n",
      "2024-11-26 06:49:29.893014: Epoch time: 129.8 s\n",
      "2024-11-26 06:49:30.873235: \n",
      "2024-11-26 06:49:30.878236: Epoch 258\n",
      "2024-11-26 06:49:30.882236: Current learning rate: 0.0052\n",
      "2024-11-26 06:51:40.528166: train_loss -0.7701\n",
      "2024-11-26 06:51:40.536168: val_loss -0.5285\n",
      "2024-11-26 06:51:40.541169: Pseudo dice [0.7694]\n",
      "2024-11-26 06:51:40.548171: Epoch time: 129.66 s\n",
      "2024-11-26 06:51:41.527392: \n",
      "2024-11-26 06:51:41.533393: Epoch 259\n",
      "2024-11-26 06:51:41.537394: Current learning rate: 0.00518\n",
      "2024-11-26 06:53:51.050237: train_loss -0.7732\n",
      "2024-11-26 06:53:51.058239: val_loss -0.4995\n",
      "2024-11-26 06:53:51.063240: Pseudo dice [0.7555]\n",
      "2024-11-26 06:53:51.067240: Epoch time: 129.52 s\n",
      "2024-11-26 06:53:52.046461: \n",
      "2024-11-26 06:53:52.052462: Epoch 260\n",
      "2024-11-26 06:53:52.056463: Current learning rate: 0.00517\n",
      "2024-11-26 06:56:01.616855: train_loss -0.7743\n",
      "2024-11-26 06:56:01.625857: val_loss -0.5468\n",
      "2024-11-26 06:56:01.632859: Pseudo dice [0.8011]\n",
      "2024-11-26 06:56:01.638860: Epoch time: 129.57 s\n",
      "2024-11-26 06:56:02.626082: \n",
      "2024-11-26 06:56:02.632083: Epoch 261\n",
      "2024-11-26 06:56:02.637085: Current learning rate: 0.00515\n",
      "2024-11-26 06:58:12.182638: train_loss -0.8036\n",
      "2024-11-26 06:58:12.192640: val_loss -0.3383\n",
      "2024-11-26 06:58:12.197642: Pseudo dice [0.6596]\n",
      "2024-11-26 06:58:12.201642: Epoch time: 129.56 s\n",
      "2024-11-26 06:58:13.180862: \n",
      "2024-11-26 06:58:13.186864: Epoch 262\n",
      "2024-11-26 06:58:13.189864: Current learning rate: 0.00513\n",
      "2024-11-26 07:00:22.840137: train_loss -0.775\n",
      "2024-11-26 07:00:22.847140: val_loss -0.5393\n",
      "2024-11-26 07:00:22.853142: Pseudo dice [0.7875]\n",
      "2024-11-26 07:00:22.857142: Epoch time: 129.66 s\n",
      "2024-11-26 07:00:24.014402: \n",
      "2024-11-26 07:00:24.020404: Epoch 263\n",
      "2024-11-26 07:00:24.023404: Current learning rate: 0.00511\n",
      "2024-11-26 07:02:33.733500: train_loss -0.7863\n",
      "2024-11-26 07:02:33.741503: val_loss -0.3956\n",
      "2024-11-26 07:02:33.748505: Pseudo dice [0.7025]\n",
      "2024-11-26 07:02:33.753505: Epoch time: 129.72 s\n",
      "2024-11-26 07:02:34.736727: \n",
      "2024-11-26 07:02:34.742728: Epoch 264\n",
      "2024-11-26 07:02:34.746728: Current learning rate: 0.00509\n",
      "2024-11-26 07:04:44.343664: train_loss -0.7659\n",
      "2024-11-26 07:04:44.352667: val_loss -0.268\n",
      "2024-11-26 07:04:44.359668: Pseudo dice [0.6648]\n",
      "2024-11-26 07:04:44.364669: Epoch time: 129.61 s\n",
      "2024-11-26 07:04:45.350164: \n",
      "2024-11-26 07:04:45.356166: Epoch 265\n",
      "2024-11-26 07:04:45.360167: Current learning rate: 0.00507\n",
      "2024-11-26 07:06:55.022784: train_loss -0.7691\n",
      "2024-11-26 07:06:55.031786: val_loss -0.5033\n",
      "2024-11-26 07:06:55.037788: Pseudo dice [0.7382]\n",
      "2024-11-26 07:06:55.043789: Epoch time: 129.67 s\n",
      "2024-11-26 07:06:56.045014: \n",
      "2024-11-26 07:06:56.051016: Epoch 266\n",
      "2024-11-26 07:06:56.055017: Current learning rate: 0.00505\n",
      "2024-11-26 07:09:05.673000: train_loss -0.7718\n",
      "2024-11-26 07:09:05.682003: val_loss -0.4777\n",
      "2024-11-26 07:09:05.686003: Pseudo dice [0.7522]\n",
      "2024-11-26 07:09:05.691005: Epoch time: 129.63 s\n",
      "2024-11-26 07:09:06.673214: \n",
      "2024-11-26 07:09:06.678216: Epoch 267\n",
      "2024-11-26 07:09:06.684090: Current learning rate: 0.00503\n",
      "2024-11-26 07:11:16.298497: train_loss -0.7823\n",
      "2024-11-26 07:11:16.308499: val_loss -0.5253\n",
      "2024-11-26 07:11:16.314500: Pseudo dice [0.7661]\n",
      "2024-11-26 07:11:16.320502: Epoch time: 129.63 s\n",
      "2024-11-26 07:11:17.307724: \n",
      "2024-11-26 07:11:17.313726: Epoch 268\n",
      "2024-11-26 07:11:17.317727: Current learning rate: 0.00501\n",
      "2024-11-26 07:13:26.952995: train_loss -0.8078\n",
      "2024-11-26 07:13:26.959996: val_loss -0.5378\n",
      "2024-11-26 07:13:26.965997: Pseudo dice [0.7864]\n",
      "2024-11-26 07:13:26.970999: Epoch time: 129.65 s\n",
      "2024-11-26 07:13:27.956220: \n",
      "2024-11-26 07:13:27.962222: Epoch 269\n",
      "2024-11-26 07:13:27.966223: Current learning rate: 0.00499\n",
      "2024-11-26 07:15:37.617668: train_loss -0.7856\n",
      "2024-11-26 07:15:37.626670: val_loss -0.4513\n",
      "2024-11-26 07:15:37.632672: Pseudo dice [0.7384]\n",
      "2024-11-26 07:15:37.637673: Epoch time: 129.66 s\n",
      "2024-11-26 07:15:38.617893: \n",
      "2024-11-26 07:15:38.622895: Epoch 270\n",
      "2024-11-26 07:15:38.626896: Current learning rate: 0.00497\n",
      "2024-11-26 07:17:48.266339: train_loss -0.7705\n",
      "2024-11-26 07:17:48.273340: val_loss -0.4692\n",
      "2024-11-26 07:17:48.278341: Pseudo dice [0.7217]\n",
      "2024-11-26 07:17:48.284342: Epoch time: 129.65 s\n",
      "2024-11-26 07:17:49.446894: \n",
      "2024-11-26 07:17:49.453895: Epoch 271\n",
      "2024-11-26 07:17:49.458896: Current learning rate: 0.00495\n",
      "2024-11-26 07:19:59.061838: train_loss -0.7729\n",
      "2024-11-26 07:19:59.071841: val_loss -0.5976\n",
      "2024-11-26 07:19:59.077842: Pseudo dice [0.7858]\n",
      "2024-11-26 07:19:59.084844: Epoch time: 129.62 s\n",
      "2024-11-26 07:20:00.071066: \n",
      "2024-11-26 07:20:00.078067: Epoch 272\n",
      "2024-11-26 07:20:00.082068: Current learning rate: 0.00493\n",
      "2024-11-26 07:22:09.893996: train_loss -0.802\n",
      "2024-11-26 07:22:09.903999: val_loss -0.4665\n",
      "2024-11-26 07:22:09.909000: Pseudo dice [0.7331]\n",
      "2024-11-26 07:22:09.915002: Epoch time: 129.82 s\n",
      "2024-11-26 07:22:10.896223: \n",
      "2024-11-26 07:22:10.902224: Epoch 273\n",
      "2024-11-26 07:22:10.906225: Current learning rate: 0.00491\n",
      "2024-11-26 07:24:20.648962: train_loss -0.8037\n",
      "2024-11-26 07:24:20.657965: val_loss -0.5361\n",
      "2024-11-26 07:24:20.662966: Pseudo dice [0.7871]\n",
      "2024-11-26 07:24:20.667967: Epoch time: 129.75 s\n",
      "2024-11-26 07:24:21.650188: \n",
      "2024-11-26 07:24:21.656189: Epoch 274\n",
      "2024-11-26 07:24:21.660190: Current learning rate: 0.00489\n",
      "2024-11-26 07:26:31.339723: train_loss -0.8082\n",
      "2024-11-26 07:26:31.348725: val_loss -0.6115\n",
      "2024-11-26 07:26:31.357728: Pseudo dice [0.8125]\n",
      "2024-11-26 07:26:31.363729: Epoch time: 129.69 s\n",
      "2024-11-26 07:26:31.369731: Yayy! New best EMA pseudo Dice: 0.7537\n",
      "2024-11-26 07:26:32.591774: \n",
      "2024-11-26 07:26:32.598775: Epoch 275\n",
      "2024-11-26 07:26:32.602776: Current learning rate: 0.00487\n",
      "2024-11-26 07:28:42.155048: train_loss -0.8051\n",
      "2024-11-26 07:28:42.165050: val_loss -0.5496\n",
      "2024-11-26 07:28:42.173052: Pseudo dice [0.7806]\n",
      "2024-11-26 07:28:42.179054: Epoch time: 129.56 s\n",
      "2024-11-26 07:28:42.185055: Yayy! New best EMA pseudo Dice: 0.7564\n",
      "2024-11-26 07:28:43.414530: \n",
      "2024-11-26 07:28:43.420532: Epoch 276\n",
      "2024-11-26 07:28:43.424534: Current learning rate: 0.00485\n",
      "2024-11-26 07:30:53.013846: train_loss -0.8125\n",
      "2024-11-26 07:30:53.022848: val_loss -0.566\n",
      "2024-11-26 07:30:53.028850: Pseudo dice [0.7781]\n",
      "2024-11-26 07:30:53.033850: Epoch time: 129.6 s\n",
      "2024-11-26 07:30:53.040851: Yayy! New best EMA pseudo Dice: 0.7586\n",
      "2024-11-26 07:30:54.267096: \n",
      "2024-11-26 07:30:54.273097: Epoch 277\n",
      "2024-11-26 07:30:54.277098: Current learning rate: 0.00484\n",
      "2024-11-26 07:33:03.961038: train_loss -0.8137\n",
      "2024-11-26 07:33:03.971040: val_loss -0.4095\n",
      "2024-11-26 07:33:03.975041: Pseudo dice [0.7231]\n",
      "2024-11-26 07:33:03.983043: Epoch time: 129.69 s\n",
      "2024-11-26 07:33:05.133302: \n",
      "2024-11-26 07:33:05.139303: Epoch 278\n",
      "2024-11-26 07:33:05.143304: Current learning rate: 0.00482\n",
      "2024-11-26 07:35:14.887066: train_loss -0.7813\n",
      "2024-11-26 07:35:14.896069: val_loss -0.5799\n",
      "2024-11-26 07:35:14.902069: Pseudo dice [0.7908]\n",
      "2024-11-26 07:35:14.907071: Epoch time: 129.75 s\n",
      "2024-11-26 07:35:14.912071: Yayy! New best EMA pseudo Dice: 0.7586\n",
      "2024-11-26 07:35:16.132198: \n",
      "2024-11-26 07:35:16.138199: Epoch 279\n",
      "2024-11-26 07:35:16.142200: Current learning rate: 0.0048\n",
      "2024-11-26 07:37:25.777247: train_loss -0.765\n",
      "2024-11-26 07:37:25.787249: val_loss -0.422\n",
      "2024-11-26 07:37:25.795251: Pseudo dice [0.7252]\n",
      "2024-11-26 07:37:25.800252: Epoch time: 129.65 s\n",
      "2024-11-26 07:37:26.782475: \n",
      "2024-11-26 07:37:26.789475: Epoch 280\n",
      "2024-11-26 07:37:26.793476: Current learning rate: 0.00478\n",
      "2024-11-26 07:39:36.481767: train_loss -0.7833\n",
      "2024-11-26 07:39:36.488769: val_loss -0.5672\n",
      "2024-11-26 07:39:36.495772: Pseudo dice [0.7773]\n",
      "2024-11-26 07:39:36.499771: Epoch time: 129.7 s\n",
      "2024-11-26 07:39:37.483993: \n",
      "2024-11-26 07:39:37.489994: Epoch 281\n",
      "2024-11-26 07:39:37.493994: Current learning rate: 0.00476\n",
      "2024-11-26 07:41:47.119543: train_loss -0.7949\n",
      "2024-11-26 07:41:47.127545: val_loss -0.4742\n",
      "2024-11-26 07:41:47.133546: Pseudo dice [0.7458]\n",
      "2024-11-26 07:41:47.139548: Epoch time: 129.64 s\n",
      "2024-11-26 07:41:48.119767: \n",
      "2024-11-26 07:41:48.125770: Epoch 282\n",
      "2024-11-26 07:41:48.128770: Current learning rate: 0.00474\n",
      "2024-11-26 07:43:57.774142: train_loss -0.7713\n",
      "2024-11-26 07:43:57.783144: val_loss -0.4354\n",
      "2024-11-26 07:43:57.788146: Pseudo dice [0.735]\n",
      "2024-11-26 07:43:57.792146: Epoch time: 129.66 s\n",
      "2024-11-26 07:43:58.775367: \n",
      "2024-11-26 07:43:58.781368: Epoch 283\n",
      "2024-11-26 07:43:58.784369: Current learning rate: 0.00472\n",
      "2024-11-26 07:46:08.401561: train_loss -0.793\n",
      "2024-11-26 07:46:08.413564: val_loss -0.5194\n",
      "2024-11-26 07:46:08.421564: Pseudo dice [0.7681]\n",
      "2024-11-26 07:46:08.426566: Epoch time: 129.63 s\n",
      "2024-11-26 07:46:09.408083: \n",
      "2024-11-26 07:46:09.414081: Epoch 284\n",
      "2024-11-26 07:46:09.418082: Current learning rate: 0.0047\n",
      "2024-11-26 07:48:19.042412: train_loss -0.808\n",
      "2024-11-26 07:48:19.051414: val_loss -0.4466\n",
      "2024-11-26 07:48:19.058414: Pseudo dice [0.7219]\n",
      "2024-11-26 07:48:19.063415: Epoch time: 129.64 s\n",
      "2024-11-26 07:48:20.217676: \n",
      "2024-11-26 07:48:20.223072: Epoch 285\n",
      "2024-11-26 07:48:20.227072: Current learning rate: 0.00468\n",
      "2024-11-26 07:50:29.865854: train_loss -0.7747\n",
      "2024-11-26 07:50:29.874855: val_loss -0.5013\n",
      "2024-11-26 07:50:29.880856: Pseudo dice [0.7759]\n",
      "2024-11-26 07:50:29.884856: Epoch time: 129.65 s\n",
      "2024-11-26 07:50:30.864239: \n",
      "2024-11-26 07:50:30.870240: Epoch 286\n",
      "2024-11-26 07:50:30.875242: Current learning rate: 0.00466\n",
      "2024-11-26 07:52:40.465872: train_loss -0.8066\n",
      "2024-11-26 07:52:40.474874: val_loss -0.4524\n",
      "2024-11-26 07:52:40.482876: Pseudo dice [0.7291]\n",
      "2024-11-26 07:52:40.488878: Epoch time: 129.6 s\n",
      "2024-11-26 07:52:41.484101: \n",
      "2024-11-26 07:52:41.490103: Epoch 287\n",
      "2024-11-26 07:52:41.494103: Current learning rate: 0.00464\n",
      "2024-11-26 07:54:51.082850: train_loss -0.7341\n",
      "2024-11-26 07:54:51.093852: val_loss -0.2398\n",
      "2024-11-26 07:54:51.099853: Pseudo dice [0.6528]\n",
      "2024-11-26 07:54:51.105855: Epoch time: 129.6 s\n",
      "2024-11-26 07:54:52.104080: \n",
      "2024-11-26 07:54:52.110082: Epoch 288\n",
      "2024-11-26 07:54:52.114082: Current learning rate: 0.00462\n",
      "2024-11-26 07:57:01.706577: train_loss -0.7707\n",
      "2024-11-26 07:57:01.715580: val_loss -0.4924\n",
      "2024-11-26 07:57:01.721580: Pseudo dice [0.7511]\n",
      "2024-11-26 07:57:01.726582: Epoch time: 129.6 s\n",
      "2024-11-26 07:57:02.725806: \n",
      "2024-11-26 07:57:02.730808: Epoch 289\n",
      "2024-11-26 07:57:02.734809: Current learning rate: 0.0046\n",
      "2024-11-26 07:59:12.353709: train_loss -0.7458\n",
      "2024-11-26 07:59:12.363711: val_loss -0.5142\n",
      "2024-11-26 07:59:12.370714: Pseudo dice [0.7673]\n",
      "2024-11-26 07:59:12.376715: Epoch time: 129.63 s\n",
      "2024-11-26 07:59:13.376940: \n",
      "2024-11-26 07:59:13.382941: Epoch 290\n",
      "2024-11-26 07:59:13.387718: Current learning rate: 0.00458\n",
      "2024-11-26 08:01:23.069635: train_loss -0.7693\n",
      "2024-11-26 08:01:23.078637: val_loss -0.4811\n",
      "2024-11-26 08:01:23.085638: Pseudo dice [0.7517]\n",
      "2024-11-26 08:01:23.092640: Epoch time: 129.69 s\n",
      "2024-11-26 08:01:24.095866: \n",
      "2024-11-26 08:01:24.101867: Epoch 291\n",
      "2024-11-26 08:01:24.106869: Current learning rate: 0.00456\n",
      "2024-11-26 08:03:33.774342: train_loss -0.7848\n",
      "2024-11-26 08:03:33.782344: val_loss -0.4623\n",
      "2024-11-26 08:03:33.789346: Pseudo dice [0.761]\n",
      "2024-11-26 08:03:33.794346: Epoch time: 129.68 s\n",
      "2024-11-26 08:03:34.974887: \n",
      "2024-11-26 08:03:34.981414: Epoch 292\n",
      "2024-11-26 08:03:34.985416: Current learning rate: 0.00454\n",
      "2024-11-26 08:05:44.600341: train_loss -0.8052\n",
      "2024-11-26 08:05:44.609344: val_loss -0.4812\n",
      "2024-11-26 08:05:44.617345: Pseudo dice [0.7565]\n",
      "2024-11-26 08:05:44.622346: Epoch time: 129.63 s\n",
      "2024-11-26 08:05:45.617570: \n",
      "2024-11-26 08:05:45.623571: Epoch 293\n",
      "2024-11-26 08:05:45.627572: Current learning rate: 0.00452\n",
      "2024-11-26 08:07:55.336756: train_loss -0.7906\n",
      "2024-11-26 08:07:55.344759: val_loss -0.2977\n",
      "2024-11-26 08:07:55.349759: Pseudo dice [0.6636]\n",
      "2024-11-26 08:07:55.356761: Epoch time: 129.72 s\n",
      "2024-11-26 08:07:56.357262: \n",
      "2024-11-26 08:07:56.364263: Epoch 294\n",
      "2024-11-26 08:07:56.368263: Current learning rate: 0.0045\n",
      "2024-11-26 08:10:05.957246: train_loss -0.8069\n",
      "2024-11-26 08:10:05.966248: val_loss -0.1882\n",
      "2024-11-26 08:10:05.974250: Pseudo dice [0.6237]\n",
      "2024-11-26 08:10:05.980251: Epoch time: 129.6 s\n",
      "2024-11-26 08:10:06.985477: \n",
      "2024-11-26 08:10:06.991478: Epoch 295\n",
      "2024-11-26 08:10:06.995480: Current learning rate: 0.00448\n",
      "2024-11-26 08:12:16.609371: train_loss -0.7809\n",
      "2024-11-26 08:12:16.618373: val_loss -0.2776\n",
      "2024-11-26 08:12:16.624375: Pseudo dice [0.6767]\n",
      "2024-11-26 08:12:16.629377: Epoch time: 129.62 s\n",
      "2024-11-26 08:12:17.619599: \n",
      "2024-11-26 08:12:17.624600: Epoch 296\n",
      "2024-11-26 08:12:17.630492: Current learning rate: 0.00446\n",
      "2024-11-26 08:14:27.235113: train_loss -0.7824\n",
      "2024-11-26 08:14:27.245117: val_loss -0.2953\n",
      "2024-11-26 08:14:27.251117: Pseudo dice [0.6694]\n",
      "2024-11-26 08:14:27.258120: Epoch time: 129.62 s\n",
      "2024-11-26 08:14:28.247342: \n",
      "2024-11-26 08:14:28.253342: Epoch 297\n",
      "2024-11-26 08:14:28.257344: Current learning rate: 0.00444\n",
      "2024-11-26 08:16:37.875683: train_loss -0.7881\n",
      "2024-11-26 08:16:37.884684: val_loss -0.5196\n",
      "2024-11-26 08:16:37.892686: Pseudo dice [0.7608]\n",
      "2024-11-26 08:16:37.898687: Epoch time: 129.63 s\n",
      "2024-11-26 08:16:38.906914: \n",
      "2024-11-26 08:16:38.912915: Epoch 298\n",
      "2024-11-26 08:16:38.916916: Current learning rate: 0.00442\n",
      "2024-11-26 08:18:48.554112: train_loss -0.7985\n",
      "2024-11-26 08:18:48.561114: val_loss -0.544\n",
      "2024-11-26 08:18:48.570115: Pseudo dice [0.7974]\n",
      "2024-11-26 08:18:48.577119: Epoch time: 129.65 s\n",
      "2024-11-26 08:18:49.573341: \n",
      "2024-11-26 08:18:49.580343: Epoch 299\n",
      "2024-11-26 08:18:49.584344: Current learning rate: 0.0044\n",
      "2024-11-26 08:20:59.138689: train_loss -0.771\n",
      "2024-11-26 08:20:59.147691: val_loss -0.1271\n",
      "2024-11-26 08:20:59.153693: Pseudo dice [0.6154]\n",
      "2024-11-26 08:20:59.160694: Epoch time: 129.57 s\n",
      "2024-11-26 08:21:00.573175: \n",
      "2024-11-26 08:21:00.579176: Epoch 300\n",
      "2024-11-26 08:21:00.583178: Current learning rate: 0.00438\n",
      "2024-11-26 08:23:10.145383: train_loss -0.7509\n",
      "2024-11-26 08:23:10.154386: val_loss -0.5923\n",
      "2024-11-26 08:23:10.163388: Pseudo dice [0.7982]\n",
      "2024-11-26 08:23:10.168389: Epoch time: 129.57 s\n",
      "2024-11-26 08:23:11.163612: \n",
      "2024-11-26 08:23:11.168614: Epoch 301\n",
      "2024-11-26 08:23:11.172614: Current learning rate: 0.00436\n",
      "2024-11-26 08:25:20.760756: train_loss -0.7686\n",
      "2024-11-26 08:25:20.769758: val_loss -0.2602\n",
      "2024-11-26 08:25:20.774758: Pseudo dice [0.6468]\n",
      "2024-11-26 08:25:20.782760: Epoch time: 129.6 s\n",
      "2024-11-26 08:25:21.782985: \n",
      "2024-11-26 08:25:21.789987: Epoch 302\n",
      "2024-11-26 08:25:21.794987: Current learning rate: 0.00434\n",
      "2024-11-26 08:27:31.381311: train_loss -0.8059\n",
      "2024-11-26 08:27:31.391315: val_loss -0.5252\n",
      "2024-11-26 08:27:31.397314: Pseudo dice [0.7751]\n",
      "2024-11-26 08:27:31.402315: Epoch time: 129.6 s\n",
      "2024-11-26 08:27:32.394539: \n",
      "2024-11-26 08:27:32.400540: Epoch 303\n",
      "2024-11-26 08:27:32.404541: Current learning rate: 0.00432\n",
      "2024-11-26 08:29:42.001804: train_loss -0.7805\n",
      "2024-11-26 08:29:42.010807: val_loss -0.3835\n",
      "2024-11-26 08:29:42.018808: Pseudo dice [0.704]\n",
      "2024-11-26 08:29:42.024809: Epoch time: 129.61 s\n",
      "2024-11-26 08:29:43.027435: \n",
      "2024-11-26 08:29:43.033435: Epoch 304\n",
      "2024-11-26 08:29:43.037436: Current learning rate: 0.0043\n",
      "2024-11-26 08:31:52.730204: train_loss -0.7846\n",
      "2024-11-26 08:31:52.739206: val_loss -0.4645\n",
      "2024-11-26 08:31:52.743207: Pseudo dice [0.7482]\n",
      "2024-11-26 08:31:52.750208: Epoch time: 129.7 s\n",
      "2024-11-26 08:31:53.751435: \n",
      "2024-11-26 08:31:53.757436: Epoch 305\n",
      "2024-11-26 08:31:53.761436: Current learning rate: 0.00429\n",
      "2024-11-26 08:34:03.507045: train_loss -0.8138\n",
      "2024-11-26 08:34:03.515046: val_loss -0.397\n",
      "2024-11-26 08:34:03.520047: Pseudo dice [0.7035]\n",
      "2024-11-26 08:34:03.526048: Epoch time: 129.76 s\n",
      "2024-11-26 08:34:04.528274: \n",
      "2024-11-26 08:34:04.534275: Epoch 306\n",
      "2024-11-26 08:34:04.538275: Current learning rate: 0.00427\n",
      "2024-11-26 08:36:14.242437: train_loss -0.8197\n",
      "2024-11-26 08:36:14.251439: val_loss -0.4484\n",
      "2024-11-26 08:36:14.259441: Pseudo dice [0.7488]\n",
      "2024-11-26 08:36:14.264441: Epoch time: 129.72 s\n",
      "2024-11-26 08:36:15.445708: \n",
      "2024-11-26 08:36:15.451709: Epoch 307\n",
      "2024-11-26 08:36:15.455710: Current learning rate: 0.00425\n",
      "2024-11-26 08:38:25.058685: train_loss -0.8152\n",
      "2024-11-26 08:38:25.067686: val_loss -0.471\n",
      "2024-11-26 08:38:25.074688: Pseudo dice [0.7281]\n",
      "2024-11-26 08:38:25.078689: Epoch time: 129.61 s\n",
      "2024-11-26 08:38:26.082915: \n",
      "2024-11-26 08:38:26.088916: Epoch 308\n",
      "2024-11-26 08:38:26.092917: Current learning rate: 0.00423\n",
      "2024-11-26 08:40:35.713034: train_loss -0.8056\n",
      "2024-11-26 08:40:35.722036: val_loss -0.4195\n",
      "2024-11-26 08:40:35.730038: Pseudo dice [0.7405]\n",
      "2024-11-26 08:40:35.735039: Epoch time: 129.63 s\n",
      "2024-11-26 08:40:36.734648: \n",
      "2024-11-26 08:40:36.739650: Epoch 309\n",
      "2024-11-26 08:40:36.743652: Current learning rate: 0.00421\n",
      "2024-11-26 08:42:46.350368: train_loss -0.8139\n",
      "2024-11-26 08:42:46.359370: val_loss -0.5494\n",
      "2024-11-26 08:42:46.365372: Pseudo dice [0.7886]\n",
      "2024-11-26 08:42:46.370373: Epoch time: 129.62 s\n",
      "2024-11-26 08:42:47.366915: \n",
      "2024-11-26 08:42:47.372913: Epoch 310\n",
      "2024-11-26 08:42:47.376914: Current learning rate: 0.00419\n",
      "2024-11-26 08:44:57.040437: train_loss -0.8229\n",
      "2024-11-26 08:44:57.049439: val_loss -0.5259\n",
      "2024-11-26 08:44:57.058442: Pseudo dice [0.7513]\n",
      "2024-11-26 08:44:57.063442: Epoch time: 129.67 s\n",
      "2024-11-26 08:44:58.071670: \n",
      "2024-11-26 08:44:58.077671: Epoch 311\n",
      "2024-11-26 08:44:58.081672: Current learning rate: 0.00417\n",
      "2024-11-26 08:47:07.814617: train_loss -0.8186\n",
      "2024-11-26 08:47:07.825620: val_loss -0.5808\n",
      "2024-11-26 08:47:07.830622: Pseudo dice [0.7944]\n",
      "2024-11-26 08:47:07.837624: Epoch time: 129.74 s\n",
      "2024-11-26 08:47:08.845685: \n",
      "2024-11-26 08:47:08.851686: Epoch 312\n",
      "2024-11-26 08:47:08.855686: Current learning rate: 0.00415\n",
      "2024-11-26 08:49:18.488175: train_loss -0.8143\n",
      "2024-11-26 08:49:18.497176: val_loss -0.5301\n",
      "2024-11-26 08:49:18.505178: Pseudo dice [0.7751]\n",
      "2024-11-26 08:49:18.510180: Epoch time: 129.64 s\n",
      "2024-11-26 08:49:19.513405: \n",
      "2024-11-26 08:49:19.519761: Epoch 313\n",
      "2024-11-26 08:49:19.523762: Current learning rate: 0.00413\n",
      "2024-11-26 08:51:29.122148: train_loss -0.8199\n",
      "2024-11-26 08:51:29.131150: val_loss -0.3662\n",
      "2024-11-26 08:51:29.135151: Pseudo dice [0.6819]\n",
      "2024-11-26 08:51:29.142152: Epoch time: 129.61 s\n",
      "2024-11-26 08:51:30.314706: \n",
      "2024-11-26 08:51:30.321707: Epoch 314\n",
      "2024-11-26 08:51:30.326708: Current learning rate: 0.00411\n",
      "2024-11-26 08:53:39.921934: train_loss -0.8084\n",
      "2024-11-26 08:53:39.929936: val_loss -0.2397\n",
      "2024-11-26 08:53:39.938938: Pseudo dice [0.6446]\n",
      "2024-11-26 08:53:39.944939: Epoch time: 129.61 s\n",
      "2024-11-26 08:53:40.946075: \n",
      "2024-11-26 08:53:40.952076: Epoch 315\n",
      "2024-11-26 08:53:40.956077: Current learning rate: 0.00409\n",
      "2024-11-26 08:55:50.572864: train_loss -0.7642\n",
      "2024-11-26 08:55:50.581865: val_loss -0.4947\n",
      "2024-11-26 08:55:50.590867: Pseudo dice [0.7662]\n",
      "2024-11-26 08:55:50.596869: Epoch time: 129.63 s\n",
      "2024-11-26 08:55:51.601804: \n",
      "2024-11-26 08:55:51.607804: Epoch 316\n",
      "2024-11-26 08:55:51.611805: Current learning rate: 0.00407\n",
      "2024-11-26 08:58:01.223021: train_loss -0.7586\n",
      "2024-11-26 08:58:01.232023: val_loss -0.3655\n",
      "2024-11-26 08:58:01.237024: Pseudo dice [0.6551]\n",
      "2024-11-26 08:58:01.242025: Epoch time: 129.62 s\n",
      "2024-11-26 08:58:02.251252: \n",
      "2024-11-26 08:58:02.258255: Epoch 317\n",
      "2024-11-26 08:58:02.262256: Current learning rate: 0.00405\n",
      "2024-11-26 09:00:11.852805: train_loss -0.8149\n",
      "2024-11-26 09:00:11.861807: val_loss -0.4333\n",
      "2024-11-26 09:00:11.868810: Pseudo dice [0.7359]\n",
      "2024-11-26 09:00:11.872809: Epoch time: 129.6 s\n",
      "2024-11-26 09:00:12.869034: \n",
      "2024-11-26 09:00:12.876035: Epoch 318\n",
      "2024-11-26 09:00:12.880036: Current learning rate: 0.00403\n",
      "2024-11-26 09:02:22.468963: train_loss -0.7941\n",
      "2024-11-26 09:02:22.478966: val_loss -0.4863\n",
      "2024-11-26 09:02:22.482966: Pseudo dice [0.74]\n",
      "2024-11-26 09:02:22.487967: Epoch time: 129.6 s\n",
      "2024-11-26 09:02:23.496195: \n",
      "2024-11-26 09:02:23.502195: Epoch 319\n",
      "2024-11-26 09:02:23.506196: Current learning rate: 0.00401\n",
      "2024-11-26 09:04:33.091827: train_loss -0.8009\n",
      "2024-11-26 09:04:33.100829: val_loss -0.3656\n",
      "2024-11-26 09:04:33.107831: Pseudo dice [0.6924]\n",
      "2024-11-26 09:04:33.111832: Epoch time: 129.6 s\n",
      "2024-11-26 09:04:34.116791: \n",
      "2024-11-26 09:04:34.121792: Epoch 320\n",
      "2024-11-26 09:04:34.125793: Current learning rate: 0.00399\n",
      "2024-11-26 09:06:43.693739: train_loss -0.8011\n",
      "2024-11-26 09:06:43.703742: val_loss -0.5025\n",
      "2024-11-26 09:06:43.712745: Pseudo dice [0.7527]\n",
      "2024-11-26 09:06:43.716745: Epoch time: 129.58 s\n",
      "2024-11-26 09:06:44.894318: \n",
      "2024-11-26 09:06:44.901319: Epoch 321\n",
      "2024-11-26 09:06:44.905320: Current learning rate: 0.00397\n",
      "2024-11-26 09:08:54.465281: train_loss -0.8106\n",
      "2024-11-26 09:08:54.475283: val_loss -0.5136\n",
      "2024-11-26 09:08:54.482285: Pseudo dice [0.7575]\n",
      "2024-11-26 09:08:54.488286: Epoch time: 129.57 s\n",
      "2024-11-26 09:08:55.495513: \n",
      "2024-11-26 09:08:55.501514: Epoch 322\n",
      "2024-11-26 09:08:55.505515: Current learning rate: 0.00395\n",
      "2024-11-26 09:11:05.147024: train_loss -0.809\n",
      "2024-11-26 09:11:05.155025: val_loss -0.5194\n",
      "2024-11-26 09:11:05.164028: Pseudo dice [0.7665]\n",
      "2024-11-26 09:11:05.170029: Epoch time: 129.65 s\n",
      "2024-11-26 09:11:06.172378: \n",
      "2024-11-26 09:11:06.178381: Epoch 323\n",
      "2024-11-26 09:11:06.182382: Current learning rate: 0.00393\n",
      "2024-11-26 09:13:15.979327: train_loss -0.7906\n",
      "2024-11-26 09:13:15.988329: val_loss -0.4374\n",
      "2024-11-26 09:13:15.994331: Pseudo dice [0.7053]\n",
      "2024-11-26 09:13:15.999332: Epoch time: 129.81 s\n",
      "2024-11-26 09:13:16.994556: \n",
      "2024-11-26 09:13:17.000557: Epoch 324\n",
      "2024-11-26 09:13:17.004558: Current learning rate: 0.00391\n",
      "2024-11-26 09:15:26.778188: train_loss -0.7845\n",
      "2024-11-26 09:15:26.778188: val_loss -0.5344\n",
      "2024-11-26 09:15:26.788187: Pseudo dice [0.7808]\n",
      "2024-11-26 09:15:26.798189: Epoch time: 129.78 s\n",
      "2024-11-26 09:15:27.808202: \n",
      "2024-11-26 09:15:27.818202: Epoch 325\n",
      "2024-11-26 09:15:27.818202: Current learning rate: 0.00389\n",
      "2024-11-26 09:17:37.486145: train_loss -0.7977\n",
      "2024-11-26 09:17:37.496146: val_loss -0.5136\n",
      "2024-11-26 09:17:37.496146: Pseudo dice [0.7637]\n",
      "2024-11-26 09:17:37.506146: Epoch time: 129.68 s\n",
      "2024-11-26 09:17:38.516160: \n",
      "2024-11-26 09:17:38.516160: Epoch 326\n",
      "2024-11-26 09:17:38.526160: Current learning rate: 0.00387\n",
      "2024-11-26 09:19:48.206532: train_loss -0.7752\n",
      "2024-11-26 09:19:48.206532: val_loss -0.3707\n",
      "2024-11-26 09:19:48.216532: Pseudo dice [0.6904]\n",
      "2024-11-26 09:19:48.216532: Epoch time: 129.69 s\n",
      "2024-11-26 09:19:49.226546: \n",
      "2024-11-26 09:19:49.236546: Epoch 327\n",
      "2024-11-26 09:19:49.236546: Current learning rate: 0.00385\n",
      "2024-11-26 09:21:58.882298: train_loss -0.7727\n",
      "2024-11-26 09:21:58.892298: val_loss -0.357\n",
      "2024-11-26 09:21:58.892298: Pseudo dice [0.6962]\n",
      "2024-11-26 09:21:58.902298: Epoch time: 129.66 s\n",
      "2024-11-26 09:22:00.092235: \n",
      "2024-11-26 09:22:00.092235: Epoch 328\n",
      "2024-11-26 09:22:00.102235: Current learning rate: 0.00383\n",
      "2024-11-26 09:24:09.775851: train_loss -0.7897\n",
      "2024-11-26 09:24:09.785852: val_loss -0.1443\n",
      "2024-11-26 09:24:09.785852: Pseudo dice [0.5699]\n",
      "2024-11-26 09:24:09.795851: Epoch time: 129.68 s\n",
      "2024-11-26 09:24:10.809552: \n",
      "2024-11-26 09:24:10.819552: Epoch 329\n",
      "2024-11-26 09:24:10.819552: Current learning rate: 0.00381\n",
      "2024-11-26 09:26:20.489838: train_loss -0.8044\n",
      "2024-11-26 09:26:20.499837: val_loss -0.2169\n",
      "2024-11-26 09:26:20.509839: Pseudo dice [0.6286]\n",
      "2024-11-26 09:26:20.509839: Epoch time: 129.68 s\n",
      "2024-11-26 09:26:21.519409: \n",
      "2024-11-26 09:26:21.529409: Epoch 330\n",
      "2024-11-26 09:26:21.529409: Current learning rate: 0.00379\n",
      "2024-11-26 09:28:31.129732: train_loss -0.7917\n",
      "2024-11-26 09:28:31.139733: val_loss -0.1105\n",
      "2024-11-26 09:28:31.149731: Pseudo dice [0.5676]\n",
      "2024-11-26 09:28:31.149731: Epoch time: 129.61 s\n",
      "2024-11-26 09:28:32.164153: \n",
      "2024-11-26 09:28:32.164153: Epoch 331\n",
      "2024-11-26 09:28:32.174153: Current learning rate: 0.00377\n",
      "2024-11-26 09:30:41.928628: train_loss -0.7927\n",
      "2024-11-26 09:30:41.935630: val_loss -0.4599\n",
      "2024-11-26 09:30:41.940630: Pseudo dice [0.7163]\n",
      "2024-11-26 09:30:41.945632: Epoch time: 129.76 s\n",
      "2024-11-26 09:30:42.963861: \n",
      "2024-11-26 09:30:42.969862: Epoch 332\n",
      "2024-11-26 09:30:42.973863: Current learning rate: 0.00375\n",
      "2024-11-26 09:32:54.823739: train_loss -0.8081\n",
      "2024-11-26 09:32:54.823739: val_loss -0.4595\n",
      "2024-11-26 09:32:54.833739: Pseudo dice [0.7409]\n",
      "2024-11-26 09:32:54.833739: Epoch time: 131.86 s\n",
      "2024-11-26 09:32:55.853449: \n",
      "2024-11-26 09:32:55.853449: Epoch 333\n",
      "2024-11-26 09:32:55.853449: Current learning rate: 0.00373\n",
      "2024-11-26 09:35:05.470939: train_loss -0.8085\n",
      "2024-11-26 09:35:05.470939: val_loss -0.3023\n",
      "2024-11-26 09:35:05.480938: Pseudo dice [0.6786]\n",
      "2024-11-26 09:35:05.490939: Epoch time: 129.62 s\n",
      "2024-11-26 09:35:06.500872: \n",
      "2024-11-26 09:35:06.500872: Epoch 334\n",
      "2024-11-26 09:35:06.510863: Current learning rate: 0.00371\n",
      "2024-11-26 09:37:16.134037: train_loss -0.8143\n",
      "2024-11-26 09:37:16.134037: val_loss -0.477\n",
      "2024-11-26 09:37:16.144038: Pseudo dice [0.7391]\n",
      "2024-11-26 09:37:16.154038: Epoch time: 129.63 s\n",
      "2024-11-26 09:37:17.364019: \n",
      "2024-11-26 09:37:17.364019: Epoch 335\n",
      "2024-11-26 09:37:17.364019: Current learning rate: 0.00369\n",
      "2024-11-26 09:39:27.027585: train_loss -0.8144\n",
      "2024-11-26 09:39:27.027585: val_loss 0.1175\n",
      "2024-11-26 09:39:27.037584: Pseudo dice [0.4867]\n",
      "2024-11-26 09:39:27.047584: Epoch time: 129.66 s\n",
      "2024-11-26 09:39:28.067607: \n",
      "2024-11-26 09:39:28.077606: Epoch 336\n",
      "2024-11-26 09:39:28.077606: Current learning rate: 0.00367\n",
      "2024-11-26 09:41:37.794525: train_loss -0.8156\n",
      "2024-11-26 09:41:37.794525: val_loss -0.1831\n",
      "2024-11-26 09:41:37.804526: Pseudo dice [0.6108]\n",
      "2024-11-26 09:41:37.804526: Epoch time: 129.73 s\n",
      "2024-11-26 09:41:38.844813: \n",
      "2024-11-26 09:41:38.844813: Epoch 337\n",
      "2024-11-26 09:41:38.844813: Current learning rate: 0.00365\n",
      "2024-11-26 09:43:48.494789: train_loss -0.8089\n",
      "2024-11-26 09:43:48.494789: val_loss -0.4362\n",
      "2024-11-26 09:43:48.504790: Pseudo dice [0.7212]\n",
      "2024-11-26 09:43:48.514790: Epoch time: 129.65 s\n",
      "2024-11-26 09:43:49.545101: \n",
      "2024-11-26 09:43:49.545101: Epoch 338\n",
      "2024-11-26 09:43:49.555094: Current learning rate: 0.00363\n",
      "2024-11-26 09:45:59.191718: train_loss -0.7949\n",
      "2024-11-26 09:45:59.191718: val_loss -0.5014\n",
      "2024-11-26 09:45:59.201720: Pseudo dice [0.7622]\n",
      "2024-11-26 09:45:59.211720: Epoch time: 129.65 s\n",
      "2024-11-26 09:46:00.241734: \n",
      "2024-11-26 09:46:00.241734: Epoch 339\n",
      "2024-11-26 09:46:00.251734: Current learning rate: 0.00361\n",
      "2024-11-26 09:48:09.908666: train_loss -0.7778\n",
      "2024-11-26 09:48:09.908666: val_loss -0.4704\n",
      "2024-11-26 09:48:09.918666: Pseudo dice [0.7381]\n",
      "2024-11-26 09:48:09.928666: Epoch time: 129.67 s\n",
      "2024-11-26 09:48:10.955239: \n",
      "2024-11-26 09:48:10.955239: Epoch 340\n",
      "2024-11-26 09:48:10.965239: Current learning rate: 0.00359\n",
      "2024-11-26 09:50:20.683110: train_loss -0.7726\n",
      "2024-11-26 09:50:20.683110: val_loss -0.4901\n",
      "2024-11-26 09:50:20.693110: Pseudo dice [0.7424]\n",
      "2024-11-26 09:50:20.693110: Epoch time: 129.73 s\n",
      "2024-11-26 09:50:21.718867: \n",
      "2024-11-26 09:50:21.718867: Epoch 341\n",
      "2024-11-26 09:50:21.728859: Current learning rate: 0.00357\n",
      "2024-11-26 09:52:31.385880: train_loss -0.789\n",
      "2024-11-26 09:52:31.385880: val_loss -0.4034\n",
      "2024-11-26 09:52:31.395883: Pseudo dice [0.7163]\n",
      "2024-11-26 09:52:31.395883: Epoch time: 129.67 s\n",
      "2024-11-26 09:52:32.605768: \n",
      "2024-11-26 09:52:32.605768: Epoch 342\n",
      "2024-11-26 09:52:32.615768: Current learning rate: 0.00355\n",
      "2024-11-26 09:54:42.189924: train_loss -0.7948\n",
      "2024-11-26 09:54:42.189924: val_loss -0.4063\n",
      "2024-11-26 09:54:42.189924: Pseudo dice [0.7167]\n",
      "2024-11-26 09:54:42.199924: Epoch time: 129.58 s\n",
      "2024-11-26 09:54:43.239362: \n",
      "2024-11-26 09:54:43.239362: Epoch 343\n",
      "2024-11-26 09:54:43.239362: Current learning rate: 0.00353\n",
      "2024-11-26 09:56:53.785956: train_loss -0.8197\n",
      "2024-11-26 09:56:53.785956: val_loss -0.4673\n",
      "2024-11-26 09:56:53.794958: Pseudo dice [0.7273]\n",
      "2024-11-26 09:56:53.801960: Epoch time: 130.56 s\n",
      "2024-11-26 09:56:54.833192: \n",
      "2024-11-26 09:56:54.833192: Epoch 344\n",
      "2024-11-26 09:56:54.840194: Current learning rate: 0.00351\n",
      "2024-11-26 09:59:06.537748: train_loss -0.8303\n",
      "2024-11-26 09:59:06.538748: val_loss -0.6607\n",
      "2024-11-26 09:59:06.545749: Pseudo dice [0.8386]\n",
      "2024-11-26 09:59:06.550750: Epoch time: 131.71 s\n",
      "2024-11-26 09:59:07.584984: \n",
      "2024-11-26 09:59:07.584984: Epoch 345\n",
      "2024-11-26 09:59:07.593986: Current learning rate: 0.00349\n",
      "2024-11-26 10:01:17.965906: train_loss -0.7915\n",
      "2024-11-26 10:01:17.965906: val_loss -0.2001\n",
      "2024-11-26 10:01:17.977909: Pseudo dice [0.6443]\n",
      "2024-11-26 10:01:17.987912: Epoch time: 130.38 s\n",
      "2024-11-26 10:01:19.025146: \n",
      "2024-11-26 10:01:19.025146: Epoch 346\n",
      "2024-11-26 10:01:19.032146: Current learning rate: 0.00346\n",
      "2024-11-26 10:03:28.710704: train_loss -0.8122\n",
      "2024-11-26 10:03:28.710704: val_loss -0.2464\n",
      "2024-11-26 10:03:28.720707: Pseudo dice [0.6298]\n",
      "2024-11-26 10:03:28.729709: Epoch time: 129.69 s\n",
      "2024-11-26 10:03:29.766205: \n",
      "2024-11-26 10:03:29.766205: Epoch 347\n",
      "2024-11-26 10:03:29.773207: Current learning rate: 0.00344\n",
      "2024-11-26 10:05:39.495410: train_loss -0.8091\n",
      "2024-11-26 10:05:39.495410: val_loss -0.3341\n",
      "2024-11-26 10:05:39.505412: Pseudo dice [0.6769]\n",
      "2024-11-26 10:05:39.512414: Epoch time: 129.73 s\n",
      "2024-11-26 10:05:40.547647: \n",
      "2024-11-26 10:05:40.548647: Epoch 348\n",
      "2024-11-26 10:05:40.554648: Current learning rate: 0.00342\n",
      "2024-11-26 10:07:50.148688: train_loss -0.8024\n",
      "2024-11-26 10:07:50.149688: val_loss -0.5641\n",
      "2024-11-26 10:07:50.159690: Pseudo dice [0.7881]\n",
      "2024-11-26 10:07:50.166692: Epoch time: 129.6 s\n",
      "2024-11-26 10:07:51.376130: \n",
      "2024-11-26 10:07:51.376130: Epoch 349\n",
      "2024-11-26 10:07:51.382131: Current learning rate: 0.0034\n",
      "2024-11-26 10:10:01.034757: train_loss -0.7926\n",
      "2024-11-26 10:10:01.034757: val_loss -0.3\n",
      "2024-11-26 10:10:01.047760: Pseudo dice [0.6795]\n",
      "2024-11-26 10:10:01.054761: Epoch time: 129.66 s\n",
      "2024-11-26 10:10:02.350719: \n",
      "2024-11-26 10:10:02.350719: Epoch 350\n",
      "2024-11-26 10:10:02.357720: Current learning rate: 0.00338\n",
      "2024-11-26 10:12:11.889376: train_loss -0.7978\n",
      "2024-11-26 10:12:11.889376: val_loss -0.3946\n",
      "2024-11-26 10:12:11.898378: Pseudo dice [0.729]\n",
      "2024-11-26 10:12:11.903379: Epoch time: 129.54 s\n",
      "2024-11-26 10:12:12.940612: \n",
      "2024-11-26 10:12:12.940612: Epoch 351\n",
      "2024-11-26 10:12:12.947613: Current learning rate: 0.00336\n",
      "2024-11-26 10:14:22.603092: train_loss -0.8128\n",
      "2024-11-26 10:14:22.603092: val_loss -0.3354\n",
      "2024-11-26 10:14:22.612094: Pseudo dice [0.6854]\n",
      "2024-11-26 10:14:22.620096: Epoch time: 129.66 s\n",
      "2024-11-26 10:14:23.659897: \n",
      "2024-11-26 10:14:23.659897: Epoch 352\n",
      "2024-11-26 10:14:23.665899: Current learning rate: 0.00334\n",
      "2024-11-26 10:16:33.411037: train_loss -0.8149\n",
      "2024-11-26 10:16:33.412036: val_loss -0.3834\n",
      "2024-11-26 10:16:33.422039: Pseudo dice [0.6891]\n",
      "2024-11-26 10:16:33.428041: Epoch time: 129.75 s\n",
      "2024-11-26 10:16:34.458272: \n",
      "2024-11-26 10:16:34.458272: Epoch 353\n",
      "2024-11-26 10:16:34.464273: Current learning rate: 0.00332\n",
      "2024-11-26 10:18:44.257921: train_loss -0.8289\n",
      "2024-11-26 10:18:44.258921: val_loss -0.6148\n",
      "2024-11-26 10:18:44.268924: Pseudo dice [0.8059]\n",
      "2024-11-26 10:18:44.274925: Epoch time: 129.8 s\n",
      "2024-11-26 10:18:45.321825: \n",
      "2024-11-26 10:18:45.321825: Epoch 354\n",
      "2024-11-26 10:18:45.328827: Current learning rate: 0.0033\n",
      "2024-11-26 10:20:55.158427: train_loss -0.8068\n",
      "2024-11-26 10:20:55.158427: val_loss -0.5363\n",
      "2024-11-26 10:20:55.169430: Pseudo dice [0.7771]\n",
      "2024-11-26 10:20:55.174431: Epoch time: 129.84 s\n",
      "2024-11-26 10:20:56.206663: \n",
      "2024-11-26 10:20:56.206663: Epoch 355\n",
      "2024-11-26 10:20:56.212664: Current learning rate: 0.00328\n",
      "2024-11-26 10:23:05.863706: train_loss -0.8275\n",
      "2024-11-26 10:23:05.864706: val_loss -0.4128\n",
      "2024-11-26 10:23:05.872708: Pseudo dice [0.7326]\n",
      "2024-11-26 10:23:05.878709: Epoch time: 129.66 s\n",
      "2024-11-26 10:23:07.103984: \n",
      "2024-11-26 10:23:07.103984: Epoch 356\n",
      "2024-11-26 10:23:07.111986: Current learning rate: 0.00326\n",
      "2024-11-26 10:25:16.774636: train_loss -0.797\n",
      "2024-11-26 10:25:16.774636: val_loss -0.3331\n",
      "2024-11-26 10:25:16.785638: Pseudo dice [0.6963]\n",
      "2024-11-26 10:25:16.792640: Epoch time: 129.67 s\n",
      "2024-11-26 10:25:17.834874: \n",
      "2024-11-26 10:25:17.834874: Epoch 357\n",
      "2024-11-26 10:25:17.841876: Current learning rate: 0.00324\n",
      "2024-11-26 10:27:27.457620: train_loss -0.8241\n",
      "2024-11-26 10:27:27.458621: val_loss -0.3567\n",
      "2024-11-26 10:27:27.470624: Pseudo dice [0.6914]\n",
      "2024-11-26 10:27:27.477626: Epoch time: 129.62 s\n",
      "2024-11-26 10:27:28.515860: \n",
      "2024-11-26 10:27:28.515860: Epoch 358\n",
      "2024-11-26 10:27:28.521861: Current learning rate: 0.00322\n",
      "2024-11-26 10:29:38.288743: train_loss -0.8216\n",
      "2024-11-26 10:29:38.289743: val_loss -0.3951\n",
      "2024-11-26 10:29:38.300745: Pseudo dice [0.7217]\n",
      "2024-11-26 10:29:38.305746: Epoch time: 129.77 s\n",
      "2024-11-26 10:29:39.340979: \n",
      "2024-11-26 10:29:39.340979: Epoch 359\n",
      "2024-11-26 10:29:39.347981: Current learning rate: 0.0032\n",
      "2024-11-26 10:31:49.706466: train_loss -0.8032\n",
      "2024-11-26 10:31:49.706466: val_loss -0.4545\n",
      "2024-11-26 10:31:49.716470: Pseudo dice [0.7472]\n",
      "2024-11-26 10:31:49.721471: Epoch time: 130.37 s\n",
      "2024-11-26 10:31:50.770706: \n",
      "2024-11-26 10:31:50.770706: Epoch 360\n",
      "2024-11-26 10:31:50.777707: Current learning rate: 0.00318\n",
      "2024-11-26 10:34:00.410989: train_loss -0.8079\n",
      "2024-11-26 10:34:00.410989: val_loss -0.5174\n",
      "2024-11-26 10:34:00.419991: Pseudo dice [0.7778]\n",
      "2024-11-26 10:34:00.423991: Epoch time: 129.64 s\n",
      "2024-11-26 10:34:01.455224: \n",
      "2024-11-26 10:34:01.455224: Epoch 361\n",
      "2024-11-26 10:34:01.462225: Current learning rate: 0.00316\n",
      "2024-11-26 10:36:11.158210: train_loss -0.8084\n",
      "2024-11-26 10:36:11.159210: val_loss -0.559\n",
      "2024-11-26 10:36:11.168213: Pseudo dice [0.7765]\n",
      "2024-11-26 10:36:11.173213: Epoch time: 129.7 s\n",
      "2024-11-26 10:36:12.230451: \n",
      "2024-11-26 10:36:12.230451: Epoch 362\n",
      "2024-11-26 10:36:12.237453: Current learning rate: 0.00314\n",
      "2024-11-26 10:38:21.915977: train_loss -0.8346\n",
      "2024-11-26 10:38:21.916977: val_loss -0.6223\n",
      "2024-11-26 10:38:21.925979: Pseudo dice [0.8173]\n",
      "2024-11-26 10:38:21.934982: Epoch time: 129.69 s\n",
      "2024-11-26 10:38:23.152846: \n",
      "2024-11-26 10:38:23.152846: Epoch 363\n",
      "2024-11-26 10:38:23.158846: Current learning rate: 0.00312\n",
      "2024-11-26 10:40:32.776711: train_loss -0.8306\n",
      "2024-11-26 10:40:32.776711: val_loss -0.4697\n",
      "2024-11-26 10:40:32.787713: Pseudo dice [0.7598]\n",
      "2024-11-26 10:40:32.793715: Epoch time: 129.62 s\n",
      "2024-11-26 10:40:33.820547: \n",
      "2024-11-26 10:40:33.820547: Epoch 364\n",
      "2024-11-26 10:40:33.826548: Current learning rate: 0.0031\n",
      "2024-11-26 10:42:43.455544: train_loss -0.8231\n",
      "2024-11-26 10:42:43.455544: val_loss -0.4206\n",
      "2024-11-26 10:42:43.464546: Pseudo dice [0.6862]\n",
      "2024-11-26 10:42:43.469547: Epoch time: 129.64 s\n",
      "2024-11-26 10:42:44.499779: \n",
      "2024-11-26 10:42:44.499779: Epoch 365\n",
      "2024-11-26 10:42:44.506781: Current learning rate: 0.00308\n",
      "2024-11-26 10:44:54.090561: train_loss -0.8203\n",
      "2024-11-26 10:44:54.090561: val_loss -0.5682\n",
      "2024-11-26 10:44:54.100563: Pseudo dice [0.7982]\n",
      "2024-11-26 10:44:54.106564: Epoch time: 129.59 s\n",
      "2024-11-26 10:44:55.136909: \n",
      "2024-11-26 10:44:55.136909: Epoch 366\n",
      "2024-11-26 10:44:55.143911: Current learning rate: 0.00306\n",
      "2024-11-26 10:47:04.784809: train_loss -0.8149\n",
      "2024-11-26 10:47:04.784809: val_loss -0.5162\n",
      "2024-11-26 10:47:04.792811: Pseudo dice [0.7806]\n",
      "2024-11-26 10:47:04.799812: Epoch time: 129.65 s\n",
      "2024-11-26 10:47:05.831044: \n",
      "2024-11-26 10:47:05.831044: Epoch 367\n",
      "2024-11-26 10:47:05.838046: Current learning rate: 0.00304\n",
      "2024-11-26 10:49:15.505297: train_loss -0.8066\n",
      "2024-11-26 10:49:15.506297: val_loss -0.4675\n",
      "2024-11-26 10:49:15.515301: Pseudo dice [0.7359]\n",
      "2024-11-26 10:49:15.520302: Epoch time: 129.68 s\n",
      "2024-11-26 10:49:16.557535: \n",
      "2024-11-26 10:49:16.557535: Epoch 368\n",
      "2024-11-26 10:49:16.564537: Current learning rate: 0.00302\n",
      "2024-11-26 10:51:26.215170: train_loss -0.7775\n",
      "2024-11-26 10:51:26.215170: val_loss -0.4992\n",
      "2024-11-26 10:51:26.224172: Pseudo dice [0.7397]\n",
      "2024-11-26 10:51:26.231174: Epoch time: 129.66 s\n",
      "2024-11-26 10:51:27.269408: \n",
      "2024-11-26 10:51:27.269408: Epoch 369\n",
      "2024-11-26 10:51:27.275409: Current learning rate: 0.003\n",
      "2024-11-26 10:53:39.816097: train_loss -0.8202\n",
      "2024-11-26 10:53:39.817097: val_loss -0.285\n",
      "2024-11-26 10:53:39.826099: Pseudo dice [0.6686]\n",
      "2024-11-26 10:53:39.830101: Epoch time: 132.55 s\n",
      "2024-11-26 10:53:41.048375: \n",
      "2024-11-26 10:53:41.048375: Epoch 370\n",
      "2024-11-26 10:53:41.055376: Current learning rate: 0.00297\n",
      "2024-11-26 10:55:51.276136: train_loss -0.8243\n",
      "2024-11-26 10:55:51.276136: val_loss -0.3008\n",
      "2024-11-26 10:55:51.285138: Pseudo dice [0.6575]\n",
      "2024-11-26 10:55:51.290139: Epoch time: 130.23 s\n",
      "2024-11-26 10:55:52.323371: \n",
      "2024-11-26 10:55:52.323371: Epoch 371\n",
      "2024-11-26 10:55:52.330373: Current learning rate: 0.00295\n",
      "2024-11-26 10:58:07.085046: train_loss -0.7872\n",
      "2024-11-26 10:58:07.085046: val_loss -0.5419\n",
      "2024-11-26 10:58:07.096049: Pseudo dice [0.7851]\n",
      "2024-11-26 10:58:07.105051: Epoch time: 134.76 s\n",
      "2024-11-26 10:58:08.137283: \n",
      "2024-11-26 10:58:08.137283: Epoch 372\n",
      "2024-11-26 10:58:08.144284: Current learning rate: 0.00293\n",
      "2024-11-26 11:00:28.440434: train_loss -0.8142\n",
      "2024-11-26 11:00:28.440434: val_loss -0.4921\n",
      "2024-11-26 11:00:28.450436: Pseudo dice [0.7508]\n",
      "2024-11-26 11:00:28.457438: Epoch time: 140.3 s\n",
      "2024-11-26 11:00:29.486670: \n",
      "2024-11-26 11:00:29.486670: Epoch 373\n",
      "2024-11-26 11:00:29.493672: Current learning rate: 0.00291\n",
      "2024-11-26 11:02:49.756084: train_loss -0.8183\n",
      "2024-11-26 11:02:49.756084: val_loss -0.5938\n",
      "2024-11-26 11:02:49.764086: Pseudo dice [0.8081]\n",
      "2024-11-26 11:02:49.769087: Epoch time: 140.27 s\n",
      "2024-11-26 11:02:50.809321: \n",
      "2024-11-26 11:02:50.809321: Epoch 374\n",
      "2024-11-26 11:02:50.816323: Current learning rate: 0.00289\n",
      "2024-11-26 11:05:11.194651: train_loss -0.806\n",
      "2024-11-26 11:05:11.195651: val_loss -0.4359\n",
      "2024-11-26 11:05:11.206654: Pseudo dice [0.7363]\n",
      "2024-11-26 11:05:11.211655: Epoch time: 140.39 s\n",
      "2024-11-26 11:05:12.250888: \n",
      "2024-11-26 11:05:12.250888: Epoch 375\n",
      "2024-11-26 11:05:12.257890: Current learning rate: 0.00287\n",
      "2024-11-26 11:07:32.806079: train_loss -0.8061\n",
      "2024-11-26 11:07:32.806079: val_loss -0.4893\n",
      "2024-11-26 11:07:32.817083: Pseudo dice [0.7402]\n",
      "2024-11-26 11:07:32.822083: Epoch time: 140.56 s\n",
      "2024-11-26 11:07:33.863320: \n",
      "2024-11-26 11:07:33.864316: Epoch 376\n",
      "2024-11-26 11:07:33.873319: Current learning rate: 0.00285\n",
      "2024-11-26 11:09:54.425688: train_loss -0.8345\n",
      "2024-11-26 11:09:54.425688: val_loss -0.4989\n",
      "2024-11-26 11:09:54.434692: Pseudo dice [0.7535]\n",
      "2024-11-26 11:09:54.439693: Epoch time: 140.56 s\n",
      "2024-11-26 11:09:55.686973: \n",
      "2024-11-26 11:09:55.687973: Epoch 377\n",
      "2024-11-26 11:09:55.694974: Current learning rate: 0.00283\n",
      "2024-11-26 11:12:16.455793: train_loss -0.8307\n",
      "2024-11-26 11:12:16.455793: val_loss -0.5904\n",
      "2024-11-26 11:12:16.470796: Pseudo dice [0.801]\n",
      "2024-11-26 11:12:16.475797: Epoch time: 140.77 s\n",
      "2024-11-26 11:12:17.514030: \n",
      "2024-11-26 11:12:17.514030: Epoch 378\n",
      "2024-11-26 11:12:17.521033: Current learning rate: 0.00281\n",
      "2024-11-26 11:14:38.259660: train_loss -0.825\n",
      "2024-11-26 11:14:38.259660: val_loss -0.3154\n",
      "2024-11-26 11:14:38.270662: Pseudo dice [0.6944]\n",
      "2024-11-26 11:14:38.279664: Epoch time: 140.75 s\n",
      "2024-11-26 11:14:39.316898: \n",
      "2024-11-26 11:14:39.316898: Epoch 379\n",
      "2024-11-26 11:14:39.323900: Current learning rate: 0.00279\n",
      "2024-11-26 11:16:56.031647: train_loss -0.8332\n",
      "2024-11-26 11:16:56.032647: val_loss -0.5051\n",
      "2024-11-26 11:16:56.039649: Pseudo dice [0.7555]\n",
      "2024-11-26 11:16:56.047652: Epoch time: 136.72 s\n",
      "2024-11-26 11:16:57.083884: \n",
      "2024-11-26 11:16:57.083884: Epoch 380\n",
      "2024-11-26 11:16:57.090886: Current learning rate: 0.00277\n",
      "2024-11-26 11:19:13.822883: train_loss -0.8367\n",
      "2024-11-26 11:19:13.823883: val_loss -0.3901\n",
      "2024-11-26 11:19:13.835885: Pseudo dice [0.7283]\n",
      "2024-11-26 11:19:13.841887: Epoch time: 136.74 s\n",
      "2024-11-26 11:19:14.901126: \n",
      "2024-11-26 11:19:14.902126: Epoch 381\n",
      "2024-11-26 11:19:14.909127: Current learning rate: 0.00275\n",
      "2024-11-26 11:21:35.205818: train_loss -0.8313\n",
      "2024-11-26 11:21:35.205818: val_loss -0.5088\n",
      "2024-11-26 11:21:35.215821: Pseudo dice [0.7628]\n",
      "2024-11-26 11:21:35.221822: Epoch time: 140.31 s\n",
      "2024-11-26 11:21:36.277058: \n",
      "2024-11-26 11:21:36.277058: Epoch 382\n",
      "2024-11-26 11:21:36.284060: Current learning rate: 0.00273\n",
      "2024-11-26 11:23:56.597470: train_loss -0.8456\n",
      "2024-11-26 11:23:56.597470: val_loss -0.325\n",
      "2024-11-26 11:23:56.610472: Pseudo dice [0.6935]\n",
      "2024-11-26 11:23:56.617474: Epoch time: 140.32 s\n",
      "2024-11-26 11:23:57.837748: \n",
      "2024-11-26 11:23:57.837748: Epoch 383\n",
      "2024-11-26 11:23:57.844749: Current learning rate: 0.00271\n",
      "2024-11-26 11:26:18.273331: train_loss -0.8425\n",
      "2024-11-26 11:26:18.274333: val_loss -0.4497\n",
      "2024-11-26 11:26:18.282334: Pseudo dice [0.7262]\n",
      "2024-11-26 11:26:18.292337: Epoch time: 140.44 s\n",
      "2024-11-26 11:26:19.355576: \n",
      "2024-11-26 11:26:19.356575: Epoch 384\n",
      "2024-11-26 11:26:19.363577: Current learning rate: 0.00268\n",
      "2024-11-26 11:28:39.905495: train_loss -0.8281\n",
      "2024-11-26 11:28:39.905495: val_loss -0.5386\n",
      "2024-11-26 11:28:39.914497: Pseudo dice [0.7836]\n",
      "2024-11-26 11:28:39.919497: Epoch time: 140.55 s\n",
      "2024-11-26 11:28:40.983737: \n",
      "2024-11-26 11:28:40.983737: Epoch 385\n",
      "2024-11-26 11:28:40.990739: Current learning rate: 0.00266\n",
      "2024-11-26 11:31:01.499384: train_loss -0.8463\n",
      "2024-11-26 11:31:01.499384: val_loss -0.5379\n",
      "2024-11-26 11:31:01.511388: Pseudo dice [0.7844]\n",
      "2024-11-26 11:31:01.517389: Epoch time: 140.52 s\n",
      "2024-11-26 11:31:02.573105: \n",
      "2024-11-26 11:31:02.573105: Epoch 386\n",
      "2024-11-26 11:31:02.580107: Current learning rate: 0.00264\n",
      "2024-11-26 11:33:22.941480: train_loss -0.8337\n",
      "2024-11-26 11:33:22.941480: val_loss -0.5962\n",
      "2024-11-26 11:33:22.951482: Pseudo dice [0.8145]\n",
      "2024-11-26 11:33:22.957483: Epoch time: 140.37 s\n",
      "2024-11-26 11:33:24.008721: \n",
      "2024-11-26 11:33:24.008721: Epoch 387\n",
      "2024-11-26 11:33:24.015722: Current learning rate: 0.00262\n",
      "2024-11-26 11:35:43.127458: train_loss -0.8256\n",
      "2024-11-26 11:35:43.127458: val_loss -0.4734\n",
      "2024-11-26 11:35:43.139461: Pseudo dice [0.7684]\n",
      "2024-11-26 11:35:43.146462: Epoch time: 139.12 s\n",
      "2024-11-26 11:35:44.204702: \n",
      "2024-11-26 11:35:44.204702: Epoch 388\n",
      "2024-11-26 11:35:44.211702: Current learning rate: 0.0026\n",
      "2024-11-26 11:38:00.296086: train_loss -0.812\n",
      "2024-11-26 11:38:00.296086: val_loss -0.4951\n",
      "2024-11-26 11:38:00.306088: Pseudo dice [0.7449]\n",
      "2024-11-26 11:38:00.311091: Epoch time: 136.09 s\n",
      "2024-11-26 11:38:01.371327: \n",
      "2024-11-26 11:38:01.371327: Epoch 389\n",
      "2024-11-26 11:38:01.378329: Current learning rate: 0.00258\n",
      "2024-11-26 11:40:11.849096: train_loss -0.8368\n",
      "2024-11-26 11:40:11.849096: val_loss -0.605\n",
      "2024-11-26 11:40:11.860098: Pseudo dice [0.8008]\n",
      "2024-11-26 11:40:11.866099: Epoch time: 130.48 s\n",
      "2024-11-26 11:40:11.871100: Yayy! New best EMA pseudo Dice: 0.759\n",
      "2024-11-26 11:40:13.330433: \n",
      "2024-11-26 11:40:13.330433: Epoch 390\n",
      "2024-11-26 11:40:13.337436: Current learning rate: 0.00256\n",
      "2024-11-26 11:42:30.836724: train_loss -0.8495\n",
      "2024-11-26 11:42:30.837725: val_loss -0.6362\n",
      "2024-11-26 11:42:30.849728: Pseudo dice [0.8208]\n",
      "2024-11-26 11:42:30.860731: Epoch time: 137.51 s\n",
      "2024-11-26 11:42:30.868731: Yayy! New best EMA pseudo Dice: 0.7652\n",
      "2024-11-26 11:42:32.169048: \n",
      "2024-11-26 11:42:32.170046: Epoch 391\n",
      "2024-11-26 11:42:32.177048: Current learning rate: 0.00254\n",
      "2024-11-26 11:44:52.285448: train_loss -0.8442\n",
      "2024-11-26 11:44:52.285448: val_loss -0.5251\n",
      "2024-11-26 11:44:52.299452: Pseudo dice [0.7707]\n",
      "2024-11-26 11:44:52.309454: Epoch time: 140.12 s\n",
      "2024-11-26 11:44:52.317456: Yayy! New best EMA pseudo Dice: 0.7657\n",
      "2024-11-26 11:44:53.626139: \n",
      "2024-11-26 11:44:53.626139: Epoch 392\n",
      "2024-11-26 11:44:53.633142: Current learning rate: 0.00252\n",
      "2024-11-26 11:47:05.178998: train_loss -0.8107\n",
      "2024-11-26 11:47:05.179998: val_loss -0.2913\n",
      "2024-11-26 11:47:05.193001: Pseudo dice [0.6342]\n",
      "2024-11-26 11:47:05.202003: Epoch time: 131.55 s\n",
      "2024-11-26 11:47:06.259242: \n",
      "2024-11-26 11:47:06.259242: Epoch 393\n",
      "2024-11-26 11:47:06.265242: Current learning rate: 0.0025\n",
      "2024-11-26 11:49:23.492040: train_loss -0.8481\n",
      "2024-11-26 11:49:23.492040: val_loss -0.5525\n",
      "2024-11-26 11:49:23.502042: Pseudo dice [0.7782]\n",
      "2024-11-26 11:49:23.508043: Epoch time: 137.23 s\n",
      "2024-11-26 11:49:24.559280: \n",
      "2024-11-26 11:49:24.559280: Epoch 394\n",
      "2024-11-26 11:49:24.565281: Current learning rate: 0.00248\n",
      "2024-11-26 11:51:44.809954: train_loss -0.8593\n",
      "2024-11-26 11:51:44.810955: val_loss -0.3046\n",
      "2024-11-26 11:51:44.821957: Pseudo dice [0.6869]\n",
      "2024-11-26 11:51:44.828959: Epoch time: 140.25 s\n",
      "2024-11-26 11:51:45.895200: \n",
      "2024-11-26 11:51:45.895200: Epoch 395\n",
      "2024-11-26 11:51:45.901201: Current learning rate: 0.00245\n",
      "2024-11-26 11:54:05.942973: train_loss -0.8469\n",
      "2024-11-26 11:54:05.943973: val_loss -0.5562\n",
      "2024-11-26 11:54:05.953975: Pseudo dice [0.7816]\n",
      "2024-11-26 11:54:05.960977: Epoch time: 140.05 s\n",
      "2024-11-26 11:54:07.022216: \n",
      "2024-11-26 11:54:07.022216: Epoch 396\n",
      "2024-11-26 11:54:07.029218: Current learning rate: 0.00243\n",
      "2024-11-26 11:56:27.204631: train_loss -0.8221\n",
      "2024-11-26 11:56:27.205631: val_loss -0.5321\n",
      "2024-11-26 11:56:27.214633: Pseudo dice [0.7736]\n",
      "2024-11-26 11:56:27.219634: Epoch time: 140.18 s\n",
      "2024-11-26 11:56:28.461914: \n",
      "2024-11-26 11:56:28.461914: Epoch 397\n",
      "2024-11-26 11:56:28.468915: Current learning rate: 0.00241\n",
      "2024-11-26 11:58:48.585213: train_loss -0.8361\n",
      "2024-11-26 11:58:48.586213: val_loss -0.5366\n",
      "2024-11-26 11:58:48.595216: Pseudo dice [0.7731]\n",
      "2024-11-26 11:58:48.600217: Epoch time: 140.12 s\n",
      "2024-11-26 11:58:49.661455: \n",
      "2024-11-26 11:58:49.661455: Epoch 398\n",
      "2024-11-26 11:58:49.668457: Current learning rate: 0.00239\n",
      "2024-11-26 12:01:10.257682: train_loss -0.8451\n",
      "2024-11-26 12:01:10.257682: val_loss -0.4\n",
      "2024-11-26 12:01:10.267684: Pseudo dice [0.7158]\n",
      "2024-11-26 12:01:10.274685: Epoch time: 140.6 s\n",
      "2024-11-26 12:01:11.338926: \n",
      "2024-11-26 12:01:11.338926: Epoch 399\n",
      "2024-11-26 12:01:11.345927: Current learning rate: 0.00237\n",
      "2024-11-26 12:03:32.032116: train_loss -0.8466\n",
      "2024-11-26 12:03:32.033117: val_loss -0.461\n",
      "2024-11-26 12:03:32.042120: Pseudo dice [0.7204]\n",
      "2024-11-26 12:03:32.050121: Epoch time: 140.69 s\n",
      "2024-11-26 12:03:33.348309: \n",
      "2024-11-26 12:03:33.348309: Epoch 400\n",
      "2024-11-26 12:03:33.355309: Current learning rate: 0.00235\n",
      "2024-11-26 12:05:53.341857: train_loss -0.827\n",
      "2024-11-26 12:05:53.341857: val_loss -0.4182\n",
      "2024-11-26 12:05:53.354863: Pseudo dice [0.7283]\n",
      "2024-11-26 12:05:53.360861: Epoch time: 139.99 s\n",
      "2024-11-26 12:05:54.431103: \n",
      "2024-11-26 12:05:54.431103: Epoch 401\n",
      "2024-11-26 12:05:54.438104: Current learning rate: 0.00233\n",
      "2024-11-26 12:08:14.330250: train_loss -0.7835\n",
      "2024-11-26 12:08:14.331250: val_loss -0.348\n",
      "2024-11-26 12:08:14.341252: Pseudo dice [0.6872]\n",
      "2024-11-26 12:08:14.348254: Epoch time: 139.9 s\n",
      "2024-11-26 12:08:15.402491: \n",
      "2024-11-26 12:08:15.402491: Epoch 402\n",
      "2024-11-26 12:08:15.409492: Current learning rate: 0.00231\n",
      "2024-11-26 12:10:35.260235: train_loss -0.8384\n",
      "2024-11-26 12:10:35.260235: val_loss -0.4387\n",
      "2024-11-26 12:10:35.272238: Pseudo dice [0.7071]\n",
      "2024-11-26 12:10:35.280240: Epoch time: 139.86 s\n",
      "2024-11-26 12:10:36.337478: \n",
      "2024-11-26 12:10:36.337478: Epoch 403\n",
      "2024-11-26 12:10:36.344479: Current learning rate: 0.00229\n",
      "2024-11-26 12:12:56.234660: train_loss -0.8432\n",
      "2024-11-26 12:12:56.234660: val_loss -0.4718\n",
      "2024-11-26 12:12:56.245662: Pseudo dice [0.7271]\n",
      "2024-11-26 12:12:56.253664: Epoch time: 139.9 s\n",
      "2024-11-26 12:12:57.494233: \n",
      "2024-11-26 12:12:57.494233: Epoch 404\n",
      "2024-11-26 12:12:57.501235: Current learning rate: 0.00226\n",
      "2024-11-26 12:15:17.395037: train_loss -0.8397\n",
      "2024-11-26 12:15:17.396036: val_loss -0.4474\n",
      "2024-11-26 12:15:17.406039: Pseudo dice [0.721]\n",
      "2024-11-26 12:15:17.413040: Epoch time: 139.9 s\n",
      "2024-11-26 12:15:18.488282: \n",
      "2024-11-26 12:15:18.488282: Epoch 405\n",
      "2024-11-26 12:15:18.495284: Current learning rate: 0.00224\n",
      "2024-11-26 12:17:38.324357: train_loss -0.8154\n",
      "2024-11-26 12:17:38.325362: val_loss -0.3165\n",
      "2024-11-26 12:17:38.332359: Pseudo dice [0.6596]\n",
      "2024-11-26 12:17:38.339361: Epoch time: 139.84 s\n",
      "2024-11-26 12:17:39.411602: \n",
      "2024-11-26 12:17:39.411602: Epoch 406\n",
      "2024-11-26 12:17:39.419604: Current learning rate: 0.00222\n",
      "2024-11-26 12:19:57.589649: train_loss -0.838\n",
      "2024-11-26 12:19:57.590649: val_loss -0.5655\n",
      "2024-11-26 12:19:57.599652: Pseudo dice [0.786]\n",
      "2024-11-26 12:19:57.604653: Epoch time: 138.18 s\n",
      "2024-11-26 12:19:58.668893: \n",
      "2024-11-26 12:19:58.668893: Epoch 407\n",
      "2024-11-26 12:19:58.676895: Current learning rate: 0.0022\n",
      "2024-11-26 12:22:18.652090: train_loss -0.8403\n",
      "2024-11-26 12:22:18.652090: val_loss -0.3878\n",
      "2024-11-26 12:22:18.663092: Pseudo dice [0.6941]\n",
      "2024-11-26 12:22:18.670094: Epoch time: 139.98 s\n",
      "2024-11-26 12:22:19.811351: \n",
      "2024-11-26 12:22:19.812351: Epoch 408\n",
      "2024-11-26 12:22:19.819352: Current learning rate: 0.00218\n",
      "2024-11-26 12:24:29.922611: train_loss -0.8446\n",
      "2024-11-26 12:24:29.922611: val_loss -0.399\n",
      "2024-11-26 12:24:29.932613: Pseudo dice [0.7128]\n",
      "2024-11-26 12:24:29.939615: Epoch time: 130.11 s\n",
      "2024-11-26 12:24:30.995854: \n",
      "2024-11-26 12:24:30.995854: Epoch 409\n",
      "2024-11-26 12:24:31.001854: Current learning rate: 0.00216\n",
      "2024-11-26 12:26:40.716225: train_loss -0.8453\n",
      "2024-11-26 12:26:40.717225: val_loss -0.4331\n",
      "2024-11-26 12:26:40.729228: Pseudo dice [0.7235]\n",
      "2024-11-26 12:26:40.736229: Epoch time: 129.72 s\n",
      "2024-11-26 12:26:41.972309: \n",
      "2024-11-26 12:26:41.972309: Epoch 410\n",
      "2024-11-26 12:26:41.978311: Current learning rate: 0.00214\n",
      "2024-11-26 12:28:58.093482: train_loss -0.8452\n",
      "2024-11-26 12:28:58.094482: val_loss -0.1667\n",
      "2024-11-26 12:28:58.103485: Pseudo dice [0.6206]\n",
      "2024-11-26 12:28:58.110486: Epoch time: 136.12 s\n",
      "2024-11-26 12:28:59.159723: \n",
      "2024-11-26 12:28:59.159723: Epoch 411\n",
      "2024-11-26 12:28:59.166724: Current learning rate: 0.00212\n",
      "2024-11-26 12:31:17.996959: train_loss -0.8427\n",
      "2024-11-26 12:31:17.996959: val_loss -0.4558\n",
      "2024-11-26 12:31:18.006961: Pseudo dice [0.7433]\n",
      "2024-11-26 12:31:18.013963: Epoch time: 138.84 s\n",
      "2024-11-26 12:31:19.057199: \n",
      "2024-11-26 12:31:19.057199: Epoch 412\n",
      "2024-11-26 12:31:19.064200: Current learning rate: 0.00209\n",
      "2024-11-26 12:33:37.641311: train_loss -0.8475\n",
      "2024-11-26 12:33:37.641311: val_loss -0.4002\n",
      "2024-11-26 12:33:37.652314: Pseudo dice [0.7158]\n",
      "2024-11-26 12:33:37.659315: Epoch time: 138.59 s\n",
      "2024-11-26 12:33:38.722554: \n",
      "2024-11-26 12:33:38.723555: Epoch 413\n",
      "2024-11-26 12:33:38.730556: Current learning rate: 0.00207\n",
      "2024-11-26 12:35:57.437251: train_loss -0.852\n",
      "2024-11-26 12:35:57.437251: val_loss -0.5255\n",
      "2024-11-26 12:35:57.446253: Pseudo dice [0.7778]\n",
      "2024-11-26 12:35:57.451254: Epoch time: 138.72 s\n",
      "2024-11-26 12:35:58.497490: \n",
      "2024-11-26 12:35:58.497490: Epoch 414\n",
      "2024-11-26 12:35:58.505496: Current learning rate: 0.00205\n",
      "2024-11-26 12:38:17.210699: train_loss -0.8257\n",
      "2024-11-26 12:38:17.210699: val_loss -0.5239\n",
      "2024-11-26 12:38:17.222702: Pseudo dice [0.7665]\n",
      "2024-11-26 12:38:17.229703: Epoch time: 138.72 s\n",
      "2024-11-26 12:38:18.267936: \n",
      "2024-11-26 12:38:18.267936: Epoch 415\n",
      "2024-11-26 12:38:18.274939: Current learning rate: 0.00203\n",
      "2024-11-26 12:40:36.987146: train_loss -0.8411\n",
      "2024-11-26 12:40:36.987146: val_loss -0.6071\n",
      "2024-11-26 12:40:36.996149: Pseudo dice [0.8153]\n",
      "2024-11-26 12:40:37.002149: Epoch time: 138.72 s\n",
      "2024-11-26 12:40:38.061389: \n",
      "2024-11-26 12:40:38.062389: Epoch 416\n",
      "2024-11-26 12:40:38.069391: Current learning rate: 0.00201\n",
      "2024-11-26 12:42:55.835386: train_loss -0.827\n",
      "2024-11-26 12:42:55.835386: val_loss 0.0849\n",
      "2024-11-26 12:42:55.843388: Pseudo dice [0.5081]\n",
      "2024-11-26 12:42:55.851389: Epoch time: 137.77 s\n",
      "2024-11-26 12:42:56.868618: \n",
      "2024-11-26 12:42:56.868618: Epoch 417\n",
      "2024-11-26 12:42:56.875620: Current learning rate: 0.00199\n",
      "2024-11-26 12:45:08.922666: train_loss -0.8346\n",
      "2024-11-26 12:45:08.923667: val_loss -0.5369\n",
      "2024-11-26 12:45:08.933670: Pseudo dice [0.7627]\n",
      "2024-11-26 12:45:08.938670: Epoch time: 132.06 s\n",
      "2024-11-26 12:45:10.148942: \n",
      "2024-11-26 12:45:10.148942: Epoch 418\n",
      "2024-11-26 12:45:10.155944: Current learning rate: 0.00196\n",
      "2024-11-26 12:47:20.259930: train_loss -0.84\n",
      "2024-11-26 12:47:20.259930: val_loss -0.3792\n",
      "2024-11-26 12:47:20.270932: Pseudo dice [0.7097]\n",
      "2024-11-26 12:47:20.275933: Epoch time: 130.11 s\n",
      "2024-11-26 12:47:21.277158: \n",
      "2024-11-26 12:47:21.278159: Epoch 419\n",
      "2024-11-26 12:47:21.284160: Current learning rate: 0.00194\n",
      "2024-11-26 12:49:31.238369: train_loss -0.8457\n",
      "2024-11-26 12:49:31.239369: val_loss -0.2607\n",
      "2024-11-26 12:49:31.251372: Pseudo dice [0.6343]\n",
      "2024-11-26 12:49:31.258373: Epoch time: 129.96 s\n",
      "2024-11-26 12:49:32.256599: \n",
      "2024-11-26 12:49:32.256599: Epoch 420\n",
      "2024-11-26 12:49:32.263600: Current learning rate: 0.00192\n",
      "2024-11-26 12:51:47.571649: train_loss -0.8398\n",
      "2024-11-26 12:51:47.571649: val_loss -0.5542\n",
      "2024-11-26 12:51:47.580651: Pseudo dice [0.7892]\n",
      "2024-11-26 12:51:47.585652: Epoch time: 135.32 s\n",
      "2024-11-26 12:51:48.599880: \n",
      "2024-11-26 12:51:48.599880: Epoch 421\n",
      "2024-11-26 12:51:48.606882: Current learning rate: 0.0019\n",
      "2024-11-26 12:53:59.275475: train_loss -0.8442\n",
      "2024-11-26 12:53:59.275475: val_loss -0.405\n",
      "2024-11-26 12:53:59.285477: Pseudo dice [0.7251]\n",
      "2024-11-26 12:53:59.290479: Epoch time: 130.68 s\n",
      "2024-11-26 12:54:00.295704: \n",
      "2024-11-26 12:54:00.296705: Epoch 422\n",
      "2024-11-26 12:54:00.302706: Current learning rate: 0.00188\n",
      "2024-11-26 12:56:11.651809: train_loss -0.8184\n",
      "2024-11-26 12:56:11.651809: val_loss -0.373\n",
      "2024-11-26 12:56:11.660812: Pseudo dice [0.6956]\n",
      "2024-11-26 12:56:11.667813: Epoch time: 131.36 s\n",
      "2024-11-26 12:56:12.716050: \n",
      "2024-11-26 12:56:12.716050: Epoch 423\n",
      "2024-11-26 12:56:12.724051: Current learning rate: 0.00186\n",
      "2024-11-26 12:58:27.873349: train_loss -0.8433\n",
      "2024-11-26 12:58:27.873349: val_loss -0.403\n",
      "2024-11-26 12:58:27.882350: Pseudo dice [0.7192]\n",
      "2024-11-26 12:58:27.890353: Epoch time: 135.16 s\n",
      "2024-11-26 12:58:28.962143: \n",
      "2024-11-26 12:58:28.962143: Epoch 424\n",
      "2024-11-26 12:58:28.969145: Current learning rate: 0.00184\n",
      "2024-11-26 13:00:41.750000: train_loss -0.8547\n",
      "2024-11-26 13:00:41.750000: val_loss -0.282\n",
      "2024-11-26 13:00:41.759004: Pseudo dice [0.6613]\n",
      "2024-11-26 13:00:41.766006: Epoch time: 132.79 s\n",
      "2024-11-26 13:00:43.015846: \n",
      "2024-11-26 13:00:43.016846: Epoch 425\n",
      "2024-11-26 13:00:43.023847: Current learning rate: 0.00181\n",
      "2024-11-26 13:02:55.679252: train_loss -0.8382\n",
      "2024-11-26 13:02:55.679252: val_loss -0.4168\n",
      "2024-11-26 13:02:55.691255: Pseudo dice [0.7197]\n",
      "2024-11-26 13:02:55.698257: Epoch time: 132.66 s\n",
      "2024-11-26 13:02:56.854542: \n",
      "2024-11-26 13:02:56.854542: Epoch 426\n",
      "2024-11-26 13:02:56.862544: Current learning rate: 0.00179\n",
      "2024-11-26 13:05:11.717878: train_loss -0.8448\n",
      "2024-11-26 13:05:11.717878: val_loss -0.5112\n",
      "2024-11-26 13:05:11.731882: Pseudo dice [0.7573]\n",
      "2024-11-26 13:05:11.736882: Epoch time: 134.86 s\n",
      "2024-11-26 13:05:12.857257: \n",
      "2024-11-26 13:05:12.857257: Epoch 427\n",
      "2024-11-26 13:05:12.865260: Current learning rate: 0.00177\n",
      "2024-11-26 13:07:24.723081: train_loss -0.8575\n",
      "2024-11-26 13:07:24.723081: val_loss -0.3952\n",
      "2024-11-26 13:07:24.733467: Pseudo dice [0.7103]\n",
      "2024-11-26 13:07:24.738971: Epoch time: 131.87 s\n",
      "2024-11-26 13:07:25.921012: \n",
      "2024-11-26 13:07:25.921012: Epoch 428\n",
      "2024-11-26 13:07:25.929015: Current learning rate: 0.00175\n",
      "2024-11-26 13:09:38.065967: train_loss -0.8334\n",
      "2024-11-26 13:09:38.066967: val_loss -0.2582\n",
      "2024-11-26 13:09:38.076484: Pseudo dice [0.6463]\n",
      "2024-11-26 13:09:38.084990: Epoch time: 132.15 s\n",
      "2024-11-26 13:09:39.234369: \n",
      "2024-11-26 13:09:39.234369: Epoch 429\n",
      "2024-11-26 13:09:39.242877: Current learning rate: 0.00173\n",
      "2024-11-26 13:11:55.740677: train_loss -0.85\n",
      "2024-11-26 13:11:55.741676: val_loss -0.5049\n",
      "2024-11-26 13:11:55.752678: Pseudo dice [0.7635]\n",
      "2024-11-26 13:11:55.759185: Epoch time: 136.51 s\n",
      "2024-11-26 13:11:56.820499: \n",
      "2024-11-26 13:11:56.821500: Epoch 430\n",
      "2024-11-26 13:11:56.828501: Current learning rate: 0.0017\n",
      "2024-11-26 13:14:15.593425: train_loss -0.8494\n",
      "2024-11-26 13:14:15.593425: val_loss -0.2419\n",
      "2024-11-26 13:14:15.613933: Pseudo dice [0.6523]\n",
      "2024-11-26 13:14:15.619935: Epoch time: 138.77 s\n",
      "2024-11-26 13:14:16.727316: \n",
      "2024-11-26 13:14:16.727316: Epoch 431\n",
      "2024-11-26 13:14:16.735318: Current learning rate: 0.00168\n",
      "2024-11-26 13:16:34.092128: train_loss -0.8455\n",
      "2024-11-26 13:16:34.092128: val_loss -0.3489\n",
      "2024-11-26 13:16:34.102130: Pseudo dice [0.7043]\n",
      "2024-11-26 13:16:34.108132: Epoch time: 137.37 s\n",
      "2024-11-26 13:16:35.239959: \n",
      "2024-11-26 13:16:35.239959: Epoch 432\n",
      "2024-11-26 13:16:35.246961: Current learning rate: 0.00166\n",
      "2024-11-26 13:18:52.700706: train_loss -0.8459\n",
      "2024-11-26 13:18:52.701706: val_loss -0.4792\n",
      "2024-11-26 13:18:52.709707: Pseudo dice [0.7374]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nnunetv2\\training\\nnUNetTrainer\\nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
      "C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-26 13:18:52.715707: Epoch time: 137.46 s\n",
      "2024-11-26 13:18:53.977724: \n",
      "2024-11-26 13:18:53.977724: Epoch 433\n",
      "2024-11-26 13:18:53.984726: Current learning rate: 0.00164\n",
      "2024-11-26 13:21:11.351154: train_loss -0.8572\n",
      "2024-11-26 13:21:11.351154: val_loss -0.4457\n",
      "2024-11-26 13:21:11.360157: Pseudo dice [0.7389]\n",
      "2024-11-26 13:21:11.365157: Epoch time: 137.38 s\n",
      "2024-11-26 13:21:12.419433: \n",
      "2024-11-26 13:21:12.419433: Epoch 434\n",
      "2024-11-26 13:21:12.427436: Current learning rate: 0.00162\n",
      "2024-11-26 13:23:29.748319: train_loss -0.8506\n",
      "2024-11-26 13:23:29.748319: val_loss -0.2625\n",
      "2024-11-26 13:23:29.760323: Pseudo dice [0.663]\n",
      "2024-11-26 13:23:29.767325: Epoch time: 137.33 s\n",
      "2024-11-26 13:23:30.791889: \n",
      "2024-11-26 13:23:30.791889: Epoch 435\n",
      "2024-11-26 13:23:30.798891: Current learning rate: 0.00159\n",
      "2024-11-26 13:25:48.146020: train_loss -0.8437\n",
      "2024-11-26 13:25:48.146020: val_loss -0.1731\n",
      "2024-11-26 13:25:48.157527: Pseudo dice [0.6375]\n",
      "2024-11-26 13:25:48.164528: Epoch time: 137.36 s\n",
      "2024-11-26 13:25:49.176729: \n",
      "2024-11-26 13:25:49.176729: Epoch 436\n",
      "2024-11-26 13:25:49.183732: Current learning rate: 0.00157\n",
      "2024-11-26 13:28:01.125779: train_loss -0.8511\n",
      "2024-11-26 13:28:01.125779: val_loss -0.3638\n",
      "2024-11-26 13:28:01.137783: Pseudo dice [0.7245]\n",
      "2024-11-26 13:28:01.144783: Epoch time: 131.95 s\n",
      "2024-11-26 13:28:02.264611: \n",
      "2024-11-26 13:28:02.264611: Epoch 437\n",
      "2024-11-26 13:28:02.272613: Current learning rate: 0.00155\n",
      "2024-11-26 13:30:12.046878: train_loss -0.8482\n",
      "2024-11-26 13:30:12.047878: val_loss -0.3978\n",
      "2024-11-26 13:30:12.060385: Pseudo dice [0.721]\n",
      "2024-11-26 13:30:12.066387: Epoch time: 129.78 s\n",
      "2024-11-26 13:30:13.198755: \n",
      "2024-11-26 13:30:13.198755: Epoch 438\n",
      "2024-11-26 13:30:13.206757: Current learning rate: 0.00153\n",
      "2024-11-26 13:32:23.019919: train_loss -0.8394\n",
      "2024-11-26 13:32:23.019919: val_loss -0.546\n",
      "2024-11-26 13:32:23.030921: Pseudo dice [0.7944]\n",
      "2024-11-26 13:32:23.035922: Epoch time: 129.82 s\n",
      "2024-11-26 13:32:24.016207: \n",
      "2024-11-26 13:32:24.016207: Epoch 439\n",
      "2024-11-26 13:32:24.023209: Current learning rate: 0.00151\n",
      "2024-11-26 13:34:36.331997: train_loss -0.842\n",
      "2024-11-26 13:34:36.331997: val_loss -0.1815\n",
      "2024-11-26 13:34:36.344001: Pseudo dice [0.643]\n",
      "2024-11-26 13:34:36.351508: Epoch time: 132.32 s\n",
      "2024-11-26 13:34:37.528351: \n",
      "2024-11-26 13:34:37.528351: Epoch 440\n",
      "2024-11-26 13:34:37.535354: Current learning rate: 0.00148\n",
      "2024-11-26 13:36:56.009632: train_loss -0.86\n",
      "2024-11-26 13:36:56.009632: val_loss -0.2248\n",
      "2024-11-26 13:36:56.019636: Pseudo dice [0.6534]\n",
      "2024-11-26 13:36:56.026637: Epoch time: 138.48 s\n",
      "2024-11-26 13:36:57.024918: \n",
      "2024-11-26 13:36:57.024918: Epoch 441\n",
      "2024-11-26 13:36:57.030918: Current learning rate: 0.00146\n",
      "2024-11-26 13:39:15.638626: train_loss -0.8581\n",
      "2024-11-26 13:39:15.638626: val_loss -0.2869\n",
      "2024-11-26 13:39:15.647630: Pseudo dice [0.6935]\n",
      "2024-11-26 13:39:15.654632: Epoch time: 138.61 s\n",
      "2024-11-26 13:39:16.651923: \n",
      "2024-11-26 13:39:16.651923: Epoch 442\n",
      "2024-11-26 13:39:16.658925: Current learning rate: 0.00144\n",
      "2024-11-26 13:41:35.325348: train_loss -0.8476\n",
      "2024-11-26 13:41:35.325348: val_loss -0.1856\n",
      "2024-11-26 13:41:35.335350: Pseudo dice [0.6391]\n",
      "2024-11-26 13:41:35.341351: Epoch time: 138.67 s\n",
      "2024-11-26 13:41:36.348901: \n",
      "2024-11-26 13:41:36.348901: Epoch 443\n",
      "2024-11-26 13:41:36.354903: Current learning rate: 0.00142\n",
      "2024-11-26 13:43:52.479098: train_loss -0.8614\n",
      "2024-11-26 13:43:52.479098: val_loss -0.4625\n",
      "2024-11-26 13:43:52.489101: Pseudo dice [0.7467]\n",
      "2024-11-26 13:43:52.497102: Epoch time: 136.13 s\n",
      "2024-11-26 13:43:53.569934: \n",
      "2024-11-26 13:43:53.569934: Epoch 444\n",
      "2024-11-26 13:43:53.577936: Current learning rate: 0.00139\n",
      "2024-11-26 13:46:05.861829: train_loss -0.8425\n",
      "2024-11-26 13:46:05.861829: val_loss -0.4492\n",
      "2024-11-26 13:46:05.870831: Pseudo dice [0.7392]\n",
      "2024-11-26 13:46:05.876832: Epoch time: 132.29 s\n",
      "2024-11-26 13:46:06.880117: \n",
      "2024-11-26 13:46:06.880117: Epoch 445\n",
      "2024-11-26 13:46:06.887118: Current learning rate: 0.00137\n",
      "2024-11-26 13:48:18.440845: train_loss -0.8535\n",
      "2024-11-26 13:48:18.440845: val_loss 0.0543\n",
      "2024-11-26 13:48:18.450845: Pseudo dice [0.5477]\n",
      "2024-11-26 13:48:18.450845: Epoch time: 131.56 s\n",
      "2024-11-26 13:48:19.460859: \n",
      "2024-11-26 13:48:19.460859: Epoch 446\n",
      "2024-11-26 13:48:19.460859: Current learning rate: 0.00135\n",
      "2024-11-26 13:50:29.112657: train_loss -0.8508\n",
      "2024-11-26 13:50:29.112657: val_loss -0.511\n",
      "2024-11-26 13:50:29.122658: Pseudo dice [0.76]\n",
      "2024-11-26 13:50:29.122658: Epoch time: 129.65 s\n",
      "2024-11-26 13:50:30.122672: \n",
      "2024-11-26 13:50:30.122672: Epoch 447\n",
      "2024-11-26 13:50:30.132672: Current learning rate: 0.00133\n",
      "2024-11-26 13:52:39.806188: train_loss -0.8549\n",
      "2024-11-26 13:52:39.806188: val_loss -0.0965\n",
      "2024-11-26 13:52:39.816189: Pseudo dice [0.6093]\n",
      "2024-11-26 13:52:39.826188: Epoch time: 129.68 s\n",
      "2024-11-26 13:52:41.096206: \n",
      "2024-11-26 13:52:41.106206: Epoch 448\n",
      "2024-11-26 13:52:41.106206: Current learning rate: 0.0013\n",
      "2024-11-26 13:54:50.705200: train_loss -0.8601\n",
      "2024-11-26 13:54:50.705200: val_loss -0.3878\n",
      "2024-11-26 13:54:50.715201: Pseudo dice [0.717]\n",
      "2024-11-26 13:54:50.715201: Epoch time: 129.62 s\n",
      "2024-11-26 13:54:51.715214: \n",
      "2024-11-26 13:54:51.715214: Epoch 449\n",
      "2024-11-26 13:54:51.725214: Current learning rate: 0.00128\n",
      "2024-11-26 13:57:01.320660: train_loss -0.8495\n",
      "2024-11-26 13:57:01.320660: val_loss -0.438\n",
      "2024-11-26 13:57:01.330662: Pseudo dice [0.7205]\n",
      "2024-11-26 13:57:01.340662: Epoch time: 129.61 s\n",
      "2024-11-26 13:57:02.580678: \n",
      "2024-11-26 13:57:02.580678: Epoch 450\n",
      "2024-11-26 13:57:02.590678: Current learning rate: 0.00126\n",
      "2024-11-26 13:59:12.186592: train_loss -0.8523\n",
      "2024-11-26 13:59:12.186592: val_loss -0.4785\n",
      "2024-11-26 13:59:12.196590: Pseudo dice [0.7713]\n",
      "2024-11-26 13:59:12.206593: Epoch time: 129.61 s\n",
      "2024-11-26 13:59:13.206605: \n",
      "2024-11-26 13:59:13.206605: Epoch 451\n",
      "2024-11-26 13:59:13.206605: Current learning rate: 0.00124\n",
      "2024-11-26 14:01:22.765875: train_loss -0.8598\n",
      "2024-11-26 14:01:22.765875: val_loss -0.4527\n",
      "2024-11-26 14:01:22.775876: Pseudo dice [0.7575]\n",
      "2024-11-26 14:01:22.785876: Epoch time: 129.56 s\n",
      "2024-11-26 14:01:23.785889: \n",
      "2024-11-26 14:01:23.785889: Epoch 452\n",
      "2024-11-26 14:01:23.785889: Current learning rate: 0.00121\n",
      "2024-11-26 14:03:33.383889: train_loss -0.8665\n",
      "2024-11-26 14:03:33.383889: val_loss -0.3564\n",
      "2024-11-26 14:03:33.393889: Pseudo dice [0.7045]\n",
      "2024-11-26 14:03:33.393889: Epoch time: 129.6 s\n",
      "2024-11-26 14:03:34.504209: \n",
      "2024-11-26 14:03:34.504209: Epoch 453\n",
      "2024-11-26 14:03:34.504209: Current learning rate: 0.00119\n",
      "2024-11-26 14:05:44.149913: train_loss -0.864\n",
      "2024-11-26 14:05:44.149913: val_loss -0.456\n",
      "2024-11-26 14:05:44.159913: Pseudo dice [0.7361]\n",
      "2024-11-26 14:05:44.169914: Epoch time: 129.66 s\n",
      "2024-11-26 14:05:45.169928: \n",
      "2024-11-26 14:05:45.169928: Epoch 454\n",
      "2024-11-26 14:05:45.169928: Current learning rate: 0.00117\n",
      "2024-11-26 14:07:54.808665: train_loss -0.8578\n",
      "2024-11-26 14:07:54.808665: val_loss -0.5405\n",
      "2024-11-26 14:07:54.818666: Pseudo dice [0.7844]\n",
      "2024-11-26 14:07:54.818666: Epoch time: 129.64 s\n",
      "2024-11-26 14:07:55.999142: \n",
      "2024-11-26 14:07:55.999142: Epoch 455\n",
      "2024-11-26 14:07:56.009143: Current learning rate: 0.00115\n",
      "2024-11-26 14:10:05.634418: train_loss -0.8552\n",
      "2024-11-26 14:10:05.634418: val_loss -0.3497\n",
      "2024-11-26 14:10:05.644417: Pseudo dice [0.7075]\n",
      "2024-11-26 14:10:05.654417: Epoch time: 129.64 s\n",
      "2024-11-26 14:10:06.645561: \n",
      "2024-11-26 14:10:06.645561: Epoch 456\n",
      "2024-11-26 14:10:06.655561: Current learning rate: 0.00112\n",
      "2024-11-26 14:12:16.328969: train_loss -0.8544\n",
      "2024-11-26 14:12:16.328969: val_loss -0.4004\n",
      "2024-11-26 14:12:16.328969: Pseudo dice [0.7006]\n",
      "2024-11-26 14:12:16.338969: Epoch time: 129.68 s\n",
      "2024-11-26 14:12:17.338982: \n",
      "2024-11-26 14:12:17.338982: Epoch 457\n",
      "2024-11-26 14:12:17.348982: Current learning rate: 0.0011\n",
      "2024-11-26 14:14:26.957235: train_loss -0.859\n",
      "2024-11-26 14:14:26.957235: val_loss -0.5125\n",
      "2024-11-26 14:14:26.967235: Pseudo dice [0.7587]\n",
      "2024-11-26 14:14:26.977236: Epoch time: 129.62 s\n",
      "2024-11-26 14:14:27.977553: \n",
      "2024-11-26 14:14:27.977553: Epoch 458\n",
      "2024-11-26 14:14:27.977553: Current learning rate: 0.00108\n",
      "2024-11-26 14:16:37.591752: train_loss -0.8647\n",
      "2024-11-26 14:16:37.591752: val_loss -0.6027\n",
      "2024-11-26 14:16:37.601752: Pseudo dice [0.8056]\n",
      "2024-11-26 14:16:37.611753: Epoch time: 129.61 s\n",
      "2024-11-26 14:16:38.611768: \n",
      "2024-11-26 14:16:38.611768: Epoch 459\n",
      "2024-11-26 14:16:38.611768: Current learning rate: 0.00105\n",
      "2024-11-26 14:18:48.249930: train_loss -0.859\n",
      "2024-11-26 14:18:48.249930: val_loss -0.5162\n",
      "2024-11-26 14:18:48.259931: Pseudo dice [0.7709]\n",
      "2024-11-26 14:18:48.269931: Epoch time: 129.65 s\n",
      "2024-11-26 14:18:49.270206: \n",
      "2024-11-26 14:18:49.270206: Epoch 460\n",
      "2024-11-26 14:18:49.280206: Current learning rate: 0.00103\n",
      "2024-11-26 14:20:58.938946: train_loss -0.8603\n",
      "2024-11-26 14:20:58.938946: val_loss -0.4695\n",
      "2024-11-26 14:20:58.948947: Pseudo dice [0.7311]\n",
      "2024-11-26 14:20:58.948947: Epoch time: 129.67 s\n",
      "2024-11-26 14:20:59.959265: \n",
      "2024-11-26 14:20:59.959265: Epoch 461\n",
      "2024-11-26 14:20:59.969265: Current learning rate: 0.00101\n",
      "2024-11-26 14:23:09.590299: train_loss -0.8549\n",
      "2024-11-26 14:23:09.590299: val_loss -0.5574\n",
      "2024-11-26 14:23:09.590299: Pseudo dice [0.779]\n",
      "2024-11-26 14:23:09.600300: Epoch time: 129.63 s\n",
      "2024-11-26 14:23:10.600312: \n",
      "2024-11-26 14:23:10.600312: Epoch 462\n",
      "2024-11-26 14:23:10.610313: Current learning rate: 0.00098\n",
      "2024-11-26 14:25:20.269321: train_loss -0.8662\n",
      "2024-11-26 14:25:20.269321: val_loss -0.5172\n",
      "2024-11-26 14:25:20.279322: Pseudo dice [0.7696]\n",
      "2024-11-26 14:25:20.279322: Epoch time: 129.67 s\n",
      "2024-11-26 14:25:21.459631: \n",
      "2024-11-26 14:25:21.459631: Epoch 463\n",
      "2024-11-26 14:25:21.469631: Current learning rate: 0.00096\n",
      "2024-11-26 14:27:31.115989: train_loss -0.8596\n",
      "2024-11-26 14:27:31.115989: val_loss -0.509\n",
      "2024-11-26 14:27:31.125990: Pseudo dice [0.7584]\n",
      "2024-11-26 14:27:31.125990: Epoch time: 129.66 s\n",
      "2024-11-26 14:27:32.126003: \n",
      "2024-11-26 14:27:32.126003: Epoch 464\n",
      "2024-11-26 14:27:32.136003: Current learning rate: 0.00094\n",
      "2024-11-26 14:29:41.793139: train_loss -0.8577\n",
      "2024-11-26 14:29:41.793139: val_loss 1e-04\n",
      "2024-11-26 14:29:41.803139: Pseudo dice [0.5137]\n",
      "2024-11-26 14:29:41.803139: Epoch time: 129.67 s\n",
      "2024-11-26 14:29:42.803153: \n",
      "2024-11-26 14:29:42.803153: Epoch 465\n",
      "2024-11-26 14:29:42.813153: Current learning rate: 0.00091\n",
      "2024-11-26 14:31:52.459439: train_loss -0.8492\n",
      "2024-11-26 14:31:52.459439: val_loss -0.4493\n",
      "2024-11-26 14:31:52.469439: Pseudo dice [0.7256]\n",
      "2024-11-26 14:31:52.479440: Epoch time: 129.66 s\n",
      "2024-11-26 14:31:53.479453: \n",
      "2024-11-26 14:31:53.479453: Epoch 466\n",
      "2024-11-26 14:31:53.489453: Current learning rate: 0.00089\n",
      "2024-11-26 14:34:03.146752: train_loss -0.8581\n",
      "2024-11-26 14:34:03.146752: val_loss -0.3991\n",
      "2024-11-26 14:34:03.156752: Pseudo dice [0.7062]\n",
      "2024-11-26 14:34:03.156752: Epoch time: 129.67 s\n",
      "2024-11-26 14:34:04.167073: \n",
      "2024-11-26 14:34:04.167073: Epoch 467\n",
      "2024-11-26 14:34:04.167073: Current learning rate: 0.00087\n",
      "2024-11-26 14:36:13.790675: train_loss -0.8592\n",
      "2024-11-26 14:36:13.790675: val_loss -0.2994\n",
      "2024-11-26 14:36:13.800676: Pseudo dice [0.69]\n",
      "2024-11-26 14:36:13.810677: Epoch time: 129.63 s\n",
      "2024-11-26 14:36:14.821003: \n",
      "2024-11-26 14:36:14.821003: Epoch 468\n",
      "2024-11-26 14:36:14.821003: Current learning rate: 0.00084\n",
      "2024-11-26 14:38:24.476704: train_loss -0.867\n",
      "2024-11-26 14:38:24.476704: val_loss -0.6193\n",
      "2024-11-26 14:38:24.486706: Pseudo dice [0.8057]\n",
      "2024-11-26 14:38:24.486706: Epoch time: 129.67 s\n",
      "2024-11-26 14:38:25.487167: \n",
      "2024-11-26 14:38:25.487167: Epoch 469\n",
      "2024-11-26 14:38:25.497168: Current learning rate: 0.00082\n",
      "2024-11-26 14:40:35.053077: train_loss -0.8606\n",
      "2024-11-26 14:40:35.053077: val_loss -0.5084\n",
      "2024-11-26 14:40:35.063077: Pseudo dice [0.763]\n",
      "2024-11-26 14:40:35.073078: Epoch time: 129.57 s\n",
      "2024-11-26 14:40:36.254114: \n",
      "2024-11-26 14:40:36.254114: Epoch 470\n",
      "2024-11-26 14:40:36.254114: Current learning rate: 0.00079\n",
      "2024-11-26 14:42:45.816271: train_loss -0.8684\n",
      "2024-11-26 14:42:45.816271: val_loss -0.4879\n",
      "2024-11-26 14:42:45.826272: Pseudo dice [0.7622]\n",
      "2024-11-26 14:42:45.826272: Epoch time: 129.56 s\n",
      "2024-11-26 14:42:46.826285: \n",
      "2024-11-26 14:42:46.826285: Epoch 471\n",
      "2024-11-26 14:42:46.836285: Current learning rate: 0.00077\n",
      "2024-11-26 14:44:56.463600: train_loss -0.8637\n",
      "2024-11-26 14:44:56.463600: val_loss -0.2286\n",
      "2024-11-26 14:44:56.473601: Pseudo dice [0.637]\n",
      "2024-11-26 14:44:56.473601: Epoch time: 129.64 s\n",
      "2024-11-26 14:44:57.483614: \n",
      "2024-11-26 14:44:57.483614: Epoch 472\n",
      "2024-11-26 14:44:57.493615: Current learning rate: 0.00075\n",
      "2024-11-26 14:47:07.108219: train_loss -0.8703\n",
      "2024-11-26 14:47:07.108219: val_loss -0.2503\n",
      "2024-11-26 14:47:07.118218: Pseudo dice [0.6587]\n",
      "2024-11-26 14:47:07.118218: Epoch time: 129.62 s\n",
      "2024-11-26 14:47:08.129351: \n",
      "2024-11-26 14:47:08.129351: Epoch 473\n",
      "2024-11-26 14:47:08.139351: Current learning rate: 0.00072\n",
      "2024-11-26 14:49:17.739674: train_loss -0.8605\n",
      "2024-11-26 14:49:17.739674: val_loss -0.399\n",
      "2024-11-26 14:49:17.749674: Pseudo dice [0.7144]\n",
      "2024-11-26 14:49:17.759674: Epoch time: 129.61 s\n",
      "2024-11-26 14:49:18.769689: \n",
      "2024-11-26 14:49:18.769689: Epoch 474\n",
      "2024-11-26 14:49:18.769689: Current learning rate: 0.0007\n",
      "2024-11-26 14:51:28.407793: train_loss -0.8654\n",
      "2024-11-26 14:51:28.407793: val_loss -0.4195\n",
      "2024-11-26 14:51:28.417792: Pseudo dice [0.7334]\n",
      "2024-11-26 14:51:28.427794: Epoch time: 129.64 s\n",
      "2024-11-26 14:51:29.437810: \n",
      "2024-11-26 14:51:29.437810: Epoch 475\n",
      "2024-11-26 14:51:29.437810: Current learning rate: 0.00067\n",
      "2024-11-26 14:53:39.025481: train_loss -0.8572\n",
      "2024-11-26 14:53:39.025481: val_loss -0.3628\n",
      "2024-11-26 14:53:39.035481: Pseudo dice [0.7055]\n",
      "2024-11-26 14:53:39.045482: Epoch time: 129.59 s\n",
      "2024-11-26 14:53:40.045498: \n",
      "2024-11-26 14:53:40.045498: Epoch 476\n",
      "2024-11-26 14:53:40.045498: Current learning rate: 0.00065\n",
      "2024-11-26 14:55:49.654448: train_loss -0.8668\n",
      "2024-11-26 14:55:49.654448: val_loss -0.3606\n",
      "2024-11-26 14:55:49.664448: Pseudo dice [0.7139]\n",
      "2024-11-26 14:55:49.674448: Epoch time: 129.61 s\n",
      "2024-11-26 14:55:50.684465: \n",
      "2024-11-26 14:55:50.684465: Epoch 477\n",
      "2024-11-26 14:55:50.684465: Current learning rate: 0.00063\n",
      "2024-11-26 14:58:00.282475: train_loss -0.8697\n",
      "2024-11-26 14:58:00.282475: val_loss -0.4607\n",
      "2024-11-26 14:58:00.292475: Pseudo dice [0.746]\n",
      "2024-11-26 14:58:00.302477: Epoch time: 129.6 s\n",
      "2024-11-26 14:58:01.502492: \n",
      "2024-11-26 14:58:01.502492: Epoch 478\n",
      "2024-11-26 14:58:01.512492: Current learning rate: 0.0006\n",
      "2024-11-26 15:00:11.121983: train_loss -0.8653\n",
      "2024-11-26 15:00:11.121983: val_loss -0.4825\n",
      "2024-11-26 15:00:11.131985: Pseudo dice [0.7346]\n",
      "2024-11-26 15:00:11.141984: Epoch time: 129.62 s\n",
      "2024-11-26 15:00:12.171999: \n",
      "2024-11-26 15:00:12.171999: Epoch 479\n",
      "2024-11-26 15:00:12.171999: Current learning rate: 0.00058\n",
      "2024-11-26 15:02:21.829433: train_loss -0.8694\n",
      "2024-11-26 15:02:21.829433: val_loss -0.4183\n",
      "2024-11-26 15:02:21.839434: Pseudo dice [0.7369]\n",
      "2024-11-26 15:02:21.839434: Epoch time: 129.67 s\n",
      "2024-11-26 15:02:22.859447: \n",
      "2024-11-26 15:02:22.859447: Epoch 480\n",
      "2024-11-26 15:02:22.869448: Current learning rate: 0.00055\n",
      "2024-11-26 15:04:32.495406: train_loss -0.8606\n",
      "2024-11-26 15:04:32.495406: val_loss -0.5089\n",
      "2024-11-26 15:04:32.505406: Pseudo dice [0.7437]\n",
      "2024-11-26 15:04:32.515407: Epoch time: 129.64 s\n",
      "2024-11-26 15:04:33.535760: \n",
      "2024-11-26 15:04:33.535760: Epoch 481\n",
      "2024-11-26 15:04:33.535760: Current learning rate: 0.00053\n",
      "2024-11-26 15:06:43.220719: train_loss -0.8659\n",
      "2024-11-26 15:06:43.220719: val_loss -0.2392\n",
      "2024-11-26 15:06:43.230720: Pseudo dice [0.6551]\n",
      "2024-11-26 15:06:43.240720: Epoch time: 129.68 s\n",
      "2024-11-26 15:06:44.260700: \n",
      "2024-11-26 15:06:44.260700: Epoch 482\n",
      "2024-11-26 15:06:44.270700: Current learning rate: 0.0005\n",
      "2024-11-26 15:08:53.937869: train_loss -0.8665\n",
      "2024-11-26 15:08:53.937869: val_loss -0.4141\n",
      "2024-11-26 15:08:53.947869: Pseudo dice [0.7333]\n",
      "2024-11-26 15:08:53.947869: Epoch time: 129.68 s\n",
      "2024-11-26 15:08:54.967883: \n",
      "2024-11-26 15:08:54.967883: Epoch 483\n",
      "2024-11-26 15:08:54.977883: Current learning rate: 0.00048\n",
      "2024-11-26 15:11:04.654755: train_loss -0.8588\n",
      "2024-11-26 15:11:04.654755: val_loss -0.3819\n",
      "2024-11-26 15:11:04.664755: Pseudo dice [0.7064]\n",
      "2024-11-26 15:11:04.664755: Epoch time: 129.69 s\n",
      "2024-11-26 15:11:05.684769: \n",
      "2024-11-26 15:11:05.684769: Epoch 484\n",
      "2024-11-26 15:11:05.694770: Current learning rate: 0.00045\n",
      "2024-11-26 15:13:15.337720: train_loss -0.8702\n",
      "2024-11-26 15:13:15.337720: val_loss -0.4533\n",
      "2024-11-26 15:13:15.347720: Pseudo dice [0.7406]\n",
      "2024-11-26 15:13:15.357721: Epoch time: 129.65 s\n",
      "2024-11-26 15:13:16.557737: \n",
      "2024-11-26 15:13:16.557737: Epoch 485\n",
      "2024-11-26 15:13:16.567737: Current learning rate: 0.00043\n",
      "2024-11-26 15:15:26.264941: train_loss -0.8702\n",
      "2024-11-26 15:15:26.264941: val_loss -0.5184\n",
      "2024-11-26 15:15:26.274942: Pseudo dice [0.7714]\n",
      "2024-11-26 15:15:26.274942: Epoch time: 129.71 s\n",
      "2024-11-26 15:15:27.304955: \n",
      "2024-11-26 15:15:27.304955: Epoch 486\n",
      "2024-11-26 15:15:27.304955: Current learning rate: 0.0004\n",
      "2024-11-26 15:17:36.966170: train_loss -0.8684\n",
      "2024-11-26 15:17:36.966170: val_loss -0.5297\n",
      "2024-11-26 15:17:36.976169: Pseudo dice [0.7768]\n",
      "2024-11-26 15:17:36.986171: Epoch time: 129.66 s\n",
      "2024-11-26 15:17:38.016187: \n",
      "2024-11-26 15:17:38.016187: Epoch 487\n",
      "2024-11-26 15:17:38.016187: Current learning rate: 0.00037\n",
      "2024-11-26 15:19:47.672848: train_loss -0.8733\n",
      "2024-11-26 15:19:47.672848: val_loss -0.4977\n",
      "2024-11-26 15:19:47.682848: Pseudo dice [0.7499]\n",
      "2024-11-26 15:19:47.692849: Epoch time: 129.66 s\n",
      "2024-11-26 15:19:48.713212: \n",
      "2024-11-26 15:19:48.713212: Epoch 488\n",
      "2024-11-26 15:19:48.713212: Current learning rate: 0.00035\n",
      "2024-11-26 15:21:58.349999: train_loss -0.8587\n",
      "2024-11-26 15:21:58.349999: val_loss -0.5212\n",
      "2024-11-26 15:21:58.359999: Pseudo dice [0.7689]\n",
      "2024-11-26 15:21:58.359999: Epoch time: 129.65 s\n",
      "2024-11-26 15:21:59.390013: \n",
      "2024-11-26 15:21:59.390013: Epoch 489\n",
      "2024-11-26 15:21:59.390013: Current learning rate: 0.00032\n",
      "2024-11-26 15:24:09.045949: train_loss -0.8649\n",
      "2024-11-26 15:24:09.045949: val_loss -0.4489\n",
      "2024-11-26 15:24:09.055949: Pseudo dice [0.7245]\n",
      "2024-11-26 15:24:09.065950: Epoch time: 129.66 s\n",
      "2024-11-26 15:24:10.105728: \n",
      "2024-11-26 15:24:10.105728: Epoch 490\n",
      "2024-11-26 15:24:10.115728: Current learning rate: 0.0003\n",
      "2024-11-26 15:26:19.726222: train_loss -0.8719\n",
      "2024-11-26 15:26:19.726222: val_loss -0.2855\n",
      "2024-11-26 15:26:19.736223: Pseudo dice [0.6895]\n",
      "2024-11-26 15:26:19.736223: Epoch time: 129.62 s\n",
      "2024-11-26 15:26:20.756237: \n",
      "2024-11-26 15:26:20.756237: Epoch 491\n",
      "2024-11-26 15:26:20.766237: Current learning rate: 0.00027\n",
      "2024-11-26 15:28:30.345328: train_loss -0.8742\n",
      "2024-11-26 15:28:30.345328: val_loss -0.4456\n",
      "2024-11-26 15:28:30.355328: Pseudo dice [0.7246]\n",
      "2024-11-26 15:28:30.365328: Epoch time: 129.59 s\n",
      "2024-11-26 15:28:31.565344: \n",
      "2024-11-26 15:28:31.565344: Epoch 492\n",
      "2024-11-26 15:28:31.575344: Current learning rate: 0.00024\n",
      "2024-11-26 15:30:41.193928: train_loss -0.8728\n",
      "2024-11-26 15:30:41.193928: val_loss -0.4793\n",
      "2024-11-26 15:30:41.203929: Pseudo dice [0.7526]\n",
      "2024-11-26 15:30:41.213929: Epoch time: 129.63 s\n",
      "2024-11-26 15:30:42.233943: \n",
      "2024-11-26 15:30:42.233943: Epoch 493\n",
      "2024-11-26 15:30:42.233943: Current learning rate: 0.00021\n",
      "2024-11-26 15:32:51.800333: train_loss -0.8703\n",
      "2024-11-26 15:32:51.800333: val_loss -0.3268\n",
      "2024-11-26 15:32:51.810335: Pseudo dice [0.7078]\n",
      "2024-11-26 15:32:51.820334: Epoch time: 129.58 s\n",
      "2024-11-26 15:32:52.854664: \n",
      "2024-11-26 15:32:52.854664: Epoch 494\n",
      "2024-11-26 15:32:52.859782: Current learning rate: 0.00019\n",
      "2024-11-26 15:35:02.502373: train_loss -0.8687\n",
      "2024-11-26 15:35:02.502373: val_loss -0.4524\n",
      "2024-11-26 15:35:02.512373: Pseudo dice [0.7489]\n",
      "2024-11-26 15:35:02.512373: Epoch time: 129.65 s\n",
      "2024-11-26 15:35:03.542695: \n",
      "2024-11-26 15:35:03.542695: Epoch 495\n",
      "2024-11-26 15:35:03.542695: Current learning rate: 0.00016\n",
      "2024-11-26 15:37:13.183583: train_loss -0.8673\n",
      "2024-11-26 15:37:13.183583: val_loss -0.4436\n",
      "2024-11-26 15:37:13.193584: Pseudo dice [0.7487]\n",
      "2024-11-26 15:37:13.203583: Epoch time: 129.65 s\n",
      "2024-11-26 15:37:14.223598: \n",
      "2024-11-26 15:37:14.223598: Epoch 496\n",
      "2024-11-26 15:37:14.233598: Current learning rate: 0.00013\n",
      "2024-11-26 15:39:23.847126: train_loss -0.8697\n",
      "2024-11-26 15:39:23.847126: val_loss -0.3749\n",
      "2024-11-26 15:39:23.857126: Pseudo dice [0.7015]\n",
      "2024-11-26 15:39:23.867127: Epoch time: 129.62 s\n",
      "2024-11-26 15:39:24.898121: \n",
      "2024-11-26 15:39:24.898121: Epoch 497\n",
      "2024-11-26 15:39:24.908122: Current learning rate: 0.0001\n",
      "2024-11-26 15:41:34.562328: train_loss -0.8618\n",
      "2024-11-26 15:41:34.562328: val_loss -0.5213\n",
      "2024-11-26 15:41:34.572328: Pseudo dice [0.7556]\n",
      "2024-11-26 15:41:34.582329: Epoch time: 129.66 s\n",
      "2024-11-26 15:41:35.613293: \n",
      "2024-11-26 15:41:35.613293: Epoch 498\n",
      "2024-11-26 15:41:35.613293: Current learning rate: 7e-05\n",
      "2024-11-26 15:43:45.260600: train_loss -0.8624\n",
      "2024-11-26 15:43:45.260600: val_loss -0.4487\n",
      "2024-11-26 15:43:45.270599: Pseudo dice [0.738]\n",
      "2024-11-26 15:43:45.280600: Epoch time: 129.65 s\n",
      "2024-11-26 15:43:46.300614: \n",
      "2024-11-26 15:43:46.310614: Epoch 499\n",
      "2024-11-26 15:43:46.310614: Current learning rate: 4e-05\n",
      "2024-11-26 15:45:55.940205: train_loss -0.8604\n",
      "2024-11-26 15:45:55.940205: val_loss -0.3878\n",
      "2024-11-26 15:45:55.950204: Pseudo dice [0.7109]\n",
      "2024-11-26 15:45:55.960207: Epoch time: 129.64 s\n",
      "2024-11-26 15:45:57.470225: Training done.\n",
      "2024-11-26 15:45:57.520226: Using splits from existing split file: D:/Liver Segmentation Meena 2024/nnUNet_blastoma_2025/nnUNet_preprocessed\\Dataset007_Blastoma\\splits_final.json\n",
      "2024-11-26 15:45:57.530227: The split file contains 5 splits.\n",
      "2024-11-26 15:45:57.546231: Desired fold for training: 3\n",
      "2024-11-26 15:45:57.550238: This split has 19 training and 5 validation cases.\n",
      "2024-11-26 15:45:57.560240: predicting volume_15\n",
      "2024-11-26 15:45:57.570241: volume_15, shape torch.Size([1, 461, 512, 512]), rank 0\n",
      "2024-11-26 15:49:24.811346: predicting volume_3\n",
      "2024-11-26 15:49:24.861346: volume_3, shape torch.Size([1, 594, 512, 512]), rank 0\n",
      "2024-11-26 15:53:48.825393: predicting volume_7\n",
      "2024-11-26 15:53:48.885394: volume_7, shape torch.Size([1, 625, 596, 596]), rank 0\n",
      "2024-11-26 16:01:05.495353: predicting volume_8\n",
      "2024-11-26 16:01:05.575594: volume_8, shape torch.Size([1, 594, 512, 512]), rank 0\n",
      "2024-11-26 16:05:30.620269: predicting volume_9\n",
      "2024-11-26 16:05:30.690270: volume_9, shape torch.Size([1, 634, 479, 479]), rank 0\n",
      "2024-11-26 16:10:15.761765: Validation complete\n",
      "2024-11-26 16:10:15.761765: Mean Validation Dice:  0.6417853683355939\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "try:\n",
    "    !nnUNetv2_train 007 3d_fullres 3 -tr nnUNetTrainer\n",
    "except Exception as e:\n",
    "    print(f\"Error during training: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nnunetv2\\training\\nnUNetTrainer\\nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
      "C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2024-11-25 02:34:44.775848: do_dummy_2d_data_aug: False\n",
      "2024-11-25 02:34:44.780849: Using splits from existing split file: D:/Liver Segmentation Meena 2024/nnUNet_blastoma_2025/nnUNet_preprocessed\\Dataset007_Blastoma\\splits_final.json\n",
      "2024-11-25 02:34:44.787851: The split file contains 5 splits.\n",
      "2024-11-25 02:34:44.791852: Desired fold for training: 2\n",
      "2024-11-25 02:34:44.794853: This split has 19 training and 5 validation cases.\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 3d_fullres\n",
      " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [569.5, 512.0, 512.0], 'spacing': [0.625, 0.4882810115814209, 0.4882810115814209], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset007_Blastoma', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.625, 0.4882810115814209, 0.4882810115814209], 'original_median_shape_after_transp': [471, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2609.056396484375, 'mean': 68.07295227050781, 'median': 66.0, 'min': -1028.0, 'percentile_00_5': -59.0, 'percentile_99_5': 248.0, 'std': 47.62541198730469}}} \n",
      "\n",
      "2024-11-25 02:34:56.201766: unpacking dataset...\n",
      "2024-11-25 02:34:56.595855: unpacking done...\n",
      "2024-11-25 02:34:56.608858: Unable to plot network architecture:\n",
      "2024-11-25 02:34:56.612859: No module named 'hiddenlayer'\n",
      "2024-11-25 02:34:56.639865: \n",
      "2024-11-25 02:34:56.646866: Epoch 0\n",
      "2024-11-25 02:34:56.650867: Current learning rate: 0.01\n",
      "2024-11-25 02:37:21.051448: train_loss 0.0487\n",
      "2024-11-25 02:37:21.061448: val_loss -0.2737\n",
      "2024-11-25 02:37:21.061448: Pseudo dice [0.5797]\n",
      "2024-11-25 02:37:21.061448: Epoch time: 144.41 s\n",
      "2024-11-25 02:37:21.071449: Yayy! New best EMA pseudo Dice: 0.5797\n",
      "2024-11-25 02:37:22.339436: \n",
      "2024-11-25 02:37:22.339436: Epoch 1\n",
      "2024-11-25 02:37:22.349437: Current learning rate: 0.00998\n",
      "2024-11-25 02:39:32.172079: train_loss -0.115\n",
      "2024-11-25 02:39:32.182079: val_loss -0.1697\n",
      "2024-11-25 02:39:32.182079: Pseudo dice [0.4705]\n",
      "2024-11-25 02:39:32.192080: Epoch time: 129.84 s\n",
      "2024-11-25 02:39:33.178566: \n",
      "2024-11-25 02:39:33.178566: Epoch 2\n",
      "2024-11-25 02:39:33.188566: Current learning rate: 0.00996\n",
      "2024-11-25 02:41:42.935533: train_loss -0.1479\n",
      "2024-11-25 02:41:42.945534: val_loss -0.26\n",
      "2024-11-25 02:41:42.945534: Pseudo dice [0.5917]\n",
      "2024-11-25 02:41:42.955534: Epoch time: 129.76 s\n",
      "2024-11-25 02:41:43.983706: \n",
      "2024-11-25 02:41:43.993706: Epoch 3\n",
      "2024-11-25 02:41:44.003706: Current learning rate: 0.00995\n",
      "2024-11-25 02:43:54.035104: train_loss -0.144\n",
      "2024-11-25 02:43:54.065105: val_loss -0.1715\n",
      "2024-11-25 02:43:54.065105: Pseudo dice [0.5164]\n",
      "2024-11-25 02:43:54.075105: Epoch time: 130.05 s\n",
      "2024-11-25 02:43:55.075118: \n",
      "2024-11-25 02:43:55.085118: Epoch 4\n",
      "2024-11-25 02:43:55.095118: Current learning rate: 0.00993\n",
      "2024-11-25 02:46:04.966983: train_loss -0.1908\n",
      "2024-11-25 02:46:04.976983: val_loss -0.0328\n",
      "2024-11-25 02:46:04.976983: Pseudo dice [0.3719]\n",
      "2024-11-25 02:46:04.986982: Epoch time: 129.89 s\n",
      "2024-11-25 02:46:06.016997: \n",
      "2024-11-25 02:46:06.016997: Epoch 5\n",
      "2024-11-25 02:46:06.026997: Current learning rate: 0.00991\n",
      "2024-11-25 02:48:15.809000: train_loss -0.1972\n",
      "2024-11-25 02:48:15.819000: val_loss -0.2128\n",
      "2024-11-25 02:48:15.829000: Pseudo dice [0.5145]\n",
      "2024-11-25 02:48:15.829000: Epoch time: 129.8 s\n",
      "2024-11-25 02:48:16.795068: \n",
      "2024-11-25 02:48:16.805068: Epoch 6\n",
      "2024-11-25 02:48:16.805068: Current learning rate: 0.00989\n",
      "2024-11-25 02:50:26.572057: train_loss -0.2543\n",
      "2024-11-25 02:50:26.582057: val_loss -0.2662\n",
      "2024-11-25 02:50:26.582057: Pseudo dice [0.5263]\n",
      "2024-11-25 02:50:26.592056: Epoch time: 129.77 s\n",
      "2024-11-25 02:50:27.592071: \n",
      "2024-11-25 02:50:27.592071: Epoch 7\n",
      "2024-11-25 02:50:27.602071: Current learning rate: 0.00987\n",
      "2024-11-25 02:52:37.495716: train_loss -0.2202\n",
      "2024-11-25 02:52:37.515716: val_loss -0.2274\n",
      "2024-11-25 02:52:37.515716: Pseudo dice [0.5404]\n",
      "2024-11-25 02:52:37.525715: Epoch time: 129.91 s\n",
      "2024-11-25 02:52:38.705733: \n",
      "2024-11-25 02:52:38.705733: Epoch 8\n",
      "2024-11-25 02:52:38.715732: Current learning rate: 0.00986\n",
      "2024-11-25 02:54:48.473893: train_loss -0.2846\n",
      "2024-11-25 02:54:48.483893: val_loss -0.2025\n",
      "2024-11-25 02:54:48.483893: Pseudo dice [0.4806]\n",
      "2024-11-25 02:54:48.493893: Epoch time: 129.77 s\n",
      "2024-11-25 02:54:49.499205: \n",
      "2024-11-25 02:54:49.509204: Epoch 9\n",
      "2024-11-25 02:54:49.509204: Current learning rate: 0.00984\n",
      "2024-11-25 02:56:59.291605: train_loss -0.2794\n",
      "2024-11-25 02:56:59.301607: val_loss -0.2411\n",
      "2024-11-25 02:56:59.311607: Pseudo dice [0.4785]\n",
      "2024-11-25 02:56:59.311607: Epoch time: 129.79 s\n",
      "2024-11-25 02:57:00.284582: \n",
      "2024-11-25 02:57:00.294582: Epoch 10\n",
      "2024-11-25 02:57:00.294582: Current learning rate: 0.00982\n",
      "2024-11-25 02:59:10.153093: train_loss -0.2675\n",
      "2024-11-25 02:59:10.163094: val_loss -0.4016\n",
      "2024-11-25 02:59:10.173095: Pseudo dice [0.643]\n",
      "2024-11-25 02:59:10.173095: Epoch time: 129.87 s\n",
      "2024-11-25 02:59:11.153107: \n",
      "2024-11-25 02:59:11.163107: Epoch 11\n",
      "2024-11-25 02:59:11.163107: Current learning rate: 0.0098\n",
      "2024-11-25 03:01:20.873572: train_loss -0.2608\n",
      "2024-11-25 03:01:20.883571: val_loss -0.3374\n",
      "2024-11-25 03:01:20.883571: Pseudo dice [0.5603]\n",
      "2024-11-25 03:01:20.893573: Epoch time: 129.72 s\n",
      "2024-11-25 03:01:21.870489: \n",
      "2024-11-25 03:01:21.879992: Epoch 12\n",
      "2024-11-25 03:01:21.879992: Current learning rate: 0.00978\n",
      "2024-11-25 03:03:31.600355: train_loss -0.2834\n",
      "2024-11-25 03:03:31.610355: val_loss -0.2217\n",
      "2024-11-25 03:03:31.620356: Pseudo dice [0.4835]\n",
      "2024-11-25 03:03:31.630355: Epoch time: 129.73 s\n",
      "2024-11-25 03:03:32.619416: \n",
      "2024-11-25 03:03:32.629416: Epoch 13\n",
      "2024-11-25 03:03:32.639416: Current learning rate: 0.00977\n",
      "2024-11-25 03:05:42.490603: train_loss -0.2804\n",
      "2024-11-25 03:05:42.500604: val_loss -0.3075\n",
      "2024-11-25 03:05:42.510604: Pseudo dice [0.5653]\n",
      "2024-11-25 03:05:42.510604: Epoch time: 129.87 s\n",
      "2024-11-25 03:05:43.506657: \n",
      "2024-11-25 03:05:43.516657: Epoch 14\n",
      "2024-11-25 03:05:43.516657: Current learning rate: 0.00975\n",
      "2024-11-25 03:07:55.505545: train_loss -0.3211\n",
      "2024-11-25 03:07:55.515544: val_loss -0.2532\n",
      "2024-11-25 03:07:55.525545: Pseudo dice [0.5287]\n",
      "2024-11-25 03:07:55.535545: Epoch time: 132.0 s\n",
      "2024-11-25 03:07:56.705562: \n",
      "2024-11-25 03:07:56.715562: Epoch 15\n",
      "2024-11-25 03:07:56.715562: Current learning rate: 0.00973\n",
      "2024-11-25 03:10:06.409112: train_loss -0.3445\n",
      "2024-11-25 03:10:06.409112: val_loss -0.2865\n",
      "2024-11-25 03:10:06.419113: Pseudo dice [0.5508]\n",
      "2024-11-25 03:10:06.429112: Epoch time: 129.7 s\n",
      "2024-11-25 03:10:07.439126: \n",
      "2024-11-25 03:10:07.449127: Epoch 16\n",
      "2024-11-25 03:10:07.449127: Current learning rate: 0.00971\n",
      "2024-11-25 03:12:17.123684: train_loss -0.3421\n",
      "2024-11-25 03:12:17.133685: val_loss -0.3956\n",
      "2024-11-25 03:12:17.143685: Pseudo dice [0.6127]\n",
      "2024-11-25 03:12:17.143685: Epoch time: 129.68 s\n",
      "2024-11-25 03:12:18.194254: \n",
      "2024-11-25 03:12:18.202256: Epoch 17\n",
      "2024-11-25 03:12:18.209258: Current learning rate: 0.00969\n",
      "2024-11-25 03:14:28.016373: train_loss -0.3599\n",
      "2024-11-25 03:14:28.026374: val_loss -0.4042\n",
      "2024-11-25 03:14:28.026374: Pseudo dice [0.6372]\n",
      "2024-11-25 03:14:28.036374: Epoch time: 129.82 s\n",
      "2024-11-25 03:14:29.046387: \n",
      "2024-11-25 03:14:29.056388: Epoch 18\n",
      "2024-11-25 03:14:29.056388: Current learning rate: 0.00968\n",
      "2024-11-25 03:16:38.767711: train_loss -0.3539\n",
      "2024-11-25 03:16:38.777712: val_loss -0.3936\n",
      "2024-11-25 03:16:38.787711: Pseudo dice [0.6349]\n",
      "2024-11-25 03:16:38.797711: Epoch time: 129.72 s\n",
      "2024-11-25 03:16:39.816534: \n",
      "2024-11-25 03:16:39.826535: Epoch 19\n",
      "2024-11-25 03:16:39.826535: Current learning rate: 0.00966\n",
      "2024-11-25 03:18:49.560170: train_loss -0.3816\n",
      "2024-11-25 03:18:49.570169: val_loss -0.3554\n",
      "2024-11-25 03:18:49.580170: Pseudo dice [0.5896]\n",
      "2024-11-25 03:18:49.580170: Epoch time: 129.74 s\n",
      "2024-11-25 03:18:50.585511: \n",
      "2024-11-25 03:18:50.595511: Epoch 20\n",
      "2024-11-25 03:18:50.595511: Current learning rate: 0.00964\n",
      "2024-11-25 03:21:00.424279: train_loss -0.3898\n",
      "2024-11-25 03:21:00.444281: val_loss -0.4405\n",
      "2024-11-25 03:21:00.444281: Pseudo dice [0.6646]\n",
      "2024-11-25 03:21:00.454281: Epoch time: 129.84 s\n",
      "2024-11-25 03:21:01.477111: \n",
      "2024-11-25 03:21:01.477111: Epoch 21\n",
      "2024-11-25 03:21:01.487111: Current learning rate: 0.00962\n",
      "2024-11-25 03:23:11.285242: train_loss -0.4042\n",
      "2024-11-25 03:23:11.295243: val_loss -0.3508\n",
      "2024-11-25 03:23:11.305244: Pseudo dice [0.5957]\n",
      "2024-11-25 03:23:11.305244: Epoch time: 129.82 s\n",
      "2024-11-25 03:23:12.444007: \n",
      "2024-11-25 03:23:12.454007: Epoch 22\n",
      "2024-11-25 03:23:12.454007: Current learning rate: 0.0096\n",
      "2024-11-25 03:25:22.120225: train_loss -0.3076\n",
      "2024-11-25 03:25:22.130225: val_loss -0.3604\n",
      "2024-11-25 03:25:22.140226: Pseudo dice [0.5407]\n",
      "2024-11-25 03:25:22.140226: Epoch time: 129.68 s\n",
      "2024-11-25 03:25:23.110239: \n",
      "2024-11-25 03:25:23.120239: Epoch 23\n",
      "2024-11-25 03:25:23.120239: Current learning rate: 0.00959\n",
      "2024-11-25 03:27:32.817003: train_loss -0.3945\n",
      "2024-11-25 03:27:32.827004: val_loss -0.3425\n",
      "2024-11-25 03:27:32.827004: Pseudo dice [0.5597]\n",
      "2024-11-25 03:27:32.837005: Epoch time: 129.71 s\n",
      "2024-11-25 03:27:33.787918: \n",
      "2024-11-25 03:27:33.797918: Epoch 24\n",
      "2024-11-25 03:27:33.797918: Current learning rate: 0.00957\n",
      "2024-11-25 03:29:43.588928: train_loss -0.3802\n",
      "2024-11-25 03:29:43.598929: val_loss -0.3453\n",
      "2024-11-25 03:29:43.608928: Pseudo dice [0.5787]\n",
      "2024-11-25 03:29:43.616455: Epoch time: 129.8 s\n",
      "2024-11-25 03:29:44.591593: \n",
      "2024-11-25 03:29:44.601593: Epoch 25\n",
      "2024-11-25 03:29:44.601593: Current learning rate: 0.00955\n",
      "2024-11-25 03:31:54.246936: train_loss -0.3008\n",
      "2024-11-25 03:31:54.258900: val_loss -0.3879\n",
      "2024-11-25 03:31:54.272385: Pseudo dice [0.5954]\n",
      "2024-11-25 03:31:54.279391: Epoch time: 129.66 s\n",
      "2024-11-25 03:31:55.252609: \n",
      "2024-11-25 03:31:55.262609: Epoch 26\n",
      "2024-11-25 03:31:55.262609: Current learning rate: 0.00953\n",
      "2024-11-25 03:34:04.905411: train_loss -0.3712\n",
      "2024-11-25 03:34:04.915412: val_loss -0.361\n",
      "2024-11-25 03:34:04.915412: Pseudo dice [0.5507]\n",
      "2024-11-25 03:34:04.925412: Epoch time: 129.65 s\n",
      "2024-11-25 03:34:05.902858: \n",
      "2024-11-25 03:34:05.912858: Epoch 27\n",
      "2024-11-25 03:34:05.922858: Current learning rate: 0.00951\n",
      "2024-11-25 03:36:15.605706: train_loss -0.4041\n",
      "2024-11-25 03:36:15.615706: val_loss -0.3527\n",
      "2024-11-25 03:36:15.615706: Pseudo dice [0.5822]\n",
      "2024-11-25 03:36:15.625706: Epoch time: 129.7 s\n",
      "2024-11-25 03:36:16.615719: \n",
      "2024-11-25 03:36:16.615719: Epoch 28\n",
      "2024-11-25 03:36:16.625720: Current learning rate: 0.00949\n",
      "2024-11-25 03:38:26.239113: train_loss -0.4343\n",
      "2024-11-25 03:38:26.259114: val_loss -0.3967\n",
      "2024-11-25 03:38:26.269114: Pseudo dice [0.576]\n",
      "2024-11-25 03:38:26.269114: Epoch time: 129.63 s\n",
      "2024-11-25 03:38:27.415944: \n",
      "2024-11-25 03:38:27.415944: Epoch 29\n",
      "2024-11-25 03:38:27.425944: Current learning rate: 0.00948\n",
      "2024-11-25 03:40:37.070413: train_loss -0.4764\n",
      "2024-11-25 03:40:37.080412: val_loss -0.3852\n",
      "2024-11-25 03:40:37.090414: Pseudo dice [0.6029]\n",
      "2024-11-25 03:40:37.100414: Epoch time: 129.66 s\n",
      "2024-11-25 03:40:38.080427: \n",
      "2024-11-25 03:40:38.090427: Epoch 30\n",
      "2024-11-25 03:40:38.090427: Current learning rate: 0.00946\n",
      "2024-11-25 03:42:47.740247: train_loss -0.4172\n",
      "2024-11-25 03:42:47.750249: val_loss -0.3996\n",
      "2024-11-25 03:42:47.760248: Pseudo dice [0.6016]\n",
      "2024-11-25 03:42:47.770248: Epoch time: 129.66 s\n",
      "2024-11-25 03:42:48.763199: \n",
      "2024-11-25 03:42:48.773199: Epoch 31\n",
      "2024-11-25 03:42:48.773199: Current learning rate: 0.00944\n",
      "2024-11-25 03:44:58.530257: train_loss -0.4439\n",
      "2024-11-25 03:44:58.540257: val_loss -0.4203\n",
      "2024-11-25 03:44:58.550257: Pseudo dice [0.5943]\n",
      "2024-11-25 03:44:58.560258: Epoch time: 129.77 s\n",
      "2024-11-25 03:44:58.560258: Yayy! New best EMA pseudo Dice: 0.5811\n",
      "2024-11-25 03:44:59.800099: \n",
      "2024-11-25 03:44:59.810098: Epoch 32\n",
      "2024-11-25 03:44:59.810098: Current learning rate: 0.00942\n",
      "2024-11-25 03:47:09.410423: train_loss -0.4674\n",
      "2024-11-25 03:47:09.420424: val_loss -0.3351\n",
      "2024-11-25 03:47:09.430424: Pseudo dice [0.5997]\n",
      "2024-11-25 03:47:09.440424: Epoch time: 129.61 s\n",
      "2024-11-25 03:47:09.450424: Yayy! New best EMA pseudo Dice: 0.583\n",
      "2024-11-25 03:47:10.680440: \n",
      "2024-11-25 03:47:10.690441: Epoch 33\n",
      "2024-11-25 03:47:10.690441: Current learning rate: 0.0094\n",
      "2024-11-25 03:49:20.325305: train_loss -0.4552\n",
      "2024-11-25 03:49:20.335305: val_loss -0.377\n",
      "2024-11-25 03:49:20.335305: Pseudo dice [0.6105]\n",
      "2024-11-25 03:49:20.345306: Epoch time: 129.64 s\n",
      "2024-11-25 03:49:20.345306: Yayy! New best EMA pseudo Dice: 0.5857\n",
      "2024-11-25 03:49:21.607904: \n",
      "2024-11-25 03:49:21.617904: Epoch 34\n",
      "2024-11-25 03:49:21.627904: Current learning rate: 0.00939\n",
      "2024-11-25 03:51:31.284121: train_loss -0.4349\n",
      "2024-11-25 03:51:31.294122: val_loss -0.4376\n",
      "2024-11-25 03:51:31.304123: Pseudo dice [0.6763]\n",
      "2024-11-25 03:51:31.314122: Epoch time: 129.68 s\n",
      "2024-11-25 03:51:31.324123: Yayy! New best EMA pseudo Dice: 0.5948\n",
      "2024-11-25 03:51:32.604140: \n",
      "2024-11-25 03:51:32.614141: Epoch 35\n",
      "2024-11-25 03:51:32.614141: Current learning rate: 0.00937\n",
      "2024-11-25 03:53:42.587894: train_loss -0.44\n",
      "2024-11-25 03:53:42.597896: val_loss -0.3515\n",
      "2024-11-25 03:53:42.607895: Pseudo dice [0.6019]\n",
      "2024-11-25 03:53:42.607895: Epoch time: 129.98 s\n",
      "2024-11-25 03:53:42.617895: Yayy! New best EMA pseudo Dice: 0.5955\n",
      "2024-11-25 03:53:44.067057: \n",
      "2024-11-25 03:53:44.077057: Epoch 36\n",
      "2024-11-25 03:53:44.077057: Current learning rate: 0.00935\n",
      "2024-11-25 03:55:53.671540: train_loss -0.4396\n",
      "2024-11-25 03:55:53.681540: val_loss -0.3903\n",
      "2024-11-25 03:55:53.691541: Pseudo dice [0.6131]\n",
      "2024-11-25 03:55:53.691541: Epoch time: 129.6 s\n",
      "2024-11-25 03:55:53.701541: Yayy! New best EMA pseudo Dice: 0.5973\n",
      "2024-11-25 03:55:54.941397: \n",
      "2024-11-25 03:55:54.941397: Epoch 37\n",
      "2024-11-25 03:55:54.951397: Current learning rate: 0.00933\n",
      "2024-11-25 03:58:04.528411: train_loss -0.4844\n",
      "2024-11-25 03:58:04.538410: val_loss -0.2735\n",
      "2024-11-25 03:58:04.538410: Pseudo dice [0.4818]\n",
      "2024-11-25 03:58:04.548412: Epoch time: 129.59 s\n",
      "2024-11-25 03:58:05.558425: \n",
      "2024-11-25 03:58:05.568425: Epoch 38\n",
      "2024-11-25 03:58:05.568425: Current learning rate: 0.00931\n",
      "2024-11-25 04:00:15.322444: train_loss -0.4793\n",
      "2024-11-25 04:00:15.342075: val_loss -0.4525\n",
      "2024-11-25 04:00:15.352078: Pseudo dice [0.6167]\n",
      "2024-11-25 04:00:15.362077: Epoch time: 129.76 s\n",
      "2024-11-25 04:00:16.375280: \n",
      "2024-11-25 04:00:16.385280: Epoch 39\n",
      "2024-11-25 04:00:16.385280: Current learning rate: 0.0093\n",
      "2024-11-25 04:02:25.965610: train_loss -0.4346\n",
      "2024-11-25 04:02:25.975611: val_loss -0.3285\n",
      "2024-11-25 04:02:25.985610: Pseudo dice [0.5406]\n",
      "2024-11-25 04:02:25.995610: Epoch time: 129.59 s\n",
      "2024-11-25 04:02:27.015633: \n",
      "2024-11-25 04:02:27.025623: Epoch 40\n",
      "2024-11-25 04:02:27.025623: Current learning rate: 0.00928\n",
      "2024-11-25 04:04:36.625858: train_loss -0.4274\n",
      "2024-11-25 04:04:36.635859: val_loss -0.3692\n",
      "2024-11-25 04:04:36.645858: Pseudo dice [0.5968]\n",
      "2024-11-25 04:04:36.645858: Epoch time: 129.61 s\n",
      "2024-11-25 04:04:37.692980: \n",
      "2024-11-25 04:04:37.700009: Epoch 41\n",
      "2024-11-25 04:04:37.705009: Current learning rate: 0.00926\n",
      "2024-11-25 04:06:47.296150: train_loss -0.5065\n",
      "2024-11-25 04:06:47.306151: val_loss -0.4325\n",
      "2024-11-25 04:06:47.316150: Pseudo dice [0.6307]\n",
      "2024-11-25 04:06:47.316150: Epoch time: 129.6 s\n",
      "2024-11-25 04:06:48.275261: \n",
      "2024-11-25 04:06:48.285260: Epoch 42\n",
      "2024-11-25 04:06:48.285260: Current learning rate: 0.00924\n",
      "2024-11-25 04:08:58.196389: train_loss -0.4245\n",
      "2024-11-25 04:08:58.206389: val_loss -0.4174\n",
      "2024-11-25 04:08:58.206389: Pseudo dice [0.6033]\n",
      "2024-11-25 04:08:58.216389: Epoch time: 129.92 s\n",
      "2024-11-25 04:08:59.349690: \n",
      "2024-11-25 04:08:59.349690: Epoch 43\n",
      "2024-11-25 04:08:59.359691: Current learning rate: 0.00922\n",
      "2024-11-25 04:11:08.936710: train_loss -0.4878\n",
      "2024-11-25 04:11:08.946711: val_loss -0.4129\n",
      "2024-11-25 04:11:08.956711: Pseudo dice [0.5923]\n",
      "2024-11-25 04:11:08.966711: Epoch time: 129.59 s\n",
      "2024-11-25 04:11:09.923304: \n",
      "2024-11-25 04:11:09.933296: Epoch 44\n",
      "2024-11-25 04:11:09.933296: Current learning rate: 0.0092\n",
      "2024-11-25 04:13:19.509568: train_loss -0.4647\n",
      "2024-11-25 04:13:19.520162: val_loss -0.47\n",
      "2024-11-25 04:13:19.529164: Pseudo dice [0.6727]\n",
      "2024-11-25 04:13:19.530743: Epoch time: 129.59 s\n",
      "2024-11-25 04:13:19.530743: Yayy! New best EMA pseudo Dice: 0.5994\n",
      "2024-11-25 04:13:20.730264: \n",
      "2024-11-25 04:13:20.740264: Epoch 45\n",
      "2024-11-25 04:13:20.740264: Current learning rate: 0.00919\n",
      "2024-11-25 04:15:30.337173: train_loss -0.472\n",
      "2024-11-25 04:15:30.347172: val_loss -0.4423\n",
      "2024-11-25 04:15:30.347172: Pseudo dice [0.6403]\n",
      "2024-11-25 04:15:30.357173: Epoch time: 129.61 s\n",
      "2024-11-25 04:15:30.367173: Yayy! New best EMA pseudo Dice: 0.6035\n",
      "2024-11-25 04:15:31.567198: \n",
      "2024-11-25 04:15:31.577190: Epoch 46\n",
      "2024-11-25 04:15:31.577190: Current learning rate: 0.00917\n",
      "2024-11-25 04:17:41.234140: train_loss -0.5344\n",
      "2024-11-25 04:17:41.244140: val_loss -0.3184\n",
      "2024-11-25 04:17:41.254140: Pseudo dice [0.5784]\n",
      "2024-11-25 04:17:41.264140: Epoch time: 129.67 s\n",
      "2024-11-25 04:17:42.214163: \n",
      "2024-11-25 04:17:42.224154: Epoch 47\n",
      "2024-11-25 04:17:42.224154: Current learning rate: 0.00915\n",
      "2024-11-25 04:19:51.787711: train_loss -0.4857\n",
      "2024-11-25 04:19:51.797712: val_loss -0.4866\n",
      "2024-11-25 04:19:51.807713: Pseudo dice [0.6914]\n",
      "2024-11-25 04:19:51.817712: Epoch time: 129.57 s\n",
      "2024-11-25 04:19:51.817712: Yayy! New best EMA pseudo Dice: 0.61\n",
      "2024-11-25 04:19:53.041025: \n",
      "2024-11-25 04:19:53.041025: Epoch 48\n",
      "2024-11-25 04:19:53.051017: Current learning rate: 0.00913\n",
      "2024-11-25 04:22:02.598046: train_loss -0.4847\n",
      "2024-11-25 04:22:02.608046: val_loss -0.399\n",
      "2024-11-25 04:22:02.618046: Pseudo dice [0.6257]\n",
      "2024-11-25 04:22:02.618046: Epoch time: 129.57 s\n",
      "2024-11-25 04:22:02.628047: Yayy! New best EMA pseudo Dice: 0.6116\n",
      "2024-11-25 04:22:03.844626: \n",
      "2024-11-25 04:22:03.854617: Epoch 49\n",
      "2024-11-25 04:22:03.854617: Current learning rate: 0.00911\n",
      "2024-11-25 04:24:13.368279: train_loss -0.4867\n",
      "2024-11-25 04:24:13.378280: val_loss -0.4944\n",
      "2024-11-25 04:24:13.388279: Pseudo dice [0.698]\n",
      "2024-11-25 04:24:13.398281: Epoch time: 129.52 s\n",
      "2024-11-25 04:24:13.628283: Yayy! New best EMA pseudo Dice: 0.6202\n",
      "2024-11-25 04:24:14.981628: \n",
      "2024-11-25 04:24:14.991628: Epoch 50\n",
      "2024-11-25 04:24:14.991628: Current learning rate: 0.0091\n",
      "2024-11-25 04:26:24.598579: train_loss -0.5249\n",
      "2024-11-25 04:26:24.608578: val_loss -0.5095\n",
      "2024-11-25 04:26:24.618579: Pseudo dice [0.661]\n",
      "2024-11-25 04:26:24.628579: Epoch time: 129.62 s\n",
      "2024-11-25 04:26:24.638580: Yayy! New best EMA pseudo Dice: 0.6243\n",
      "2024-11-25 04:26:25.848596: \n",
      "2024-11-25 04:26:25.858596: Epoch 51\n",
      "2024-11-25 04:26:25.858596: Current learning rate: 0.00908\n",
      "2024-11-25 04:28:35.379057: train_loss -0.5154\n",
      "2024-11-25 04:28:35.389056: val_loss -0.3701\n",
      "2024-11-25 04:28:35.399058: Pseudo dice [0.5602]\n",
      "2024-11-25 04:28:35.409058: Epoch time: 129.53 s\n",
      "2024-11-25 04:28:36.395391: \n",
      "2024-11-25 04:28:36.405388: Epoch 52\n",
      "2024-11-25 04:28:36.415388: Current learning rate: 0.00906\n",
      "2024-11-25 04:30:45.949067: train_loss -0.4751\n",
      "2024-11-25 04:30:45.959068: val_loss -0.5039\n",
      "2024-11-25 04:30:45.969069: Pseudo dice [0.6738]\n",
      "2024-11-25 04:30:45.969069: Epoch time: 129.55 s\n",
      "2024-11-25 04:30:46.959082: \n",
      "2024-11-25 04:30:46.969082: Epoch 53\n",
      "2024-11-25 04:30:46.969082: Current learning rate: 0.00904\n",
      "2024-11-25 04:32:56.679340: train_loss -0.5588\n",
      "2024-11-25 04:32:56.689340: val_loss -0.4104\n",
      "2024-11-25 04:32:56.699341: Pseudo dice [0.649]\n",
      "2024-11-25 04:32:56.699341: Epoch time: 129.72 s\n",
      "2024-11-25 04:32:56.709341: Yayy! New best EMA pseudo Dice: 0.6261\n",
      "2024-11-25 04:32:57.935965: \n",
      "2024-11-25 04:32:57.935965: Epoch 54\n",
      "2024-11-25 04:32:57.945966: Current learning rate: 0.00902\n",
      "2024-11-25 04:35:07.554483: train_loss -0.5609\n",
      "2024-11-25 04:35:07.574484: val_loss -0.4989\n",
      "2024-11-25 04:35:07.574484: Pseudo dice [0.6897]\n",
      "2024-11-25 04:35:07.584485: Epoch time: 129.62 s\n",
      "2024-11-25 04:35:07.594486: Yayy! New best EMA pseudo Dice: 0.6324\n",
      "2024-11-25 04:35:08.812882: \n",
      "2024-11-25 04:35:08.822882: Epoch 55\n",
      "2024-11-25 04:35:08.822882: Current learning rate: 0.009\n",
      "2024-11-25 04:37:18.403304: train_loss -0.573\n",
      "2024-11-25 04:37:18.413304: val_loss -0.453\n",
      "2024-11-25 04:37:18.413304: Pseudo dice [0.675]\n",
      "2024-11-25 04:37:18.423304: Epoch time: 129.58 s\n",
      "2024-11-25 04:37:18.433304: Yayy! New best EMA pseudo Dice: 0.6367\n",
      "2024-11-25 04:37:19.699834: \n",
      "2024-11-25 04:37:19.709834: Epoch 56\n",
      "2024-11-25 04:37:19.719835: Current learning rate: 0.00899\n",
      "2024-11-25 04:39:29.220146: train_loss -0.566\n",
      "2024-11-25 04:39:29.230146: val_loss -0.3466\n",
      "2024-11-25 04:39:29.240146: Pseudo dice [0.5839]\n",
      "2024-11-25 04:39:29.250145: Epoch time: 129.52 s\n",
      "2024-11-25 04:39:30.400162: \n",
      "2024-11-25 04:39:30.410162: Epoch 57\n",
      "2024-11-25 04:39:30.410162: Current learning rate: 0.00897\n",
      "2024-11-25 04:41:39.953712: train_loss -0.5921\n",
      "2024-11-25 04:41:39.963712: val_loss -0.4084\n",
      "2024-11-25 04:41:39.973712: Pseudo dice [0.5642]\n",
      "2024-11-25 04:41:39.983713: Epoch time: 129.55 s\n",
      "2024-11-25 04:41:40.973726: \n",
      "2024-11-25 04:41:40.983726: Epoch 58\n",
      "2024-11-25 04:41:40.983726: Current learning rate: 0.00895\n",
      "2024-11-25 04:43:50.670683: train_loss -0.5595\n",
      "2024-11-25 04:43:50.680682: val_loss -0.3601\n",
      "2024-11-25 04:43:50.690683: Pseudo dice [0.5844]\n",
      "2024-11-25 04:43:50.690683: Epoch time: 129.7 s\n",
      "2024-11-25 04:43:51.690705: \n",
      "2024-11-25 04:43:51.700696: Epoch 59\n",
      "2024-11-25 04:43:51.700696: Current learning rate: 0.00893\n",
      "2024-11-25 04:46:01.267669: train_loss -0.5547\n",
      "2024-11-25 04:46:01.277669: val_loss -0.407\n",
      "2024-11-25 04:46:01.287670: Pseudo dice [0.5939]\n",
      "2024-11-25 04:46:01.297671: Epoch time: 129.58 s\n",
      "2024-11-25 04:46:02.287683: \n",
      "2024-11-25 04:46:02.287683: Epoch 60\n",
      "2024-11-25 04:46:02.297684: Current learning rate: 0.00891\n",
      "2024-11-25 04:48:11.844834: train_loss -0.5605\n",
      "2024-11-25 04:48:11.854834: val_loss -0.3185\n",
      "2024-11-25 04:48:11.864834: Pseudo dice [0.5435]\n",
      "2024-11-25 04:48:11.864834: Epoch time: 129.57 s\n",
      "2024-11-25 04:48:12.864857: \n",
      "2024-11-25 04:48:12.874848: Epoch 61\n",
      "2024-11-25 04:48:12.874848: Current learning rate: 0.00889\n",
      "2024-11-25 04:50:22.514863: train_loss -0.5828\n",
      "2024-11-25 04:50:22.524863: val_loss -0.4602\n",
      "2024-11-25 04:50:22.534863: Pseudo dice [0.672]\n",
      "2024-11-25 04:50:22.534863: Epoch time: 129.65 s\n",
      "2024-11-25 04:50:23.531451: \n",
      "2024-11-25 04:50:23.541451: Epoch 62\n",
      "2024-11-25 04:50:23.541451: Current learning rate: 0.00888\n",
      "2024-11-25 04:52:33.248465: train_loss -0.5521\n",
      "2024-11-25 04:52:33.248465: val_loss -0.4225\n",
      "2024-11-25 04:52:33.258466: Pseudo dice [0.6351]\n",
      "2024-11-25 04:52:33.268467: Epoch time: 129.72 s\n",
      "2024-11-25 04:52:34.268397: \n",
      "2024-11-25 04:52:34.278397: Epoch 63\n",
      "2024-11-25 04:52:34.278397: Current learning rate: 0.00886\n",
      "2024-11-25 04:54:43.862608: train_loss -0.5336\n",
      "2024-11-25 04:54:43.872609: val_loss -0.5063\n",
      "2024-11-25 04:54:43.872609: Pseudo dice [0.7065]\n",
      "2024-11-25 04:54:43.882609: Epoch time: 129.59 s\n",
      "2024-11-25 04:54:45.048670: \n",
      "2024-11-25 04:54:45.048670: Epoch 64\n",
      "2024-11-25 04:54:45.058669: Current learning rate: 0.00884\n",
      "2024-11-25 04:56:54.630417: train_loss -0.5275\n",
      "2024-11-25 04:56:54.640418: val_loss -0.3236\n",
      "2024-11-25 04:56:54.650419: Pseudo dice [0.6244]\n",
      "2024-11-25 04:56:54.660419: Epoch time: 129.59 s\n",
      "2024-11-25 04:56:55.645607: \n",
      "2024-11-25 04:56:55.655607: Epoch 65\n",
      "2024-11-25 04:56:55.655607: Current learning rate: 0.00882\n",
      "2024-11-25 04:59:05.382653: train_loss -0.6093\n",
      "2024-11-25 04:59:05.402653: val_loss -0.5344\n",
      "2024-11-25 04:59:05.412654: Pseudo dice [0.6882]\n",
      "2024-11-25 04:59:05.412654: Epoch time: 129.74 s\n",
      "2024-11-25 04:59:06.423062: \n",
      "2024-11-25 04:59:06.433062: Epoch 66\n",
      "2024-11-25 04:59:06.433062: Current learning rate: 0.0088\n",
      "2024-11-25 05:01:16.082837: train_loss -0.54\n",
      "2024-11-25 05:01:16.082837: val_loss -0.4181\n",
      "2024-11-25 05:01:16.092838: Pseudo dice [0.6777]\n",
      "2024-11-25 05:01:16.102839: Epoch time: 129.66 s\n",
      "2024-11-25 05:01:16.102839: Yayy! New best EMA pseudo Dice: 0.6376\n",
      "2024-11-25 05:01:17.312855: \n",
      "2024-11-25 05:01:17.322855: Epoch 67\n",
      "2024-11-25 05:01:17.322855: Current learning rate: 0.00879\n",
      "2024-11-25 05:03:26.929823: train_loss -0.5609\n",
      "2024-11-25 05:03:26.939823: val_loss -0.4999\n",
      "2024-11-25 05:03:26.949823: Pseudo dice [0.6927]\n",
      "2024-11-25 05:03:26.949823: Epoch time: 129.62 s\n",
      "2024-11-25 05:03:26.959824: Yayy! New best EMA pseudo Dice: 0.6431\n",
      "2024-11-25 05:03:28.209841: \n",
      "2024-11-25 05:03:28.219841: Epoch 68\n",
      "2024-11-25 05:03:28.219841: Current learning rate: 0.00877\n",
      "2024-11-25 05:05:37.781011: train_loss -0.614\n",
      "2024-11-25 05:05:37.791011: val_loss -0.4582\n",
      "2024-11-25 05:05:37.801013: Pseudo dice [0.6464]\n",
      "2024-11-25 05:05:37.801013: Epoch time: 129.57 s\n",
      "2024-11-25 05:05:37.811012: Yayy! New best EMA pseudo Dice: 0.6434\n",
      "2024-11-25 05:05:39.076687: \n",
      "2024-11-25 05:05:39.076687: Epoch 69\n",
      "2024-11-25 05:05:39.086687: Current learning rate: 0.00875\n",
      "2024-11-25 05:07:48.860325: train_loss -0.4651\n",
      "2024-11-25 05:07:48.870325: val_loss -0.4437\n",
      "2024-11-25 05:07:48.880327: Pseudo dice [0.6313]\n",
      "2024-11-25 05:07:48.890325: Epoch time: 129.78 s\n",
      "2024-11-25 05:07:49.913615: \n",
      "2024-11-25 05:07:49.913615: Epoch 70\n",
      "2024-11-25 05:07:49.923615: Current learning rate: 0.00873\n",
      "2024-11-25 05:09:59.547318: train_loss -0.5884\n",
      "2024-11-25 05:09:59.547318: val_loss -0.4195\n",
      "2024-11-25 05:09:59.557317: Pseudo dice [0.6672]\n",
      "2024-11-25 05:09:59.567318: Epoch time: 129.63 s\n",
      "2024-11-25 05:09:59.567318: Yayy! New best EMA pseudo Dice: 0.6447\n",
      "2024-11-25 05:10:01.013898: \n",
      "2024-11-25 05:10:01.013898: Epoch 71\n",
      "2024-11-25 05:10:01.023898: Current learning rate: 0.00871\n",
      "2024-11-25 05:12:10.640873: train_loss -0.5664\n",
      "2024-11-25 05:12:10.650873: val_loss -0.4902\n",
      "2024-11-25 05:12:10.650873: Pseudo dice [0.6541]\n",
      "2024-11-25 05:12:10.660874: Epoch time: 129.63 s\n",
      "2024-11-25 05:12:10.660874: Yayy! New best EMA pseudo Dice: 0.6457\n",
      "2024-11-25 05:12:11.921188: \n",
      "2024-11-25 05:12:11.931188: Epoch 72\n",
      "2024-11-25 05:12:11.931188: Current learning rate: 0.00869\n",
      "2024-11-25 05:14:21.531133: train_loss -0.6055\n",
      "2024-11-25 05:14:21.541135: val_loss -0.4922\n",
      "2024-11-25 05:14:21.551135: Pseudo dice [0.7097]\n",
      "2024-11-25 05:14:21.551135: Epoch time: 129.61 s\n",
      "2024-11-25 05:14:21.561135: Yayy! New best EMA pseudo Dice: 0.6521\n",
      "2024-11-25 05:14:22.801450: \n",
      "2024-11-25 05:14:22.801450: Epoch 73\n",
      "2024-11-25 05:14:22.811450: Current learning rate: 0.00868\n",
      "2024-11-25 05:16:32.697434: train_loss -0.5944\n",
      "2024-11-25 05:16:32.717434: val_loss -0.4433\n",
      "2024-11-25 05:16:32.727433: Pseudo dice [0.6848]\n",
      "2024-11-25 05:16:32.727433: Epoch time: 129.9 s\n",
      "2024-11-25 05:16:32.727433: Yayy! New best EMA pseudo Dice: 0.6553\n",
      "2024-11-25 05:16:34.004702: \n",
      "2024-11-25 05:16:34.014702: Epoch 74\n",
      "2024-11-25 05:16:34.014702: Current learning rate: 0.00866\n",
      "2024-11-25 05:18:43.688382: train_loss -0.5873\n",
      "2024-11-25 05:18:43.698382: val_loss -0.3636\n",
      "2024-11-25 05:18:43.708385: Pseudo dice [0.6688]\n",
      "2024-11-25 05:18:43.718383: Epoch time: 129.68 s\n",
      "2024-11-25 05:18:43.718383: Yayy! New best EMA pseudo Dice: 0.6567\n",
      "2024-11-25 05:18:44.968581: \n",
      "2024-11-25 05:18:44.978580: Epoch 75\n",
      "2024-11-25 05:18:44.978580: Current learning rate: 0.00864\n",
      "2024-11-25 05:20:54.651949: train_loss -0.4948\n",
      "2024-11-25 05:20:54.661949: val_loss -0.2339\n",
      "2024-11-25 05:20:54.671950: Pseudo dice [0.5334]\n",
      "2024-11-25 05:20:54.671950: Epoch time: 129.68 s\n",
      "2024-11-25 05:20:55.691963: \n",
      "2024-11-25 05:20:55.701963: Epoch 76\n",
      "2024-11-25 05:20:55.701963: Current learning rate: 0.00862\n",
      "2024-11-25 05:23:05.418903: train_loss -0.5761\n",
      "2024-11-25 05:23:05.428904: val_loss -0.4392\n",
      "2024-11-25 05:23:05.428904: Pseudo dice [0.6269]\n",
      "2024-11-25 05:23:05.438905: Epoch time: 129.73 s\n",
      "2024-11-25 05:23:06.448919: \n",
      "2024-11-25 05:23:06.448919: Epoch 77\n",
      "2024-11-25 05:23:06.458918: Current learning rate: 0.0086\n",
      "2024-11-25 05:25:16.105860: train_loss -0.6\n",
      "2024-11-25 05:25:16.115860: val_loss -0.4108\n",
      "2024-11-25 05:25:16.125859: Pseudo dice [0.5704]\n",
      "2024-11-25 05:25:16.125859: Epoch time: 129.66 s\n",
      "2024-11-25 05:25:17.337338: \n",
      "2024-11-25 05:25:17.343380: Epoch 78\n",
      "2024-11-25 05:25:17.347333: Current learning rate: 0.00858\n",
      "2024-11-25 05:27:27.026103: train_loss -0.5836\n",
      "2024-11-25 05:27:27.036103: val_loss -0.4417\n",
      "2024-11-25 05:27:27.046103: Pseudo dice [0.6601]\n",
      "2024-11-25 05:27:27.056103: Epoch time: 129.69 s\n",
      "2024-11-25 05:27:28.096048: \n",
      "2024-11-25 05:27:28.096048: Epoch 79\n",
      "2024-11-25 05:27:28.106048: Current learning rate: 0.00857\n",
      "2024-11-25 05:29:37.697258: train_loss -0.6021\n",
      "2024-11-25 05:29:37.697258: val_loss -0.36\n",
      "2024-11-25 05:29:37.707258: Pseudo dice [0.6345]\n",
      "2024-11-25 05:29:37.717258: Epoch time: 129.6 s\n",
      "2024-11-25 05:29:38.752979: \n",
      "2024-11-25 05:29:38.762979: Epoch 80\n",
      "2024-11-25 05:29:38.762979: Current learning rate: 0.00855\n",
      "2024-11-25 05:31:48.636670: train_loss -0.5186\n",
      "2024-11-25 05:31:48.646672: val_loss -0.4615\n",
      "2024-11-25 05:31:48.656672: Pseudo dice [0.6775]\n",
      "2024-11-25 05:31:48.656672: Epoch time: 129.88 s\n",
      "2024-11-25 05:31:49.693266: \n",
      "2024-11-25 05:31:49.703267: Epoch 81\n",
      "2024-11-25 05:31:49.703267: Current learning rate: 0.00853\n",
      "2024-11-25 05:33:59.390210: train_loss -0.6\n",
      "2024-11-25 05:33:59.400212: val_loss -0.5125\n",
      "2024-11-25 05:33:59.400212: Pseudo dice [0.7189]\n",
      "2024-11-25 05:33:59.410212: Epoch time: 129.7 s\n",
      "2024-11-25 05:34:00.440226: \n",
      "2024-11-25 05:34:00.440226: Epoch 82\n",
      "2024-11-25 05:34:00.450226: Current learning rate: 0.00851\n",
      "2024-11-25 05:36:10.123834: train_loss -0.641\n",
      "2024-11-25 05:36:10.133834: val_loss -0.509\n",
      "2024-11-25 05:36:10.143834: Pseudo dice [0.7144]\n",
      "2024-11-25 05:36:10.143834: Epoch time: 129.68 s\n",
      "2024-11-25 05:36:11.130460: \n",
      "2024-11-25 05:36:11.140460: Epoch 83\n",
      "2024-11-25 05:36:11.140460: Current learning rate: 0.00849\n",
      "2024-11-25 05:38:20.950784: train_loss -0.6205\n",
      "2024-11-25 05:38:20.980785: val_loss -0.4029\n",
      "2024-11-25 05:38:20.990787: Pseudo dice [0.5595]\n",
      "2024-11-25 05:38:20.990787: Epoch time: 129.82 s\n",
      "2024-11-25 05:38:21.970798: \n",
      "2024-11-25 05:38:21.980799: Epoch 84\n",
      "2024-11-25 05:38:21.980799: Current learning rate: 0.00847\n",
      "2024-11-25 05:40:31.655902: train_loss -0.5932\n",
      "2024-11-25 05:40:31.665902: val_loss -0.4395\n",
      "2024-11-25 05:40:31.675904: Pseudo dice [0.6769]\n",
      "2024-11-25 05:40:31.675904: Epoch time: 129.69 s\n",
      "2024-11-25 05:40:32.811017: \n",
      "2024-11-25 05:40:32.821016: Epoch 85\n",
      "2024-11-25 05:40:32.821016: Current learning rate: 0.00846\n",
      "2024-11-25 05:42:42.524695: train_loss -0.6168\n",
      "2024-11-25 05:42:42.534695: val_loss -0.5096\n",
      "2024-11-25 05:42:42.534695: Pseudo dice [0.7233]\n",
      "2024-11-25 05:42:42.544694: Epoch time: 129.71 s\n",
      "2024-11-25 05:42:43.524612: \n",
      "2024-11-25 05:42:43.534612: Epoch 86\n",
      "2024-11-25 05:42:43.534612: Current learning rate: 0.00844\n",
      "2024-11-25 05:44:53.212777: train_loss -0.6416\n",
      "2024-11-25 05:44:53.222777: val_loss -0.5159\n",
      "2024-11-25 05:44:53.232777: Pseudo dice [0.7311]\n",
      "2024-11-25 05:44:53.232777: Epoch time: 129.69 s\n",
      "2024-11-25 05:44:53.242777: Yayy! New best EMA pseudo Dice: 0.6641\n",
      "2024-11-25 05:44:54.441574: \n",
      "2024-11-25 05:44:54.451575: Epoch 87\n",
      "2024-11-25 05:44:54.451575: Current learning rate: 0.00842\n",
      "2024-11-25 05:47:04.309157: train_loss -0.6321\n",
      "2024-11-25 05:47:04.319158: val_loss -0.3676\n",
      "2024-11-25 05:47:04.319158: Pseudo dice [0.6083]\n",
      "2024-11-25 05:47:04.329158: Epoch time: 129.87 s\n",
      "2024-11-25 05:47:05.309171: \n",
      "2024-11-25 05:47:05.319171: Epoch 88\n",
      "2024-11-25 05:47:05.319171: Current learning rate: 0.0084\n",
      "2024-11-25 05:49:14.989283: train_loss -0.6131\n",
      "2024-11-25 05:49:14.999283: val_loss -0.4218\n",
      "2024-11-25 05:49:15.009283: Pseudo dice [0.698]\n",
      "2024-11-25 05:49:15.019284: Epoch time: 129.68 s\n",
      "2024-11-25 05:49:15.999296: \n",
      "2024-11-25 05:49:16.009296: Epoch 89\n",
      "2024-11-25 05:49:16.009296: Current learning rate: 0.00838\n",
      "2024-11-25 05:51:25.662401: train_loss -0.5911\n",
      "2024-11-25 05:51:25.672402: val_loss -0.4854\n",
      "2024-11-25 05:51:25.672402: Pseudo dice [0.6767]\n",
      "2024-11-25 05:51:25.682403: Epoch time: 129.66 s\n",
      "2024-11-25 05:51:26.652416: \n",
      "2024-11-25 05:51:26.662416: Epoch 90\n",
      "2024-11-25 05:51:26.662416: Current learning rate: 0.00836\n",
      "2024-11-25 05:53:36.289401: train_loss -0.5961\n",
      "2024-11-25 05:53:36.299402: val_loss -0.5747\n",
      "2024-11-25 05:53:36.309402: Pseudo dice [0.7592]\n",
      "2024-11-25 05:53:36.309402: Epoch time: 129.64 s\n",
      "2024-11-25 05:53:36.319402: Yayy! New best EMA pseudo Dice: 0.6734\n",
      "2024-11-25 05:53:37.529702: \n",
      "2024-11-25 05:53:37.539702: Epoch 91\n",
      "2024-11-25 05:53:37.539702: Current learning rate: 0.00835\n",
      "2024-11-25 05:55:47.417216: train_loss -0.6129\n",
      "2024-11-25 05:55:47.437217: val_loss -0.5498\n",
      "2024-11-25 05:55:47.437217: Pseudo dice [0.7438]\n",
      "2024-11-25 05:55:47.447216: Epoch time: 129.89 s\n",
      "2024-11-25 05:55:47.447216: Yayy! New best EMA pseudo Dice: 0.6804\n",
      "2024-11-25 05:55:48.842936: \n",
      "2024-11-25 05:55:48.842936: Epoch 92\n",
      "2024-11-25 05:55:48.842936: Current learning rate: 0.00833\n",
      "2024-11-25 05:57:58.603304: train_loss -0.6298\n",
      "2024-11-25 05:57:58.613303: val_loss -0.3737\n",
      "2024-11-25 05:57:58.613303: Pseudo dice [0.6253]\n",
      "2024-11-25 05:57:58.623305: Epoch time: 129.77 s\n",
      "2024-11-25 05:57:59.589878: \n",
      "2024-11-25 05:57:59.589878: Epoch 93\n",
      "2024-11-25 05:57:59.599878: Current learning rate: 0.00831\n",
      "2024-11-25 06:00:09.343498: train_loss -0.5998\n",
      "2024-11-25 06:00:09.353498: val_loss -0.4432\n",
      "2024-11-25 06:00:09.353498: Pseudo dice [0.6504]\n",
      "2024-11-25 06:00:09.363499: Epoch time: 129.75 s\n",
      "2024-11-25 06:00:10.323512: \n",
      "2024-11-25 06:00:10.333512: Epoch 94\n",
      "2024-11-25 06:00:10.333512: Current learning rate: 0.00829\n",
      "2024-11-25 06:02:20.203836: train_loss -0.5948\n",
      "2024-11-25 06:02:20.223837: val_loss -0.3548\n",
      "2024-11-25 06:02:20.223837: Pseudo dice [0.5672]\n",
      "2024-11-25 06:02:20.233838: Epoch time: 129.88 s\n",
      "2024-11-25 06:02:21.213851: \n",
      "2024-11-25 06:02:21.223851: Epoch 95\n",
      "2024-11-25 06:02:21.223851: Current learning rate: 0.00827\n",
      "2024-11-25 06:04:31.241064: train_loss -0.5639\n",
      "2024-11-25 06:04:31.251064: val_loss -0.4863\n",
      "2024-11-25 06:04:31.251064: Pseudo dice [0.6357]\n",
      "2024-11-25 06:04:31.261063: Epoch time: 130.03 s\n",
      "2024-11-25 06:04:32.234015: \n",
      "2024-11-25 06:04:32.234015: Epoch 96\n",
      "2024-11-25 06:04:32.234015: Current learning rate: 0.00825\n",
      "2024-11-25 06:06:42.121296: train_loss -0.6187\n",
      "2024-11-25 06:06:42.131296: val_loss -0.4564\n",
      "2024-11-25 06:06:42.141296: Pseudo dice [0.6842]\n",
      "2024-11-25 06:06:42.151296: Epoch time: 129.9 s\n",
      "2024-11-25 06:06:43.157615: \n",
      "2024-11-25 06:06:43.157615: Epoch 97\n",
      "2024-11-25 06:06:43.167615: Current learning rate: 0.00824\n",
      "2024-11-25 06:08:53.031333: train_loss -0.6428\n",
      "2024-11-25 06:08:53.041332: val_loss -0.4073\n",
      "2024-11-25 06:08:53.051334: Pseudo dice [0.6306]\n",
      "2024-11-25 06:08:53.051334: Epoch time: 129.87 s\n",
      "2024-11-25 06:08:54.034569: \n",
      "2024-11-25 06:08:54.044569: Epoch 98\n",
      "2024-11-25 06:08:54.044569: Current learning rate: 0.00822\n",
      "2024-11-25 06:11:04.024859: train_loss -0.6241\n",
      "2024-11-25 06:11:04.044860: val_loss -0.4072\n",
      "2024-11-25 06:11:04.054860: Pseudo dice [0.6702]\n",
      "2024-11-25 06:11:04.064861: Epoch time: 129.99 s\n",
      "2024-11-25 06:11:05.224876: \n",
      "2024-11-25 06:11:05.234876: Epoch 99\n",
      "2024-11-25 06:11:05.234876: Current learning rate: 0.0082\n",
      "2024-11-25 06:13:15.085147: train_loss -0.6406\n",
      "2024-11-25 06:13:15.095148: val_loss -0.5714\n",
      "2024-11-25 06:13:15.105147: Pseudo dice [0.7493]\n",
      "2024-11-25 06:13:15.105147: Epoch time: 129.86 s\n",
      "2024-11-25 06:13:16.342725: \n",
      "2024-11-25 06:13:16.352725: Epoch 100\n",
      "2024-11-25 06:13:16.352725: Current learning rate: 0.00818\n",
      "2024-11-25 06:15:26.208800: train_loss -0.6396\n",
      "2024-11-25 06:15:26.218800: val_loss -0.3371\n",
      "2024-11-25 06:15:26.228800: Pseudo dice [0.6155]\n",
      "2024-11-25 06:15:26.228800: Epoch time: 129.87 s\n",
      "2024-11-25 06:15:27.218713: \n",
      "2024-11-25 06:15:27.218713: Epoch 101\n",
      "2024-11-25 06:15:27.228713: Current learning rate: 0.00816\n",
      "2024-11-25 06:17:37.065736: train_loss -0.587\n",
      "2024-11-25 06:17:37.075738: val_loss -0.4268\n",
      "2024-11-25 06:17:37.085737: Pseudo dice [0.6772]\n",
      "2024-11-25 06:17:37.085737: Epoch time: 129.85 s\n",
      "2024-11-25 06:17:38.082332: \n",
      "2024-11-25 06:17:38.092332: Epoch 102\n",
      "2024-11-25 06:17:38.092332: Current learning rate: 0.00814\n",
      "2024-11-25 06:19:48.059561: train_loss -0.6556\n",
      "2024-11-25 06:19:48.069562: val_loss -0.1213\n",
      "2024-11-25 06:19:48.079562: Pseudo dice [0.447]\n",
      "2024-11-25 06:19:48.079562: Epoch time: 129.98 s\n",
      "2024-11-25 06:19:49.089576: \n",
      "2024-11-25 06:19:49.099576: Epoch 103\n",
      "2024-11-25 06:19:49.099576: Current learning rate: 0.00813\n",
      "2024-11-25 06:21:58.862908: train_loss -0.6269\n",
      "2024-11-25 06:21:58.872909: val_loss -0.4626\n",
      "2024-11-25 06:21:58.882909: Pseudo dice [0.6702]\n",
      "2024-11-25 06:21:58.892909: Epoch time: 129.77 s\n",
      "2024-11-25 06:21:59.892922: \n",
      "2024-11-25 06:21:59.902922: Epoch 104\n",
      "2024-11-25 06:21:59.902922: Current learning rate: 0.00811\n",
      "2024-11-25 06:24:09.726532: train_loss -0.6506\n",
      "2024-11-25 06:24:09.736532: val_loss -0.5186\n",
      "2024-11-25 06:24:09.746533: Pseudo dice [0.7051]\n",
      "2024-11-25 06:24:09.746533: Epoch time: 129.83 s\n",
      "2024-11-25 06:24:10.736546: \n",
      "2024-11-25 06:24:10.746545: Epoch 105\n",
      "2024-11-25 06:24:10.746545: Current learning rate: 0.00809\n",
      "2024-11-25 06:26:21.364936: train_loss -0.6596\n",
      "2024-11-25 06:26:21.373938: val_loss -0.47\n",
      "2024-11-25 06:26:21.380939: Pseudo dice [0.6899]\n",
      "2024-11-25 06:26:21.387941: Epoch time: 130.63 s\n",
      "2024-11-25 06:26:22.420173: \n",
      "2024-11-25 06:26:22.427175: Epoch 106\n",
      "2024-11-25 06:26:22.432176: Current learning rate: 0.00807\n",
      "2024-11-25 06:28:35.785663: train_loss -0.6672\n",
      "2024-11-25 06:28:35.793665: val_loss -0.3371\n",
      "2024-11-25 06:28:35.802669: Pseudo dice [0.6259]\n",
      "2024-11-25 06:28:35.807669: Epoch time: 133.37 s\n",
      "2024-11-25 06:28:36.987934: \n",
      "2024-11-25 06:28:36.993936: Epoch 107\n",
      "2024-11-25 06:28:36.997936: Current learning rate: 0.00805\n",
      "2024-11-25 06:30:48.449172: train_loss -0.6601\n",
      "2024-11-25 06:30:48.449172: val_loss -0.4851\n",
      "2024-11-25 06:30:48.456174: Pseudo dice [0.6752]\n",
      "2024-11-25 06:30:48.464176: Epoch time: 131.46 s\n",
      "2024-11-25 06:30:49.463332: \n",
      "2024-11-25 06:30:49.469333: Epoch 108\n",
      "2024-11-25 06:30:49.473335: Current learning rate: 0.00803\n",
      "2024-11-25 06:33:00.569438: train_loss -0.6401\n",
      "2024-11-25 06:33:00.569438: val_loss -0.5191\n",
      "2024-11-25 06:33:00.579437: Pseudo dice [0.7]\n",
      "2024-11-25 06:33:00.589438: Epoch time: 131.11 s\n",
      "2024-11-25 06:33:01.589451: \n",
      "2024-11-25 06:33:01.599451: Epoch 109\n",
      "2024-11-25 06:33:01.599451: Current learning rate: 0.00801\n",
      "2024-11-25 06:35:13.893764: train_loss -0.6606\n",
      "2024-11-25 06:35:13.903768: val_loss -0.2854\n",
      "2024-11-25 06:35:13.907769: Pseudo dice [0.5893]\n",
      "2024-11-25 06:35:13.912771: Epoch time: 132.3 s\n",
      "2024-11-25 06:35:14.915567: \n",
      "2024-11-25 06:35:14.922569: Epoch 110\n",
      "2024-11-25 06:35:14.926569: Current learning rate: 0.008\n",
      "2024-11-25 06:37:26.242799: train_loss -0.6715\n",
      "2024-11-25 06:37:26.251801: val_loss -0.3518\n",
      "2024-11-25 06:37:26.257802: Pseudo dice [0.6799]\n",
      "2024-11-25 06:37:26.261804: Epoch time: 131.33 s\n",
      "2024-11-25 06:37:27.268090: \n",
      "2024-11-25 06:37:27.273777: Epoch 111\n",
      "2024-11-25 06:37:27.277778: Current learning rate: 0.00798\n",
      "2024-11-25 06:39:37.699189: train_loss -0.635\n",
      "2024-11-25 06:39:37.709190: val_loss -0.4525\n",
      "2024-11-25 06:39:37.719191: Pseudo dice [0.6837]\n",
      "2024-11-25 06:39:37.719191: Epoch time: 130.43 s\n",
      "2024-11-25 06:39:38.719213: \n",
      "2024-11-25 06:39:38.729203: Epoch 112\n",
      "2024-11-25 06:39:38.729203: Current learning rate: 0.00796\n",
      "2024-11-25 06:41:49.819226: train_loss -0.6227\n",
      "2024-11-25 06:41:49.849227: val_loss -0.4501\n",
      "2024-11-25 06:41:49.849227: Pseudo dice [0.715]\n",
      "2024-11-25 06:41:49.859227: Epoch time: 131.1 s\n",
      "2024-11-25 06:41:50.859250: \n",
      "2024-11-25 06:41:50.869250: Epoch 113\n",
      "2024-11-25 06:41:50.869250: Current learning rate: 0.00794\n",
      "2024-11-25 06:44:01.828379: train_loss -0.631\n",
      "2024-11-25 06:44:01.858378: val_loss -0.3926\n",
      "2024-11-25 06:44:01.858378: Pseudo dice [0.6331]\n",
      "2024-11-25 06:44:01.868380: Epoch time: 130.97 s\n",
      "2024-11-25 06:44:03.028404: \n",
      "2024-11-25 06:44:03.038395: Epoch 114\n",
      "2024-11-25 06:44:03.038395: Current learning rate: 0.00792\n",
      "2024-11-25 06:46:14.631611: train_loss -0.6715\n",
      "2024-11-25 06:46:14.641612: val_loss -0.4634\n",
      "2024-11-25 06:46:14.651612: Pseudo dice [0.7062]\n",
      "2024-11-25 06:46:14.651612: Epoch time: 131.6 s\n",
      "2024-11-25 06:46:15.631626: \n",
      "2024-11-25 06:46:15.631626: Epoch 115\n",
      "2024-11-25 06:46:15.641634: Current learning rate: 0.0079\n",
      "2024-11-25 06:48:26.586204: train_loss -0.7011\n",
      "2024-11-25 06:48:26.596204: val_loss -0.3627\n",
      "2024-11-25 06:48:26.606205: Pseudo dice [0.6125]\n",
      "2024-11-25 06:48:26.616205: Epoch time: 130.95 s\n",
      "2024-11-25 06:48:27.606227: \n",
      "2024-11-25 06:48:27.616227: Epoch 116\n",
      "2024-11-25 06:48:27.616227: Current learning rate: 0.00789\n",
      "2024-11-25 06:50:38.504791: train_loss -0.6926\n",
      "2024-11-25 06:50:38.514791: val_loss -0.4641\n",
      "2024-11-25 06:50:38.514791: Pseudo dice [0.7144]\n",
      "2024-11-25 06:50:38.524792: Epoch time: 130.9 s\n",
      "2024-11-25 06:50:39.514814: \n",
      "2024-11-25 06:50:39.524814: Epoch 117\n",
      "2024-11-25 06:50:39.524814: Current learning rate: 0.00787\n",
      "2024-11-25 06:52:51.229716: train_loss -0.7001\n",
      "2024-11-25 06:52:51.249716: val_loss -0.5552\n",
      "2024-11-25 06:52:51.259716: Pseudo dice [0.748]\n",
      "2024-11-25 06:52:51.259716: Epoch time: 131.71 s\n",
      "2024-11-25 06:52:52.270105: \n",
      "2024-11-25 06:52:52.280096: Epoch 118\n",
      "2024-11-25 06:52:52.280096: Current learning rate: 0.00785\n",
      "2024-11-25 06:55:03.185039: train_loss -0.6941\n",
      "2024-11-25 06:55:03.195039: val_loss -0.3542\n",
      "2024-11-25 06:55:03.205039: Pseudo dice [0.5958]\n",
      "2024-11-25 06:55:03.205039: Epoch time: 130.91 s\n",
      "2024-11-25 06:55:04.205062: \n",
      "2024-11-25 06:55:04.215053: Epoch 119\n",
      "2024-11-25 06:55:04.215053: Current learning rate: 0.00783\n",
      "2024-11-25 06:57:15.176581: train_loss -0.7001\n",
      "2024-11-25 06:57:15.186582: val_loss -0.3193\n",
      "2024-11-25 06:57:15.186582: Pseudo dice [0.6471]\n",
      "2024-11-25 06:57:15.196582: Epoch time: 130.97 s\n",
      "2024-11-25 06:57:16.186604: \n",
      "2024-11-25 06:57:16.196603: Epoch 120\n",
      "2024-11-25 06:57:16.196603: Current learning rate: 0.00781\n",
      "2024-11-25 06:59:27.107561: train_loss -0.6089\n",
      "2024-11-25 06:59:27.117562: val_loss -0.4923\n",
      "2024-11-25 06:59:27.117562: Pseudo dice [0.7198]\n",
      "2024-11-25 06:59:27.127562: Epoch time: 130.92 s\n",
      "2024-11-25 06:59:28.287587: \n",
      "2024-11-25 06:59:28.287587: Epoch 121\n",
      "2024-11-25 06:59:28.297587: Current learning rate: 0.00779\n",
      "2024-11-25 07:01:39.831821: train_loss -0.6833\n",
      "2024-11-25 07:01:39.841822: val_loss -0.4931\n",
      "2024-11-25 07:01:39.851822: Pseudo dice [0.7113]\n",
      "2024-11-25 07:01:39.851822: Epoch time: 131.54 s\n",
      "2024-11-25 07:01:40.861845: \n",
      "2024-11-25 07:01:40.861845: Epoch 122\n",
      "2024-11-25 07:01:40.861845: Current learning rate: 0.00777\n",
      "2024-11-25 07:03:51.806821: train_loss -0.6508\n",
      "2024-11-25 07:03:51.816821: val_loss -0.3986\n",
      "2024-11-25 07:03:51.816821: Pseudo dice [0.6406]\n",
      "2024-11-25 07:03:51.826822: Epoch time: 130.95 s\n",
      "2024-11-25 07:03:52.816844: \n",
      "2024-11-25 07:03:52.826835: Epoch 123\n",
      "2024-11-25 07:03:52.826835: Current learning rate: 0.00776\n",
      "2024-11-25 07:06:03.751495: train_loss -0.6493\n",
      "2024-11-25 07:06:03.761495: val_loss -0.4099\n",
      "2024-11-25 07:06:03.771496: Pseudo dice [0.6649]\n",
      "2024-11-25 07:06:03.771496: Epoch time: 130.93 s\n",
      "2024-11-25 07:06:04.781509: \n",
      "2024-11-25 07:06:04.781509: Epoch 124\n",
      "2024-11-25 07:06:04.791518: Current learning rate: 0.00774\n",
      "2024-11-25 07:08:15.677561: train_loss -0.6662\n",
      "2024-11-25 07:08:15.687564: val_loss -0.5023\n",
      "2024-11-25 07:08:15.697562: Pseudo dice [0.708]\n",
      "2024-11-25 07:08:15.697562: Epoch time: 130.91 s\n",
      "2024-11-25 07:08:16.707575: \n",
      "2024-11-25 07:08:16.707575: Epoch 125\n",
      "2024-11-25 07:08:16.707575: Current learning rate: 0.00772\n",
      "2024-11-25 07:10:28.592441: train_loss -0.6775\n",
      "2024-11-25 07:10:28.602441: val_loss -0.4812\n",
      "2024-11-25 07:10:28.612442: Pseudo dice [0.6813]\n",
      "2024-11-25 07:10:28.622441: Epoch time: 131.89 s\n",
      "2024-11-25 07:10:29.622454: \n",
      "2024-11-25 07:10:29.622454: Epoch 126\n",
      "2024-11-25 07:10:29.632454: Current learning rate: 0.0077\n",
      "2024-11-25 07:12:40.618512: train_loss -0.646\n",
      "2024-11-25 07:12:40.628513: val_loss -0.4514\n",
      "2024-11-25 07:12:40.638513: Pseudo dice [0.6646]\n",
      "2024-11-25 07:12:40.638513: Epoch time: 131.0 s\n",
      "2024-11-25 07:12:41.659065: \n",
      "2024-11-25 07:12:41.659065: Epoch 127\n",
      "2024-11-25 07:12:41.669056: Current learning rate: 0.00768\n",
      "2024-11-25 07:14:52.989811: train_loss -0.6219\n",
      "2024-11-25 07:14:52.997812: val_loss -0.537\n",
      "2024-11-25 07:14:53.002814: Pseudo dice [0.7581]\n",
      "2024-11-25 07:14:53.012816: Epoch time: 131.33 s\n",
      "2024-11-25 07:14:53.017817: Yayy! New best EMA pseudo Dice: 0.6819\n",
      "2024-11-25 07:14:54.441598: \n",
      "2024-11-25 07:14:54.449600: Epoch 128\n",
      "2024-11-25 07:14:54.453600: Current learning rate: 0.00766\n",
      "2024-11-25 07:17:09.021232: train_loss -0.6083\n",
      "2024-11-25 07:17:09.033235: val_loss -0.4293\n",
      "2024-11-25 07:17:09.041237: Pseudo dice [0.6674]\n",
      "2024-11-25 07:17:09.047238: Epoch time: 134.58 s\n",
      "2024-11-25 07:17:10.063468: \n",
      "2024-11-25 07:17:10.069469: Epoch 129\n",
      "2024-11-25 07:17:10.073470: Current learning rate: 0.00764\n",
      "2024-11-25 07:19:21.141929: train_loss -0.6658\n",
      "2024-11-25 07:19:21.152932: val_loss -0.385\n",
      "2024-11-25 07:19:21.161933: Pseudo dice [0.6478]\n",
      "2024-11-25 07:19:21.166934: Epoch time: 131.08 s\n",
      "2024-11-25 07:19:22.164159: \n",
      "2024-11-25 07:19:22.170160: Epoch 130\n",
      "2024-11-25 07:19:22.175161: Current learning rate: 0.00763\n",
      "2024-11-25 07:21:32.920053: train_loss -0.6744\n",
      "2024-11-25 07:21:32.929053: val_loss -0.3419\n",
      "2024-11-25 07:21:32.934054: Pseudo dice [0.6252]\n",
      "2024-11-25 07:21:32.941056: Epoch time: 130.76 s\n",
      "2024-11-25 07:21:33.936280: \n",
      "2024-11-25 07:21:33.943282: Epoch 131\n",
      "2024-11-25 07:21:33.947283: Current learning rate: 0.00761\n",
      "2024-11-25 07:23:44.688325: train_loss -0.7029\n",
      "2024-11-25 07:23:44.698327: val_loss -0.4293\n",
      "2024-11-25 07:23:44.704328: Pseudo dice [0.6887]\n",
      "2024-11-25 07:23:44.710329: Epoch time: 130.75 s\n",
      "2024-11-25 07:23:45.742561: \n",
      "2024-11-25 07:23:45.749563: Epoch 132\n",
      "2024-11-25 07:23:45.754564: Current learning rate: 0.00759\n",
      "2024-11-25 07:25:57.305121: train_loss -0.6825\n",
      "2024-11-25 07:25:57.316123: val_loss -0.4849\n",
      "2024-11-25 07:25:57.323124: Pseudo dice [0.7571]\n",
      "2024-11-25 07:25:57.330126: Epoch time: 131.56 s\n",
      "2024-11-25 07:25:57.336128: Yayy! New best EMA pseudo Dice: 0.682\n",
      "2024-11-25 07:25:58.599411: \n",
      "2024-11-25 07:25:58.606413: Epoch 133\n",
      "2024-11-25 07:25:58.611415: Current learning rate: 0.00757\n",
      "2024-11-25 07:28:08.864389: train_loss -0.6998\n",
      "2024-11-25 07:28:08.874391: val_loss -0.3329\n",
      "2024-11-25 07:28:08.880393: Pseudo dice [0.6351]\n",
      "2024-11-25 07:28:08.885394: Epoch time: 130.27 s\n",
      "2024-11-25 07:28:09.890620: \n",
      "2024-11-25 07:28:09.897622: Epoch 134\n",
      "2024-11-25 07:28:09.901623: Current learning rate: 0.00755\n",
      "2024-11-25 07:30:21.211295: train_loss -0.7127\n",
      "2024-11-25 07:30:21.219297: val_loss -0.4982\n",
      "2024-11-25 07:30:21.227298: Pseudo dice [0.7271]\n",
      "2024-11-25 07:30:21.232299: Epoch time: 131.32 s\n",
      "2024-11-25 07:30:21.237300: Yayy! New best EMA pseudo Dice: 0.6823\n",
      "2024-11-25 07:30:22.732350: \n",
      "2024-11-25 07:30:22.739351: Epoch 135\n",
      "2024-11-25 07:30:22.744353: Current learning rate: 0.00753\n",
      "2024-11-25 07:32:40.233647: train_loss -0.7274\n",
      "2024-11-25 07:32:40.243648: val_loss -0.3874\n",
      "2024-11-25 07:32:40.249649: Pseudo dice [0.6443]\n",
      "2024-11-25 07:32:40.255651: Epoch time: 137.5 s\n",
      "2024-11-25 07:32:41.269880: \n",
      "2024-11-25 07:32:41.276881: Epoch 136\n",
      "2024-11-25 07:32:41.281882: Current learning rate: 0.00751\n",
      "2024-11-25 07:34:59.236609: train_loss -0.7165\n",
      "2024-11-25 07:34:59.245611: val_loss -0.397\n",
      "2024-11-25 07:34:59.251614: Pseudo dice [0.6442]\n",
      "2024-11-25 07:34:59.257615: Epoch time: 137.97 s\n",
      "2024-11-25 07:35:00.272844: \n",
      "2024-11-25 07:35:00.278845: Epoch 137\n",
      "2024-11-25 07:35:00.283846: Current learning rate: 0.0075\n",
      "2024-11-25 07:37:18.267983: train_loss -0.6517\n",
      "2024-11-25 07:37:18.277985: val_loss -0.2395\n",
      "2024-11-25 07:37:18.286987: Pseudo dice [0.5704]\n",
      "2024-11-25 07:37:18.293989: Epoch time: 138.0 s\n",
      "2024-11-25 07:37:19.310219: \n",
      "2024-11-25 07:37:19.318219: Epoch 138\n",
      "2024-11-25 07:37:19.323220: Current learning rate: 0.00748\n",
      "2024-11-25 07:39:37.072990: train_loss -0.6526\n",
      "2024-11-25 07:39:37.080993: val_loss -0.4025\n",
      "2024-11-25 07:39:37.089994: Pseudo dice [0.6691]\n",
      "2024-11-25 07:39:37.095995: Epoch time: 137.76 s\n",
      "2024-11-25 07:39:38.207246: \n",
      "2024-11-25 07:39:38.215248: Epoch 139\n",
      "2024-11-25 07:39:38.220248: Current learning rate: 0.00746\n",
      "2024-11-25 07:41:57.284491: train_loss -0.6579\n",
      "2024-11-25 07:41:57.294493: val_loss -0.4764\n",
      "2024-11-25 07:41:57.303495: Pseudo dice [0.681]\n",
      "2024-11-25 07:41:57.310497: Epoch time: 139.08 s\n",
      "2024-11-25 07:41:58.341729: \n",
      "2024-11-25 07:41:58.348731: Epoch 140\n",
      "2024-11-25 07:41:58.353733: Current learning rate: 0.00744\n",
      "2024-11-25 07:44:17.368088: train_loss -0.6519\n",
      "2024-11-25 07:44:17.378090: val_loss -0.4892\n",
      "2024-11-25 07:44:17.387092: Pseudo dice [0.7121]\n",
      "2024-11-25 07:44:17.393094: Epoch time: 139.03 s\n",
      "2024-11-25 07:44:18.589362: \n",
      "2024-11-25 07:44:18.595364: Epoch 141\n",
      "2024-11-25 07:44:18.601366: Current learning rate: 0.00742\n",
      "2024-11-25 07:46:37.664825: train_loss -0.675\n",
      "2024-11-25 07:46:37.674827: val_loss -0.523\n",
      "2024-11-25 07:46:37.681828: Pseudo dice [0.722]\n",
      "2024-11-25 07:46:37.687829: Epoch time: 139.08 s\n",
      "2024-11-25 07:46:38.709059: \n",
      "2024-11-25 07:46:38.718061: Epoch 142\n",
      "2024-11-25 07:46:38.725063: Current learning rate: 0.0074\n",
      "2024-11-25 07:48:57.641617: train_loss -0.6805\n",
      "2024-11-25 07:48:57.653620: val_loss -0.4133\n",
      "2024-11-25 07:48:57.663623: Pseudo dice [0.6782]\n",
      "2024-11-25 07:48:57.670624: Epoch time: 138.93 s\n",
      "2024-11-25 07:48:58.692854: \n",
      "2024-11-25 07:48:58.700856: Epoch 143\n",
      "2024-11-25 07:48:58.706857: Current learning rate: 0.00738\n",
      "2024-11-25 07:51:17.646685: train_loss -0.6767\n",
      "2024-11-25 07:51:17.656687: val_loss -0.3552\n",
      "2024-11-25 07:51:17.664690: Pseudo dice [0.6453]\n",
      "2024-11-25 07:51:17.672691: Epoch time: 138.95 s\n",
      "2024-11-25 07:51:18.690920: \n",
      "2024-11-25 07:51:18.698922: Epoch 144\n",
      "2024-11-25 07:51:18.703923: Current learning rate: 0.00737\n",
      "2024-11-25 07:53:34.513242: train_loss -0.6699\n",
      "2024-11-25 07:53:34.526246: val_loss -0.5088\n",
      "2024-11-25 07:53:34.534247: Pseudo dice [0.7227]\n",
      "2024-11-25 07:53:34.539248: Epoch time: 135.82 s\n",
      "2024-11-25 07:53:35.558477: \n",
      "2024-11-25 07:53:35.564478: Epoch 145\n",
      "2024-11-25 07:53:35.568479: Current learning rate: 0.00735\n",
      "2024-11-25 07:55:45.848230: train_loss -0.6605\n",
      "2024-11-25 07:55:45.858231: val_loss -0.4074\n",
      "2024-11-25 07:55:45.858231: Pseudo dice [0.6852]\n",
      "2024-11-25 07:55:45.868231: Epoch time: 130.29 s\n",
      "2024-11-25 07:55:46.905293: \n",
      "2024-11-25 07:55:46.905293: Epoch 146\n",
      "2024-11-25 07:55:46.915293: Current learning rate: 0.00733\n",
      "2024-11-25 07:57:56.991862: train_loss -0.6505\n",
      "2024-11-25 07:57:57.001862: val_loss -0.4165\n",
      "2024-11-25 07:57:57.001862: Pseudo dice [0.6722]\n",
      "2024-11-25 07:57:57.011862: Epoch time: 130.08 s\n",
      "2024-11-25 07:57:58.039390: \n",
      "2024-11-25 07:57:58.046393: Epoch 147\n",
      "2024-11-25 07:57:58.048898: Current learning rate: 0.00731\n",
      "2024-11-25 08:00:08.162546: train_loss -0.6785\n",
      "2024-11-25 08:00:08.172548: val_loss -0.4515\n",
      "2024-11-25 08:00:08.182548: Pseudo dice [0.6793]\n",
      "2024-11-25 08:00:08.192548: Epoch time: 130.12 s\n",
      "2024-11-25 08:00:09.389174: \n",
      "2024-11-25 08:00:09.389174: Epoch 148\n",
      "2024-11-25 08:00:09.399173: Current learning rate: 0.00729\n",
      "2024-11-25 08:02:19.559483: train_loss -0.6613\n",
      "2024-11-25 08:02:19.569484: val_loss -0.5255\n",
      "2024-11-25 08:02:19.579484: Pseudo dice [0.7373]\n",
      "2024-11-25 08:02:19.579484: Epoch time: 130.17 s\n",
      "2024-11-25 08:02:19.589484: Yayy! New best EMA pseudo Dice: 0.6843\n",
      "2024-11-25 08:02:20.839443: \n",
      "2024-11-25 08:02:20.849444: Epoch 149\n",
      "2024-11-25 08:02:20.859444: Current learning rate: 0.00727\n",
      "2024-11-25 08:04:30.896451: train_loss -0.6628\n",
      "2024-11-25 08:04:30.916453: val_loss -0.423\n",
      "2024-11-25 08:04:30.916453: Pseudo dice [0.6606]\n",
      "2024-11-25 08:04:30.926452: Epoch time: 130.06 s\n",
      "2024-11-25 08:04:32.166390: \n",
      "2024-11-25 08:04:32.166390: Epoch 150\n",
      "2024-11-25 08:04:32.176390: Current learning rate: 0.00725\n",
      "2024-11-25 08:06:42.246711: train_loss -0.7146\n",
      "2024-11-25 08:06:42.256711: val_loss -0.3613\n",
      "2024-11-25 08:06:42.266711: Pseudo dice [0.6548]\n",
      "2024-11-25 08:06:42.276711: Epoch time: 130.08 s\n",
      "2024-11-25 08:06:43.293324: \n",
      "2024-11-25 08:06:43.293324: Epoch 151\n",
      "2024-11-25 08:06:43.303323: Current learning rate: 0.00724\n",
      "2024-11-25 08:08:53.433652: train_loss -0.7305\n",
      "2024-11-25 08:08:53.443653: val_loss -0.4891\n",
      "2024-11-25 08:08:53.453653: Pseudo dice [0.6946]\n",
      "2024-11-25 08:08:53.453653: Epoch time: 130.14 s\n",
      "2024-11-25 08:08:54.476951: \n",
      "2024-11-25 08:08:54.486950: Epoch 152\n",
      "2024-11-25 08:08:54.486950: Current learning rate: 0.00722\n",
      "2024-11-25 08:11:04.583914: train_loss -0.6548\n",
      "2024-11-25 08:11:04.593914: val_loss -0.466\n",
      "2024-11-25 08:11:04.603914: Pseudo dice [0.6912]\n",
      "2024-11-25 08:11:04.613914: Epoch time: 130.11 s\n",
      "2024-11-25 08:11:05.640559: \n",
      "2024-11-25 08:11:05.640559: Epoch 153\n",
      "2024-11-25 08:11:05.650559: Current learning rate: 0.0072\n",
      "2024-11-25 08:13:15.724216: train_loss -0.625\n",
      "2024-11-25 08:13:15.734217: val_loss -0.4738\n",
      "2024-11-25 08:13:15.744218: Pseudo dice [0.668]\n",
      "2024-11-25 08:13:15.744218: Epoch time: 130.09 s\n",
      "2024-11-25 08:13:16.780870: \n",
      "2024-11-25 08:13:16.780870: Epoch 154\n",
      "2024-11-25 08:13:16.790870: Current learning rate: 0.00718\n",
      "2024-11-25 08:15:26.890721: train_loss -0.6576\n",
      "2024-11-25 08:15:26.900342: val_loss -0.4303\n",
      "2024-11-25 08:15:26.907804: Pseudo dice [0.6961]\n",
      "2024-11-25 08:15:26.907804: Epoch time: 130.12 s\n",
      "2024-11-25 08:15:28.131096: \n",
      "2024-11-25 08:15:28.141097: Epoch 155\n",
      "2024-11-25 08:15:28.141097: Current learning rate: 0.00716\n",
      "2024-11-25 08:17:38.210913: train_loss -0.6967\n",
      "2024-11-25 08:17:38.220912: val_loss -0.5017\n",
      "2024-11-25 08:17:38.230913: Pseudo dice [0.7107]\n",
      "2024-11-25 08:17:38.240913: Epoch time: 130.08 s\n",
      "2024-11-25 08:17:38.240913: Yayy! New best EMA pseudo Dice: 0.6849\n",
      "2024-11-25 08:17:39.514712: \n",
      "2024-11-25 08:17:39.524712: Epoch 156\n",
      "2024-11-25 08:17:39.524712: Current learning rate: 0.00714\n",
      "2024-11-25 08:19:49.565015: train_loss -0.7191\n",
      "2024-11-25 08:19:49.575014: val_loss -0.467\n",
      "2024-11-25 08:19:49.585014: Pseudo dice [0.6881]\n",
      "2024-11-25 08:19:49.585014: Epoch time: 130.05 s\n",
      "2024-11-25 08:19:49.595016: Yayy! New best EMA pseudo Dice: 0.6852\n",
      "2024-11-25 08:19:50.871209: \n",
      "2024-11-25 08:19:50.871209: Epoch 157\n",
      "2024-11-25 08:19:50.881206: Current learning rate: 0.00712\n",
      "2024-11-25 08:22:00.915297: train_loss -0.6867\n",
      "2024-11-25 08:22:00.935297: val_loss -0.4136\n",
      "2024-11-25 08:22:00.935297: Pseudo dice [0.6063]\n",
      "2024-11-25 08:22:00.945298: Epoch time: 130.04 s\n",
      "2024-11-25 08:22:01.981426: \n",
      "2024-11-25 08:22:01.991427: Epoch 158\n",
      "2024-11-25 08:22:01.991427: Current learning rate: 0.0071\n",
      "2024-11-25 08:24:12.035161: train_loss -0.7098\n",
      "2024-11-25 08:24:12.045162: val_loss -0.4759\n",
      "2024-11-25 08:24:12.055162: Pseudo dice [0.6869]\n",
      "2024-11-25 08:24:12.055162: Epoch time: 130.05 s\n",
      "2024-11-25 08:24:13.098866: \n",
      "2024-11-25 08:24:13.108866: Epoch 159\n",
      "2024-11-25 08:24:13.108866: Current learning rate: 0.00709\n",
      "2024-11-25 08:26:23.162023: train_loss -0.7076\n",
      "2024-11-25 08:26:23.172023: val_loss -0.4006\n",
      "2024-11-25 08:26:23.172023: Pseudo dice [0.6591]\n",
      "2024-11-25 08:26:23.182024: Epoch time: 130.06 s\n",
      "2024-11-25 08:26:24.225809: \n",
      "2024-11-25 08:26:24.235312: Epoch 160\n",
      "2024-11-25 08:26:24.235312: Current learning rate: 0.00707\n",
      "2024-11-25 08:28:34.332824: train_loss -0.6678\n",
      "2024-11-25 08:28:34.342824: val_loss -0.4193\n",
      "2024-11-25 08:28:34.342824: Pseudo dice [0.697]\n",
      "2024-11-25 08:28:34.352824: Epoch time: 130.11 s\n",
      "2024-11-25 08:28:35.389419: \n",
      "2024-11-25 08:28:35.399417: Epoch 161\n",
      "2024-11-25 08:28:35.399417: Current learning rate: 0.00705\n",
      "2024-11-25 08:30:45.436394: train_loss -0.6416\n",
      "2024-11-25 08:30:45.456394: val_loss -0.4769\n",
      "2024-11-25 08:30:45.456394: Pseudo dice [0.6726]\n",
      "2024-11-25 08:30:45.466395: Epoch time: 130.05 s\n",
      "2024-11-25 08:30:46.676387: \n",
      "2024-11-25 08:30:46.686388: Epoch 162\n",
      "2024-11-25 08:30:46.696388: Current learning rate: 0.00703\n",
      "2024-11-25 08:32:56.736701: train_loss -0.6592\n",
      "2024-11-25 08:32:56.746701: val_loss -0.3362\n",
      "2024-11-25 08:32:56.756702: Pseudo dice [0.5923]\n",
      "2024-11-25 08:32:56.756702: Epoch time: 130.06 s\n",
      "2024-11-25 08:32:57.799962: \n",
      "2024-11-25 08:32:57.809960: Epoch 163\n",
      "2024-11-25 08:32:57.809960: Current learning rate: 0.00701\n",
      "2024-11-25 08:35:07.844722: train_loss -0.7069\n",
      "2024-11-25 08:35:07.847008: val_loss -0.3479\n",
      "2024-11-25 08:35:07.857006: Pseudo dice [0.6899]\n",
      "2024-11-25 08:35:07.868846: Epoch time: 130.04 s\n",
      "2024-11-25 08:35:08.910259: \n",
      "2024-11-25 08:35:08.920259: Epoch 164\n",
      "2024-11-25 08:35:08.920259: Current learning rate: 0.00699\n",
      "2024-11-25 08:37:19.033879: train_loss -0.7103\n",
      "2024-11-25 08:37:19.043879: val_loss -0.4769\n",
      "2024-11-25 08:37:19.053878: Pseudo dice [0.7025]\n",
      "2024-11-25 08:37:19.063879: Epoch time: 130.12 s\n",
      "2024-11-25 08:37:20.070061: \n",
      "2024-11-25 08:37:20.080061: Epoch 165\n",
      "2024-11-25 08:37:20.080061: Current learning rate: 0.00697\n",
      "2024-11-25 08:39:30.147517: train_loss -0.7193\n",
      "2024-11-25 08:39:30.167518: val_loss -0.4456\n",
      "2024-11-25 08:39:30.167518: Pseudo dice [0.6643]\n",
      "2024-11-25 08:39:30.177518: Epoch time: 130.08 s\n",
      "2024-11-25 08:39:31.190823: \n",
      "2024-11-25 08:39:31.190823: Epoch 166\n",
      "2024-11-25 08:39:31.200822: Current learning rate: 0.00696\n",
      "2024-11-25 08:41:41.354462: train_loss -0.5833\n",
      "2024-11-25 08:41:41.364463: val_loss -0.4049\n",
      "2024-11-25 08:41:41.364463: Pseudo dice [0.6465]\n",
      "2024-11-25 08:41:41.374464: Epoch time: 130.16 s\n",
      "2024-11-25 08:41:42.397264: \n",
      "2024-11-25 08:41:42.397264: Epoch 167\n",
      "2024-11-25 08:41:42.407264: Current learning rate: 0.00694\n",
      "2024-11-25 08:43:52.557773: train_loss -0.6561\n",
      "2024-11-25 08:43:52.566775: val_loss -0.4436\n",
      "2024-11-25 08:43:52.568045: Pseudo dice [0.7044]\n",
      "2024-11-25 08:43:52.578044: Epoch time: 130.16 s\n",
      "2024-11-25 08:43:53.781350: \n",
      "2024-11-25 08:43:53.781350: Epoch 168\n",
      "2024-11-25 08:43:53.791351: Current learning rate: 0.00692\n",
      "2024-11-25 08:46:03.901703: train_loss -0.6879\n",
      "2024-11-25 08:46:03.921702: val_loss -0.5255\n",
      "2024-11-25 08:46:03.921702: Pseudo dice [0.6802]\n",
      "2024-11-25 08:46:03.931703: Epoch time: 130.12 s\n",
      "2024-11-25 08:46:04.958756: \n",
      "2024-11-25 08:46:04.965089: Epoch 169\n",
      "2024-11-25 08:46:04.970089: Current learning rate: 0.0069\n",
      "2024-11-25 08:48:15.031908: train_loss -0.6582\n",
      "2024-11-25 08:48:15.041908: val_loss -0.4168\n",
      "2024-11-25 08:48:15.041908: Pseudo dice [0.6868]\n",
      "2024-11-25 08:48:15.051907: Epoch time: 130.08 s\n",
      "2024-11-25 08:48:16.081938: \n",
      "2024-11-25 08:48:16.081938: Epoch 170\n",
      "2024-11-25 08:48:16.091935: Current learning rate: 0.00688\n",
      "2024-11-25 08:50:26.108874: train_loss -0.6933\n",
      "2024-11-25 08:50:26.118064: val_loss -0.5241\n",
      "2024-11-25 08:50:26.123065: Pseudo dice [0.7592]\n",
      "2024-11-25 08:50:26.125540: Epoch time: 130.03 s\n",
      "2024-11-25 08:50:27.145532: \n",
      "2024-11-25 08:50:27.155532: Epoch 171\n",
      "2024-11-25 08:50:27.165532: Current learning rate: 0.00686\n",
      "2024-11-25 08:52:37.285873: train_loss -0.6543\n",
      "2024-11-25 08:52:37.295874: val_loss -0.5459\n",
      "2024-11-25 08:52:37.295874: Pseudo dice [0.7383]\n",
      "2024-11-25 08:52:37.295874: Epoch time: 130.14 s\n",
      "2024-11-25 08:52:37.305873: Yayy! New best EMA pseudo Dice: 0.6896\n",
      "2024-11-25 08:52:38.555788: \n",
      "2024-11-25 08:52:38.565788: Epoch 172\n",
      "2024-11-25 08:52:38.565788: Current learning rate: 0.00684\n",
      "2024-11-25 08:54:48.676120: train_loss -0.7002\n",
      "2024-11-25 08:54:48.696120: val_loss -0.4718\n",
      "2024-11-25 08:54:48.696120: Pseudo dice [0.6952]\n",
      "2024-11-25 08:54:48.706120: Epoch time: 130.12 s\n",
      "2024-11-25 08:54:48.706120: Yayy! New best EMA pseudo Dice: 0.6902\n",
      "2024-11-25 08:54:49.978963: \n",
      "2024-11-25 08:54:49.978963: Epoch 173\n",
      "2024-11-25 08:54:49.988968: Current learning rate: 0.00682\n",
      "2024-11-25 08:57:00.059756: train_loss -0.7062\n",
      "2024-11-25 08:57:00.069758: val_loss -0.5566\n",
      "2024-11-25 08:57:00.069758: Pseudo dice [0.7437]\n",
      "2024-11-25 08:57:00.079757: Epoch time: 130.09 s\n",
      "2024-11-25 08:57:00.079757: Yayy! New best EMA pseudo Dice: 0.6955\n",
      "2024-11-25 08:57:01.353012: \n",
      "2024-11-25 08:57:01.353012: Epoch 174\n",
      "2024-11-25 08:57:01.363011: Current learning rate: 0.0068\n",
      "2024-11-25 08:59:11.406633: train_loss -0.7424\n",
      "2024-11-25 08:59:11.416633: val_loss -0.5206\n",
      "2024-11-25 08:59:11.426632: Pseudo dice [0.7167]\n",
      "2024-11-25 08:59:11.426632: Epoch time: 130.05 s\n",
      "2024-11-25 08:59:11.436633: Yayy! New best EMA pseudo Dice: 0.6977\n",
      "2024-11-25 08:59:12.882806: \n",
      "2024-11-25 08:59:12.892805: Epoch 175\n",
      "2024-11-25 08:59:12.897788: Current learning rate: 0.00679\n",
      "2024-11-25 09:01:22.956479: train_loss -0.7405\n",
      "2024-11-25 09:01:22.966480: val_loss -0.4075\n",
      "2024-11-25 09:01:22.976480: Pseudo dice [0.6603]\n",
      "2024-11-25 09:01:22.986480: Epoch time: 130.07 s\n",
      "2024-11-25 09:01:24.014925: \n",
      "2024-11-25 09:01:24.020927: Epoch 176\n",
      "2024-11-25 09:01:24.024928: Current learning rate: 0.00677\n",
      "2024-11-25 09:03:34.217214: train_loss -0.6738\n",
      "2024-11-25 09:03:34.237215: val_loss -0.5\n",
      "2024-11-25 09:03:34.247214: Pseudo dice [0.722]\n",
      "2024-11-25 09:03:34.257215: Epoch time: 130.2 s\n",
      "2024-11-25 09:03:35.280479: \n",
      "2024-11-25 09:03:35.280479: Epoch 177\n",
      "2024-11-25 09:03:35.290479: Current learning rate: 0.00675\n",
      "2024-11-25 09:05:45.370772: train_loss -0.6981\n",
      "2024-11-25 09:05:45.380774: val_loss -0.3665\n",
      "2024-11-25 09:05:45.390773: Pseudo dice [0.6371]\n",
      "2024-11-25 09:05:45.400772: Epoch time: 130.09 s\n",
      "2024-11-25 09:05:46.430759: \n",
      "2024-11-25 09:05:46.430759: Epoch 178\n",
      "2024-11-25 09:05:46.440759: Current learning rate: 0.00673\n",
      "2024-11-25 09:07:56.547738: train_loss -0.6574\n",
      "2024-11-25 09:07:56.557739: val_loss -0.3839\n",
      "2024-11-25 09:07:56.567738: Pseudo dice [0.6411]\n",
      "2024-11-25 09:07:56.567738: Epoch time: 130.12 s\n",
      "2024-11-25 09:07:57.602467: \n",
      "2024-11-25 09:07:57.608468: Epoch 179\n",
      "2024-11-25 09:07:57.612469: Current learning rate: 0.00671\n",
      "2024-11-25 09:10:07.674721: train_loss -0.7144\n",
      "2024-11-25 09:10:07.684722: val_loss -0.4546\n",
      "2024-11-25 09:10:07.694722: Pseudo dice [0.6983]\n",
      "2024-11-25 09:10:07.702248: Epoch time: 130.07 s\n",
      "2024-11-25 09:10:08.727979: \n",
      "2024-11-25 09:10:08.737981: Epoch 180\n",
      "2024-11-25 09:10:08.737981: Current learning rate: 0.00669\n",
      "2024-11-25 09:12:18.841616: train_loss -0.7104\n",
      "2024-11-25 09:12:18.851616: val_loss -0.3306\n",
      "2024-11-25 09:12:18.851616: Pseudo dice [0.6244]\n",
      "2024-11-25 09:12:18.861615: Epoch time: 130.12 s\n",
      "2024-11-25 09:12:19.884444: \n",
      "2024-11-25 09:12:19.884444: Epoch 181\n",
      "2024-11-25 09:12:19.897999: Current learning rate: 0.00667\n",
      "2024-11-25 09:14:29.924775: train_loss -0.7365\n",
      "2024-11-25 09:14:29.935197: val_loss -0.5221\n",
      "2024-11-25 09:14:29.935197: Pseudo dice [0.7457]\n",
      "2024-11-25 09:14:29.945198: Epoch time: 130.04 s\n",
      "2024-11-25 09:14:31.148548: \n",
      "2024-11-25 09:14:31.148548: Epoch 182\n",
      "2024-11-25 09:14:31.158548: Current learning rate: 0.00665\n",
      "2024-11-25 09:16:41.175070: train_loss -0.7325\n",
      "2024-11-25 09:16:41.185072: val_loss -0.3912\n",
      "2024-11-25 09:16:41.195071: Pseudo dice [0.6829]\n",
      "2024-11-25 09:16:41.205072: Epoch time: 130.04 s\n",
      "2024-11-25 09:16:42.237336: \n",
      "2024-11-25 09:16:42.243992: Epoch 183\n",
      "2024-11-25 09:16:42.249993: Current learning rate: 0.00664\n",
      "2024-11-25 09:18:52.285786: train_loss -0.727\n",
      "2024-11-25 09:18:52.295786: val_loss -0.418\n",
      "2024-11-25 09:18:52.305786: Pseudo dice [0.6991]\n",
      "2024-11-25 09:18:52.305786: Epoch time: 130.05 s\n",
      "2024-11-25 09:18:53.332409: \n",
      "2024-11-25 09:18:53.342408: Epoch 184\n",
      "2024-11-25 09:18:53.342408: Current learning rate: 0.00662\n",
      "2024-11-25 09:21:03.549387: train_loss -0.6738\n",
      "2024-11-25 09:21:03.569386: val_loss -0.4469\n",
      "2024-11-25 09:21:03.569386: Pseudo dice [0.6867]\n",
      "2024-11-25 09:21:03.579387: Epoch time: 130.22 s\n",
      "2024-11-25 09:21:04.611575: \n",
      "2024-11-25 09:21:04.618200: Epoch 185\n",
      "2024-11-25 09:21:04.622201: Current learning rate: 0.0066\n",
      "2024-11-25 09:23:14.679688: train_loss -0.6964\n",
      "2024-11-25 09:23:14.679688: val_loss -0.4674\n",
      "2024-11-25 09:23:14.689687: Pseudo dice [0.7054]\n",
      "2024-11-25 09:23:14.699688: Epoch time: 130.07 s\n",
      "2024-11-25 09:23:15.725805: \n",
      "2024-11-25 09:23:15.735806: Epoch 186\n",
      "2024-11-25 09:23:15.745808: Current learning rate: 0.00658\n",
      "2024-11-25 09:25:25.793314: train_loss -0.6797\n",
      "2024-11-25 09:25:25.803312: val_loss -0.3262\n",
      "2024-11-25 09:25:25.803312: Pseudo dice [0.5915]\n",
      "2024-11-25 09:25:25.813312: Epoch time: 130.07 s\n",
      "2024-11-25 09:25:26.849907: \n",
      "2024-11-25 09:25:26.849907: Epoch 187\n",
      "2024-11-25 09:25:26.859908: Current learning rate: 0.00656\n",
      "2024-11-25 09:27:36.880252: train_loss -0.7165\n",
      "2024-11-25 09:27:36.890251: val_loss -0.297\n",
      "2024-11-25 09:27:36.890251: Pseudo dice [0.5928]\n",
      "2024-11-25 09:27:36.900251: Epoch time: 130.04 s\n",
      "2024-11-25 09:27:37.936435: \n",
      "2024-11-25 09:27:37.936435: Epoch 188\n",
      "2024-11-25 09:27:37.946436: Current learning rate: 0.00654\n",
      "2024-11-25 09:29:48.107176: train_loss -0.7269\n",
      "2024-11-25 09:29:48.117176: val_loss -0.4368\n",
      "2024-11-25 09:29:48.127175: Pseudo dice [0.6946]\n",
      "2024-11-25 09:29:48.127175: Epoch time: 130.17 s\n",
      "2024-11-25 09:29:49.330478: \n",
      "2024-11-25 09:29:49.340478: Epoch 189\n",
      "2024-11-25 09:29:49.350478: Current learning rate: 0.00652\n",
      "2024-11-25 09:31:59.447476: train_loss -0.7127\n",
      "2024-11-25 09:31:59.457476: val_loss -0.4001\n",
      "2024-11-25 09:31:59.467477: Pseudo dice [0.6554]\n",
      "2024-11-25 09:31:59.467477: Epoch time: 130.12 s\n",
      "2024-11-25 09:32:00.504100: \n",
      "2024-11-25 09:32:00.504100: Epoch 190\n",
      "2024-11-25 09:32:00.514099: Current learning rate: 0.0065\n",
      "2024-11-25 09:34:10.630652: train_loss -0.7237\n",
      "2024-11-25 09:34:10.640652: val_loss -0.465\n",
      "2024-11-25 09:34:10.640652: Pseudo dice [0.7099]\n",
      "2024-11-25 09:34:10.650653: Epoch time: 130.13 s\n",
      "2024-11-25 09:34:11.673866: \n",
      "2024-11-25 09:34:11.683866: Epoch 191\n",
      "2024-11-25 09:34:11.683866: Current learning rate: 0.00648\n",
      "2024-11-25 09:36:21.694244: train_loss -0.7423\n",
      "2024-11-25 09:36:21.704244: val_loss -0.3321\n",
      "2024-11-25 09:36:21.704244: Pseudo dice [0.6164]\n",
      "2024-11-25 09:36:21.714244: Epoch time: 130.02 s\n",
      "2024-11-25 09:36:22.760052: \n",
      "2024-11-25 09:36:22.770052: Epoch 192\n",
      "2024-11-25 09:36:22.770052: Current learning rate: 0.00647\n",
      "2024-11-25 09:38:33.390978: train_loss -0.7538\n",
      "2024-11-25 09:38:33.400980: val_loss -0.3663\n",
      "2024-11-25 09:38:33.406982: Pseudo dice [0.6589]\n",
      "2024-11-25 09:38:33.410982: Epoch time: 130.63 s\n",
      "2024-11-25 09:38:34.453217: \n",
      "2024-11-25 09:38:34.464219: Epoch 193\n",
      "2024-11-25 09:38:34.468220: Current learning rate: 0.00645\n",
      "2024-11-25 09:40:45.139811: train_loss -0.7503\n",
      "2024-11-25 09:40:45.146812: val_loss -0.5122\n",
      "2024-11-25 09:40:45.151813: Pseudo dice [0.7398]\n",
      "2024-11-25 09:40:45.156815: Epoch time: 130.69 s\n",
      "2024-11-25 09:40:46.197049: \n",
      "2024-11-25 09:40:46.203050: Epoch 194\n",
      "2024-11-25 09:40:46.208051: Current learning rate: 0.00643\n",
      "2024-11-25 09:42:56.116283: train_loss -0.7349\n",
      "2024-11-25 09:42:56.126286: val_loss -0.4376\n",
      "2024-11-25 09:42:56.132287: Pseudo dice [0.6694]\n",
      "2024-11-25 09:42:56.137288: Epoch time: 129.92 s\n",
      "2024-11-25 09:42:57.338557: \n",
      "2024-11-25 09:42:57.344559: Epoch 195\n",
      "2024-11-25 09:42:57.348560: Current learning rate: 0.00641\n",
      "2024-11-25 09:45:07.177056: train_loss -0.7474\n",
      "2024-11-25 09:45:07.189059: val_loss -0.3997\n",
      "2024-11-25 09:45:07.197061: Pseudo dice [0.6774]\n",
      "2024-11-25 09:45:07.203063: Epoch time: 129.84 s\n",
      "2024-11-25 09:45:08.239295: \n",
      "2024-11-25 09:45:08.245297: Epoch 196\n",
      "2024-11-25 09:45:08.249297: Current learning rate: 0.00639\n",
      "2024-11-25 09:47:18.121262: train_loss -0.7635\n",
      "2024-11-25 09:47:18.130264: val_loss -0.4199\n",
      "2024-11-25 09:47:18.136266: Pseudo dice [0.6853]\n",
      "2024-11-25 09:47:18.142267: Epoch time: 129.88 s\n",
      "2024-11-25 09:47:19.174500: \n",
      "2024-11-25 09:47:19.181502: Epoch 197\n",
      "2024-11-25 09:47:19.185503: Current learning rate: 0.00637\n",
      "2024-11-25 09:49:28.990783: train_loss -0.6991\n",
      "2024-11-25 09:49:29.000786: val_loss -0.4975\n",
      "2024-11-25 09:49:29.008787: Pseudo dice [0.7163]\n",
      "2024-11-25 09:49:29.014789: Epoch time: 129.82 s\n",
      "2024-11-25 09:49:30.059246: \n",
      "2024-11-25 09:49:30.065247: Epoch 198\n",
      "2024-11-25 09:49:30.069248: Current learning rate: 0.00635\n",
      "2024-11-25 09:51:39.933084: train_loss -0.724\n",
      "2024-11-25 09:51:39.946087: val_loss -0.5226\n",
      "2024-11-25 09:51:39.953089: Pseudo dice [0.6985]\n",
      "2024-11-25 09:51:39.957089: Epoch time: 129.87 s\n",
      "2024-11-25 09:51:40.993324: \n",
      "2024-11-25 09:51:40.999324: Epoch 199\n",
      "2024-11-25 09:51:41.003325: Current learning rate: 0.00633\n",
      "2024-11-25 09:53:50.983427: train_loss -0.6983\n",
      "2024-11-25 09:53:50.993429: val_loss -0.4662\n",
      "2024-11-25 09:53:50.998430: Pseudo dice [0.6645]\n",
      "2024-11-25 09:53:51.003431: Epoch time: 129.99 s\n",
      "2024-11-25 09:53:52.258225: \n",
      "2024-11-25 09:53:52.264228: Epoch 200\n",
      "2024-11-25 09:53:52.268229: Current learning rate: 0.00631\n",
      "2024-11-25 09:56:02.090073: train_loss -0.7559\n",
      "2024-11-25 09:56:02.100075: val_loss -0.3872\n",
      "2024-11-25 09:56:02.105077: Pseudo dice [0.668]\n",
      "2024-11-25 09:56:02.109078: Epoch time: 129.83 s\n",
      "2024-11-25 09:56:03.146311: \n",
      "2024-11-25 09:56:03.152311: Epoch 201\n",
      "2024-11-25 09:56:03.157313: Current learning rate: 0.0063\n",
      "2024-11-25 09:58:12.974449: train_loss -0.7541\n",
      "2024-11-25 09:58:12.984452: val_loss -0.3974\n",
      "2024-11-25 09:58:12.991453: Pseudo dice [0.6771]\n",
      "2024-11-25 09:58:12.999454: Epoch time: 129.83 s\n",
      "2024-11-25 09:58:14.221730: \n",
      "2024-11-25 09:58:14.227731: Epoch 202\n",
      "2024-11-25 09:58:14.231731: Current learning rate: 0.00628\n",
      "2024-11-25 10:00:24.079638: train_loss -0.7439\n",
      "2024-11-25 10:00:24.091641: val_loss -0.3785\n",
      "2024-11-25 10:00:24.097642: Pseudo dice [0.6203]\n",
      "2024-11-25 10:00:24.104643: Epoch time: 129.86 s\n",
      "2024-11-25 10:00:25.141876: \n",
      "2024-11-25 10:00:25.147878: Epoch 203\n",
      "2024-11-25 10:00:25.151879: Current learning rate: 0.00626\n",
      "2024-11-25 10:02:35.012122: train_loss -0.7467\n",
      "2024-11-25 10:02:35.021124: val_loss -0.4029\n",
      "2024-11-25 10:02:35.027124: Pseudo dice [0.6762]\n",
      "2024-11-25 10:02:35.032125: Epoch time: 129.87 s\n",
      "2024-11-25 10:02:36.069360: \n",
      "2024-11-25 10:02:36.075361: Epoch 204\n",
      "2024-11-25 10:02:36.079362: Current learning rate: 0.00624\n",
      "2024-11-25 10:04:45.928360: train_loss -0.7153\n",
      "2024-11-25 10:04:45.937362: val_loss -0.4006\n",
      "2024-11-25 10:04:45.941363: Pseudo dice [0.6899]\n",
      "2024-11-25 10:04:45.946365: Epoch time: 129.86 s\n",
      "2024-11-25 10:04:46.995601: \n",
      "2024-11-25 10:04:47.002603: Epoch 205\n",
      "2024-11-25 10:04:47.007604: Current learning rate: 0.00622\n",
      "2024-11-25 10:06:56.916227: train_loss -0.7275\n",
      "2024-11-25 10:06:56.927229: val_loss -0.4464\n",
      "2024-11-25 10:06:56.935233: Pseudo dice [0.6667]\n",
      "2024-11-25 10:06:56.940233: Epoch time: 129.92 s\n",
      "2024-11-25 10:06:57.920454: \n",
      "2024-11-25 10:06:57.925455: Epoch 206\n",
      "2024-11-25 10:06:57.929456: Current learning rate: 0.0062\n",
      "2024-11-25 10:09:07.857342: train_loss -0.7261\n",
      "2024-11-25 10:09:07.864344: val_loss -0.39\n",
      "2024-11-25 10:09:07.869344: Pseudo dice [0.6447]\n",
      "2024-11-25 10:09:07.875345: Epoch time: 129.94 s\n",
      "2024-11-25 10:09:08.879573: \n",
      "2024-11-25 10:09:08.887574: Epoch 207\n",
      "2024-11-25 10:09:08.894575: Current learning rate: 0.00618\n",
      "2024-11-25 10:11:18.794673: train_loss -0.7378\n",
      "2024-11-25 10:11:18.803674: val_loss -0.2873\n",
      "2024-11-25 10:11:18.809675: Pseudo dice [0.6173]\n",
      "2024-11-25 10:11:18.815676: Epoch time: 129.92 s\n",
      "2024-11-25 10:11:19.799899: \n",
      "2024-11-25 10:11:19.805900: Epoch 208\n",
      "2024-11-25 10:11:19.808901: Current learning rate: 0.00616\n",
      "2024-11-25 10:13:29.764818: train_loss -0.7633\n",
      "2024-11-25 10:13:29.777821: val_loss -0.3538\n",
      "2024-11-25 10:13:29.783822: Pseudo dice [0.6661]\n",
      "2024-11-25 10:13:29.788823: Epoch time: 129.97 s\n",
      "2024-11-25 10:13:30.944083: \n",
      "2024-11-25 10:13:30.950084: Epoch 209\n",
      "2024-11-25 10:13:30.954085: Current learning rate: 0.00614\n",
      "2024-11-25 10:15:40.768169: train_loss -0.7188\n",
      "2024-11-25 10:15:40.778171: val_loss -0.4629\n",
      "2024-11-25 10:15:40.786173: Pseudo dice [0.6875]\n",
      "2024-11-25 10:15:40.793174: Epoch time: 129.83 s\n",
      "2024-11-25 10:15:41.774395: \n",
      "2024-11-25 10:15:41.780396: Epoch 210\n",
      "2024-11-25 10:15:41.783397: Current learning rate: 0.00612\n",
      "2024-11-25 10:17:51.656571: train_loss -0.7122\n",
      "2024-11-25 10:17:51.665573: val_loss -0.3487\n",
      "2024-11-25 10:17:51.672575: Pseudo dice [0.6476]\n",
      "2024-11-25 10:17:51.677576: Epoch time: 129.88 s\n",
      "2024-11-25 10:17:52.659797: \n",
      "2024-11-25 10:17:52.665798: Epoch 211\n",
      "2024-11-25 10:17:52.670799: Current learning rate: 0.00611\n",
      "2024-11-25 10:20:02.526158: train_loss -0.7196\n",
      "2024-11-25 10:20:02.540160: val_loss -0.3034\n",
      "2024-11-25 10:20:02.548162: Pseudo dice [0.5937]\n",
      "2024-11-25 10:20:02.554164: Epoch time: 129.87 s\n",
      "2024-11-25 10:20:03.538386: \n",
      "2024-11-25 10:20:03.544386: Epoch 212\n",
      "2024-11-25 10:20:03.549388: Current learning rate: 0.00609\n",
      "2024-11-25 10:22:13.385602: train_loss -0.6925\n",
      "2024-11-25 10:22:13.394603: val_loss -0.3652\n",
      "2024-11-25 10:22:13.400604: Pseudo dice [0.6685]\n",
      "2024-11-25 10:22:13.404605: Epoch time: 129.85 s\n",
      "2024-11-25 10:22:14.391828: \n",
      "2024-11-25 10:22:14.397829: Epoch 213\n",
      "2024-11-25 10:22:14.401830: Current learning rate: 0.00607\n",
      "2024-11-25 10:24:24.215984: train_loss -0.738\n",
      "2024-11-25 10:24:24.228985: val_loss -0.4904\n",
      "2024-11-25 10:24:24.236988: Pseudo dice [0.7224]\n",
      "2024-11-25 10:24:24.243989: Epoch time: 129.83 s\n",
      "2024-11-25 10:24:25.222209: \n",
      "2024-11-25 10:24:25.227211: Epoch 214\n",
      "2024-11-25 10:24:25.231212: Current learning rate: 0.00605\n",
      "2024-11-25 10:26:35.101823: train_loss -0.7303\n",
      "2024-11-25 10:26:35.110825: val_loss -0.4606\n",
      "2024-11-25 10:26:35.114826: Pseudo dice [0.6755]\n",
      "2024-11-25 10:26:35.119827: Epoch time: 129.88 s\n",
      "2024-11-25 10:26:36.108051: \n",
      "2024-11-25 10:26:36.113951: Epoch 215\n",
      "2024-11-25 10:26:36.117952: Current learning rate: 0.00603\n",
      "2024-11-25 10:28:46.240957: train_loss -0.7015\n",
      "2024-11-25 10:28:46.249959: val_loss -0.4385\n",
      "2024-11-25 10:28:46.254961: Pseudo dice [0.694]\n",
      "2024-11-25 10:28:46.260961: Epoch time: 130.13 s\n",
      "2024-11-25 10:28:47.421748: \n",
      "2024-11-25 10:28:47.427750: Epoch 216\n",
      "2024-11-25 10:28:47.431751: Current learning rate: 0.00601\n",
      "2024-11-25 10:30:57.395246: train_loss -0.7372\n",
      "2024-11-25 10:30:57.405248: val_loss -0.274\n",
      "2024-11-25 10:30:57.411250: Pseudo dice [0.6043]\n",
      "2024-11-25 10:30:57.418251: Epoch time: 129.97 s\n",
      "2024-11-25 10:30:58.405473: \n",
      "2024-11-25 10:30:58.411475: Epoch 217\n",
      "2024-11-25 10:30:58.415476: Current learning rate: 0.00599\n",
      "2024-11-25 10:33:08.578200: train_loss -0.744\n",
      "2024-11-25 10:33:08.592203: val_loss -0.3549\n",
      "2024-11-25 10:33:08.600205: Pseudo dice [0.6163]\n",
      "2024-11-25 10:33:08.606206: Epoch time: 130.17 s\n",
      "2024-11-25 10:33:09.587427: \n",
      "2024-11-25 10:33:09.593429: Epoch 218\n",
      "2024-11-25 10:33:09.598430: Current learning rate: 0.00597\n",
      "2024-11-25 10:35:20.738038: train_loss -0.7351\n",
      "2024-11-25 10:35:20.752041: val_loss -0.4056\n",
      "2024-11-25 10:35:20.758042: Pseudo dice [0.6879]\n",
      "2024-11-25 10:35:20.764044: Epoch time: 131.15 s\n",
      "2024-11-25 10:35:21.785274: \n",
      "2024-11-25 10:35:21.791275: Epoch 219\n",
      "2024-11-25 10:35:21.796276: Current learning rate: 0.00595\n",
      "2024-11-25 10:37:33.561726: train_loss -0.7667\n",
      "2024-11-25 10:37:33.575729: val_loss -0.3597\n",
      "2024-11-25 10:37:33.581730: Pseudo dice [0.647]\n",
      "2024-11-25 10:37:33.588732: Epoch time: 131.78 s\n",
      "2024-11-25 10:37:34.577954: \n",
      "2024-11-25 10:37:34.583956: Epoch 220\n",
      "2024-11-25 10:37:34.588958: Current learning rate: 0.00593\n",
      "2024-11-25 10:39:53.417029: train_loss -0.7314\n",
      "2024-11-25 10:39:53.430033: val_loss -0.3866\n",
      "2024-11-25 10:39:53.435034: Pseudo dice [0.6806]\n",
      "2024-11-25 10:39:53.443036: Epoch time: 138.84 s\n",
      "2024-11-25 10:39:54.431258: \n",
      "2024-11-25 10:39:54.437259: Epoch 221\n",
      "2024-11-25 10:39:54.443262: Current learning rate: 0.00592\n",
      "2024-11-25 10:42:04.588804: train_loss -0.7405\n",
      "2024-11-25 10:42:04.597806: val_loss -0.4687\n",
      "2024-11-25 10:42:04.604808: Pseudo dice [0.6637]\n",
      "2024-11-25 10:42:04.611809: Epoch time: 130.16 s\n",
      "2024-11-25 10:42:05.605034: \n",
      "2024-11-25 10:42:05.612036: Epoch 222\n",
      "2024-11-25 10:42:05.616036: Current learning rate: 0.0059\n",
      "2024-11-25 10:44:15.690786: train_loss -0.7479\n",
      "2024-11-25 10:44:15.699789: val_loss -0.5092\n",
      "2024-11-25 10:44:15.707791: Pseudo dice [0.7287]\n",
      "2024-11-25 10:44:15.713791: Epoch time: 130.09 s\n",
      "2024-11-25 10:44:16.873052: \n",
      "2024-11-25 10:44:16.879054: Epoch 223\n",
      "2024-11-25 10:44:16.883054: Current learning rate: 0.00588\n",
      "2024-11-25 10:46:28.689061: train_loss -0.718\n",
      "2024-11-25 10:46:28.698063: val_loss -0.3424\n",
      "2024-11-25 10:46:28.705064: Pseudo dice [0.6557]\n",
      "2024-11-25 10:46:28.710065: Epoch time: 131.82 s\n",
      "2024-11-25 10:46:29.680285: \n",
      "2024-11-25 10:46:29.686285: Epoch 224\n",
      "2024-11-25 10:46:29.690286: Current learning rate: 0.00586\n",
      "2024-11-25 10:48:39.697209: train_loss -0.7661\n",
      "2024-11-25 10:48:39.708212: val_loss -0.4477\n",
      "2024-11-25 10:48:39.714214: Pseudo dice [0.6869]\n",
      "2024-11-25 10:48:39.719214: Epoch time: 130.02 s\n",
      "2024-11-25 10:48:40.691434: \n",
      "2024-11-25 10:48:40.698435: Epoch 225\n",
      "2024-11-25 10:48:40.702436: Current learning rate: 0.00584\n",
      "2024-11-25 10:50:50.574368: train_loss -0.7661\n",
      "2024-11-25 10:50:50.583370: val_loss -0.4095\n",
      "2024-11-25 10:50:50.588372: Pseudo dice [0.714]\n",
      "2024-11-25 10:50:50.593373: Epoch time: 129.88 s\n",
      "2024-11-25 10:50:51.562592: \n",
      "2024-11-25 10:50:51.568592: Epoch 226\n",
      "2024-11-25 10:50:51.572593: Current learning rate: 0.00582\n",
      "2024-11-25 10:53:01.997098: train_loss -0.7586\n",
      "2024-11-25 10:53:02.010100: val_loss -0.2944\n",
      "2024-11-25 10:53:02.019103: Pseudo dice [0.5948]\n",
      "2024-11-25 10:53:02.024104: Epoch time: 130.44 s\n",
      "2024-11-25 10:53:03.006325: \n",
      "2024-11-25 10:53:03.012326: Epoch 227\n",
      "2024-11-25 10:53:03.016327: Current learning rate: 0.0058\n",
      "2024-11-25 10:55:15.229318: train_loss -0.723\n",
      "2024-11-25 10:55:15.243320: val_loss -0.4999\n",
      "2024-11-25 10:55:15.249322: Pseudo dice [0.6731]\n",
      "2024-11-25 10:55:15.254323: Epoch time: 132.22 s\n",
      "2024-11-25 10:55:16.235544: \n",
      "2024-11-25 10:55:16.242546: Epoch 228\n",
      "2024-11-25 10:55:16.247547: Current learning rate: 0.00578\n",
      "2024-11-25 10:57:26.493484: train_loss -0.7343\n",
      "2024-11-25 10:57:26.503485: val_loss -0.5193\n",
      "2024-11-25 10:57:26.509487: Pseudo dice [0.7411]\n",
      "2024-11-25 10:57:26.516489: Epoch time: 130.26 s\n",
      "2024-11-25 10:57:27.519715: \n",
      "2024-11-25 10:57:27.526716: Epoch 229\n",
      "2024-11-25 10:57:27.531717: Current learning rate: 0.00576\n",
      "2024-11-25 10:59:37.403258: train_loss -0.7153\n",
      "2024-11-25 10:59:37.412260: val_loss -0.2582\n",
      "2024-11-25 10:59:37.418262: Pseudo dice [0.6346]\n",
      "2024-11-25 10:59:37.424262: Epoch time: 129.88 s\n",
      "2024-11-25 10:59:38.577522: \n",
      "2024-11-25 10:59:38.584524: Epoch 230\n",
      "2024-11-25 10:59:38.588525: Current learning rate: 0.00574\n",
      "2024-11-25 11:01:49.732783: train_loss -0.7811\n",
      "2024-11-25 11:01:49.742785: val_loss -0.4038\n",
      "2024-11-25 11:01:49.747786: Pseudo dice [0.7131]\n",
      "2024-11-25 11:01:49.754788: Epoch time: 131.16 s\n",
      "2024-11-25 11:01:50.728007: \n",
      "2024-11-25 11:01:50.735009: Epoch 231\n",
      "2024-11-25 11:01:50.739009: Current learning rate: 0.00572\n",
      "2024-11-25 11:04:01.668003: train_loss -0.7719\n",
      "2024-11-25 11:04:01.683007: val_loss -0.4474\n",
      "2024-11-25 11:04:01.693009: Pseudo dice [0.6841]\n",
      "2024-11-25 11:04:01.698010: Epoch time: 130.94 s\n",
      "2024-11-25 11:04:02.713238: \n",
      "2024-11-25 11:04:02.719240: Epoch 232\n",
      "2024-11-25 11:04:02.723241: Current learning rate: 0.0057\n",
      "2024-11-25 11:06:13.734536: train_loss -0.7282\n",
      "2024-11-25 11:06:13.747539: val_loss -0.488\n",
      "2024-11-25 11:06:13.754542: Pseudo dice [0.7279]\n",
      "2024-11-25 11:06:13.759542: Epoch time: 131.02 s\n",
      "2024-11-25 11:06:14.733762: \n",
      "2024-11-25 11:06:14.739764: Epoch 233\n",
      "2024-11-25 11:06:14.743765: Current learning rate: 0.00569\n",
      "2024-11-25 11:08:25.416412: train_loss -0.754\n",
      "2024-11-25 11:08:25.429414: val_loss -0.2934\n",
      "2024-11-25 11:08:25.434414: Pseudo dice [0.5947]\n",
      "2024-11-25 11:08:25.438415: Epoch time: 130.68 s\n",
      "2024-11-25 11:08:26.411635: \n",
      "2024-11-25 11:08:26.417636: Epoch 234\n",
      "2024-11-25 11:08:26.421637: Current learning rate: 0.00567\n",
      "2024-11-25 11:10:38.852445: train_loss -0.7552\n",
      "2024-11-25 11:10:38.862450: val_loss -0.348\n",
      "2024-11-25 11:10:38.867450: Pseudo dice [0.6529]\n",
      "2024-11-25 11:10:38.873451: Epoch time: 132.44 s\n",
      "2024-11-25 11:10:39.841669: \n",
      "2024-11-25 11:10:39.847670: Epoch 235\n",
      "2024-11-25 11:10:39.852672: Current learning rate: 0.00565\n",
      "2024-11-25 11:12:49.720067: train_loss -0.7563\n",
      "2024-11-25 11:12:49.742072: val_loss -0.3724\n",
      "2024-11-25 11:12:49.749073: Pseudo dice [0.6848]\n",
      "2024-11-25 11:12:49.755075: Epoch time: 129.88 s\n",
      "2024-11-25 11:12:50.722292: \n",
      "2024-11-25 11:12:50.728293: Epoch 236\n",
      "2024-11-25 11:12:50.732294: Current learning rate: 0.00563\n",
      "2024-11-25 11:15:00.676867: train_loss -0.7667\n",
      "2024-11-25 11:15:00.685869: val_loss -0.3481\n",
      "2024-11-25 11:15:00.690870: Pseudo dice [0.689]\n",
      "2024-11-25 11:15:00.695872: Epoch time: 129.96 s\n",
      "2024-11-25 11:15:01.663090: \n",
      "2024-11-25 11:15:01.669091: Epoch 237\n",
      "2024-11-25 11:15:01.673092: Current learning rate: 0.00561\n",
      "2024-11-25 11:17:11.454880: train_loss -0.752\n",
      "2024-11-25 11:17:11.468883: val_loss -0.5509\n",
      "2024-11-25 11:17:11.477885: Pseudo dice [0.7644]\n",
      "2024-11-25 11:17:11.483886: Epoch time: 129.79 s\n",
      "2024-11-25 11:17:12.637146: \n",
      "2024-11-25 11:17:12.643147: Epoch 238\n",
      "2024-11-25 11:17:12.648148: Current learning rate: 0.00559\n",
      "2024-11-25 11:19:23.986754: train_loss -0.7713\n",
      "2024-11-25 11:19:23.996757: val_loss -0.4731\n",
      "2024-11-25 11:19:24.004758: Pseudo dice [0.7312]\n",
      "2024-11-25 11:19:24.010760: Epoch time: 131.35 s\n",
      "2024-11-25 11:19:24.989980: \n",
      "2024-11-25 11:19:24.994981: Epoch 239\n",
      "2024-11-25 11:19:24.999982: Current learning rate: 0.00557\n",
      "2024-11-25 11:21:35.471090: train_loss -0.7734\n",
      "2024-11-25 11:21:35.485093: val_loss -0.4537\n",
      "2024-11-25 11:21:35.492095: Pseudo dice [0.7414]\n",
      "2024-11-25 11:21:35.496097: Epoch time: 130.48 s\n",
      "2024-11-25 11:21:36.485319: \n",
      "2024-11-25 11:21:36.490319: Epoch 240\n",
      "2024-11-25 11:21:36.495321: Current learning rate: 0.00555\n",
      "2024-11-25 11:23:47.691288: train_loss -0.7595\n",
      "2024-11-25 11:23:47.704291: val_loss -0.5783\n",
      "2024-11-25 11:23:47.713293: Pseudo dice [0.7722]\n",
      "2024-11-25 11:23:47.718294: Epoch time: 131.21 s\n",
      "2024-11-25 11:23:47.723295: Yayy! New best EMA pseudo Dice: 0.7007\n",
      "2024-11-25 11:23:48.931136: \n",
      "2024-11-25 11:23:48.938137: Epoch 241\n",
      "2024-11-25 11:23:48.943139: Current learning rate: 0.00553\n",
      "2024-11-25 11:26:00.111738: train_loss -0.7503\n",
      "2024-11-25 11:26:00.123741: val_loss -0.4382\n",
      "2024-11-25 11:26:00.131742: Pseudo dice [0.6751]\n",
      "2024-11-25 11:26:00.136744: Epoch time: 131.18 s\n",
      "2024-11-25 11:26:01.125967: \n",
      "2024-11-25 11:26:01.131968: Epoch 242\n",
      "2024-11-25 11:26:01.135968: Current learning rate: 0.00551\n",
      "2024-11-25 11:28:12.144087: train_loss -0.7717\n",
      "2024-11-25 11:28:12.158089: val_loss -0.3919\n",
      "2024-11-25 11:28:12.166092: Pseudo dice [0.685]\n",
      "2024-11-25 11:28:12.170092: Epoch time: 131.02 s\n",
      "2024-11-25 11:28:13.157314: \n",
      "2024-11-25 11:28:13.163316: Epoch 243\n",
      "2024-11-25 11:28:13.167316: Current learning rate: 0.00549\n",
      "2024-11-25 11:30:24.507727: train_loss -0.7643\n",
      "2024-11-25 11:30:24.516730: val_loss -0.4467\n",
      "2024-11-25 11:30:24.521732: Pseudo dice [0.6848]\n",
      "2024-11-25 11:30:24.526733: Epoch time: 131.35 s\n",
      "2024-11-25 11:30:25.537958: \n",
      "2024-11-25 11:30:25.544961: Epoch 244\n",
      "2024-11-25 11:30:25.549962: Current learning rate: 0.00547\n",
      "2024-11-25 11:32:37.104425: train_loss -0.7649\n",
      "2024-11-25 11:32:37.113427: val_loss -0.5406\n",
      "2024-11-25 11:32:37.120428: Pseudo dice [0.7743]\n",
      "2024-11-25 11:32:37.125429: Epoch time: 131.57 s\n",
      "2024-11-25 11:32:37.129430: Yayy! New best EMA pseudo Dice: 0.7035\n",
      "2024-11-25 11:32:38.540255: \n",
      "2024-11-25 11:32:38.547256: Epoch 245\n",
      "2024-11-25 11:32:38.551257: Current learning rate: 0.00546\n",
      "2024-11-25 11:34:50.353381: train_loss -0.7745\n",
      "2024-11-25 11:34:50.362382: val_loss -0.4579\n",
      "2024-11-25 11:34:50.369384: Pseudo dice [0.6769]\n",
      "2024-11-25 11:34:50.375385: Epoch time: 131.81 s\n",
      "2024-11-25 11:34:51.365608: \n",
      "2024-11-25 11:34:51.371609: Epoch 246\n",
      "2024-11-25 11:34:51.376611: Current learning rate: 0.00544\n",
      "2024-11-25 11:37:03.807882: train_loss -0.7573\n",
      "2024-11-25 11:37:03.827886: val_loss -0.4187\n",
      "2024-11-25 11:37:03.834889: Pseudo dice [0.708]\n",
      "2024-11-25 11:37:03.840889: Epoch time: 132.44 s\n",
      "2024-11-25 11:37:04.827112: \n",
      "2024-11-25 11:37:04.833112: Epoch 247\n",
      "2024-11-25 11:37:04.837113: Current learning rate: 0.00542\n",
      "2024-11-25 11:39:17.509184: train_loss -0.7716\n",
      "2024-11-25 11:39:17.518186: val_loss -0.4194\n",
      "2024-11-25 11:39:17.523187: Pseudo dice [0.6832]\n",
      "2024-11-25 11:39:17.528188: Epoch time: 132.68 s\n",
      "2024-11-25 11:39:18.554419: \n",
      "2024-11-25 11:39:18.561420: Epoch 248\n",
      "2024-11-25 11:39:18.566422: Current learning rate: 0.0054\n",
      "2024-11-25 11:41:29.975854: train_loss -0.7337\n",
      "2024-11-25 11:41:29.985857: val_loss -0.3766\n",
      "2024-11-25 11:41:29.994858: Pseudo dice [0.7072]\n",
      "2024-11-25 11:41:30.000859: Epoch time: 131.42 s\n",
      "2024-11-25 11:41:31.026090: \n",
      "2024-11-25 11:41:31.033092: Epoch 249\n",
      "2024-11-25 11:41:31.037092: Current learning rate: 0.00538\n",
      "2024-11-25 11:43:42.738173: train_loss -0.7641\n",
      "2024-11-25 11:43:42.747175: val_loss -0.4366\n",
      "2024-11-25 11:43:42.754177: Pseudo dice [0.7224]\n",
      "2024-11-25 11:43:42.760178: Epoch time: 131.71 s\n",
      "2024-11-25 11:43:44.053469: \n",
      "2024-11-25 11:43:44.060471: Epoch 250\n",
      "2024-11-25 11:43:44.066471: Current learning rate: 0.00536\n",
      "2024-11-25 11:46:04.880194: train_loss -0.7514\n",
      "2024-11-25 11:46:04.904199: val_loss -0.4045\n",
      "2024-11-25 11:46:04.911202: Pseudo dice [0.6631]\n",
      "2024-11-25 11:46:04.919204: Epoch time: 140.83 s\n",
      "2024-11-25 11:46:06.022452: \n",
      "2024-11-25 11:46:06.034385: Epoch 251\n",
      "2024-11-25 11:46:06.039386: Current learning rate: 0.00534\n",
      "2024-11-25 11:48:19.613290: train_loss -0.7098\n",
      "2024-11-25 11:48:19.622293: val_loss -0.4862\n",
      "2024-11-25 11:48:19.628294: Pseudo dice [0.6693]\n",
      "2024-11-25 11:48:19.634296: Epoch time: 133.59 s\n",
      "2024-11-25 11:48:20.649524: \n",
      "2024-11-25 11:48:20.658004: Epoch 252\n",
      "2024-11-25 11:48:20.662005: Current learning rate: 0.00532\n",
      "2024-11-25 11:50:40.543948: train_loss -0.7021\n",
      "2024-11-25 11:50:40.554951: val_loss -0.4837\n",
      "2024-11-25 11:50:40.562953: Pseudo dice [0.6987]\n",
      "2024-11-25 11:50:40.568954: Epoch time: 139.9 s\n",
      "2024-11-25 11:50:41.755219: \n",
      "2024-11-25 11:50:41.762222: Epoch 253\n",
      "2024-11-25 11:50:41.767223: Current learning rate: 0.0053\n",
      "2024-11-25 11:53:02.551211: train_loss -0.7198\n",
      "2024-11-25 11:53:02.564214: val_loss -0.4566\n",
      "2024-11-25 11:53:02.572216: Pseudo dice [0.7159]\n",
      "2024-11-25 11:53:02.579217: Epoch time: 140.8 s\n",
      "2024-11-25 11:53:03.584444: \n",
      "2024-11-25 11:53:03.592445: Epoch 254\n",
      "2024-11-25 11:53:03.597446: Current learning rate: 0.00528\n",
      "2024-11-25 11:55:21.331109: train_loss -0.758\n",
      "2024-11-25 11:55:21.352114: val_loss -0.3626\n",
      "2024-11-25 11:55:21.359116: Pseudo dice [0.6561]\n",
      "2024-11-25 11:55:21.365117: Epoch time: 137.75 s\n",
      "2024-11-25 11:55:22.467366: \n",
      "2024-11-25 11:55:22.475368: Epoch 255\n",
      "2024-11-25 11:55:22.480369: Current learning rate: 0.00526\n",
      "2024-11-25 11:57:33.334809: train_loss -0.7497\n",
      "2024-11-25 11:57:33.348812: val_loss -0.3823\n",
      "2024-11-25 11:57:33.357814: Pseudo dice [0.652]\n",
      "2024-11-25 11:57:33.364816: Epoch time: 130.87 s\n",
      "2024-11-25 11:57:34.395047: \n",
      "2024-11-25 11:57:34.402049: Epoch 256\n",
      "2024-11-25 11:57:34.407050: Current learning rate: 0.00524\n",
      "2024-11-25 11:59:45.243486: train_loss -0.7359\n",
      "2024-11-25 11:59:45.253488: val_loss -0.4098\n",
      "2024-11-25 11:59:45.260490: Pseudo dice [0.694]\n",
      "2024-11-25 11:59:45.265491: Epoch time: 130.85 s\n",
      "2024-11-25 11:59:46.283720: \n",
      "2024-11-25 11:59:46.290722: Epoch 257\n",
      "2024-11-25 11:59:46.295723: Current learning rate: 0.00522\n",
      "2024-11-25 12:01:56.326979: train_loss -0.7343\n",
      "2024-11-25 12:01:56.337981: val_loss -0.5316\n",
      "2024-11-25 12:01:56.345983: Pseudo dice [0.7206]\n",
      "2024-11-25 12:01:56.351984: Epoch time: 130.04 s\n",
      "2024-11-25 12:01:57.353209: \n",
      "2024-11-25 12:01:57.360211: Epoch 258\n",
      "2024-11-25 12:01:57.365212: Current learning rate: 0.0052\n",
      "2024-11-25 12:04:07.470265: train_loss -0.7453\n",
      "2024-11-25 12:04:07.480267: val_loss -0.4531\n",
      "2024-11-25 12:04:07.486268: Pseudo dice [0.7104]\n",
      "2024-11-25 12:04:07.491269: Epoch time: 130.12 s\n",
      "2024-11-25 12:04:08.481492: \n",
      "2024-11-25 12:04:08.488495: Epoch 259\n",
      "2024-11-25 12:04:08.492495: Current learning rate: 0.00518\n",
      "2024-11-25 12:06:18.472386: train_loss -0.7129\n",
      "2024-11-25 12:06:18.482388: val_loss -0.2152\n",
      "2024-11-25 12:06:18.488389: Pseudo dice [0.5249]\n",
      "2024-11-25 12:06:18.493390: Epoch time: 129.99 s\n",
      "2024-11-25 12:06:19.664292: \n",
      "2024-11-25 12:06:19.670294: Epoch 260\n",
      "2024-11-25 12:06:19.674295: Current learning rate: 0.00517\n",
      "2024-11-25 12:08:29.663071: train_loss -0.7271\n",
      "2024-11-25 12:08:29.672073: val_loss -0.358\n",
      "2024-11-25 12:08:29.679075: Pseudo dice [0.6078]\n",
      "2024-11-25 12:08:29.685077: Epoch time: 130.0 s\n",
      "2024-11-25 12:08:30.675300: \n",
      "2024-11-25 12:08:30.680301: Epoch 261\n",
      "2024-11-25 12:08:30.684302: Current learning rate: 0.00515\n",
      "2024-11-25 12:10:40.883198: train_loss -0.7435\n",
      "2024-11-25 12:10:40.893200: val_loss -0.4828\n",
      "2024-11-25 12:10:40.900201: Pseudo dice [0.6996]\n",
      "2024-11-25 12:10:40.905202: Epoch time: 130.21 s\n",
      "2024-11-25 12:10:41.892425: \n",
      "2024-11-25 12:10:41.898425: Epoch 262\n",
      "2024-11-25 12:10:41.902426: Current learning rate: 0.00513\n",
      "2024-11-25 12:12:52.730147: train_loss -0.7333\n",
      "2024-11-25 12:12:52.744150: val_loss -0.2474\n",
      "2024-11-25 12:12:52.753151: Pseudo dice [0.6061]\n",
      "2024-11-25 12:12:52.759153: Epoch time: 130.84 s\n",
      "2024-11-25 12:12:53.750376: \n",
      "2024-11-25 12:12:53.756379: Epoch 263\n",
      "2024-11-25 12:12:53.761378: Current learning rate: 0.00511\n",
      "2024-11-25 12:15:04.234659: train_loss -0.7004\n",
      "2024-11-25 12:15:04.244662: val_loss -0.3807\n",
      "2024-11-25 12:15:04.250663: Pseudo dice [0.6305]\n",
      "2024-11-25 12:15:04.254664: Epoch time: 130.49 s\n",
      "2024-11-25 12:15:05.249888: \n",
      "2024-11-25 12:15:05.255890: Epoch 264\n",
      "2024-11-25 12:15:05.259891: Current learning rate: 0.00509\n",
      "2024-11-25 12:17:16.425381: train_loss -0.7477\n",
      "2024-11-25 12:17:16.438384: val_loss -0.318\n",
      "2024-11-25 12:17:16.445385: Pseudo dice [0.5421]\n",
      "2024-11-25 12:17:16.453387: Epoch time: 131.18 s\n",
      "2024-11-25 12:17:17.733675: \n",
      "2024-11-25 12:17:17.742678: Epoch 265\n",
      "2024-11-25 12:17:17.749679: Current learning rate: 0.00507\n",
      "2024-11-25 12:19:31.710608: train_loss -0.771\n",
      "2024-11-25 12:19:31.724613: val_loss -0.482\n",
      "2024-11-25 12:19:31.731614: Pseudo dice [0.7532]\n",
      "2024-11-25 12:19:31.736615: Epoch time: 133.98 s\n",
      "2024-11-25 12:19:32.725838: \n",
      "2024-11-25 12:19:32.731839: Epoch 266\n",
      "2024-11-25 12:19:32.736840: Current learning rate: 0.00505\n",
      "2024-11-25 12:21:43.584740: train_loss -0.7774\n",
      "2024-11-25 12:21:43.593741: val_loss -0.5082\n",
      "2024-11-25 12:21:43.599743: Pseudo dice [0.7559]\n",
      "2024-11-25 12:21:43.604744: Epoch time: 130.86 s\n",
      "2024-11-25 12:21:44.598978: \n",
      "2024-11-25 12:21:44.604979: Epoch 267\n",
      "2024-11-25 12:21:44.609980: Current learning rate: 0.00503\n",
      "2024-11-25 12:23:55.188857: train_loss -0.7796\n",
      "2024-11-25 12:23:55.201859: val_loss -0.4012\n",
      "2024-11-25 12:23:55.208860: Pseudo dice [0.6966]\n",
      "2024-11-25 12:23:55.214862: Epoch time: 130.59 s\n",
      "2024-11-25 12:23:56.390126: \n",
      "2024-11-25 12:23:56.396128: Epoch 268\n",
      "2024-11-25 12:23:56.400129: Current learning rate: 0.00501\n",
      "2024-11-25 12:26:08.506672: train_loss -0.8003\n",
      "2024-11-25 12:26:08.515675: val_loss -0.4497\n",
      "2024-11-25 12:26:08.521676: Pseudo dice [0.6901]\n",
      "2024-11-25 12:26:08.527677: Epoch time: 132.12 s\n",
      "2024-11-25 12:26:09.540906: \n",
      "2024-11-25 12:26:09.547906: Epoch 269\n",
      "2024-11-25 12:26:09.552907: Current learning rate: 0.00499\n",
      "2024-11-25 12:28:20.735987: train_loss -0.7755\n",
      "2024-11-25 12:28:20.747991: val_loss -0.2293\n",
      "2024-11-25 12:28:20.755992: Pseudo dice [0.607]\n",
      "2024-11-25 12:28:20.762994: Epoch time: 131.2 s\n",
      "2024-11-25 12:28:21.778222: \n",
      "2024-11-25 12:28:21.785224: Epoch 270\n",
      "2024-11-25 12:28:21.789224: Current learning rate: 0.00497\n",
      "2024-11-25 12:30:32.699849: train_loss -0.7958\n",
      "2024-11-25 12:30:32.709851: val_loss -0.4493\n",
      "2024-11-25 12:30:32.716852: Pseudo dice [0.716]\n",
      "2024-11-25 12:30:32.722853: Epoch time: 130.92 s\n",
      "2024-11-25 12:30:33.705076: \n",
      "2024-11-25 12:30:33.711076: Epoch 271\n",
      "2024-11-25 12:30:33.715078: Current learning rate: 0.00495\n",
      "2024-11-25 12:32:46.639052: train_loss -0.7516\n",
      "2024-11-25 12:32:46.650055: val_loss -0.3859\n",
      "2024-11-25 12:32:46.659057: Pseudo dice [0.6218]\n",
      "2024-11-25 12:32:46.664058: Epoch time: 132.93 s\n",
      "2024-11-25 12:32:47.658282: \n",
      "2024-11-25 12:32:47.664283: Epoch 272\n",
      "2024-11-25 12:32:47.668285: Current learning rate: 0.00493\n",
      "2024-11-25 12:34:59.687670: train_loss -0.739\n",
      "2024-11-25 12:34:59.702673: val_loss -0.4124\n",
      "2024-11-25 12:34:59.708675: Pseudo dice [0.701]\n",
      "2024-11-25 12:34:59.714676: Epoch time: 132.03 s\n",
      "2024-11-25 12:35:00.704899: \n",
      "2024-11-25 12:35:00.711901: Epoch 273\n",
      "2024-11-25 12:35:00.716902: Current learning rate: 0.00491\n",
      "2024-11-25 12:37:11.081069: train_loss -0.738\n",
      "2024-11-25 12:37:11.091071: val_loss -0.3513\n",
      "2024-11-25 12:37:11.098071: Pseudo dice [0.6737]\n",
      "2024-11-25 12:37:11.102072: Epoch time: 130.38 s\n",
      "2024-11-25 12:37:12.094559: \n",
      "2024-11-25 12:37:12.101561: Epoch 274\n",
      "2024-11-25 12:37:12.105561: Current learning rate: 0.00489\n",
      "2024-11-25 12:39:22.544687: train_loss -0.7562\n",
      "2024-11-25 12:39:22.552688: val_loss -0.4402\n",
      "2024-11-25 12:39:22.558689: Pseudo dice [0.6519]\n",
      "2024-11-25 12:39:22.565691: Epoch time: 130.45 s\n",
      "2024-11-25 12:39:23.749959: \n",
      "2024-11-25 12:39:23.757960: Epoch 275\n",
      "2024-11-25 12:39:23.762961: Current learning rate: 0.00487\n",
      "2024-11-25 12:41:34.160055: train_loss -0.7423\n",
      "2024-11-25 12:41:34.170058: val_loss -0.4073\n",
      "2024-11-25 12:41:34.176059: Pseudo dice [0.7086]\n",
      "2024-11-25 12:41:34.181060: Epoch time: 130.41 s\n",
      "2024-11-25 12:41:35.175285: \n",
      "2024-11-25 12:41:35.181285: Epoch 276\n",
      "2024-11-25 12:41:35.185286: Current learning rate: 0.00485\n",
      "2024-11-25 12:43:45.583658: train_loss -0.7656\n",
      "2024-11-25 12:43:45.596660: val_loss -0.4702\n",
      "2024-11-25 12:43:45.601662: Pseudo dice [0.7243]\n",
      "2024-11-25 12:43:45.605664: Epoch time: 130.41 s\n",
      "2024-11-25 12:43:46.591886: \n",
      "2024-11-25 12:43:46.598886: Epoch 277\n",
      "2024-11-25 12:43:46.603888: Current learning rate: 0.00484\n",
      "2024-11-25 12:45:57.014907: train_loss -0.7763\n",
      "2024-11-25 12:45:57.027910: val_loss -0.355\n",
      "2024-11-25 12:45:57.033911: Pseudo dice [0.6789]\n",
      "2024-11-25 12:45:57.039913: Epoch time: 130.42 s\n",
      "2024-11-25 12:45:58.031137: \n",
      "2024-11-25 12:45:58.038138: Epoch 278\n",
      "2024-11-25 12:45:58.042139: Current learning rate: 0.00482\n",
      "2024-11-25 12:48:09.231603: train_loss -0.794\n",
      "2024-11-25 12:48:09.244606: val_loss -0.4146\n",
      "2024-11-25 12:48:09.253608: Pseudo dice [0.6812]\n",
      "2024-11-25 12:48:09.258609: Epoch time: 131.2 s\n",
      "2024-11-25 12:48:10.247832: \n",
      "2024-11-25 12:48:10.253832: Epoch 279\n",
      "2024-11-25 12:48:10.257834: Current learning rate: 0.0048\n",
      "2024-11-25 12:50:20.877169: train_loss -0.764\n",
      "2024-11-25 12:50:20.887171: val_loss -0.3042\n",
      "2024-11-25 12:50:20.893172: Pseudo dice [0.6161]\n",
      "2024-11-25 12:50:20.900174: Epoch time: 130.63 s\n",
      "2024-11-25 12:50:21.891990: \n",
      "2024-11-25 12:50:21.898991: Epoch 280\n",
      "2024-11-25 12:50:21.903992: Current learning rate: 0.00478\n",
      "2024-11-25 12:52:32.338039: train_loss -0.738\n",
      "2024-11-25 12:52:32.348335: val_loss -0.3816\n",
      "2024-11-25 12:52:32.356444: Pseudo dice [0.6338]\n",
      "2024-11-25 12:52:32.361522: Epoch time: 130.45 s\n",
      "2024-11-25 12:52:33.355423: \n",
      "2024-11-25 12:52:33.361425: Epoch 281\n",
      "2024-11-25 12:52:33.365426: Current learning rate: 0.00476\n",
      "2024-11-25 12:54:43.762335: train_loss -0.7015\n",
      "2024-11-25 12:54:43.772337: val_loss -0.5621\n",
      "2024-11-25 12:54:43.780339: Pseudo dice [0.7574]\n",
      "2024-11-25 12:54:43.786340: Epoch time: 130.41 s\n",
      "2024-11-25 12:54:44.962605: \n",
      "2024-11-25 12:54:44.968606: Epoch 282\n",
      "2024-11-25 12:54:44.973608: Current learning rate: 0.00474\n",
      "2024-11-25 12:56:55.497873: train_loss -0.7145\n",
      "2024-11-25 12:56:55.511876: val_loss -0.2489\n",
      "2024-11-25 12:56:55.519878: Pseudo dice [0.6001]\n",
      "2024-11-25 12:56:55.525880: Epoch time: 130.54 s\n",
      "2024-11-25 12:56:56.619126: \n",
      "2024-11-25 12:56:56.626127: Epoch 283\n",
      "2024-11-25 12:56:56.630128: Current learning rate: 0.00472\n",
      "2024-11-25 12:59:06.970398: train_loss -0.7429\n",
      "2024-11-25 12:59:06.983402: val_loss -0.3178\n",
      "2024-11-25 12:59:06.992404: Pseudo dice [0.6245]\n",
      "2024-11-25 12:59:07.003407: Epoch time: 130.35 s\n",
      "2024-11-25 12:59:07.999631: \n",
      "2024-11-25 12:59:08.008633: Epoch 284\n",
      "2024-11-25 12:59:08.012634: Current learning rate: 0.0047\n",
      "2024-11-25 13:01:18.338089: train_loss -0.7809\n",
      "2024-11-25 13:01:18.348092: val_loss -0.4364\n",
      "2024-11-25 13:01:18.354092: Pseudo dice [0.6799]\n",
      "2024-11-25 13:01:18.361094: Epoch time: 130.34 s\n",
      "2024-11-25 13:01:19.365320: \n",
      "2024-11-25 13:01:19.372322: Epoch 285\n",
      "2024-11-25 13:01:19.376322: Current learning rate: 0.00468\n",
      "2024-11-25 13:03:29.667701: train_loss -0.7855\n",
      "2024-11-25 13:03:29.676702: val_loss -0.4843\n",
      "2024-11-25 13:03:29.681703: Pseudo dice [0.7177]\n",
      "2024-11-25 13:03:29.685705: Epoch time: 130.3 s\n",
      "2024-11-25 13:03:30.682929: \n",
      "2024-11-25 13:03:30.688930: Epoch 286\n",
      "2024-11-25 13:03:30.692931: Current learning rate: 0.00466\n",
      "2024-11-25 13:05:41.108793: train_loss -0.7661\n",
      "2024-11-25 13:05:41.118796: val_loss -0.4041\n",
      "2024-11-25 13:05:41.125798: Pseudo dice [0.6887]\n",
      "2024-11-25 13:05:41.130799: Epoch time: 130.43 s\n",
      "2024-11-25 13:05:42.143027: \n",
      "2024-11-25 13:05:42.149028: Epoch 287\n",
      "2024-11-25 13:05:42.153029: Current learning rate: 0.00464\n",
      "2024-11-25 13:07:52.770682: train_loss -0.7102\n",
      "2024-11-25 13:07:52.781684: val_loss -0.4542\n",
      "2024-11-25 13:07:52.787685: Pseudo dice [0.7214]\n",
      "2024-11-25 13:07:52.792687: Epoch time: 130.63 s\n",
      "2024-11-25 13:07:53.808915: \n",
      "2024-11-25 13:07:53.814917: Epoch 288\n",
      "2024-11-25 13:07:53.818918: Current learning rate: 0.00462\n",
      "2024-11-25 13:10:04.431712: train_loss -0.7326\n",
      "2024-11-25 13:10:04.441712: val_loss -0.4067\n",
      "2024-11-25 13:10:04.447715: Pseudo dice [0.6728]\n",
      "2024-11-25 13:10:04.453716: Epoch time: 130.62 s\n",
      "2024-11-25 13:10:05.654986: \n",
      "2024-11-25 13:10:05.661987: Epoch 289\n",
      "2024-11-25 13:10:05.665988: Current learning rate: 0.0046\n",
      "2024-11-25 13:12:16.191915: train_loss -0.7392\n",
      "2024-11-25 13:12:16.199916: val_loss -0.3759\n",
      "2024-11-25 13:12:16.204917: Pseudo dice [0.6831]\n",
      "2024-11-25 13:12:16.211919: Epoch time: 130.54 s\n",
      "2024-11-25 13:12:17.220147: \n",
      "2024-11-25 13:12:17.227148: Epoch 290\n",
      "2024-11-25 13:12:17.230148: Current learning rate: 0.00458\n",
      "2024-11-25 13:14:27.302316: train_loss -0.785\n",
      "2024-11-25 13:14:27.326321: val_loss -0.493\n",
      "2024-11-25 13:14:27.332323: Pseudo dice [0.743]\n",
      "2024-11-25 13:14:27.338325: Epoch time: 130.08 s\n",
      "2024-11-25 13:14:28.349553: \n",
      "2024-11-25 13:14:28.356554: Epoch 291\n",
      "2024-11-25 13:14:28.360555: Current learning rate: 0.00456\n",
      "2024-11-25 13:16:40.630451: train_loss -0.7942\n",
      "2024-11-25 13:16:40.643453: val_loss -0.3767\n",
      "2024-11-25 13:16:40.648455: Pseudo dice [0.6934]\n",
      "2024-11-25 13:16:40.652456: Epoch time: 132.28 s\n",
      "2024-11-25 13:16:41.658682: \n",
      "2024-11-25 13:16:41.664683: Epoch 292\n",
      "2024-11-25 13:16:41.668684: Current learning rate: 0.00454\n",
      "2024-11-25 13:18:52.211196: train_loss -0.7748\n",
      "2024-11-25 13:18:52.220198: val_loss -0.5125\n",
      "2024-11-25 13:18:52.227200: Pseudo dice [0.7358]\n",
      "2024-11-25 13:18:52.232200: Epoch time: 130.55 s\n",
      "2024-11-25 13:18:53.252255: \n",
      "2024-11-25 13:18:53.259257: Epoch 293\n",
      "2024-11-25 13:18:53.263257: Current learning rate: 0.00452\n",
      "2024-11-25 13:21:03.772772: train_loss -0.7814\n",
      "2024-11-25 13:21:03.782774: val_loss -0.4138\n",
      "2024-11-25 13:21:03.788776: Pseudo dice [0.7133]\n",
      "2024-11-25 13:21:03.793777: Epoch time: 130.52 s\n",
      "2024-11-25 13:21:04.806005: \n",
      "2024-11-25 13:21:04.812006: Epoch 294\n",
      "2024-11-25 13:21:04.817007: Current learning rate: 0.0045\n",
      "2024-11-25 13:23:15.329915: train_loss -0.7438\n",
      "2024-11-25 13:23:15.343918: val_loss -0.4654\n",
      "2024-11-25 13:23:15.347919: Pseudo dice [0.7051]\n",
      "2024-11-25 13:23:15.352920: Epoch time: 130.52 s\n",
      "2024-11-25 13:23:16.368149: \n",
      "2024-11-25 13:23:16.375151: Epoch 295\n",
      "2024-11-25 13:23:16.378151: Current learning rate: 0.00448\n",
      "2024-11-25 13:25:26.889496: train_loss -0.7495\n",
      "2024-11-25 13:25:26.899498: val_loss -0.4284\n",
      "2024-11-25 13:25:26.904499: Pseudo dice [0.6899]\n",
      "2024-11-25 13:25:26.909500: Epoch time: 130.52 s\n",
      "2024-11-25 13:25:27.943733: \n",
      "2024-11-25 13:25:27.949734: Epoch 296\n",
      "2024-11-25 13:25:27.954737: Current learning rate: 0.00446\n",
      "2024-11-25 13:27:38.208884: train_loss -0.7558\n",
      "2024-11-25 13:27:38.221887: val_loss -0.4093\n",
      "2024-11-25 13:27:38.229888: Pseudo dice [0.7169]\n",
      "2024-11-25 13:27:38.235890: Epoch time: 130.27 s\n",
      "2024-11-25 13:27:39.273124: \n",
      "2024-11-25 13:27:39.280125: Epoch 297\n",
      "2024-11-25 13:27:39.285127: Current learning rate: 0.00444\n",
      "2024-11-25 13:29:49.275303: train_loss -0.7645\n",
      "2024-11-25 13:29:49.284305: val_loss -0.4251\n",
      "2024-11-25 13:29:49.293307: Pseudo dice [0.6842]\n",
      "2024-11-25 13:29:49.297308: Epoch time: 130.0 s\n",
      "2024-11-25 13:29:50.301827: \n",
      "2024-11-25 13:29:50.307827: Epoch 298\n",
      "2024-11-25 13:29:50.311828: Current learning rate: 0.00442\n",
      "2024-11-25 13:32:00.367714: train_loss -0.752\n",
      "2024-11-25 13:32:00.381717: val_loss -0.5345\n",
      "2024-11-25 13:32:00.387719: Pseudo dice [0.7264]\n",
      "2024-11-25 13:32:00.392720: Epoch time: 130.07 s\n",
      "2024-11-25 13:32:01.403947: \n",
      "2024-11-25 13:32:01.410949: Epoch 299\n",
      "2024-11-25 13:32:01.414950: Current learning rate: 0.0044\n",
      "2024-11-25 13:34:19.353186: train_loss -0.785\n",
      "2024-11-25 13:34:19.364189: val_loss -0.3849\n",
      "2024-11-25 13:34:19.372190: Pseudo dice [0.6617]\n",
      "2024-11-25 13:34:19.378192: Epoch time: 137.95 s\n",
      "2024-11-25 13:34:20.707675: \n",
      "2024-11-25 13:34:20.715677: Epoch 300\n",
      "2024-11-25 13:34:20.720678: Current learning rate: 0.00438\n",
      "2024-11-25 13:36:34.411355: train_loss -0.7879\n",
      "2024-11-25 13:36:34.477623: val_loss -0.3028\n",
      "2024-11-25 13:36:34.488626: Pseudo dice [0.6554]\n",
      "2024-11-25 13:36:34.492628: Epoch time: 133.7 s\n",
      "2024-11-25 13:36:35.501857: \n",
      "2024-11-25 13:36:35.508857: Epoch 301\n",
      "2024-11-25 13:36:35.512857: Current learning rate: 0.00436\n",
      "2024-11-25 13:38:45.993745: train_loss -0.7766\n",
      "2024-11-25 13:38:46.008748: val_loss -0.5509\n",
      "2024-11-25 13:38:46.017749: Pseudo dice [0.7529]\n",
      "2024-11-25 13:38:46.024753: Epoch time: 130.49 s\n",
      "2024-11-25 13:38:47.070987: \n",
      "2024-11-25 13:38:47.077988: Epoch 302\n",
      "2024-11-25 13:38:47.082989: Current learning rate: 0.00434\n",
      "2024-11-25 13:40:57.469306: train_loss -0.7833\n",
      "2024-11-25 13:40:57.481308: val_loss -0.3707\n",
      "2024-11-25 13:40:57.490310: Pseudo dice [0.6633]\n",
      "2024-11-25 13:40:57.497313: Epoch time: 130.4 s\n",
      "2024-11-25 13:40:58.536547: \n",
      "2024-11-25 13:40:58.543548: Epoch 303\n",
      "2024-11-25 13:40:58.548550: Current learning rate: 0.00432\n",
      "2024-11-25 13:43:09.125024: train_loss -0.7785\n",
      "2024-11-25 13:43:09.136027: val_loss -0.4713\n",
      "2024-11-25 13:43:09.143027: Pseudo dice [0.7371]\n",
      "2024-11-25 13:43:09.149030: Epoch time: 130.59 s\n",
      "2024-11-25 13:43:10.199266: \n",
      "2024-11-25 13:43:10.206267: Epoch 304\n",
      "2024-11-25 13:43:10.210268: Current learning rate: 0.0043\n",
      "2024-11-25 13:45:20.635304: train_loss -0.8083\n",
      "2024-11-25 13:45:20.644306: val_loss -0.4408\n",
      "2024-11-25 13:45:20.650307: Pseudo dice [0.713]\n",
      "2024-11-25 13:45:20.655309: Epoch time: 130.44 s\n",
      "2024-11-25 13:45:21.672538: \n",
      "2024-11-25 13:45:21.679540: Epoch 305\n",
      "2024-11-25 13:45:21.683541: Current learning rate: 0.00429\n",
      "2024-11-25 13:47:32.127455: train_loss -0.7658\n",
      "2024-11-25 13:47:32.143458: val_loss -0.3593\n",
      "2024-11-25 13:47:32.152461: Pseudo dice [0.6608]\n",
      "2024-11-25 13:47:32.157461: Epoch time: 130.46 s\n",
      "2024-11-25 13:47:33.174690: \n",
      "2024-11-25 13:47:33.180692: Epoch 306\n",
      "2024-11-25 13:47:33.184692: Current learning rate: 0.00427\n",
      "2024-11-25 13:49:43.725569: train_loss -0.764\n",
      "2024-11-25 13:49:43.741573: val_loss -0.4834\n",
      "2024-11-25 13:49:43.750575: Pseudo dice [0.7185]\n",
      "2024-11-25 13:49:43.757578: Epoch time: 130.55 s\n",
      "2024-11-25 13:49:44.803812: \n",
      "2024-11-25 13:49:44.810814: Epoch 307\n",
      "2024-11-25 13:49:44.814816: Current learning rate: 0.00425\n",
      "2024-11-25 13:51:55.229438: train_loss -0.7912\n",
      "2024-11-25 13:51:55.241441: val_loss -0.4112\n",
      "2024-11-25 13:51:55.250443: Pseudo dice [0.6865]\n",
      "2024-11-25 13:51:55.257445: Epoch time: 130.43 s\n",
      "2024-11-25 13:51:56.318685: \n",
      "2024-11-25 13:51:56.326686: Epoch 308\n",
      "2024-11-25 13:51:56.331687: Current learning rate: 0.00423\n",
      "2024-11-25 13:54:06.968065: train_loss -0.8105\n",
      "2024-11-25 13:54:06.984066: val_loss -0.4638\n",
      "2024-11-25 13:54:06.990069: Pseudo dice [0.7417]\n",
      "2024-11-25 13:54:06.997070: Epoch time: 130.65 s\n",
      "2024-11-25 13:54:08.074605: \n",
      "2024-11-25 13:54:08.081606: Epoch 309\n",
      "2024-11-25 13:54:08.086607: Current learning rate: 0.00421\n",
      "2024-11-25 13:56:18.596646: train_loss -0.8172\n",
      "2024-11-25 13:56:18.604647: val_loss -0.3866\n",
      "2024-11-25 13:56:18.613650: Pseudo dice [0.7038]\n",
      "2024-11-25 13:56:18.618651: Epoch time: 130.52 s\n",
      "2024-11-25 13:56:19.631880: \n",
      "2024-11-25 13:56:19.638880: Epoch 310\n",
      "2024-11-25 13:56:19.642881: Current learning rate: 0.00419\n",
      "2024-11-25 13:58:29.622805: train_loss -0.811\n",
      "2024-11-25 13:58:29.632806: val_loss -0.4136\n",
      "2024-11-25 13:58:29.639808: Pseudo dice [0.7017]\n",
      "2024-11-25 13:58:29.644810: Epoch time: 129.99 s\n",
      "2024-11-25 13:58:30.825075: \n",
      "2024-11-25 13:58:30.831076: Epoch 311\n",
      "2024-11-25 13:58:30.835077: Current learning rate: 0.00417\n",
      "2024-11-25 14:00:40.711522: train_loss -0.8169\n",
      "2024-11-25 14:00:40.724524: val_loss -0.5306\n",
      "2024-11-25 14:00:40.734526: Pseudo dice [0.7635]\n",
      "2024-11-25 14:00:40.739528: Epoch time: 129.89 s\n",
      "2024-11-25 14:00:40.744529: Yayy! New best EMA pseudo Dice: 0.7076\n",
      "2024-11-25 14:00:41.980483: \n",
      "2024-11-25 14:00:41.986485: Epoch 312\n",
      "2024-11-25 14:00:41.990485: Current learning rate: 0.00415\n",
      "2024-11-25 14:02:52.124133: train_loss -0.8058\n",
      "2024-11-25 14:02:52.138137: val_loss -0.3632\n",
      "2024-11-25 14:02:52.143137: Pseudo dice [0.7028]\n",
      "2024-11-25 14:02:52.148138: Epoch time: 130.15 s\n",
      "2024-11-25 14:02:53.159366: \n",
      "2024-11-25 14:02:53.167368: Epoch 313\n",
      "2024-11-25 14:02:53.172369: Current learning rate: 0.00413\n",
      "2024-11-25 14:05:03.470304: train_loss -0.793\n",
      "2024-11-25 14:05:03.480306: val_loss -0.3556\n",
      "2024-11-25 14:05:03.488308: Pseudo dice [0.6597]\n",
      "2024-11-25 14:05:03.495309: Epoch time: 130.31 s\n",
      "2024-11-25 14:05:04.511537: \n",
      "2024-11-25 14:05:04.517539: Epoch 314\n",
      "2024-11-25 14:05:04.521584: Current learning rate: 0.00411\n",
      "2024-11-25 14:07:15.747273: train_loss -0.7588\n",
      "2024-11-25 14:07:15.758277: val_loss -0.3198\n",
      "2024-11-25 14:07:15.764277: Pseudo dice [0.6484]\n",
      "2024-11-25 14:07:15.769278: Epoch time: 131.24 s\n",
      "2024-11-25 14:07:16.790508: \n",
      "2024-11-25 14:07:16.796510: Epoch 315\n",
      "2024-11-25 14:07:16.801511: Current learning rate: 0.00409\n",
      "2024-11-25 14:09:28.084260: train_loss -0.7773\n",
      "2024-11-25 14:09:28.094263: val_loss -0.3932\n",
      "2024-11-25 14:09:28.099264: Pseudo dice [0.6725]\n",
      "2024-11-25 14:09:28.104265: Epoch time: 131.29 s\n",
      "2024-11-25 14:09:29.128809: \n",
      "2024-11-25 14:09:29.135810: Epoch 316\n",
      "2024-11-25 14:09:29.140811: Current learning rate: 0.00407\n",
      "2024-11-25 14:11:40.506979: train_loss -0.7712\n",
      "2024-11-25 14:11:40.521982: val_loss -0.3124\n",
      "2024-11-25 14:11:40.526984: Pseudo dice [0.6559]\n",
      "2024-11-25 14:11:40.533985: Epoch time: 131.38 s\n",
      "2024-11-25 14:11:41.716251: \n",
      "2024-11-25 14:11:41.723252: Epoch 317\n",
      "2024-11-25 14:11:41.729253: Current learning rate: 0.00405\n",
      "2024-11-25 14:13:51.600145: train_loss -0.7878\n",
      "2024-11-25 14:13:51.611148: val_loss -0.4029\n",
      "2024-11-25 14:13:51.616149: Pseudo dice [0.6413]\n",
      "2024-11-25 14:13:51.621150: Epoch time: 129.88 s\n",
      "2024-11-25 14:13:52.636379: \n",
      "2024-11-25 14:13:52.643380: Epoch 318\n",
      "2024-11-25 14:13:52.647381: Current learning rate: 0.00403\n",
      "2024-11-25 14:16:04.198470: train_loss -0.7936\n",
      "2024-11-25 14:16:04.208472: val_loss -0.4457\n",
      "2024-11-25 14:16:04.217474: Pseudo dice [0.7065]\n",
      "2024-11-25 14:16:04.224475: Epoch time: 131.56 s\n",
      "2024-11-25 14:16:05.265710: \n",
      "2024-11-25 14:16:05.273712: Epoch 319\n",
      "2024-11-25 14:16:05.278713: Current learning rate: 0.00401\n",
      "2024-11-25 14:18:17.648405: train_loss -0.8025\n",
      "2024-11-25 14:18:17.657407: val_loss -0.1384\n",
      "2024-11-25 14:18:17.662408: Pseudo dice [0.5491]\n",
      "2024-11-25 14:18:17.667411: Epoch time: 132.38 s\n",
      "2024-11-25 14:18:18.677638: \n",
      "2024-11-25 14:18:18.685638: Epoch 320\n",
      "2024-11-25 14:18:18.691640: Current learning rate: 0.00399\n",
      "2024-11-25 14:20:29.330137: train_loss -0.7789\n",
      "2024-11-25 14:20:29.341139: val_loss -0.4814\n",
      "2024-11-25 14:20:29.348141: Pseudo dice [0.7095]\n",
      "2024-11-25 14:20:29.353142: Epoch time: 130.65 s\n",
      "2024-11-25 14:20:30.360369: \n",
      "2024-11-25 14:20:30.367370: Epoch 321\n",
      "2024-11-25 14:20:30.375046: Current learning rate: 0.00397\n",
      "2024-11-25 14:22:41.522892: train_loss -0.8019\n",
      "2024-11-25 14:22:41.535894: val_loss -0.372\n",
      "2024-11-25 14:22:41.544897: Pseudo dice [0.6824]\n",
      "2024-11-25 14:22:41.551898: Epoch time: 131.16 s\n",
      "2024-11-25 14:22:42.584131: \n",
      "2024-11-25 14:22:42.592133: Epoch 322\n",
      "2024-11-25 14:22:42.597133: Current learning rate: 0.00395\n",
      "2024-11-25 14:24:58.401258: train_loss -0.7959\n",
      "2024-11-25 14:24:58.411259: val_loss -0.3505\n",
      "2024-11-25 14:24:58.421259: Pseudo dice [0.6776]\n",
      "2024-11-25 14:24:58.431259: Epoch time: 135.82 s\n",
      "2024-11-25 14:24:59.451166: \n",
      "2024-11-25 14:24:59.457820: Epoch 323\n",
      "2024-11-25 14:24:59.457820: Current learning rate: 0.00393\n",
      "2024-11-25 14:27:11.264875: train_loss -0.7979\n",
      "2024-11-25 14:27:11.274877: val_loss -0.4972\n",
      "2024-11-25 14:27:11.288563: Pseudo dice [0.708]\n",
      "2024-11-25 14:27:11.298562: Epoch time: 131.81 s\n",
      "2024-11-25 14:27:12.331509: \n",
      "2024-11-25 14:27:12.338449: Epoch 324\n",
      "2024-11-25 14:27:12.340884: Current learning rate: 0.00391\n",
      "2024-11-25 14:29:24.325597: train_loss -0.7894\n",
      "2024-11-25 14:29:24.339055: val_loss -0.5115\n",
      "2024-11-25 14:29:24.347055: Pseudo dice [0.7477]\n",
      "2024-11-25 14:29:24.353056: Epoch time: 132.0 s\n",
      "2024-11-25 14:29:25.368393: \n",
      "2024-11-25 14:29:25.378393: Epoch 325\n",
      "2024-11-25 14:29:25.378393: Current learning rate: 0.00389\n",
      "2024-11-25 14:31:37.178601: train_loss -0.8033\n",
      "2024-11-25 14:31:37.188602: val_loss -0.4262\n",
      "2024-11-25 14:31:37.198601: Pseudo dice [0.6977]\n",
      "2024-11-25 14:31:37.198601: Epoch time: 131.81 s\n",
      "2024-11-25 14:31:38.228618: \n",
      "2024-11-25 14:31:38.228618: Epoch 326\n",
      "2024-11-25 14:31:38.238617: Current learning rate: 0.00387\n",
      "2024-11-25 14:33:49.982241: train_loss -0.8118\n",
      "2024-11-25 14:33:49.992241: val_loss -0.391\n",
      "2024-11-25 14:33:50.002241: Pseudo dice [0.6543]\n",
      "2024-11-25 14:33:50.012242: Epoch time: 131.75 s\n",
      "2024-11-25 14:33:51.042300: \n",
      "2024-11-25 14:33:51.052300: Epoch 327\n",
      "2024-11-25 14:33:51.052300: Current learning rate: 0.00385\n",
      "2024-11-25 14:36:02.785904: train_loss -0.8068\n",
      "2024-11-25 14:36:02.795904: val_loss -0.5128\n",
      "2024-11-25 14:36:02.805905: Pseudo dice [0.6986]\n",
      "2024-11-25 14:36:02.815905: Epoch time: 131.74 s\n",
      "2024-11-25 14:36:03.835793: \n",
      "2024-11-25 14:36:03.845794: Epoch 328\n",
      "2024-11-25 14:36:03.845794: Current learning rate: 0.00383\n",
      "2024-11-25 14:38:15.802692: train_loss -0.8235\n",
      "2024-11-25 14:38:15.812691: val_loss -0.4648\n",
      "2024-11-25 14:38:15.812691: Pseudo dice [0.6615]\n",
      "2024-11-25 14:38:15.822691: Epoch time: 131.96 s\n",
      "2024-11-25 14:38:16.842686: \n",
      "2024-11-25 14:38:16.842686: Epoch 329\n",
      "2024-11-25 14:38:16.852687: Current learning rate: 0.00381\n",
      "2024-11-25 14:40:28.569562: train_loss -0.815\n",
      "2024-11-25 14:40:28.579562: val_loss -0.5295\n",
      "2024-11-25 14:40:28.589563: Pseudo dice [0.7327]\n",
      "2024-11-25 14:40:28.589563: Epoch time: 131.73 s\n",
      "2024-11-25 14:40:29.619709: \n",
      "2024-11-25 14:40:29.619709: Epoch 330\n",
      "2024-11-25 14:40:29.629709: Current learning rate: 0.00379\n",
      "2024-11-25 14:42:41.323360: train_loss -0.8101\n",
      "2024-11-25 14:42:41.333252: val_loss -0.3407\n",
      "2024-11-25 14:42:41.343251: Pseudo dice [0.6279]\n",
      "2024-11-25 14:42:41.353251: Epoch time: 131.7 s\n",
      "2024-11-25 14:42:42.383088: \n",
      "2024-11-25 14:42:42.390102: Epoch 331\n",
      "2024-11-25 14:42:42.394055: Current learning rate: 0.00377\n",
      "2024-11-25 14:44:54.113427: train_loss -0.7993\n",
      "2024-11-25 14:44:54.123469: val_loss -0.4904\n",
      "2024-11-25 14:44:54.133468: Pseudo dice [0.7091]\n",
      "2024-11-25 14:44:54.143469: Epoch time: 131.73 s\n",
      "2024-11-25 14:44:55.340236: \n",
      "2024-11-25 14:44:55.346672: Epoch 332\n",
      "2024-11-25 14:44:55.356699: Current learning rate: 0.00375\n",
      "2024-11-25 14:47:07.073656: train_loss -0.8021\n",
      "2024-11-25 14:47:07.083658: val_loss -0.5826\n",
      "2024-11-25 14:47:07.093779: Pseudo dice [0.7521]\n",
      "2024-11-25 14:47:07.093779: Epoch time: 131.73 s\n",
      "2024-11-25 14:47:08.128957: \n",
      "2024-11-25 14:47:08.135040: Epoch 333\n",
      "2024-11-25 14:47:08.139120: Current learning rate: 0.00373\n",
      "2024-11-25 14:49:19.840569: train_loss -0.7966\n",
      "2024-11-25 14:49:19.850569: val_loss -0.5263\n",
      "2024-11-25 14:49:19.850569: Pseudo dice [0.6937]\n",
      "2024-11-25 14:49:19.860569: Epoch time: 131.71 s\n",
      "2024-11-25 14:49:20.987270: \n",
      "2024-11-25 14:49:20.997271: Epoch 334\n",
      "2024-11-25 14:49:20.997271: Current learning rate: 0.00371\n",
      "2024-11-25 14:51:32.717481: train_loss -0.7911\n",
      "2024-11-25 14:51:32.737482: val_loss -0.3321\n",
      "2024-11-25 14:51:32.737482: Pseudo dice [0.6869]\n",
      "2024-11-25 14:51:32.747482: Epoch time: 131.73 s\n",
      "2024-11-25 14:51:33.790889: \n",
      "2024-11-25 14:51:33.800889: Epoch 335\n",
      "2024-11-25 14:51:33.810889: Current learning rate: 0.00369\n",
      "2024-11-25 14:53:45.594394: train_loss -0.8036\n",
      "2024-11-25 14:53:45.611044: val_loss -0.4443\n",
      "2024-11-25 14:53:45.621044: Pseudo dice [0.6999]\n",
      "2024-11-25 14:53:45.621044: Epoch time: 131.8 s\n",
      "2024-11-25 14:53:46.661280: \n",
      "2024-11-25 14:53:46.671280: Epoch 336\n",
      "2024-11-25 14:53:46.671280: Current learning rate: 0.00367\n",
      "2024-11-25 14:55:58.574643: train_loss -0.7899\n",
      "2024-11-25 14:55:58.584643: val_loss -0.4084\n",
      "2024-11-25 14:55:58.584643: Pseudo dice [0.6961]\n",
      "2024-11-25 14:55:58.594643: Epoch time: 131.91 s\n",
      "2024-11-25 14:55:59.641286: \n",
      "2024-11-25 14:55:59.641286: Epoch 337\n",
      "2024-11-25 14:55:59.651286: Current learning rate: 0.00365\n",
      "2024-11-25 14:58:11.364889: train_loss -0.739\n",
      "2024-11-25 14:58:11.374890: val_loss -0.4163\n",
      "2024-11-25 14:58:11.378291: Pseudo dice [0.6827]\n",
      "2024-11-25 14:58:11.388300: Epoch time: 131.73 s\n",
      "2024-11-25 14:58:12.421583: \n",
      "2024-11-25 14:58:12.431585: Epoch 338\n",
      "2024-11-25 14:58:12.431585: Current learning rate: 0.00363\n",
      "2024-11-25 15:00:24.218429: train_loss -0.7579\n",
      "2024-11-25 15:00:24.228429: val_loss -0.5151\n",
      "2024-11-25 15:00:24.241961: Pseudo dice [0.7484]\n",
      "2024-11-25 15:00:24.251980: Epoch time: 131.8 s\n",
      "2024-11-25 15:00:25.475082: \n",
      "2024-11-25 15:00:25.476481: Epoch 339\n",
      "2024-11-25 15:00:25.486489: Current learning rate: 0.00361\n",
      "2024-11-25 15:02:37.275362: train_loss -0.8051\n",
      "2024-11-25 15:02:37.288766: val_loss -0.5351\n",
      "2024-11-25 15:02:37.298802: Pseudo dice [0.7579]\n",
      "2024-11-25 15:02:37.298802: Epoch time: 131.81 s\n",
      "2024-11-25 15:02:38.348610: \n",
      "2024-11-25 15:02:38.358610: Epoch 340\n",
      "2024-11-25 15:02:38.368610: Current learning rate: 0.00359\n",
      "2024-11-25 15:04:50.028959: train_loss -0.8114\n",
      "2024-11-25 15:04:50.038959: val_loss -0.4165\n",
      "2024-11-25 15:04:50.048959: Pseudo dice [0.6887]\n",
      "2024-11-25 15:04:50.048959: Epoch time: 131.68 s\n",
      "2024-11-25 15:04:51.098944: \n",
      "2024-11-25 15:04:51.098944: Epoch 341\n",
      "2024-11-25 15:04:51.108943: Current learning rate: 0.00357\n",
      "2024-11-25 15:07:02.782522: train_loss -0.8184\n",
      "2024-11-25 15:07:02.792522: val_loss -0.3993\n",
      "2024-11-25 15:07:02.799288: Pseudo dice [0.7132]\n",
      "2024-11-25 15:07:02.799288: Epoch time: 131.68 s\n",
      "2024-11-25 15:07:03.835829: \n",
      "2024-11-25 15:07:03.845828: Epoch 342\n",
      "2024-11-25 15:07:03.845828: Current learning rate: 0.00355\n",
      "2024-11-25 15:09:15.522743: train_loss -0.8207\n",
      "2024-11-25 15:09:15.532745: val_loss -0.4561\n",
      "2024-11-25 15:09:15.542746: Pseudo dice [0.7102]\n",
      "2024-11-25 15:09:15.552744: Epoch time: 131.69 s\n",
      "2024-11-25 15:09:16.612671: \n",
      "2024-11-25 15:09:16.612671: Epoch 343\n",
      "2024-11-25 15:09:16.622696: Current learning rate: 0.00353\n",
      "2024-11-25 15:11:28.456381: train_loss -0.7997\n",
      "2024-11-25 15:11:28.476380: val_loss -0.3219\n",
      "2024-11-25 15:11:28.486380: Pseudo dice [0.6574]\n",
      "2024-11-25 15:11:28.486380: Epoch time: 131.84 s\n",
      "2024-11-25 15:11:29.543038: \n",
      "2024-11-25 15:11:29.543038: Epoch 344\n",
      "2024-11-25 15:11:29.553039: Current learning rate: 0.00351\n",
      "2024-11-25 15:13:41.209937: train_loss -0.8119\n",
      "2024-11-25 15:13:41.229938: val_loss -0.4903\n",
      "2024-11-25 15:13:41.239938: Pseudo dice [0.7391]\n",
      "2024-11-25 15:13:41.239938: Epoch time: 131.68 s\n",
      "2024-11-25 15:13:42.292397: \n",
      "2024-11-25 15:13:42.299397: Epoch 345\n",
      "2024-11-25 15:13:42.303398: Current learning rate: 0.00349\n",
      "2024-11-25 15:15:53.943524: train_loss -0.8062\n",
      "2024-11-25 15:15:53.953524: val_loss -0.3588\n",
      "2024-11-25 15:15:53.953524: Pseudo dice [0.6807]\n",
      "2024-11-25 15:15:53.963524: Epoch time: 131.65 s\n",
      "2024-11-25 15:15:55.186434: \n",
      "2024-11-25 15:15:55.196434: Epoch 346\n",
      "2024-11-25 15:15:55.196434: Current learning rate: 0.00346\n",
      "2024-11-25 15:18:06.856235: train_loss -0.8155\n",
      "2024-11-25 15:18:06.865238: val_loss -0.4209\n",
      "2024-11-25 15:18:06.867237: Pseudo dice [0.7024]\n",
      "2024-11-25 15:18:06.876242: Epoch time: 131.67 s\n",
      "2024-11-25 15:18:07.917087: \n",
      "2024-11-25 15:18:07.927087: Epoch 347\n",
      "2024-11-25 15:18:07.927087: Current learning rate: 0.00344\n",
      "2024-11-25 15:20:19.724069: train_loss -0.8097\n",
      "2024-11-25 15:20:19.744069: val_loss -0.3471\n",
      "2024-11-25 15:20:19.754071: Pseudo dice [0.687]\n",
      "2024-11-25 15:20:19.764070: Epoch time: 131.81 s\n",
      "2024-11-25 15:20:20.803983: \n",
      "2024-11-25 15:20:20.813983: Epoch 348\n",
      "2024-11-25 15:20:20.813983: Current learning rate: 0.00342\n",
      "2024-11-25 15:22:32.491073: train_loss -0.83\n",
      "2024-11-25 15:22:32.511073: val_loss -0.4883\n",
      "2024-11-25 15:22:32.511073: Pseudo dice [0.7265]\n",
      "2024-11-25 15:22:32.521073: Epoch time: 131.69 s\n",
      "2024-11-25 15:22:33.564224: \n",
      "2024-11-25 15:22:33.574224: Epoch 349\n",
      "2024-11-25 15:22:33.574224: Current learning rate: 0.0034\n",
      "2024-11-25 15:24:45.274410: train_loss -0.8059\n",
      "2024-11-25 15:24:45.284452: val_loss -0.4125\n",
      "2024-11-25 15:24:45.291270: Pseudo dice [0.6942]\n",
      "2024-11-25 15:24:45.301306: Epoch time: 131.71 s\n",
      "2024-11-25 15:24:46.591127: \n",
      "2024-11-25 15:24:46.601126: Epoch 350\n",
      "2024-11-25 15:24:46.607718: Current learning rate: 0.00338\n",
      "2024-11-25 15:26:58.308031: train_loss -0.7952\n",
      "2024-11-25 15:26:58.318031: val_loss -0.3539\n",
      "2024-11-25 15:26:58.328032: Pseudo dice [0.6589]\n",
      "2024-11-25 15:26:58.328032: Epoch time: 131.72 s\n",
      "2024-11-25 15:26:59.378039: \n",
      "2024-11-25 15:26:59.388039: Epoch 351\n",
      "2024-11-25 15:26:59.388039: Current learning rate: 0.00336\n",
      "2024-11-25 15:29:11.228271: train_loss -0.7805\n",
      "2024-11-25 15:29:11.238272: val_loss -0.3268\n",
      "2024-11-25 15:29:11.248272: Pseudo dice [0.68]\n",
      "2024-11-25 15:29:11.251679: Epoch time: 131.85 s\n",
      "2024-11-25 15:29:12.495026: \n",
      "2024-11-25 15:29:12.505027: Epoch 352\n",
      "2024-11-25 15:29:12.505027: Current learning rate: 0.00334\n",
      "2024-11-25 15:31:24.225200: train_loss -0.8129\n",
      "2024-11-25 15:31:24.235201: val_loss -0.4032\n",
      "2024-11-25 15:31:24.244982: Pseudo dice [0.7013]\n",
      "2024-11-25 15:31:24.250975: Epoch time: 131.73 s\n",
      "2024-11-25 15:31:25.281814: \n",
      "2024-11-25 15:31:25.291813: Epoch 353\n",
      "2024-11-25 15:31:25.298440: Current learning rate: 0.00332\n",
      "2024-11-25 15:33:36.307106: train_loss -0.7937\n",
      "2024-11-25 15:33:36.317970: val_loss -0.4074\n",
      "2024-11-25 15:33:36.325970: Pseudo dice [0.6985]\n",
      "2024-11-25 15:33:36.331391: Epoch time: 131.03 s\n",
      "2024-11-25 15:33:37.378599: \n",
      "2024-11-25 15:33:37.384291: Epoch 354\n",
      "2024-11-25 15:33:37.388292: Current learning rate: 0.0033\n",
      "2024-11-25 15:35:47.342644: train_loss -0.8122\n",
      "2024-11-25 15:35:47.356047: val_loss -0.309\n",
      "2024-11-25 15:35:47.360401: Pseudo dice [0.6608]\n",
      "2024-11-25 15:35:47.365420: Epoch time: 129.97 s\n",
      "2024-11-25 15:35:48.412780: \n",
      "2024-11-25 15:35:48.418781: Epoch 355\n",
      "2024-11-25 15:35:48.422782: Current learning rate: 0.00328\n",
      "2024-11-25 15:37:58.441414: train_loss -0.7905\n",
      "2024-11-25 15:37:58.452631: val_loss -0.3644\n",
      "2024-11-25 15:37:58.460536: Pseudo dice [0.6769]\n",
      "2024-11-25 15:37:58.468538: Epoch time: 130.03 s\n",
      "2024-11-25 15:37:59.507237: \n",
      "2024-11-25 15:37:59.513393: Epoch 356\n",
      "2024-11-25 15:37:59.517394: Current learning rate: 0.00326\n",
      "2024-11-25 15:40:09.545816: train_loss -0.7868\n",
      "2024-11-25 15:40:09.565785: val_loss -0.2804\n",
      "2024-11-25 15:40:09.574582: Pseudo dice [0.6315]\n",
      "2024-11-25 15:40:09.579582: Epoch time: 130.04 s\n",
      "2024-11-25 15:40:10.611348: \n",
      "2024-11-25 15:40:10.617349: Epoch 357\n",
      "2024-11-25 15:40:10.621954: Current learning rate: 0.00324\n",
      "2024-11-25 15:42:20.601610: train_loss -0.8042\n",
      "2024-11-25 15:42:20.611632: val_loss -0.4596\n",
      "2024-11-25 15:42:20.618933: Pseudo dice [0.7088]\n",
      "2024-11-25 15:42:20.622934: Epoch time: 129.99 s\n",
      "2024-11-25 15:42:21.663981: \n",
      "2024-11-25 15:42:21.670518: Epoch 358\n",
      "2024-11-25 15:42:21.675519: Current learning rate: 0.00322\n",
      "2024-11-25 15:44:31.625151: train_loss -0.814\n",
      "2024-11-25 15:44:31.638380: val_loss -0.4475\n",
      "2024-11-25 15:44:31.647184: Pseudo dice [0.7083]\n",
      "2024-11-25 15:44:31.653717: Epoch time: 129.96 s\n",
      "2024-11-25 15:44:32.879413: \n",
      "2024-11-25 15:44:32.886180: Epoch 359\n",
      "2024-11-25 15:44:32.890181: Current learning rate: 0.0032\n",
      "2024-11-25 15:46:42.841620: train_loss -0.8182\n",
      "2024-11-25 15:46:42.850724: val_loss -0.3156\n",
      "2024-11-25 15:46:42.856726: Pseudo dice [0.6218]\n",
      "2024-11-25 15:46:42.861909: Epoch time: 129.96 s\n",
      "2024-11-25 15:46:43.922366: \n",
      "2024-11-25 15:46:43.929059: Epoch 360\n",
      "2024-11-25 15:46:43.933059: Current learning rate: 0.00318\n",
      "2024-11-25 15:48:53.912888: train_loss -0.8351\n",
      "2024-11-25 15:48:53.928200: val_loss -0.4577\n",
      "2024-11-25 15:48:53.934201: Pseudo dice [0.7003]\n",
      "2024-11-25 15:48:53.939202: Epoch time: 129.99 s\n",
      "2024-11-25 15:48:54.990263: \n",
      "2024-11-25 15:48:54.996682: Epoch 361\n",
      "2024-11-25 15:48:55.001684: Current learning rate: 0.00316\n",
      "2024-11-25 15:51:04.934038: train_loss -0.8249\n",
      "2024-11-25 15:51:04.945082: val_loss -0.3077\n",
      "2024-11-25 15:51:04.953086: Pseudo dice [0.636]\n",
      "2024-11-25 15:51:04.960586: Epoch time: 129.94 s\n",
      "2024-11-25 15:51:06.014354: \n",
      "2024-11-25 15:51:06.021263: Epoch 362\n",
      "2024-11-25 15:51:06.024967: Current learning rate: 0.00314\n",
      "2024-11-25 15:53:16.002434: train_loss -0.8285\n",
      "2024-11-25 15:53:16.012458: val_loss -0.3293\n",
      "2024-11-25 15:53:16.021178: Pseudo dice [0.6578]\n",
      "2024-11-25 15:53:16.027179: Epoch time: 129.99 s\n",
      "2024-11-25 15:53:17.071033: \n",
      "2024-11-25 15:53:17.078034: Epoch 363\n",
      "2024-11-25 15:53:17.082035: Current learning rate: 0.00312\n",
      "2024-11-25 15:55:27.044766: train_loss -0.7925\n",
      "2024-11-25 15:55:27.058381: val_loss -0.3794\n",
      "2024-11-25 15:55:27.068112: Pseudo dice [0.6721]\n",
      "2024-11-25 15:55:27.088654: Epoch time: 129.97 s\n",
      "2024-11-25 15:55:28.130767: \n",
      "2024-11-25 15:55:28.137532: Epoch 364\n",
      "2024-11-25 15:55:28.141533: Current learning rate: 0.0031\n",
      "2024-11-25 15:57:38.053897: train_loss -0.8157\n",
      "2024-11-25 15:57:38.063948: val_loss -0.4588\n",
      "2024-11-25 15:57:38.070966: Pseudo dice [0.7236]\n",
      "2024-11-25 15:57:38.077967: Epoch time: 129.92 s\n",
      "2024-11-25 15:57:39.114166: \n",
      "2024-11-25 15:57:39.122187: Epoch 365\n",
      "2024-11-25 15:57:39.128402: Current learning rate: 0.00308\n",
      "2024-11-25 15:59:49.078555: train_loss -0.8076\n",
      "2024-11-25 15:59:49.088559: val_loss -0.3952\n",
      "2024-11-25 15:59:49.093524: Pseudo dice [0.69]\n",
      "2024-11-25 15:59:49.102546: Epoch time: 129.97 s\n",
      "2024-11-25 15:59:50.324712: \n",
      "2024-11-25 15:59:50.331469: Epoch 366\n",
      "2024-11-25 15:59:50.335470: Current learning rate: 0.00306\n",
      "2024-11-25 16:02:00.206750: train_loss -0.8168\n",
      "2024-11-25 16:02:00.216752: val_loss -0.5924\n",
      "2024-11-25 16:02:00.225755: Pseudo dice [0.7468]\n",
      "2024-11-25 16:02:00.230756: Epoch time: 129.88 s\n",
      "2024-11-25 16:02:01.276378: \n",
      "2024-11-25 16:02:01.283380: Epoch 367\n",
      "2024-11-25 16:02:01.287381: Current learning rate: 0.00304\n",
      "2024-11-25 16:04:11.319281: train_loss -0.7912\n",
      "2024-11-25 16:04:11.341043: val_loss -0.515\n",
      "2024-11-25 16:04:11.346043: Pseudo dice [0.7525]\n",
      "2024-11-25 16:04:11.350044: Epoch time: 130.04 s\n",
      "2024-11-25 16:04:12.393057: \n",
      "2024-11-25 16:04:12.400059: Epoch 368\n",
      "2024-11-25 16:04:12.403882: Current learning rate: 0.00302\n",
      "2024-11-25 16:06:22.093909: train_loss -0.8156\n",
      "2024-11-25 16:06:22.107707: val_loss -0.3282\n",
      "2024-11-25 16:06:22.114710: Pseudo dice [0.6988]\n",
      "2024-11-25 16:06:22.121377: Epoch time: 129.7 s\n",
      "2024-11-25 16:06:23.160726: \n",
      "2024-11-25 16:06:23.168289: Epoch 369\n",
      "2024-11-25 16:06:23.172290: Current learning rate: 0.003\n",
      "2024-11-25 16:08:32.928923: train_loss -0.7979\n",
      "2024-11-25 16:08:32.943021: val_loss -0.4702\n",
      "2024-11-25 16:08:32.951867: Pseudo dice [0.7173]\n",
      "2024-11-25 16:08:32.957868: Epoch time: 129.77 s\n",
      "2024-11-25 16:08:33.994838: \n",
      "2024-11-25 16:08:34.001573: Epoch 370\n",
      "2024-11-25 16:08:34.005573: Current learning rate: 0.00297\n",
      "2024-11-25 16:10:43.732973: train_loss -0.823\n",
      "2024-11-25 16:10:43.746800: val_loss -0.4897\n",
      "2024-11-25 16:10:43.753802: Pseudo dice [0.7326]\n",
      "2024-11-25 16:10:43.758803: Epoch time: 129.74 s\n",
      "2024-11-25 16:10:44.800789: \n",
      "2024-11-25 16:10:44.807791: Epoch 371\n",
      "2024-11-25 16:10:44.811873: Current learning rate: 0.00295\n",
      "2024-11-25 16:12:54.724195: train_loss -0.8053\n",
      "2024-11-25 16:12:54.734684: val_loss -0.2784\n",
      "2024-11-25 16:12:54.740801: Pseudo dice [0.5921]\n",
      "2024-11-25 16:12:54.745541: Epoch time: 129.92 s\n",
      "2024-11-25 16:12:55.788769: \n",
      "2024-11-25 16:12:55.794485: Epoch 372\n",
      "2024-11-25 16:12:55.798486: Current learning rate: 0.00293\n",
      "2024-11-25 16:15:05.697757: train_loss -0.8245\n",
      "2024-11-25 16:15:05.709053: val_loss -0.49\n",
      "2024-11-25 16:15:05.714053: Pseudo dice [0.7393]\n",
      "2024-11-25 16:15:05.720992: Epoch time: 129.91 s\n",
      "2024-11-25 16:15:06.938557: \n",
      "2024-11-25 16:15:06.946903: Epoch 373\n",
      "2024-11-25 16:15:06.950904: Current learning rate: 0.00291\n",
      "2024-11-25 16:17:16.765243: train_loss -0.8353\n",
      "2024-11-25 16:17:16.774718: val_loss -0.3319\n",
      "2024-11-25 16:17:16.782720: Pseudo dice [0.6521]\n",
      "2024-11-25 16:17:16.788841: Epoch time: 129.83 s\n",
      "2024-11-25 16:17:17.824677: \n",
      "2024-11-25 16:17:17.830679: Epoch 374\n",
      "2024-11-25 16:17:17.835668: Current learning rate: 0.00289\n",
      "2024-11-25 16:19:27.752810: train_loss -0.8164\n",
      "2024-11-25 16:19:27.762837: val_loss -0.4641\n",
      "2024-11-25 16:19:27.767093: Pseudo dice [0.7319]\n",
      "2024-11-25 16:19:27.773138: Epoch time: 129.93 s\n",
      "2024-11-25 16:19:28.813832: \n",
      "2024-11-25 16:19:28.821236: Epoch 375\n",
      "2024-11-25 16:19:28.825237: Current learning rate: 0.00287\n",
      "2024-11-25 16:21:38.757819: train_loss -0.8231\n",
      "2024-11-25 16:21:38.767820: val_loss -0.4578\n",
      "2024-11-25 16:21:38.777820: Pseudo dice [0.7331]\n",
      "2024-11-25 16:21:38.777820: Epoch time: 129.94 s\n",
      "2024-11-25 16:21:39.821079: \n",
      "2024-11-25 16:21:39.831079: Epoch 376\n",
      "2024-11-25 16:21:39.831079: Current learning rate: 0.00285\n",
      "2024-11-25 16:23:49.611400: train_loss -0.8308\n",
      "2024-11-25 16:23:49.621399: val_loss -0.5143\n",
      "2024-11-25 16:23:49.631400: Pseudo dice [0.7763]\n",
      "2024-11-25 16:23:49.631400: Epoch time: 129.79 s\n",
      "2024-11-25 16:23:50.668280: \n",
      "2024-11-25 16:23:50.678280: Epoch 377\n",
      "2024-11-25 16:23:50.678280: Current learning rate: 0.00283\n",
      "2024-11-25 16:26:00.551659: train_loss -0.8244\n",
      "2024-11-25 16:26:00.561661: val_loss -0.5068\n",
      "2024-11-25 16:26:00.571661: Pseudo dice [0.7331]\n",
      "2024-11-25 16:26:00.571661: Epoch time: 129.88 s\n",
      "2024-11-25 16:26:00.581660: Yayy! New best EMA pseudo Dice: 0.7093\n",
      "2024-11-25 16:26:01.848310: \n",
      "2024-11-25 16:26:01.848310: Epoch 378\n",
      "2024-11-25 16:26:01.858310: Current learning rate: 0.00281\n",
      "2024-11-25 16:28:11.665754: train_loss -0.7988\n",
      "2024-11-25 16:28:11.675756: val_loss -0.454\n",
      "2024-11-25 16:28:11.685755: Pseudo dice [0.7296]\n",
      "2024-11-25 16:28:11.695755: Epoch time: 129.82 s\n",
      "2024-11-25 16:28:11.695755: Yayy! New best EMA pseudo Dice: 0.7113\n",
      "2024-11-25 16:28:12.985773: \n",
      "2024-11-25 16:28:13.005772: Epoch 379\n",
      "2024-11-25 16:28:13.005772: Current learning rate: 0.00279\n",
      "2024-11-25 16:30:22.812753: train_loss -0.8054\n",
      "2024-11-25 16:30:22.822754: val_loss -0.3847\n",
      "2024-11-25 16:30:22.832753: Pseudo dice [0.6818]\n",
      "2024-11-25 16:30:22.842755: Epoch time: 129.83 s\n",
      "2024-11-25 16:30:24.062210: \n",
      "2024-11-25 16:30:24.062210: Epoch 380\n",
      "2024-11-25 16:30:24.072211: Current learning rate: 0.00277\n",
      "2024-11-25 16:32:33.829201: train_loss -0.802\n",
      "2024-11-25 16:32:33.839202: val_loss -0.4015\n",
      "2024-11-25 16:32:33.849201: Pseudo dice [0.6321]\n",
      "2024-11-25 16:32:33.859202: Epoch time: 129.78 s\n",
      "2024-11-25 16:32:34.902468: \n",
      "2024-11-25 16:32:34.912467: Epoch 381\n",
      "2024-11-25 16:32:34.912467: Current learning rate: 0.00275\n",
      "2024-11-25 16:34:44.652763: train_loss -0.7925\n",
      "2024-11-25 16:34:44.662763: val_loss -0.3867\n",
      "2024-11-25 16:34:44.662763: Pseudo dice [0.7015]\n",
      "2024-11-25 16:34:44.672763: Epoch time: 129.75 s\n",
      "2024-11-25 16:34:45.732780: \n",
      "2024-11-25 16:34:45.732780: Epoch 382\n",
      "2024-11-25 16:34:45.742778: Current learning rate: 0.00273\n",
      "2024-11-25 16:36:55.553082: train_loss -0.7995\n",
      "2024-11-25 16:36:55.563082: val_loss -0.4344\n",
      "2024-11-25 16:36:55.563082: Pseudo dice [0.7263]\n",
      "2024-11-25 16:36:55.573083: Epoch time: 129.82 s\n",
      "2024-11-25 16:36:56.633097: \n",
      "2024-11-25 16:36:56.643097: Epoch 383\n",
      "2024-11-25 16:36:56.643097: Current learning rate: 0.00271\n",
      "2024-11-25 16:39:06.480460: train_loss -0.8152\n",
      "2024-11-25 16:39:06.500461: val_loss -0.3326\n",
      "2024-11-25 16:39:06.500461: Pseudo dice [0.6644]\n",
      "2024-11-25 16:39:06.510460: Epoch time: 129.85 s\n",
      "2024-11-25 16:39:07.573820: \n",
      "2024-11-25 16:39:07.573820: Epoch 384\n",
      "2024-11-25 16:39:07.583819: Current learning rate: 0.00268\n",
      "2024-11-25 16:41:17.367028: train_loss -0.8286\n",
      "2024-11-25 16:41:17.377028: val_loss -0.3651\n",
      "2024-11-25 16:41:17.377028: Pseudo dice [0.6789]\n",
      "2024-11-25 16:41:17.387029: Epoch time: 129.79 s\n",
      "2024-11-25 16:41:18.453609: \n",
      "2024-11-25 16:41:18.453609: Epoch 385\n",
      "2024-11-25 16:41:18.463607: Current learning rate: 0.00266\n",
      "2024-11-25 16:43:28.243945: train_loss -0.8233\n",
      "2024-11-25 16:43:28.253945: val_loss -0.4528\n",
      "2024-11-25 16:43:28.263946: Pseudo dice [0.7271]\n",
      "2024-11-25 16:43:28.263946: Epoch time: 129.79 s\n",
      "2024-11-25 16:43:29.327214: \n",
      "2024-11-25 16:43:29.337215: Epoch 386\n",
      "2024-11-25 16:43:29.337215: Current learning rate: 0.00264\n",
      "2024-11-25 16:45:39.121581: train_loss -0.7705\n",
      "2024-11-25 16:45:39.131580: val_loss -0.5208\n",
      "2024-11-25 16:45:39.147275: Pseudo dice [0.7218]\n",
      "2024-11-25 16:45:39.152283: Epoch time: 129.79 s\n",
      "2024-11-25 16:45:40.387489: \n",
      "2024-11-25 16:45:40.397489: Epoch 387\n",
      "2024-11-25 16:45:40.397489: Current learning rate: 0.00262\n",
      "2024-11-25 16:47:50.281162: train_loss -0.7908\n",
      "2024-11-25 16:47:50.281162: val_loss -0.4108\n",
      "2024-11-25 16:47:50.291163: Pseudo dice [0.6703]\n",
      "2024-11-25 16:47:50.301162: Epoch time: 129.88 s\n",
      "2024-11-25 16:47:51.364427: \n",
      "2024-11-25 16:47:51.374427: Epoch 388\n",
      "2024-11-25 16:47:51.374427: Current learning rate: 0.0026\n",
      "2024-11-25 16:50:01.188074: train_loss -0.7336\n",
      "2024-11-25 16:50:01.198075: val_loss -0.5876\n",
      "2024-11-25 16:50:01.198075: Pseudo dice [0.7275]\n",
      "2024-11-25 16:50:01.208074: Epoch time: 129.82 s\n",
      "2024-11-25 16:50:02.265218: \n",
      "2024-11-25 16:50:02.275217: Epoch 389\n",
      "2024-11-25 16:50:02.275217: Current learning rate: 0.00258\n",
      "2024-11-25 16:52:12.129076: train_loss -0.7584\n",
      "2024-11-25 16:52:12.139745: val_loss -0.473\n",
      "2024-11-25 16:52:12.144746: Pseudo dice [0.7122]\n",
      "2024-11-25 16:52:12.152171: Epoch time: 129.86 s\n",
      "2024-11-25 16:52:13.201646: \n",
      "2024-11-25 16:52:13.211638: Epoch 390\n",
      "2024-11-25 16:52:13.211638: Current learning rate: 0.00256\n",
      "2024-11-25 16:54:23.035395: train_loss -0.7974\n",
      "2024-11-25 16:54:23.045395: val_loss -0.5883\n",
      "2024-11-25 16:54:23.055395: Pseudo dice [0.753]\n",
      "2024-11-25 16:54:23.055395: Epoch time: 129.83 s\n",
      "2024-11-25 16:54:24.115419: \n",
      "2024-11-25 16:54:24.126741: Epoch 391\n",
      "2024-11-25 16:54:24.130742: Current learning rate: 0.00254\n",
      "2024-11-25 16:56:34.045590: train_loss -0.8113\n",
      "2024-11-25 16:56:34.055590: val_loss -0.4889\n",
      "2024-11-25 16:56:34.065591: Pseudo dice [0.7231]\n",
      "2024-11-25 16:56:34.075591: Epoch time: 129.93 s\n",
      "2024-11-25 16:56:35.128866: \n",
      "2024-11-25 16:56:35.138856: Epoch 392\n",
      "2024-11-25 16:56:35.138856: Current learning rate: 0.00252\n",
      "2024-11-25 16:58:44.972538: train_loss -0.8294\n",
      "2024-11-25 16:58:44.982538: val_loss -0.2142\n",
      "2024-11-25 16:58:44.982538: Pseudo dice [0.5844]\n",
      "2024-11-25 16:58:44.992539: Epoch time: 129.84 s\n",
      "2024-11-25 16:58:46.039665: \n",
      "2024-11-25 16:58:46.049665: Epoch 393\n",
      "2024-11-25 16:58:46.059656: Current learning rate: 0.0025\n",
      "2024-11-25 17:00:55.798005: train_loss -0.828\n",
      "2024-11-25 17:00:55.808005: val_loss -0.4393\n",
      "2024-11-25 17:00:55.808005: Pseudo dice [0.7108]\n",
      "2024-11-25 17:00:55.818006: Epoch time: 129.76 s\n",
      "2024-11-25 17:00:57.056145: \n",
      "2024-11-25 17:00:57.056145: Epoch 394\n",
      "2024-11-25 17:00:57.066134: Current learning rate: 0.00248\n",
      "2024-11-25 17:03:06.806915: train_loss -0.8329\n",
      "2024-11-25 17:03:06.816916: val_loss -0.3377\n",
      "2024-11-25 17:03:06.826916: Pseudo dice [0.6623]\n",
      "2024-11-25 17:03:06.826916: Epoch time: 129.75 s\n",
      "2024-11-25 17:03:07.886930: \n",
      "2024-11-25 17:03:07.896930: Epoch 395\n",
      "2024-11-25 17:03:07.896930: Current learning rate: 0.00245\n",
      "2024-11-25 17:05:17.740072: train_loss -0.8368\n",
      "2024-11-25 17:05:17.750071: val_loss -0.3336\n",
      "2024-11-25 17:05:17.760071: Pseudo dice [0.6652]\n",
      "2024-11-25 17:05:17.760071: Epoch time: 129.85 s\n",
      "2024-11-25 17:05:18.821191: \n",
      "2024-11-25 17:05:18.821191: Epoch 396\n",
      "2024-11-25 17:05:18.831182: Current learning rate: 0.00243\n",
      "2024-11-25 17:07:28.607822: train_loss -0.8273\n",
      "2024-11-25 17:07:28.617822: val_loss -0.3951\n",
      "2024-11-25 17:07:28.627823: Pseudo dice [0.6735]\n",
      "2024-11-25 17:07:28.637822: Epoch time: 129.8 s\n",
      "2024-11-25 17:07:29.694060: \n",
      "2024-11-25 17:07:29.694060: Epoch 397\n",
      "2024-11-25 17:07:29.704049: Current learning rate: 0.00241\n",
      "2024-11-25 17:09:39.493908: train_loss -0.8317\n",
      "2024-11-25 17:09:39.503908: val_loss -0.4312\n",
      "2024-11-25 17:09:39.513908: Pseudo dice [0.7124]\n",
      "2024-11-25 17:09:39.523909: Epoch time: 129.8 s\n",
      "2024-11-25 17:09:40.581350: \n",
      "2024-11-25 17:09:40.591341: Epoch 398\n",
      "2024-11-25 17:09:40.591341: Current learning rate: 0.00239\n",
      "2024-11-25 17:11:50.368464: train_loss -0.8239\n",
      "2024-11-25 17:11:50.378464: val_loss -0.4154\n",
      "2024-11-25 17:11:50.388464: Pseudo dice [0.6855]\n",
      "2024-11-25 17:11:50.388464: Epoch time: 129.79 s\n",
      "2024-11-25 17:11:51.454607: \n",
      "2024-11-25 17:11:51.454607: Epoch 399\n",
      "2024-11-25 17:11:51.464596: Current learning rate: 0.00237\n",
      "2024-11-25 17:14:01.397772: train_loss -0.8217\n",
      "2024-11-25 17:14:01.417773: val_loss -0.5285\n",
      "2024-11-25 17:14:01.417773: Pseudo dice [0.7499]\n",
      "2024-11-25 17:14:01.427773: Epoch time: 129.94 s\n",
      "2024-11-25 17:14:02.711535: \n",
      "2024-11-25 17:14:02.721534: Epoch 400\n",
      "2024-11-25 17:14:02.721534: Current learning rate: 0.00235\n",
      "2024-11-25 17:16:12.484718: train_loss -0.8246\n",
      "2024-11-25 17:16:12.504718: val_loss -0.4089\n",
      "2024-11-25 17:16:12.504718: Pseudo dice [0.6751]\n",
      "2024-11-25 17:16:12.514719: Epoch time: 129.77 s\n",
      "2024-11-25 17:16:13.751816: \n",
      "2024-11-25 17:16:13.761806: Epoch 401\n",
      "2024-11-25 17:16:13.761806: Current learning rate: 0.00233\n",
      "2024-11-25 17:18:23.518924: train_loss -0.8277\n",
      "2024-11-25 17:18:23.528925: val_loss -0.3928\n",
      "2024-11-25 17:18:23.528925: Pseudo dice [0.6724]\n",
      "2024-11-25 17:18:23.538924: Epoch time: 129.77 s\n",
      "2024-11-25 17:18:24.598770: \n",
      "2024-11-25 17:18:24.608763: Epoch 402\n",
      "2024-11-25 17:18:24.608763: Current learning rate: 0.00231\n",
      "2024-11-25 17:20:34.403721: train_loss -0.812\n",
      "2024-11-25 17:20:34.412747: val_loss -0.4345\n",
      "2024-11-25 17:20:34.412747: Pseudo dice [0.702]\n",
      "2024-11-25 17:20:34.422749: Epoch time: 129.8 s\n",
      "2024-11-25 17:20:35.475713: \n",
      "2024-11-25 17:20:35.485705: Epoch 403\n",
      "2024-11-25 17:20:35.485705: Current learning rate: 0.00229\n",
      "2024-11-25 17:22:45.422180: train_loss -0.8229\n",
      "2024-11-25 17:22:45.442180: val_loss -0.2627\n",
      "2024-11-25 17:22:45.452181: Pseudo dice [0.6376]\n",
      "2024-11-25 17:22:45.452181: Epoch time: 129.95 s\n",
      "2024-11-25 17:22:46.532204: \n",
      "2024-11-25 17:22:46.532204: Epoch 404\n",
      "2024-11-25 17:22:46.542204: Current learning rate: 0.00226\n",
      "2024-11-25 17:24:56.295792: train_loss -0.8275\n",
      "2024-11-25 17:24:56.305792: val_loss -0.3483\n",
      "2024-11-25 17:24:56.305792: Pseudo dice [0.6276]\n",
      "2024-11-25 17:24:56.315792: Epoch time: 129.76 s\n",
      "2024-11-25 17:24:57.375815: \n",
      "2024-11-25 17:24:57.385808: Epoch 405\n",
      "2024-11-25 17:24:57.385808: Current learning rate: 0.00224\n",
      "2024-11-25 17:27:07.150020: train_loss -0.8091\n",
      "2024-11-25 17:27:07.160020: val_loss -0.3462\n",
      "2024-11-25 17:27:07.160020: Pseudo dice [0.6822]\n",
      "2024-11-25 17:27:07.170020: Epoch time: 129.77 s\n",
      "2024-11-25 17:27:08.230140: \n",
      "2024-11-25 17:27:08.230140: Epoch 406\n",
      "2024-11-25 17:27:08.240140: Current learning rate: 0.00222\n",
      "2024-11-25 17:29:18.066374: train_loss -0.8185\n",
      "2024-11-25 17:29:18.076375: val_loss -0.5229\n",
      "2024-11-25 17:29:18.086375: Pseudo dice [0.756]\n",
      "2024-11-25 17:29:18.086375: Epoch time: 129.84 s\n",
      "2024-11-25 17:29:19.316775: \n",
      "2024-11-25 17:29:19.316775: Epoch 407\n",
      "2024-11-25 17:29:19.326773: Current learning rate: 0.0022\n",
      "2024-11-25 17:31:29.074332: train_loss -0.8381\n",
      "2024-11-25 17:31:29.080405: val_loss -0.2956\n",
      "2024-11-25 17:31:29.090404: Pseudo dice [0.6211]\n",
      "2024-11-25 17:31:29.090404: Epoch time: 129.76 s\n",
      "2024-11-25 17:31:30.160418: \n",
      "2024-11-25 17:31:30.160418: Epoch 408\n",
      "2024-11-25 17:31:30.160418: Current learning rate: 0.00218\n",
      "2024-11-25 17:33:39.940679: train_loss -0.8281\n",
      "2024-11-25 17:33:39.950680: val_loss -0.4047\n",
      "2024-11-25 17:33:39.960680: Pseudo dice [0.7091]\n",
      "2024-11-25 17:33:39.960680: Epoch time: 129.79 s\n",
      "2024-11-25 17:33:41.030696: \n",
      "2024-11-25 17:33:41.030696: Epoch 409\n",
      "2024-11-25 17:33:41.040694: Current learning rate: 0.00216\n",
      "2024-11-25 17:35:50.847172: train_loss -0.834\n",
      "2024-11-25 17:35:50.857173: val_loss -0.4718\n",
      "2024-11-25 17:35:50.867174: Pseudo dice [0.7442]\n",
      "2024-11-25 17:35:50.867174: Epoch time: 129.82 s\n",
      "2024-11-25 17:35:51.937187: \n",
      "2024-11-25 17:35:51.937187: Epoch 410\n",
      "2024-11-25 17:35:51.947188: Current learning rate: 0.00214\n",
      "2024-11-25 17:38:01.770785: train_loss -0.8288\n",
      "2024-11-25 17:38:01.780785: val_loss -0.2282\n",
      "2024-11-25 17:38:01.780785: Pseudo dice [0.5737]\n",
      "2024-11-25 17:38:01.790785: Epoch time: 129.83 s\n",
      "2024-11-25 17:38:02.791221: \n",
      "2024-11-25 17:38:02.801221: Epoch 411\n",
      "2024-11-25 17:38:02.801221: Current learning rate: 0.00212\n",
      "2024-11-25 17:40:12.658203: train_loss -0.8341\n",
      "2024-11-25 17:40:12.668204: val_loss -0.4372\n",
      "2024-11-25 17:40:12.678204: Pseudo dice [0.7068]\n",
      "2024-11-25 17:40:12.689377: Epoch time: 129.87 s\n",
      "2024-11-25 17:40:13.684834: \n",
      "2024-11-25 17:40:13.694834: Epoch 412\n",
      "2024-11-25 17:40:13.694834: Current learning rate: 0.00209\n",
      "2024-11-25 17:42:23.515094: train_loss -0.8438\n",
      "2024-11-25 17:42:23.515094: val_loss -0.4798\n",
      "2024-11-25 17:42:23.525093: Pseudo dice [0.7312]\n",
      "2024-11-25 17:42:23.535093: Epoch time: 129.83 s\n",
      "2024-11-25 17:42:24.535109: \n",
      "2024-11-25 17:42:24.535109: Epoch 413\n",
      "2024-11-25 17:42:24.545106: Current learning rate: 0.00207\n",
      "2024-11-25 17:44:34.341827: train_loss -0.843\n",
      "2024-11-25 17:44:34.361828: val_loss -0.4498\n",
      "2024-11-25 17:44:34.361828: Pseudo dice [0.738]\n",
      "2024-11-25 17:44:34.371827: Epoch time: 129.81 s\n",
      "2024-11-25 17:44:35.541843: \n",
      "2024-11-25 17:44:35.551844: Epoch 414\n",
      "2024-11-25 17:44:35.551844: Current learning rate: 0.00205\n",
      "2024-11-25 17:46:45.379453: train_loss -0.8318\n",
      "2024-11-25 17:46:45.389453: val_loss -0.486\n",
      "2024-11-25 17:46:45.399453: Pseudo dice [0.714]\n",
      "2024-11-25 17:46:45.399453: Epoch time: 129.84 s\n",
      "2024-11-25 17:46:46.399466: \n",
      "2024-11-25 17:46:46.409466: Epoch 415\n",
      "2024-11-25 17:46:46.409466: Current learning rate: 0.00203\n",
      "2024-11-25 17:48:56.260468: train_loss -0.8263\n",
      "2024-11-25 17:48:56.270468: val_loss -0.5528\n",
      "2024-11-25 17:48:56.280468: Pseudo dice [0.7576]\n",
      "2024-11-25 17:48:56.280468: Epoch time: 129.86 s\n",
      "2024-11-25 17:48:57.285916: \n",
      "2024-11-25 17:48:57.285916: Epoch 416\n",
      "2024-11-25 17:48:57.295913: Current learning rate: 0.00201\n",
      "2024-11-25 17:51:07.104237: train_loss -0.8224\n",
      "2024-11-25 17:51:07.114238: val_loss -0.5723\n",
      "2024-11-25 17:51:07.124238: Pseudo dice [0.7452]\n",
      "2024-11-25 17:51:07.124238: Epoch time: 129.82 s\n",
      "2024-11-25 17:51:08.132381: \n",
      "2024-11-25 17:51:08.132381: Epoch 417\n",
      "2024-11-25 17:51:08.142382: Current learning rate: 0.00199\n",
      "2024-11-25 17:53:17.934489: train_loss -0.8061\n",
      "2024-11-25 17:53:17.944489: val_loss -0.4468\n",
      "2024-11-25 17:53:17.954489: Pseudo dice [0.7203]\n",
      "2024-11-25 17:53:17.954489: Epoch time: 129.8 s\n",
      "2024-11-25 17:53:18.952712: \n",
      "2024-11-25 17:53:18.962703: Epoch 418\n",
      "2024-11-25 17:53:18.972711: Current learning rate: 0.00196\n",
      "2024-11-25 17:55:28.725833: train_loss -0.8344\n",
      "2024-11-25 17:55:28.735984: val_loss -0.3401\n",
      "2024-11-25 17:55:28.742100: Pseudo dice [0.6772]\n",
      "2024-11-25 17:55:28.747131: Epoch time: 129.77 s\n",
      "2024-11-25 17:55:29.742437: \n",
      "2024-11-25 17:55:29.742437: Epoch 419\n",
      "2024-11-25 17:55:29.752436: Current learning rate: 0.00194\n",
      "2024-11-25 17:57:39.566580: train_loss -0.8387\n",
      "2024-11-25 17:57:39.576579: val_loss -0.3161\n",
      "2024-11-25 17:57:39.586579: Pseudo dice [0.6238]\n",
      "2024-11-25 17:57:39.596580: Epoch time: 129.82 s\n",
      "2024-11-25 17:57:40.596603: \n",
      "2024-11-25 17:57:40.606602: Epoch 420\n",
      "2024-11-25 17:57:40.606602: Current learning rate: 0.00192\n",
      "2024-11-25 17:59:50.394055: train_loss -0.833\n",
      "2024-11-25 17:59:50.404055: val_loss -0.4466\n",
      "2024-11-25 17:59:50.414056: Pseudo dice [0.7157]\n",
      "2024-11-25 17:59:50.414056: Epoch time: 129.8 s\n",
      "2024-11-25 17:59:51.414078: \n",
      "2024-11-25 17:59:51.424077: Epoch 421\n",
      "2024-11-25 17:59:51.424077: Current learning rate: 0.0019\n",
      "2024-11-25 18:02:01.207096: train_loss -0.8362\n",
      "2024-11-25 18:02:01.217097: val_loss -0.4343\n",
      "2024-11-25 18:02:01.217097: Pseudo dice [0.7074]\n",
      "2024-11-25 18:02:01.227097: Epoch time: 129.79 s\n",
      "2024-11-25 18:02:02.414277: \n",
      "2024-11-25 18:02:02.424276: Epoch 422\n",
      "2024-11-25 18:02:02.424276: Current learning rate: 0.00188\n",
      "2024-11-25 18:04:12.177489: train_loss -0.8129\n",
      "2024-11-25 18:04:12.187489: val_loss -0.433\n",
      "2024-11-25 18:04:12.197490: Pseudo dice [0.6803]\n",
      "2024-11-25 18:04:12.207490: Epoch time: 129.76 s\n",
      "2024-11-25 18:04:13.204353: \n",
      "2024-11-25 18:04:13.214352: Epoch 423\n",
      "2024-11-25 18:04:13.214352: Current learning rate: 0.00186\n",
      "2024-11-25 18:06:23.098173: train_loss -0.8296\n",
      "2024-11-25 18:06:23.118172: val_loss -0.5968\n",
      "2024-11-25 18:06:23.118172: Pseudo dice [0.7738]\n",
      "2024-11-25 18:06:23.128172: Epoch time: 129.89 s\n",
      "2024-11-25 18:06:24.138120: \n",
      "2024-11-25 18:06:24.138120: Epoch 424\n",
      "2024-11-25 18:06:24.148121: Current learning rate: 0.00184\n",
      "2024-11-25 18:08:33.881762: train_loss -0.8237\n",
      "2024-11-25 18:08:33.891761: val_loss -0.359\n",
      "2024-11-25 18:08:33.901762: Pseudo dice [0.6259]\n",
      "2024-11-25 18:08:33.901762: Epoch time: 129.75 s\n",
      "2024-11-25 18:08:34.911259: \n",
      "2024-11-25 18:08:34.911259: Epoch 425\n",
      "2024-11-25 18:08:34.921268: Current learning rate: 0.00181\n",
      "2024-11-25 18:10:44.732060: train_loss -0.8286\n",
      "2024-11-25 18:10:44.742059: val_loss -0.4683\n",
      "2024-11-25 18:10:44.752060: Pseudo dice [0.6973]\n",
      "2024-11-25 18:10:44.762060: Epoch time: 129.82 s\n",
      "2024-11-25 18:10:45.752075: \n",
      "2024-11-25 18:10:45.762075: Epoch 426\n",
      "2024-11-25 18:10:45.762075: Current learning rate: 0.00179\n",
      "2024-11-25 18:12:55.578530: train_loss -0.8326\n",
      "2024-11-25 18:12:55.598530: val_loss -0.4916\n",
      "2024-11-25 18:12:55.598530: Pseudo dice [0.6949]\n",
      "2024-11-25 18:12:55.608530: Epoch time: 129.83 s\n",
      "2024-11-25 18:12:56.598969: \n",
      "2024-11-25 18:12:56.608968: Epoch 427\n",
      "2024-11-25 18:12:56.608968: Current learning rate: 0.00177\n",
      "2024-11-25 18:15:06.508853: train_loss -0.825\n",
      "2024-11-25 18:15:06.538854: val_loss -0.4772\n",
      "2024-11-25 18:15:06.538854: Pseudo dice [0.7377]\n",
      "2024-11-25 18:15:06.548854: Epoch time: 129.91 s\n",
      "2024-11-25 18:15:07.539088: \n",
      "2024-11-25 18:15:07.549088: Epoch 428\n",
      "2024-11-25 18:15:07.549088: Current learning rate: 0.00175\n",
      "2024-11-25 18:17:17.339617: train_loss -0.8334\n",
      "2024-11-25 18:17:17.349617: val_loss -0.4205\n",
      "2024-11-25 18:17:17.349617: Pseudo dice [0.6716]\n",
      "2024-11-25 18:17:17.359617: Epoch time: 129.8 s\n",
      "2024-11-25 18:17:18.519069: \n",
      "2024-11-25 18:17:18.519069: Epoch 429\n",
      "2024-11-25 18:17:18.529069: Current learning rate: 0.00173\n",
      "2024-11-25 18:19:28.319833: train_loss -0.8355\n",
      "2024-11-25 18:19:28.329835: val_loss -0.4488\n",
      "2024-11-25 18:19:28.329835: Pseudo dice [0.7049]\n",
      "2024-11-25 18:19:28.339835: Epoch time: 129.8 s\n",
      "2024-11-25 18:19:29.330601: \n",
      "2024-11-25 18:19:29.330601: Epoch 430\n",
      "2024-11-25 18:19:29.340600: Current learning rate: 0.0017\n",
      "2024-11-25 18:21:39.122959: train_loss -0.8438\n",
      "2024-11-25 18:21:39.132959: val_loss -0.5099\n",
      "2024-11-25 18:21:39.142960: Pseudo dice [0.7247]\n",
      "2024-11-25 18:21:39.152959: Epoch time: 129.79 s\n",
      "2024-11-25 18:21:40.142982: \n",
      "2024-11-25 18:21:40.152982: Epoch 431\n",
      "2024-11-25 18:21:40.152982: Current learning rate: 0.00168\n",
      "2024-11-25 18:23:50.049928: train_loss -0.8411\n",
      "2024-11-25 18:23:50.059928: val_loss -0.5717\n",
      "2024-11-25 18:23:50.069929: Pseudo dice [0.7507]\n",
      "2024-11-25 18:23:50.069929: Epoch time: 129.91 s\n",
      "2024-11-25 18:23:51.066987: \n",
      "2024-11-25 18:23:51.076987: Epoch 432\n",
      "2024-11-25 18:23:51.076987: Current learning rate: 0.00166\n",
      "2024-11-25 18:26:00.887397: train_loss -0.838\n",
      "2024-11-25 18:26:00.897397: val_loss -0.36\n",
      "2024-11-25 18:26:00.907397: Pseudo dice [0.6803]\n",
      "2024-11-25 18:26:00.907397: Epoch time: 129.82 s\n",
      "2024-11-25 18:26:01.903971: \n",
      "2024-11-25 18:26:01.913963: Epoch 433\n",
      "2024-11-25 18:26:01.913963: Current learning rate: 0.00164\n",
      "2024-11-25 18:28:11.790971: train_loss -0.8512\n",
      "2024-11-25 18:28:11.800971: val_loss -0.5038\n",
      "2024-11-25 18:28:11.810970: Pseudo dice [0.7292]\n",
      "2024-11-25 18:28:11.810970: Epoch time: 129.89 s\n",
      "2024-11-25 18:28:12.807557: \n",
      "2024-11-25 18:28:12.817556: Epoch 434\n",
      "2024-11-25 18:28:12.817556: Current learning rate: 0.00162\n",
      "2024-11-25 18:30:22.761664: train_loss -0.8538\n",
      "2024-11-25 18:30:22.771664: val_loss -0.4709\n",
      "2024-11-25 18:30:22.771664: Pseudo dice [0.7457]\n",
      "2024-11-25 18:30:22.781664: Epoch time: 129.95 s\n",
      "2024-11-25 18:30:23.771687: \n",
      "2024-11-25 18:30:23.781678: Epoch 435\n",
      "2024-11-25 18:30:23.781678: Current learning rate: 0.00159\n",
      "2024-11-25 18:32:33.615602: train_loss -0.8483\n",
      "2024-11-25 18:32:33.625602: val_loss -0.5988\n",
      "2024-11-25 18:32:33.625602: Pseudo dice [0.7609]\n",
      "2024-11-25 18:32:33.635603: Epoch time: 129.84 s\n",
      "2024-11-25 18:32:33.635603: Yayy! New best EMA pseudo Dice: 0.7151\n",
      "2024-11-25 18:32:34.855628: \n",
      "2024-11-25 18:32:34.865628: Epoch 436\n",
      "2024-11-25 18:32:34.865628: Current learning rate: 0.00157\n",
      "2024-11-25 18:34:44.691937: train_loss -0.8297\n",
      "2024-11-25 18:34:44.701937: val_loss -0.5834\n",
      "2024-11-25 18:34:44.711937: Pseudo dice [0.7597]\n",
      "2024-11-25 18:34:44.711937: Epoch time: 129.84 s\n",
      "2024-11-25 18:34:44.721938: Yayy! New best EMA pseudo Dice: 0.7196\n",
      "2024-11-25 18:34:46.151729: \n",
      "2024-11-25 18:34:46.151729: Epoch 437\n",
      "2024-11-25 18:34:46.161736: Current learning rate: 0.00155\n",
      "2024-11-25 18:36:55.955349: train_loss -0.8281\n",
      "2024-11-25 18:36:55.965351: val_loss -0.5052\n",
      "2024-11-25 18:36:55.975351: Pseudo dice [0.707]\n",
      "2024-11-25 18:36:55.975351: Epoch time: 129.81 s\n",
      "2024-11-25 18:36:56.965373: \n",
      "2024-11-25 18:36:56.975363: Epoch 438\n",
      "2024-11-25 18:36:56.975363: Current learning rate: 0.00153\n",
      "2024-11-25 18:39:06.808483: train_loss -0.8385\n",
      "2024-11-25 18:39:06.818484: val_loss -0.4989\n",
      "2024-11-25 18:39:06.828485: Pseudo dice [0.7163]\n",
      "2024-11-25 18:39:06.828485: Epoch time: 129.84 s\n",
      "2024-11-25 18:39:07.818507: \n",
      "2024-11-25 18:39:07.828498: Epoch 439\n",
      "2024-11-25 18:39:07.828498: Current learning rate: 0.00151\n",
      "2024-11-25 18:41:17.635939: train_loss -0.854\n",
      "2024-11-25 18:41:17.645941: val_loss -0.3589\n",
      "2024-11-25 18:41:17.655941: Pseudo dice [0.6626]\n",
      "2024-11-25 18:41:17.655941: Epoch time: 129.82 s\n",
      "2024-11-25 18:41:18.645964: \n",
      "2024-11-25 18:41:18.655955: Epoch 440\n",
      "2024-11-25 18:41:18.655955: Current learning rate: 0.00148\n",
      "2024-11-25 18:43:28.449082: train_loss -0.833\n",
      "2024-11-25 18:43:28.459082: val_loss -0.4772\n",
      "2024-11-25 18:43:28.469082: Pseudo dice [0.7021]\n",
      "2024-11-25 18:43:28.469082: Epoch time: 129.8 s\n",
      "2024-11-25 18:43:29.469469: \n",
      "2024-11-25 18:43:29.469469: Epoch 441\n",
      "2024-11-25 18:43:29.479469: Current learning rate: 0.00146\n",
      "2024-11-25 18:45:39.336018: train_loss -0.842\n",
      "2024-11-25 18:45:39.346017: val_loss -0.5537\n",
      "2024-11-25 18:45:39.346017: Pseudo dice [0.7552]\n",
      "2024-11-25 18:45:39.356017: Epoch time: 129.87 s\n",
      "2024-11-25 18:45:40.346469: \n",
      "2024-11-25 18:45:40.356468: Epoch 442\n",
      "2024-11-25 18:45:40.356468: Current learning rate: 0.00144\n",
      "2024-11-25 18:47:50.243478: train_loss -0.8471\n",
      "2024-11-25 18:47:50.253477: val_loss -0.4477\n",
      "2024-11-25 18:47:50.263479: Pseudo dice [0.7065]\n",
      "2024-11-25 18:47:50.263479: Epoch time: 129.9 s\n",
      "2024-11-25 18:47:51.249551: \n",
      "2024-11-25 18:47:51.259542: Epoch 443\n",
      "2024-11-25 18:47:51.259542: Current learning rate: 0.00142\n",
      "2024-11-25 18:50:01.066546: train_loss -0.8398\n",
      "2024-11-25 18:50:01.076547: val_loss -0.3577\n",
      "2024-11-25 18:50:01.086547: Pseudo dice [0.6377]\n",
      "2024-11-25 18:50:01.096547: Epoch time: 129.82 s\n",
      "2024-11-25 18:50:02.266571: \n",
      "2024-11-25 18:50:02.266571: Epoch 444\n",
      "2024-11-25 18:50:02.276562: Current learning rate: 0.00139\n",
      "2024-11-25 18:52:12.073762: train_loss -0.8287\n",
      "2024-11-25 18:52:12.083762: val_loss -0.3503\n",
      "2024-11-25 18:52:12.093762: Pseudo dice [0.6854]\n",
      "2024-11-25 18:52:12.093762: Epoch time: 129.82 s\n",
      "2024-11-25 18:52:13.103779: \n",
      "2024-11-25 18:52:13.103779: Epoch 445\n",
      "2024-11-25 18:52:13.113776: Current learning rate: 0.00137\n",
      "2024-11-25 18:54:22.907388: train_loss -0.8485\n",
      "2024-11-25 18:54:22.907388: val_loss -0.3265\n",
      "2024-11-25 18:54:22.917388: Pseudo dice [0.6306]\n",
      "2024-11-25 18:54:22.927388: Epoch time: 129.8 s\n",
      "2024-11-25 18:54:23.917511: \n",
      "2024-11-25 18:54:23.927510: Epoch 446\n",
      "2024-11-25 18:54:23.927510: Current learning rate: 0.00135\n",
      "2024-11-25 18:56:33.710772: train_loss -0.8307\n",
      "2024-11-25 18:56:33.720772: val_loss -0.4745\n",
      "2024-11-25 18:56:33.730772: Pseudo dice [0.7423]\n",
      "2024-11-25 18:56:33.740772: Epoch time: 129.79 s\n",
      "2024-11-25 18:56:34.731176: \n",
      "2024-11-25 18:56:34.741169: Epoch 447\n",
      "2024-11-25 18:56:34.741169: Current learning rate: 0.00133\n",
      "2024-11-25 18:58:44.569118: train_loss -0.8225\n",
      "2024-11-25 18:58:44.578135: val_loss -0.5519\n",
      "2024-11-25 18:58:44.578135: Pseudo dice [0.7597]\n",
      "2024-11-25 18:58:44.588136: Epoch time: 129.84 s\n",
      "2024-11-25 18:58:45.588173: \n",
      "2024-11-25 18:58:45.598165: Epoch 448\n",
      "2024-11-25 18:58:45.598165: Current learning rate: 0.0013\n",
      "2024-11-25 19:00:55.408496: train_loss -0.8337\n",
      "2024-11-25 19:00:55.430471: val_loss -0.2478\n",
      "2024-11-25 19:00:55.435473: Pseudo dice [0.6406]\n",
      "2024-11-25 19:00:55.438422: Epoch time: 129.82 s\n",
      "2024-11-25 19:00:56.431777: \n",
      "2024-11-25 19:00:56.441769: Epoch 449\n",
      "2024-11-25 19:00:56.441769: Current learning rate: 0.00128\n",
      "2024-11-25 19:03:06.255368: train_loss -0.8313\n",
      "2024-11-25 19:03:06.265368: val_loss -0.3891\n",
      "2024-11-25 19:03:06.265368: Pseudo dice [0.6931]\n",
      "2024-11-25 19:03:06.275368: Epoch time: 129.82 s\n",
      "2024-11-25 19:03:07.495385: \n",
      "2024-11-25 19:03:07.505385: Epoch 450\n",
      "2024-11-25 19:03:07.505385: Current learning rate: 0.00126\n",
      "2024-11-25 19:05:17.428530: train_loss -0.8496\n",
      "2024-11-25 19:05:17.448530: val_loss -0.3711\n",
      "2024-11-25 19:05:17.458531: Pseudo dice [0.6493]\n",
      "2024-11-25 19:05:17.458531: Epoch time: 129.93 s\n",
      "2024-11-25 19:05:18.629088: \n",
      "2024-11-25 19:05:18.639088: Epoch 451\n",
      "2024-11-25 19:05:18.639088: Current learning rate: 0.00124\n",
      "2024-11-25 19:07:28.476244: train_loss -0.8501\n",
      "2024-11-25 19:07:28.486244: val_loss -0.5568\n",
      "2024-11-25 19:07:28.496244: Pseudo dice [0.7698]\n",
      "2024-11-25 19:07:28.496244: Epoch time: 129.85 s\n",
      "2024-11-25 19:07:29.495911: \n",
      "2024-11-25 19:07:29.495911: Epoch 452\n",
      "2024-11-25 19:07:29.505908: Current learning rate: 0.00121\n",
      "2024-11-25 19:09:39.332913: train_loss -0.8479\n",
      "2024-11-25 19:09:39.342913: val_loss -0.4653\n",
      "2024-11-25 19:09:39.352914: Pseudo dice [0.7004]\n",
      "2024-11-25 19:09:39.352914: Epoch time: 129.84 s\n",
      "2024-11-25 19:09:40.349013: \n",
      "2024-11-25 19:09:40.359013: Epoch 453\n",
      "2024-11-25 19:09:40.359013: Current learning rate: 0.00119\n",
      "2024-11-25 19:11:50.266470: train_loss -0.8568\n",
      "2024-11-25 19:11:50.276470: val_loss -0.4904\n",
      "2024-11-25 19:11:50.286471: Pseudo dice [0.7544]\n",
      "2024-11-25 19:11:50.286471: Epoch time: 129.92 s\n",
      "2024-11-25 19:11:51.286485: \n",
      "2024-11-25 19:11:51.286485: Epoch 454\n",
      "2024-11-25 19:11:51.296484: Current learning rate: 0.00117\n",
      "2024-11-25 19:14:01.426319: train_loss -0.8557\n",
      "2024-11-25 19:14:01.436320: val_loss -0.4936\n",
      "2024-11-25 19:14:01.436320: Pseudo dice [0.7115]\n",
      "2024-11-25 19:14:01.446319: Epoch time: 130.15 s\n",
      "2024-11-25 19:14:02.448428: \n",
      "2024-11-25 19:14:02.453364: Epoch 455\n",
      "2024-11-25 19:14:02.453364: Current learning rate: 0.00115\n",
      "2024-11-25 19:16:12.294678: train_loss -0.844\n",
      "2024-11-25 19:16:12.304678: val_loss -0.4852\n",
      "2024-11-25 19:16:12.314679: Pseudo dice [0.7331]\n",
      "2024-11-25 19:16:12.314679: Epoch time: 129.85 s\n",
      "2024-11-25 19:16:13.313201: \n",
      "2024-11-25 19:16:13.323201: Epoch 456\n",
      "2024-11-25 19:16:13.323201: Current learning rate: 0.00112\n",
      "2024-11-25 19:18:23.250213: train_loss -0.8533\n",
      "2024-11-25 19:18:23.260213: val_loss -0.391\n",
      "2024-11-25 19:18:23.260213: Pseudo dice [0.6798]\n",
      "2024-11-25 19:18:23.270213: Epoch time: 129.94 s\n",
      "2024-11-25 19:18:24.260137: \n",
      "2024-11-25 19:18:24.270137: Epoch 457\n",
      "2024-11-25 19:18:24.270137: Current learning rate: 0.0011\n",
      "2024-11-25 19:20:34.150486: train_loss -0.8504\n",
      "2024-11-25 19:20:34.160486: val_loss -0.4922\n",
      "2024-11-25 19:20:34.170486: Pseudo dice [0.7128]\n",
      "2024-11-25 19:20:34.170486: Epoch time: 129.89 s\n",
      "2024-11-25 19:20:35.170509: \n",
      "2024-11-25 19:20:35.180509: Epoch 458\n",
      "2024-11-25 19:20:35.180509: Current learning rate: 0.00108\n",
      "2024-11-25 19:22:45.155087: train_loss -0.8474\n",
      "2024-11-25 19:22:45.165087: val_loss -0.4775\n",
      "2024-11-25 19:22:45.175088: Pseudo dice [0.6884]\n",
      "2024-11-25 19:22:45.185088: Epoch time: 129.98 s\n",
      "2024-11-25 19:22:46.365105: \n",
      "2024-11-25 19:22:46.365105: Epoch 459\n",
      "2024-11-25 19:22:46.375104: Current learning rate: 0.00105\n",
      "2024-11-25 19:24:56.224643: train_loss -0.8595\n",
      "2024-11-25 19:24:56.234643: val_loss -0.4497\n",
      "2024-11-25 19:24:56.234643: Pseudo dice [0.7177]\n",
      "2024-11-25 19:24:56.244643: Epoch time: 129.87 s\n",
      "2024-11-25 19:24:57.233529: \n",
      "2024-11-25 19:24:57.243530: Epoch 460\n",
      "2024-11-25 19:24:57.243530: Current learning rate: 0.00103\n",
      "2024-11-25 19:27:07.131303: train_loss -0.8545\n",
      "2024-11-25 19:27:07.151303: val_loss -0.5922\n",
      "2024-11-25 19:27:07.151303: Pseudo dice [0.7702]\n",
      "2024-11-25 19:27:07.161304: Epoch time: 129.9 s\n",
      "2024-11-25 19:27:08.165168: \n",
      "2024-11-25 19:27:08.172262: Epoch 461\n",
      "2024-11-25 19:27:08.176301: Current learning rate: 0.00101\n",
      "2024-11-25 19:29:18.045388: train_loss -0.855\n",
      "2024-11-25 19:29:18.055388: val_loss -0.3678\n",
      "2024-11-25 19:29:18.065388: Pseudo dice [0.6766]\n",
      "2024-11-25 19:29:18.075388: Epoch time: 129.88 s\n",
      "2024-11-25 19:29:19.065411: \n",
      "2024-11-25 19:29:19.065411: Epoch 462\n",
      "2024-11-25 19:29:19.075402: Current learning rate: 0.00098\n",
      "2024-11-25 19:31:29.151874: train_loss -0.8436\n",
      "2024-11-25 19:31:29.161874: val_loss -0.5329\n",
      "2024-11-25 19:31:29.161874: Pseudo dice [0.7418]\n",
      "2024-11-25 19:31:29.171875: Epoch time: 130.09 s\n",
      "2024-11-25 19:31:30.171888: \n",
      "2024-11-25 19:31:30.171888: Epoch 463\n",
      "2024-11-25 19:31:30.181887: Current learning rate: 0.00096\n",
      "2024-11-25 19:33:40.002643: train_loss -0.8549\n",
      "2024-11-25 19:33:40.012643: val_loss -0.5014\n",
      "2024-11-25 19:33:40.022644: Pseudo dice [0.7542]\n",
      "2024-11-25 19:33:40.022644: Epoch time: 129.83 s\n",
      "2024-11-25 19:33:41.029236: \n",
      "2024-11-25 19:33:41.029236: Epoch 464\n",
      "2024-11-25 19:33:41.039235: Current learning rate: 0.00094\n",
      "2024-11-25 19:35:50.902432: train_loss -0.861\n",
      "2024-11-25 19:35:50.912433: val_loss -0.4706\n",
      "2024-11-25 19:35:50.922432: Pseudo dice [0.7168]\n",
      "2024-11-25 19:35:50.932432: Epoch time: 129.87 s\n",
      "2024-11-25 19:35:51.932870: \n",
      "2024-11-25 19:35:51.932870: Epoch 465\n",
      "2024-11-25 19:35:51.942870: Current learning rate: 0.00091\n",
      "2024-11-25 19:38:01.789930: train_loss -0.8559\n",
      "2024-11-25 19:38:01.799931: val_loss -0.4637\n",
      "2024-11-25 19:38:01.809930: Pseudo dice [0.6973]\n",
      "2024-11-25 19:38:01.819932: Epoch time: 129.87 s\n",
      "2024-11-25 19:38:02.805997: \n",
      "2024-11-25 19:38:02.818286: Epoch 466\n",
      "2024-11-25 19:38:02.818286: Current learning rate: 0.00089\n",
      "2024-11-25 19:40:12.806849: train_loss -0.8564\n",
      "2024-11-25 19:40:12.816849: val_loss -0.4653\n",
      "2024-11-25 19:40:12.816849: Pseudo dice [0.7202]\n",
      "2024-11-25 19:40:12.826849: Epoch time: 130.0 s\n",
      "2024-11-25 19:40:13.996874: \n",
      "2024-11-25 19:40:14.006873: Epoch 467\n",
      "2024-11-25 19:40:14.006873: Current learning rate: 0.00087\n",
      "2024-11-25 19:42:23.863782: train_loss -0.8442\n",
      "2024-11-25 19:42:23.873783: val_loss -0.3998\n",
      "2024-11-25 19:42:23.873783: Pseudo dice [0.6837]\n",
      "2024-11-25 19:42:23.883783: Epoch time: 129.87 s\n",
      "2024-11-25 19:42:24.883796: \n",
      "2024-11-25 19:42:24.883796: Epoch 468\n",
      "2024-11-25 19:42:24.893805: Current learning rate: 0.00084\n",
      "2024-11-25 19:44:34.763669: train_loss -0.8548\n",
      "2024-11-25 19:44:34.773668: val_loss -0.4905\n",
      "2024-11-25 19:44:34.783668: Pseudo dice [0.7634]\n",
      "2024-11-25 19:44:34.783668: Epoch time: 129.88 s\n",
      "2024-11-25 19:44:35.780643: \n",
      "2024-11-25 19:44:35.780643: Epoch 469\n",
      "2024-11-25 19:44:35.790643: Current learning rate: 0.00082\n",
      "2024-11-25 19:46:45.637744: train_loss -0.8542\n",
      "2024-11-25 19:46:45.647743: val_loss -0.488\n",
      "2024-11-25 19:46:45.657744: Pseudo dice [0.7496]\n",
      "2024-11-25 19:46:45.657744: Epoch time: 129.86 s\n",
      "2024-11-25 19:46:45.667744: Yayy! New best EMA pseudo Dice: 0.7207\n",
      "2024-11-25 19:46:46.883758: \n",
      "2024-11-25 19:46:46.893749: Epoch 470\n",
      "2024-11-25 19:46:46.893749: Current learning rate: 0.00079\n",
      "2024-11-25 19:48:56.800774: train_loss -0.8474\n",
      "2024-11-25 19:48:56.810774: val_loss -0.4527\n",
      "2024-11-25 19:48:56.820774: Pseudo dice [0.7324]\n",
      "2024-11-25 19:48:56.830774: Epoch time: 129.92 s\n",
      "2024-11-25 19:48:56.830774: Yayy! New best EMA pseudo Dice: 0.7219\n",
      "2024-11-25 19:48:58.074055: \n",
      "2024-11-25 19:48:58.074055: Epoch 471\n",
      "2024-11-25 19:48:58.084055: Current learning rate: 0.00077\n",
      "2024-11-25 19:51:07.911056: train_loss -0.8518\n",
      "2024-11-25 19:51:07.921057: val_loss -0.4713\n",
      "2024-11-25 19:51:07.931056: Pseudo dice [0.745]\n",
      "2024-11-25 19:51:07.931056: Epoch time: 129.84 s\n",
      "2024-11-25 19:51:07.941057: Yayy! New best EMA pseudo Dice: 0.7242\n",
      "2024-11-25 19:51:09.178191: \n",
      "2024-11-25 19:51:09.188183: Epoch 472\n",
      "2024-11-25 19:51:09.188183: Current learning rate: 0.00075\n",
      "2024-11-25 19:53:19.041863: train_loss -0.8592\n",
      "2024-11-25 19:53:19.051863: val_loss -0.5025\n",
      "2024-11-25 19:53:19.061864: Pseudo dice [0.733]\n",
      "2024-11-25 19:53:19.061864: Epoch time: 129.86 s\n",
      "2024-11-25 19:53:19.071864: Yayy! New best EMA pseudo Dice: 0.7251\n",
      "2024-11-25 19:53:20.325077: \n",
      "2024-11-25 19:53:20.325077: Epoch 473\n",
      "2024-11-25 19:53:20.335076: Current learning rate: 0.00072\n",
      "2024-11-25 19:55:30.192336: train_loss -0.8516\n",
      "2024-11-25 19:55:30.202337: val_loss -0.5296\n",
      "2024-11-25 19:55:30.212336: Pseudo dice [0.7642]\n",
      "2024-11-25 19:55:30.212336: Epoch time: 129.87 s\n",
      "2024-11-25 19:55:30.222337: Yayy! New best EMA pseudo Dice: 0.729\n",
      "2024-11-25 19:55:31.642367: \n",
      "2024-11-25 19:55:31.642367: Epoch 474\n",
      "2024-11-25 19:55:31.652364: Current learning rate: 0.0007\n",
      "2024-11-25 19:57:41.429318: train_loss -0.8492\n",
      "2024-11-25 19:57:41.439318: val_loss -0.4895\n",
      "2024-11-25 19:57:41.439318: Pseudo dice [0.6992]\n",
      "2024-11-25 19:57:41.449318: Epoch time: 129.79 s\n",
      "2024-11-25 19:57:42.445589: \n",
      "2024-11-25 19:57:42.445589: Epoch 475\n",
      "2024-11-25 19:57:42.455589: Current learning rate: 0.00067\n",
      "2024-11-25 19:59:52.192512: train_loss -0.8347\n",
      "2024-11-25 19:59:52.202513: val_loss -0.4597\n",
      "2024-11-25 19:59:52.212513: Pseudo dice [0.7332]\n",
      "2024-11-25 19:59:52.212513: Epoch time: 129.76 s\n",
      "2024-11-25 19:59:53.222847: \n",
      "2024-11-25 19:59:53.222847: Epoch 476\n",
      "2024-11-25 19:59:53.232849: Current learning rate: 0.00065\n",
      "2024-11-25 20:02:02.989077: train_loss -0.8547\n",
      "2024-11-25 20:02:02.999076: val_loss -0.3377\n",
      "2024-11-25 20:02:03.009077: Pseudo dice [0.6397]\n",
      "2024-11-25 20:02:03.019077: Epoch time: 129.77 s\n",
      "2024-11-25 20:02:04.016260: \n",
      "2024-11-25 20:02:04.016260: Epoch 477\n",
      "2024-11-25 20:02:04.026252: Current learning rate: 0.00063\n",
      "2024-11-25 20:04:13.806799: train_loss -0.8374\n",
      "2024-11-25 20:04:13.826800: val_loss -0.4127\n",
      "2024-11-25 20:04:13.826800: Pseudo dice [0.6977]\n",
      "2024-11-25 20:04:13.836799: Epoch time: 129.8 s\n",
      "2024-11-25 20:04:14.842655: \n",
      "2024-11-25 20:04:14.852648: Epoch 478\n",
      "2024-11-25 20:04:14.852648: Current learning rate: 0.0006\n",
      "2024-11-25 20:06:24.819637: train_loss -0.8563\n",
      "2024-11-25 20:06:24.829637: val_loss -0.3419\n",
      "2024-11-25 20:06:24.829637: Pseudo dice [0.5936]\n",
      "2024-11-25 20:06:24.839637: Epoch time: 129.98 s\n",
      "2024-11-25 20:06:25.849660: \n",
      "2024-11-25 20:06:25.859653: Epoch 479\n",
      "2024-11-25 20:06:25.859653: Current learning rate: 0.00058\n",
      "2024-11-25 20:08:35.636647: train_loss -0.8598\n",
      "2024-11-25 20:08:35.646647: val_loss -0.2497\n",
      "2024-11-25 20:08:35.656648: Pseudo dice [0.6225]\n",
      "2024-11-25 20:08:35.656648: Epoch time: 129.79 s\n",
      "2024-11-25 20:08:36.677008: \n",
      "2024-11-25 20:08:36.677008: Epoch 480\n",
      "2024-11-25 20:08:36.687000: Current learning rate: 0.00055\n",
      "2024-11-25 20:10:46.474004: train_loss -0.8459\n",
      "2024-11-25 20:10:46.484004: val_loss -0.5023\n",
      "2024-11-25 20:10:46.484004: Pseudo dice [0.7207]\n",
      "2024-11-25 20:10:46.494005: Epoch time: 129.81 s\n",
      "2024-11-25 20:10:47.670660: \n",
      "2024-11-25 20:10:47.680653: Epoch 481\n",
      "2024-11-25 20:10:47.680653: Current learning rate: 0.00053\n",
      "2024-11-25 20:12:57.447174: train_loss -0.8578\n",
      "2024-11-25 20:12:57.457174: val_loss -0.4389\n",
      "2024-11-25 20:12:57.457174: Pseudo dice [0.7045]\n",
      "2024-11-25 20:12:57.467174: Epoch time: 129.78 s\n",
      "2024-11-25 20:12:58.480911: \n",
      "2024-11-25 20:12:58.490903: Epoch 482\n",
      "2024-11-25 20:12:58.490903: Current learning rate: 0.0005\n",
      "2024-11-25 20:15:08.347931: train_loss -0.8609\n",
      "2024-11-25 20:15:08.369420: val_loss -0.4972\n",
      "2024-11-25 20:15:08.374420: Pseudo dice [0.7328]\n",
      "2024-11-25 20:15:08.381422: Epoch time: 129.87 s\n",
      "2024-11-25 20:15:09.384592: \n",
      "2024-11-25 20:15:09.394593: Epoch 483\n",
      "2024-11-25 20:15:09.394593: Current learning rate: 0.00048\n",
      "2024-11-25 20:17:19.181007: train_loss -0.8555\n",
      "2024-11-25 20:17:19.191007: val_loss -0.4759\n",
      "2024-11-25 20:17:19.201008: Pseudo dice [0.7265]\n",
      "2024-11-25 20:17:19.211008: Epoch time: 129.8 s\n",
      "2024-11-25 20:17:20.221031: \n",
      "2024-11-25 20:17:20.231021: Epoch 484\n",
      "2024-11-25 20:17:20.231021: Current learning rate: 0.00045\n",
      "2024-11-25 20:19:30.051305: train_loss -0.858\n",
      "2024-11-25 20:19:30.061304: val_loss -0.454\n",
      "2024-11-25 20:19:30.071305: Pseudo dice [0.7305]\n",
      "2024-11-25 20:19:30.081304: Epoch time: 129.83 s\n",
      "2024-11-25 20:19:31.091688: \n",
      "2024-11-25 20:19:31.101688: Epoch 485\n",
      "2024-11-25 20:19:31.101688: Current learning rate: 0.00043\n",
      "2024-11-25 20:21:40.918342: train_loss -0.8491\n",
      "2024-11-25 20:21:40.928343: val_loss -0.4459\n",
      "2024-11-25 20:21:40.928343: Pseudo dice [0.708]\n",
      "2024-11-25 20:21:40.938343: Epoch time: 129.83 s\n",
      "2024-11-25 20:21:41.958706: \n",
      "2024-11-25 20:21:41.958706: Epoch 486\n",
      "2024-11-25 20:21:41.968707: Current learning rate: 0.0004\n",
      "2024-11-25 20:23:51.895301: train_loss -0.8559\n",
      "2024-11-25 20:23:51.905301: val_loss -0.3758\n",
      "2024-11-25 20:23:51.915301: Pseudo dice [0.6761]\n",
      "2024-11-25 20:23:51.925301: Epoch time: 129.94 s\n",
      "2024-11-25 20:23:52.935673: \n",
      "2024-11-25 20:23:52.945664: Epoch 487\n",
      "2024-11-25 20:23:52.945664: Current learning rate: 0.00037\n",
      "2024-11-25 20:26:02.773431: train_loss -0.8538\n",
      "2024-11-25 20:26:02.783432: val_loss -0.425\n",
      "2024-11-25 20:26:02.793432: Pseudo dice [0.726]\n",
      "2024-11-25 20:26:02.793432: Epoch time: 129.84 s\n",
      "2024-11-25 20:26:03.982644: \n",
      "2024-11-25 20:26:03.982644: Epoch 488\n",
      "2024-11-25 20:26:03.992639: Current learning rate: 0.00035\n",
      "2024-11-25 20:28:13.805775: train_loss -0.8569\n",
      "2024-11-25 20:28:13.805775: val_loss -0.3361\n",
      "2024-11-25 20:28:13.815775: Pseudo dice [0.6274]\n",
      "2024-11-25 20:28:13.825775: Epoch time: 129.82 s\n",
      "2024-11-25 20:28:14.846702: \n",
      "2024-11-25 20:28:14.846702: Epoch 489\n",
      "2024-11-25 20:28:14.856701: Current learning rate: 0.00032\n",
      "2024-11-25 20:30:24.679895: train_loss -0.8515\n",
      "2024-11-25 20:30:24.689895: val_loss -0.4811\n",
      "2024-11-25 20:30:24.699895: Pseudo dice [0.7418]\n",
      "2024-11-25 20:30:24.709896: Epoch time: 129.83 s\n",
      "2024-11-25 20:30:25.719922: \n",
      "2024-11-25 20:30:25.719922: Epoch 490\n",
      "2024-11-25 20:30:25.729918: Current learning rate: 0.0003\n",
      "2024-11-25 20:32:35.666367: train_loss -0.8405\n",
      "2024-11-25 20:32:35.676367: val_loss -0.4271\n",
      "2024-11-25 20:32:35.686368: Pseudo dice [0.6951]\n",
      "2024-11-25 20:32:35.686368: Epoch time: 129.94 s\n",
      "2024-11-25 20:32:36.703448: \n",
      "2024-11-25 20:32:36.713440: Epoch 491\n",
      "2024-11-25 20:32:36.713440: Current learning rate: 0.00027\n",
      "2024-11-25 20:34:46.553309: train_loss -0.8588\n",
      "2024-11-25 20:34:46.563309: val_loss -0.4734\n",
      "2024-11-25 20:34:46.573309: Pseudo dice [0.697]\n",
      "2024-11-25 20:34:46.583310: Epoch time: 129.85 s\n",
      "2024-11-25 20:34:47.593747: \n",
      "2024-11-25 20:34:47.593747: Epoch 492\n",
      "2024-11-25 20:34:47.603736: Current learning rate: 0.00024\n",
      "2024-11-25 20:36:57.497471: train_loss -0.8542\n",
      "2024-11-25 20:36:57.507472: val_loss -0.4857\n",
      "2024-11-25 20:36:57.517472: Pseudo dice [0.7212]\n",
      "2024-11-25 20:36:57.517472: Epoch time: 129.9 s\n",
      "2024-11-25 20:36:58.537496: \n",
      "2024-11-25 20:36:58.537496: Epoch 493\n",
      "2024-11-25 20:36:58.547494: Current learning rate: 0.00021\n",
      "2024-11-25 20:39:08.437150: train_loss -0.8516\n",
      "2024-11-25 20:39:08.447151: val_loss -0.5015\n",
      "2024-11-25 20:39:08.457151: Pseudo dice [0.7546]\n",
      "2024-11-25 20:39:08.457151: Epoch time: 129.9 s\n",
      "2024-11-25 20:39:09.477118: \n",
      "2024-11-25 20:39:09.477118: Epoch 494\n",
      "2024-11-25 20:39:09.487108: Current learning rate: 0.00019\n",
      "2024-11-25 20:41:19.470796: train_loss -0.8611\n",
      "2024-11-25 20:41:19.500796: val_loss -0.405\n",
      "2024-11-25 20:41:19.510797: Pseudo dice [0.6947]\n",
      "2024-11-25 20:41:19.510797: Epoch time: 129.99 s\n",
      "2024-11-25 20:41:20.531228: \n",
      "2024-11-25 20:41:20.531228: Epoch 495\n",
      "2024-11-25 20:41:20.541219: Current learning rate: 0.00016\n",
      "2024-11-25 20:43:30.372737: train_loss -0.8611\n",
      "2024-11-25 20:43:30.382737: val_loss -0.4282\n",
      "2024-11-25 20:43:30.382737: Pseudo dice [0.6961]\n",
      "2024-11-25 20:43:30.392737: Epoch time: 129.85 s\n",
      "2024-11-25 20:43:31.597693: \n",
      "2024-11-25 20:43:31.607693: Epoch 496\n",
      "2024-11-25 20:43:31.607693: Current learning rate: 0.00013\n",
      "2024-11-25 20:45:41.462379: train_loss -0.8592\n",
      "2024-11-25 20:45:41.471512: val_loss -0.4431\n",
      "2024-11-25 20:45:41.477651: Pseudo dice [0.7296]\n",
      "2024-11-25 20:45:41.484747: Epoch time: 129.86 s\n",
      "2024-11-25 20:45:42.502775: \n",
      "2024-11-25 20:45:42.512766: Epoch 497\n",
      "2024-11-25 20:45:42.512766: Current learning rate: 0.0001\n",
      "2024-11-25 20:47:52.408252: train_loss -0.8642\n",
      "2024-11-25 20:47:52.428252: val_loss -0.437\n",
      "2024-11-25 20:47:52.428252: Pseudo dice [0.7023]\n",
      "2024-11-25 20:47:52.428252: Epoch time: 129.91 s\n",
      "2024-11-25 20:47:53.448557: \n",
      "2024-11-25 20:47:53.448557: Epoch 498\n",
      "2024-11-25 20:47:53.458557: Current learning rate: 7e-05\n",
      "2024-11-25 20:50:03.352422: train_loss -0.8585\n",
      "2024-11-25 20:50:03.362422: val_loss -0.5383\n",
      "2024-11-25 20:50:03.362422: Pseudo dice [0.7688]\n",
      "2024-11-25 20:50:03.372423: Epoch time: 129.91 s\n",
      "2024-11-25 20:50:04.389002: \n",
      "2024-11-25 20:50:04.399002: Epoch 499\n",
      "2024-11-25 20:50:04.399002: Current learning rate: 4e-05\n",
      "2024-11-25 20:52:14.266270: train_loss -0.8485\n",
      "2024-11-25 20:52:14.276269: val_loss -0.3369\n",
      "2024-11-25 20:52:14.286270: Pseudo dice [0.6679]\n",
      "2024-11-25 20:52:14.286270: Epoch time: 129.88 s\n",
      "2024-11-25 20:52:15.585966: Training done.\n",
      "2024-11-25 20:52:15.635968: Using splits from existing split file: D:/Liver Segmentation Meena 2024/nnUNet_blastoma_2025/nnUNet_preprocessed\\Dataset007_Blastoma\\splits_final.json\n",
      "2024-11-25 20:52:15.655968: The split file contains 5 splits.\n",
      "2024-11-25 20:52:15.665968: Desired fold for training: 2\n",
      "2024-11-25 20:52:15.675968: This split has 19 training and 5 validation cases.\n",
      "2024-11-25 20:52:15.675968: predicting volume_16\n",
      "2024-11-25 20:52:15.695968: volume_16, shape torch.Size([1, 513, 414, 414]), rank 0\n",
      "2024-11-25 20:55:09.771247: predicting volume_35\n",
      "2024-11-25 20:55:09.821247: volume_35, shape torch.Size([1, 537, 543, 543]), rank 0\n",
      "2024-11-25 21:00:15.588015: predicting volume_37\n",
      "2024-11-25 21:00:15.658018: volume_37, shape torch.Size([1, 1026, 590, 590]), rank 0\n",
      "2024-11-25 21:13:10.762559: predicting volume_4\n",
      "2024-11-25 21:13:10.912788: volume_4, shape torch.Size([1, 562, 512, 512]), rank 0\n",
      "2024-11-25 21:17:05.979231: predicting volume_5\n",
      "2024-11-25 21:17:06.049226: volume_5, shape torch.Size([1, 721, 524, 524]), rank 0\n",
      "2024-11-25 21:24:43.594740: Validation complete\n",
      "2024-11-25 21:24:43.604741: Mean Validation Dice:  0.610648666627063\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "try:\n",
    "    !nnUNetv2_train 007 3d_fullres 2 -tr nnUNetTrainer\n",
    "except Exception as e:\n",
    "    print(f\"Error during training: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2024-12-05 04:18:30.338700: do_dummy_2d_data_aug: False\n",
      "2024-12-05 04:18:30.344702: Using splits from existing split file: D:/Liver Segmentation Meena 2024/nnUNet_blastoma_2025/nnUNet_preprocessed\\Dataset007_Blastoma\\splits_final.json\n",
      "2024-12-05 04:18:30.352703: The split file contains 5 splits.\n",
      "2024-12-05 04:18:30.356078: Desired fold for training: 4\n",
      "2024-12-05 04:18:30.359080: This split has 20 training and 4 validation cases.\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 0\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 3d_fullres\n",
      " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [569.5, 512.0, 512.0], 'spacing': [0.625, 0.4882810115814209, 0.4882810115814209], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset007_Blastoma', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.625, 0.4882810115814209, 0.4882810115814209], 'original_median_shape_after_transp': [471, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2609.056396484375, 'mean': 68.07295227050781, 'median': 66.0, 'min': -1028.0, 'percentile_00_5': -59.0, 'percentile_99_5': 248.0, 'std': 47.62541198730469}}} \n",
      "\n",
      "2024-12-05 04:18:42.715091: unpacking dataset...\n",
      "2024-12-05 04:18:43.030163: unpacking done...\n",
      "2024-12-05 04:18:43.050167: Unable to plot network architecture:\n",
      "2024-12-05 04:18:43.057170: No module named 'hiddenlayer'\n",
      "2024-12-05 04:18:43.093177: \n",
      "2024-12-05 04:18:43.101179: Epoch 0\n",
      "2024-12-05 04:18:43.108183: Current learning rate: 0.01\n",
      "2024-12-05 04:21:11.061758: train_loss 0.0772\n",
      "2024-12-05 04:21:11.069605: val_loss 0.1003\n",
      "2024-12-05 04:21:11.074605: Pseudo dice [0.3685]\n",
      "2024-12-05 04:21:11.078607: Epoch time: 147.97 s\n",
      "2024-12-05 04:21:11.083607: Yayy! New best EMA pseudo Dice: 0.3685\n",
      "2024-12-05 04:21:12.590400: \n",
      "2024-12-05 04:21:12.597401: Epoch 1\n",
      "2024-12-05 04:21:12.602402: Current learning rate: 0.00999\n",
      "2024-12-05 04:23:29.639119: train_loss -0.1003\n",
      "2024-12-05 04:23:29.647122: val_loss -0.0413\n",
      "2024-12-05 04:23:29.656124: Pseudo dice [0.4813]\n",
      "2024-12-05 04:23:29.662124: Epoch time: 137.05 s\n",
      "2024-12-05 04:23:29.666125: Yayy! New best EMA pseudo Dice: 0.3798\n",
      "2024-12-05 04:23:30.903372: \n",
      "2024-12-05 04:23:30.911374: Epoch 2\n",
      "2024-12-05 04:23:30.916375: Current learning rate: 0.00998\n",
      "2024-12-05 04:25:43.330947: train_loss -0.1987\n",
      "2024-12-05 04:25:43.340946: val_loss -0.022\n",
      "2024-12-05 04:25:43.346634: Pseudo dice [0.4801]\n",
      "2024-12-05 04:25:43.346634: Epoch time: 132.43 s\n",
      "2024-12-05 04:25:43.363092: Yayy! New best EMA pseudo Dice: 0.3898\n",
      "2024-12-05 04:25:44.629609: \n",
      "2024-12-05 04:25:44.629609: Epoch 3\n",
      "2024-12-05 04:25:44.639112: Current learning rate: 0.00997\n",
      "2024-12-05 04:27:55.943316: train_loss -0.2162\n",
      "2024-12-05 04:27:55.959969: val_loss -0.146\n",
      "2024-12-05 04:27:55.959969: Pseudo dice [0.5682]\n",
      "2024-12-05 04:27:55.969968: Epoch time: 131.31 s\n",
      "2024-12-05 04:27:55.976697: Yayy! New best EMA pseudo Dice: 0.4077\n",
      "2024-12-05 04:27:57.227669: \n",
      "2024-12-05 04:27:57.227669: Epoch 4\n",
      "2024-12-05 04:27:57.237676: Current learning rate: 0.00996\n",
      "2024-12-05 04:30:08.667769: train_loss -0.2558\n",
      "2024-12-05 04:30:08.673887: val_loss -0.0492\n",
      "2024-12-05 04:30:08.673887: Pseudo dice [0.457]\n",
      "2024-12-05 04:30:08.690288: Epoch time: 131.44 s\n",
      "2024-12-05 04:30:08.690288: Yayy! New best EMA pseudo Dice: 0.4126\n",
      "2024-12-05 04:30:09.973692: \n",
      "2024-12-05 04:30:09.973692: Epoch 5\n",
      "2024-12-05 04:30:09.983698: Current learning rate: 0.00995\n",
      "2024-12-05 04:32:21.203888: train_loss -0.2724\n",
      "2024-12-05 04:32:21.213887: val_loss -0.1187\n",
      "2024-12-05 04:32:21.220708: Pseudo dice [0.5241]\n",
      "2024-12-05 04:32:21.220708: Epoch time: 131.23 s\n",
      "2024-12-05 04:32:21.230707: Yayy! New best EMA pseudo Dice: 0.4238\n",
      "2024-12-05 04:32:22.447466: \n",
      "2024-12-05 04:32:22.453887: Epoch 6\n",
      "2024-12-05 04:32:22.453887: Current learning rate: 0.00995\n",
      "2024-12-05 04:34:33.950997: train_loss -0.2397\n",
      "2024-12-05 04:34:33.950997: val_loss -0.2568\n",
      "2024-12-05 04:34:33.961999: Pseudo dice [0.5693]\n",
      "2024-12-05 04:34:33.968000: Epoch time: 131.5 s\n",
      "2024-12-05 04:34:33.975001: Yayy! New best EMA pseudo Dice: 0.4383\n",
      "2024-12-05 04:34:35.431553: \n",
      "2024-12-05 04:34:35.431553: Epoch 7\n",
      "2024-12-05 04:34:35.438555: Current learning rate: 0.00994\n",
      "2024-12-05 04:36:47.115545: train_loss -0.3371\n",
      "2024-12-05 04:36:47.115545: val_loss -0.2164\n",
      "2024-12-05 04:36:47.125544: Pseudo dice [0.6132]\n",
      "2024-12-05 04:36:47.131635: Epoch time: 131.68 s\n",
      "2024-12-05 04:36:47.131635: Yayy! New best EMA pseudo Dice: 0.4558\n",
      "2024-12-05 04:36:48.475372: \n",
      "2024-12-05 04:36:48.481204: Epoch 8\n",
      "2024-12-05 04:36:48.491202: Current learning rate: 0.00993\n",
      "2024-12-05 04:38:59.762298: train_loss -0.3433\n",
      "2024-12-05 04:38:59.763230: val_loss -0.2232\n",
      "2024-12-05 04:38:59.778232: Pseudo dice [0.5812]\n",
      "2024-12-05 04:38:59.778232: Epoch time: 131.29 s\n",
      "2024-12-05 04:38:59.788231: Yayy! New best EMA pseudo Dice: 0.4683\n",
      "2024-12-05 04:39:01.104822: \n",
      "2024-12-05 04:39:01.113340: Epoch 9\n",
      "2024-12-05 04:39:01.118340: Current learning rate: 0.00992\n",
      "2024-12-05 04:41:12.425195: train_loss -0.3571\n",
      "2024-12-05 04:41:12.425195: val_loss -0.206\n",
      "2024-12-05 04:41:12.441889: Pseudo dice [0.5605]\n",
      "2024-12-05 04:41:12.446949: Epoch time: 131.32 s\n",
      "2024-12-05 04:41:12.450998: Yayy! New best EMA pseudo Dice: 0.4775\n",
      "2024-12-05 04:41:13.691789: \n",
      "2024-12-05 04:41:13.701796: Epoch 10\n",
      "2024-12-05 04:41:13.708468: Current learning rate: 0.00991\n",
      "2024-12-05 04:43:25.055588: train_loss -0.3405\n",
      "2024-12-05 04:43:25.065586: val_loss -0.1917\n",
      "2024-12-05 04:43:25.073025: Pseudo dice [0.5992]\n",
      "2024-12-05 04:43:25.078026: Epoch time: 131.36 s\n",
      "2024-12-05 04:43:25.083027: Yayy! New best EMA pseudo Dice: 0.4897\n",
      "2024-12-05 04:43:26.323007: \n",
      "2024-12-05 04:43:26.323007: Epoch 11\n",
      "2024-12-05 04:43:26.333006: Current learning rate: 0.0099\n",
      "2024-12-05 04:45:37.602196: train_loss -0.341\n",
      "2024-12-05 04:45:37.619277: val_loss -0.2024\n",
      "2024-12-05 04:45:37.619277: Pseudo dice [0.5834]\n",
      "2024-12-05 04:45:37.629275: Epoch time: 131.28 s\n",
      "2024-12-05 04:45:37.635880: Yayy! New best EMA pseudo Dice: 0.4991\n",
      "2024-12-05 04:45:38.936886: \n",
      "2024-12-05 04:45:38.952304: Epoch 12\n",
      "2024-12-05 04:45:38.957321: Current learning rate: 0.00989\n",
      "2024-12-05 04:47:50.266183: train_loss -0.4225\n",
      "2024-12-05 04:47:50.276182: val_loss -0.1355\n",
      "2024-12-05 04:47:50.285830: Pseudo dice [0.576]\n",
      "2024-12-05 04:47:50.285830: Epoch time: 131.33 s\n",
      "2024-12-05 04:47:50.295830: Yayy! New best EMA pseudo Dice: 0.5068\n",
      "2024-12-05 04:47:51.582717: \n",
      "2024-12-05 04:47:51.599150: Epoch 13\n",
      "2024-12-05 04:47:51.599374: Current learning rate: 0.00988\n",
      "2024-12-05 04:50:06.403820: train_loss -0.3811\n",
      "2024-12-05 04:50:06.403820: val_loss -0.1383\n",
      "2024-12-05 04:50:06.417824: Pseudo dice [0.5795]\n",
      "2024-12-05 04:50:06.427825: Epoch time: 134.82 s\n",
      "2024-12-05 04:50:06.435826: Yayy! New best EMA pseudo Dice: 0.514\n",
      "2024-12-05 04:50:07.916152: \n",
      "2024-12-05 04:50:07.923154: Epoch 14\n",
      "2024-12-05 04:50:07.927154: Current learning rate: 0.00987\n",
      "2024-12-05 04:52:19.181213: train_loss -0.3413\n",
      "2024-12-05 04:52:19.189215: val_loss -0.2056\n",
      "2024-12-05 04:52:19.198217: Pseudo dice [0.6254]\n",
      "2024-12-05 04:52:19.205218: Epoch time: 131.27 s\n",
      "2024-12-05 04:52:19.211220: Yayy! New best EMA pseudo Dice: 0.5252\n",
      "2024-12-05 04:52:20.513988: \n",
      "2024-12-05 04:52:20.520991: Epoch 15\n",
      "2024-12-05 04:52:20.526992: Current learning rate: 0.00986\n",
      "2024-12-05 04:54:31.814753: train_loss -0.4135\n",
      "2024-12-05 04:54:31.824883: val_loss -0.2197\n",
      "2024-12-05 04:54:31.833926: Pseudo dice [0.5726]\n",
      "2024-12-05 04:54:31.839927: Epoch time: 131.3 s\n",
      "2024-12-05 04:54:31.845928: Yayy! New best EMA pseudo Dice: 0.5299\n",
      "2024-12-05 04:54:33.179317: \n",
      "2024-12-05 04:54:33.187317: Epoch 16\n",
      "2024-12-05 04:54:33.192318: Current learning rate: 0.00986\n",
      "2024-12-05 04:56:44.099331: train_loss -0.4389\n",
      "2024-12-05 04:56:44.109333: val_loss -0.1379\n",
      "2024-12-05 04:56:44.115334: Pseudo dice [0.5503]\n",
      "2024-12-05 04:56:44.120335: Epoch time: 130.92 s\n",
      "2024-12-05 04:56:44.129337: Yayy! New best EMA pseudo Dice: 0.532\n",
      "2024-12-05 04:56:45.417936: \n",
      "2024-12-05 04:56:45.427939: Epoch 17\n",
      "2024-12-05 04:56:45.433940: Current learning rate: 0.00985\n",
      "2024-12-05 04:58:55.816919: train_loss -0.4008\n",
      "2024-12-05 04:58:55.816919: val_loss -0.2519\n",
      "2024-12-05 04:58:55.826919: Pseudo dice [0.6283]\n",
      "2024-12-05 04:58:55.839400: Epoch time: 130.4 s\n",
      "2024-12-05 04:58:55.844692: Yayy! New best EMA pseudo Dice: 0.5416\n",
      "2024-12-05 04:58:57.134229: \n",
      "2024-12-05 04:58:57.134229: Epoch 18\n",
      "2024-12-05 04:58:57.144229: Current learning rate: 0.00984\n",
      "2024-12-05 05:01:08.083869: train_loss -0.4102\n",
      "2024-12-05 05:01:08.083869: val_loss -0.243\n",
      "2024-12-05 05:01:08.093869: Pseudo dice [0.6495]\n",
      "2024-12-05 05:01:08.103869: Epoch time: 130.95 s\n",
      "2024-12-05 05:01:08.113868: Yayy! New best EMA pseudo Dice: 0.5524\n",
      "2024-12-05 05:01:09.400269: \n",
      "2024-12-05 05:01:09.400269: Epoch 19\n",
      "2024-12-05 05:01:09.400269: Current learning rate: 0.00983\n",
      "2024-12-05 05:03:21.172155: train_loss -0.4176\n",
      "2024-12-05 05:03:21.173155: val_loss -0.3123\n",
      "2024-12-05 05:03:21.191084: Pseudo dice [0.5928]\n",
      "2024-12-05 05:03:21.194683: Epoch time: 131.77 s\n",
      "2024-12-05 05:03:21.204186: Yayy! New best EMA pseudo Dice: 0.5564\n",
      "2024-12-05 05:03:22.528237: \n",
      "2024-12-05 05:03:22.538237: Epoch 20\n",
      "2024-12-05 05:03:22.545658: Current learning rate: 0.00982\n",
      "2024-12-05 05:05:33.559367: train_loss -0.4385\n",
      "2024-12-05 05:05:33.560367: val_loss 0.0113\n",
      "2024-12-05 05:05:33.569368: Pseudo dice [0.3789]\n",
      "2024-12-05 05:05:33.575001: Epoch time: 131.03 s\n",
      "2024-12-05 05:05:34.785207: \n",
      "2024-12-05 05:05:34.785207: Epoch 21\n",
      "2024-12-05 05:05:34.791839: Current learning rate: 0.00981\n",
      "2024-12-05 05:07:45.832654: train_loss -0.4103\n",
      "2024-12-05 05:07:45.833654: val_loss -0.3028\n",
      "2024-12-05 05:07:45.842395: Pseudo dice [0.6953]\n",
      "2024-12-05 05:07:45.850398: Epoch time: 131.05 s\n",
      "2024-12-05 05:07:46.822228: \n",
      "2024-12-05 05:07:46.822228: Epoch 22\n",
      "2024-12-05 05:07:46.838709: Current learning rate: 0.0098\n",
      "2024-12-05 05:09:57.830052: train_loss -0.4438\n",
      "2024-12-05 05:09:57.830052: val_loss -0.2312\n",
      "2024-12-05 05:09:57.835658: Pseudo dice [0.621]\n",
      "2024-12-05 05:09:57.845160: Epoch time: 131.01 s\n",
      "2024-12-05 05:09:57.855163: Yayy! New best EMA pseudo Dice: 0.561\n",
      "2024-12-05 05:09:59.112532: \n",
      "2024-12-05 05:09:59.112532: Epoch 23\n",
      "2024-12-05 05:09:59.119426: Current learning rate: 0.00979\n",
      "2024-12-05 05:12:10.482156: train_loss -0.4499\n",
      "2024-12-05 05:12:10.482156: val_loss -0.1698\n",
      "2024-12-05 05:12:10.492830: Pseudo dice [0.6108]\n",
      "2024-12-05 05:12:10.498898: Epoch time: 131.38 s\n",
      "2024-12-05 05:12:10.504364: Yayy! New best EMA pseudo Dice: 0.566\n",
      "2024-12-05 05:12:11.816313: \n",
      "2024-12-05 05:12:11.816313: Epoch 24\n",
      "2024-12-05 05:12:11.826313: Current learning rate: 0.00978\n",
      "2024-12-05 05:14:22.792465: train_loss -0.4352\n",
      "2024-12-05 05:14:22.792465: val_loss -0.2677\n",
      "2024-12-05 05:14:22.804901: Pseudo dice [0.6556]\n",
      "2024-12-05 05:14:22.810928: Epoch time: 130.98 s\n",
      "2024-12-05 05:14:22.817021: Yayy! New best EMA pseudo Dice: 0.5749\n",
      "2024-12-05 05:14:24.047567: \n",
      "2024-12-05 05:14:24.047567: Epoch 25\n",
      "2024-12-05 05:14:24.063174: Current learning rate: 0.00977\n",
      "2024-12-05 05:16:35.129466: train_loss -0.4773\n",
      "2024-12-05 05:16:35.129466: val_loss -0.219\n",
      "2024-12-05 05:16:35.147329: Pseudo dice [0.6275]\n",
      "2024-12-05 05:16:35.153331: Epoch time: 131.08 s\n",
      "2024-12-05 05:16:35.159941: Yayy! New best EMA pseudo Dice: 0.5802\n",
      "2024-12-05 05:16:36.454313: \n",
      "2024-12-05 05:16:36.455326: Epoch 26\n",
      "2024-12-05 05:16:36.462711: Current learning rate: 0.00977\n",
      "2024-12-05 05:18:47.538693: train_loss -0.4445\n",
      "2024-12-05 05:18:47.538693: val_loss -0.2004\n",
      "2024-12-05 05:18:47.540693: Pseudo dice [0.6091]\n",
      "2024-12-05 05:18:47.550706: Epoch time: 131.09 s\n",
      "2024-12-05 05:18:47.560707: Yayy! New best EMA pseudo Dice: 0.5831\n",
      "2024-12-05 05:18:48.807120: \n",
      "2024-12-05 05:18:48.807120: Epoch 27\n",
      "2024-12-05 05:18:48.823803: Current learning rate: 0.00976\n",
      "2024-12-05 05:21:00.333403: train_loss -0.5028\n",
      "2024-12-05 05:21:00.333985: val_loss -0.2332\n",
      "2024-12-05 05:21:00.344317: Pseudo dice [0.6393]\n",
      "2024-12-05 05:21:00.351319: Epoch time: 131.53 s\n",
      "2024-12-05 05:21:00.353924: Yayy! New best EMA pseudo Dice: 0.5887\n",
      "2024-12-05 05:21:01.826893: \n",
      "2024-12-05 05:21:01.826893: Epoch 28\n",
      "2024-12-05 05:21:01.834895: Current learning rate: 0.00975\n",
      "2024-12-05 05:23:12.890395: train_loss -0.5221\n",
      "2024-12-05 05:23:12.900396: val_loss -0.2486\n",
      "2024-12-05 05:23:12.900396: Pseudo dice [0.7018]\n",
      "2024-12-05 05:23:12.910395: Epoch time: 131.06 s\n",
      "2024-12-05 05:23:12.923402: Yayy! New best EMA pseudo Dice: 0.6\n",
      "2024-12-05 05:23:14.167708: \n",
      "2024-12-05 05:23:14.167708: Epoch 29\n",
      "2024-12-05 05:23:14.177707: Current learning rate: 0.00974\n",
      "2024-12-05 05:25:25.209652: train_loss -0.5187\n",
      "2024-12-05 05:25:25.209652: val_loss -0.2774\n",
      "2024-12-05 05:25:25.271173: Pseudo dice [0.7651]\n",
      "2024-12-05 05:25:25.271173: Epoch time: 131.04 s\n",
      "2024-12-05 05:25:25.281174: Yayy! New best EMA pseudo Dice: 0.6165\n",
      "2024-12-05 05:25:26.541403: \n",
      "2024-12-05 05:25:26.541403: Epoch 30\n",
      "2024-12-05 05:25:26.548071: Current learning rate: 0.00973\n",
      "2024-12-05 05:27:37.558688: train_loss -0.4681\n",
      "2024-12-05 05:27:37.558688: val_loss -0.1908\n",
      "2024-12-05 05:27:37.568689: Pseudo dice [0.5888]\n",
      "2024-12-05 05:27:37.578689: Epoch time: 131.02 s\n",
      "2024-12-05 05:27:38.606266: \n",
      "2024-12-05 05:27:38.606266: Epoch 31\n",
      "2024-12-05 05:27:38.611744: Current learning rate: 0.00972\n",
      "2024-12-05 05:29:49.951365: train_loss -0.4903\n",
      "2024-12-05 05:29:49.951365: val_loss -0.4383\n",
      "2024-12-05 05:29:49.961366: Pseudo dice [0.767]\n",
      "2024-12-05 05:29:49.971367: Epoch time: 131.35 s\n",
      "2024-12-05 05:29:49.971367: Yayy! New best EMA pseudo Dice: 0.6291\n",
      "2024-12-05 05:29:51.318739: \n",
      "2024-12-05 05:29:51.318739: Epoch 32\n",
      "2024-12-05 05:29:51.326622: Current learning rate: 0.00971\n",
      "2024-12-05 05:32:02.238880: train_loss -0.5086\n",
      "2024-12-05 05:32:02.238880: val_loss -0.1487\n",
      "2024-12-05 05:32:02.248384: Pseudo dice [0.6265]\n",
      "2024-12-05 05:32:02.258386: Epoch time: 130.92 s\n",
      "2024-12-05 05:32:03.357681: \n",
      "2024-12-05 05:32:03.357681: Epoch 33\n",
      "2024-12-05 05:32:03.367680: Current learning rate: 0.0097\n",
      "2024-12-05 05:34:14.372061: train_loss -0.5265\n",
      "2024-12-05 05:34:14.372061: val_loss -0.2958\n",
      "2024-12-05 05:34:14.382061: Pseudo dice [0.7094]\n",
      "2024-12-05 05:34:14.402644: Epoch time: 131.01 s\n",
      "2024-12-05 05:34:14.407818: Yayy! New best EMA pseudo Dice: 0.6369\n",
      "2024-12-05 05:34:15.669564: \n",
      "2024-12-05 05:34:15.669564: Epoch 34\n",
      "2024-12-05 05:34:15.669564: Current learning rate: 0.00969\n",
      "2024-12-05 05:36:26.715764: train_loss -0.4917\n",
      "2024-12-05 05:36:26.716214: val_loss -0.2264\n",
      "2024-12-05 05:36:26.726211: Pseudo dice [0.644]\n",
      "2024-12-05 05:36:26.736212: Epoch time: 131.05 s\n",
      "2024-12-05 05:36:26.736212: Yayy! New best EMA pseudo Dice: 0.6376\n",
      "2024-12-05 05:36:28.195911: \n",
      "2024-12-05 05:36:28.195911: Epoch 35\n",
      "2024-12-05 05:36:28.199498: Current learning rate: 0.00968\n",
      "2024-12-05 05:38:39.168961: train_loss -0.5334\n",
      "2024-12-05 05:38:39.168961: val_loss -0.2689\n",
      "2024-12-05 05:38:39.178963: Pseudo dice [0.6916]\n",
      "2024-12-05 05:38:39.187954: Epoch time: 130.97 s\n",
      "2024-12-05 05:38:39.194956: Yayy! New best EMA pseudo Dice: 0.643\n",
      "2024-12-05 05:38:40.491959: \n",
      "2024-12-05 05:38:40.491959: Epoch 36\n",
      "2024-12-05 05:38:40.496727: Current learning rate: 0.00968\n",
      "2024-12-05 05:40:51.496153: train_loss -0.5093\n",
      "2024-12-05 05:40:51.496153: val_loss -0.3066\n",
      "2024-12-05 05:40:51.510200: Pseudo dice [0.5991]\n",
      "2024-12-05 05:40:51.515203: Epoch time: 131.0 s\n",
      "2024-12-05 05:40:52.577278: \n",
      "2024-12-05 05:40:52.577278: Epoch 37\n",
      "2024-12-05 05:40:52.587276: Current learning rate: 0.00967\n",
      "2024-12-05 05:43:03.580029: train_loss -0.5601\n",
      "2024-12-05 05:43:03.580029: val_loss -0.2703\n",
      "2024-12-05 05:43:03.590029: Pseudo dice [0.7238]\n",
      "2024-12-05 05:43:03.590029: Epoch time: 131.0 s\n",
      "2024-12-05 05:43:03.600030: Yayy! New best EMA pseudo Dice: 0.6471\n",
      "2024-12-05 05:43:04.884064: \n",
      "2024-12-05 05:43:04.884064: Epoch 38\n",
      "2024-12-05 05:43:04.890707: Current learning rate: 0.00966\n",
      "2024-12-05 05:45:15.967534: train_loss -0.494\n",
      "2024-12-05 05:45:15.967534: val_loss -0.102\n",
      "2024-12-05 05:45:15.987529: Pseudo dice [0.525]\n",
      "2024-12-05 05:45:15.994533: Epoch time: 131.08 s\n",
      "2024-12-05 05:45:17.182999: \n",
      "2024-12-05 05:45:17.182999: Epoch 39\n",
      "2024-12-05 05:45:17.187703: Current learning rate: 0.00965\n",
      "2024-12-05 05:47:28.680689: train_loss -0.547\n",
      "2024-12-05 05:47:28.680689: val_loss -0.3114\n",
      "2024-12-05 05:47:28.692386: Pseudo dice [0.7777]\n",
      "2024-12-05 05:47:28.697401: Epoch time: 131.5 s\n",
      "2024-12-05 05:47:28.702333: Yayy! New best EMA pseudo Dice: 0.6492\n",
      "2024-12-05 05:47:30.003150: \n",
      "2024-12-05 05:47:30.003150: Epoch 40\n",
      "2024-12-05 05:47:30.013181: Current learning rate: 0.00964\n",
      "2024-12-05 05:49:40.974333: train_loss -0.5238\n",
      "2024-12-05 05:49:40.974333: val_loss -0.3108\n",
      "2024-12-05 05:49:40.985513: Pseudo dice [0.7287]\n",
      "2024-12-05 05:49:40.986697: Epoch time: 130.97 s\n",
      "2024-12-05 05:49:41.000161: Yayy! New best EMA pseudo Dice: 0.6571\n",
      "2024-12-05 05:49:42.458154: \n",
      "2024-12-05 05:49:42.458154: Epoch 41\n",
      "2024-12-05 05:49:42.468155: Current learning rate: 0.00963\n",
      "2024-12-05 05:51:53.413407: train_loss -0.5747\n",
      "2024-12-05 05:51:53.413407: val_loss -0.1819\n",
      "2024-12-05 05:51:53.423431: Pseudo dice [0.6507]\n",
      "2024-12-05 05:51:53.430526: Epoch time: 130.96 s\n",
      "2024-12-05 05:51:54.463040: \n",
      "2024-12-05 05:51:54.463040: Epoch 42\n",
      "2024-12-05 05:51:54.470139: Current learning rate: 0.00962\n",
      "2024-12-05 05:54:05.493256: train_loss -0.5506\n",
      "2024-12-05 05:54:05.494256: val_loss -0.2073\n",
      "2024-12-05 05:54:05.510936: Pseudo dice [0.6024]\n",
      "2024-12-05 05:54:05.519938: Epoch time: 131.03 s\n",
      "2024-12-05 05:54:06.509052: \n",
      "2024-12-05 05:54:06.509052: Epoch 43\n",
      "2024-12-05 05:54:06.519051: Current learning rate: 0.00961\n",
      "2024-12-05 05:56:18.084556: train_loss -0.5441\n",
      "2024-12-05 05:56:18.084556: val_loss -0.175\n",
      "2024-12-05 05:56:18.094640: Pseudo dice [0.7021]\n",
      "2024-12-05 05:56:18.099641: Epoch time: 131.58 s\n",
      "2024-12-05 05:56:19.182672: \n",
      "2024-12-05 05:56:19.182672: Epoch 44\n",
      "2024-12-05 05:56:19.189344: Current learning rate: 0.0096\n",
      "2024-12-05 05:58:30.111909: train_loss -0.5842\n",
      "2024-12-05 05:58:30.111909: val_loss -0.3876\n",
      "2024-12-05 05:58:30.119537: Pseudo dice [0.7598]\n",
      "2024-12-05 05:58:30.129039: Epoch time: 130.93 s\n",
      "2024-12-05 05:58:30.139041: Yayy! New best EMA pseudo Dice: 0.6665\n",
      "2024-12-05 05:58:31.469678: \n",
      "2024-12-05 05:58:31.469678: Epoch 45\n",
      "2024-12-05 05:58:31.469678: Current learning rate: 0.00959\n",
      "2024-12-05 06:00:42.502323: train_loss -0.5785\n",
      "2024-12-05 06:00:42.502323: val_loss -0.2225\n",
      "2024-12-05 06:00:42.521457: Pseudo dice [0.6689]\n",
      "2024-12-05 06:00:42.527458: Epoch time: 131.04 s\n",
      "2024-12-05 06:00:42.533219: Yayy! New best EMA pseudo Dice: 0.6668\n",
      "2024-12-05 06:00:43.768282: \n",
      "2024-12-05 06:00:43.768282: Epoch 46\n",
      "2024-12-05 06:00:43.783334: Current learning rate: 0.00959\n",
      "2024-12-05 06:02:54.872952: train_loss -0.5835\n",
      "2024-12-05 06:02:54.872952: val_loss -0.2743\n",
      "2024-12-05 06:02:54.882954: Pseudo dice [0.7114]\n",
      "2024-12-05 06:02:54.892954: Epoch time: 131.1 s\n",
      "2024-12-05 06:02:54.892954: Yayy! New best EMA pseudo Dice: 0.6712\n",
      "2024-12-05 06:02:56.130311: \n",
      "2024-12-05 06:02:56.130311: Epoch 47\n",
      "2024-12-05 06:02:56.140309: Current learning rate: 0.00958\n",
      "2024-12-05 06:05:07.743773: train_loss -0.5514\n",
      "2024-12-05 06:05:07.743773: val_loss -0.2823\n",
      "2024-12-05 06:05:07.753275: Pseudo dice [0.6804]\n",
      "2024-12-05 06:05:07.753275: Epoch time: 131.61 s\n",
      "2024-12-05 06:05:07.763276: Yayy! New best EMA pseudo Dice: 0.6722\n",
      "2024-12-05 06:05:09.020669: \n",
      "2024-12-05 06:05:09.020669: Epoch 48\n",
      "2024-12-05 06:05:09.027355: Current learning rate: 0.00957\n",
      "2024-12-05 06:07:20.008461: train_loss -0.5977\n",
      "2024-12-05 06:07:20.009460: val_loss -0.1043\n",
      "2024-12-05 06:07:20.020463: Pseudo dice [0.6651]\n",
      "2024-12-05 06:07:20.028465: Epoch time: 130.99 s\n",
      "2024-12-05 06:07:21.217577: \n",
      "2024-12-05 06:07:21.217577: Epoch 49\n",
      "2024-12-05 06:07:21.224276: Current learning rate: 0.00956\n",
      "2024-12-05 06:09:32.253943: train_loss -0.5832\n",
      "2024-12-05 06:09:32.254266: val_loss -0.1187\n",
      "2024-12-05 06:09:32.268268: Pseudo dice [0.6251]\n",
      "2024-12-05 06:09:32.276374: Epoch time: 131.04 s\n",
      "2024-12-05 06:09:33.604676: \n",
      "2024-12-05 06:09:33.604676: Epoch 50\n",
      "2024-12-05 06:09:33.614675: Current learning rate: 0.00955\n",
      "2024-12-05 06:11:44.632566: train_loss -0.5907\n",
      "2024-12-05 06:11:44.632566: val_loss -0.4035\n",
      "2024-12-05 06:11:44.643803: Pseudo dice [0.8094]\n",
      "2024-12-05 06:11:44.650804: Epoch time: 131.03 s\n",
      "2024-12-05 06:11:44.651444: Yayy! New best EMA pseudo Dice: 0.6811\n",
      "2024-12-05 06:11:45.978312: \n",
      "2024-12-05 06:11:45.978312: Epoch 51\n",
      "2024-12-05 06:11:45.987399: Current learning rate: 0.00954\n",
      "2024-12-05 06:13:56.957496: train_loss -0.6082\n",
      "2024-12-05 06:13:56.957496: val_loss -0.396\n",
      "2024-12-05 06:13:56.970169: Pseudo dice [0.805]\n",
      "2024-12-05 06:13:56.977170: Epoch time: 130.98 s\n",
      "2024-12-05 06:13:56.981768: Yayy! New best EMA pseudo Dice: 0.6935\n",
      "2024-12-05 06:13:58.301041: \n",
      "2024-12-05 06:13:58.301041: Epoch 52\n",
      "2024-12-05 06:13:58.301041: Current learning rate: 0.00953\n",
      "2024-12-05 06:16:09.325774: train_loss -0.5847\n",
      "2024-12-05 06:16:09.325774: val_loss -0.2526\n",
      "2024-12-05 06:16:09.336844: Pseudo dice [0.7474]\n",
      "2024-12-05 06:16:09.342845: Epoch time: 131.03 s\n",
      "2024-12-05 06:16:09.345434: Yayy! New best EMA pseudo Dice: 0.6989\n",
      "2024-12-05 06:16:10.645616: \n",
      "2024-12-05 06:16:10.645616: Epoch 53\n",
      "2024-12-05 06:16:10.662349: Current learning rate: 0.00952\n",
      "2024-12-05 06:18:21.658617: train_loss -0.5971\n",
      "2024-12-05 06:18:21.658617: val_loss -0.3945\n",
      "2024-12-05 06:18:21.668616: Pseudo dice [0.7246]\n",
      "2024-12-05 06:18:21.679870: Epoch time: 131.01 s\n",
      "2024-12-05 06:18:21.689718: Yayy! New best EMA pseudo Dice: 0.7014\n",
      "2024-12-05 06:18:22.961023: \n",
      "2024-12-05 06:18:22.961023: Epoch 54\n",
      "2024-12-05 06:18:22.970526: Current learning rate: 0.00951\n",
      "2024-12-05 06:20:34.018338: train_loss -0.5992\n",
      "2024-12-05 06:20:34.018338: val_loss -0.2507\n",
      "2024-12-05 06:20:34.027829: Pseudo dice [0.7178]\n",
      "2024-12-05 06:20:34.034831: Epoch time: 131.06 s\n",
      "2024-12-05 06:20:34.039831: Yayy! New best EMA pseudo Dice: 0.7031\n",
      "2024-12-05 06:20:35.272730: \n",
      "2024-12-05 06:20:35.272730: Epoch 55\n",
      "2024-12-05 06:20:35.273143: Current learning rate: 0.0095\n",
      "2024-12-05 06:22:46.429241: train_loss -0.5903\n",
      "2024-12-05 06:22:46.429241: val_loss -0.3052\n",
      "2024-12-05 06:22:46.448336: Pseudo dice [0.6915]\n",
      "2024-12-05 06:22:46.456146: Epoch time: 131.16 s\n",
      "2024-12-05 06:22:47.647447: \n",
      "2024-12-05 06:22:47.647447: Epoch 56\n",
      "2024-12-05 06:22:47.653276: Current learning rate: 0.00949\n",
      "2024-12-05 06:24:58.697507: train_loss -0.5442\n",
      "2024-12-05 06:24:58.697507: val_loss -0.3206\n",
      "2024-12-05 06:24:58.700078: Pseudo dice [0.6502]\n",
      "2024-12-05 06:24:58.709581: Epoch time: 131.05 s\n",
      "2024-12-05 06:24:59.776920: \n",
      "2024-12-05 06:24:59.776920: Epoch 57\n",
      "2024-12-05 06:24:59.783558: Current learning rate: 0.00949\n",
      "2024-12-05 06:27:10.723236: train_loss -0.6039\n",
      "2024-12-05 06:27:10.723236: val_loss -0.1688\n",
      "2024-12-05 06:27:10.738458: Pseudo dice [0.6979]\n",
      "2024-12-05 06:27:10.745460: Epoch time: 130.95 s\n",
      "2024-12-05 06:27:11.808101: \n",
      "2024-12-05 06:27:11.808101: Epoch 58\n",
      "2024-12-05 06:27:11.815669: Current learning rate: 0.00948\n",
      "2024-12-05 06:29:22.849183: train_loss -0.6116\n",
      "2024-12-05 06:29:22.849183: val_loss -0.2901\n",
      "2024-12-05 06:29:22.857183: Pseudo dice [0.7123]\n",
      "2024-12-05 06:29:22.861768: Epoch time: 131.04 s\n",
      "2024-12-05 06:29:23.896492: \n",
      "2024-12-05 06:29:23.896492: Epoch 59\n",
      "2024-12-05 06:29:23.896492: Current learning rate: 0.00947\n",
      "2024-12-05 06:31:35.093904: train_loss -0.5899\n",
      "2024-12-05 06:31:35.093904: val_loss -0.3274\n",
      "2024-12-05 06:31:35.103904: Pseudo dice [0.6718]\n",
      "2024-12-05 06:31:35.119234: Epoch time: 131.2 s\n",
      "2024-12-05 06:31:36.134583: \n",
      "2024-12-05 06:31:36.134583: Epoch 60\n",
      "2024-12-05 06:31:36.141291: Current learning rate: 0.00946\n",
      "2024-12-05 06:33:47.129168: train_loss -0.6131\n",
      "2024-12-05 06:33:47.129168: val_loss -0.3366\n",
      "2024-12-05 06:33:47.139593: Pseudo dice [0.7305]\n",
      "2024-12-05 06:33:47.146852: Epoch time: 130.99 s\n",
      "2024-12-05 06:33:48.207448: \n",
      "2024-12-05 06:33:48.207448: Epoch 61\n",
      "2024-12-05 06:33:48.207448: Current learning rate: 0.00945\n",
      "2024-12-05 06:35:59.200129: train_loss -0.5836\n",
      "2024-12-05 06:35:59.200129: val_loss -0.3961\n",
      "2024-12-05 06:35:59.201722: Pseudo dice [0.7004]\n",
      "2024-12-05 06:35:59.211226: Epoch time: 130.99 s\n",
      "2024-12-05 06:36:00.237059: \n",
      "2024-12-05 06:36:00.237059: Epoch 62\n",
      "2024-12-05 06:36:00.251967: Current learning rate: 0.00944\n",
      "2024-12-05 06:38:11.291571: train_loss -0.6062\n",
      "2024-12-05 06:38:11.291571: val_loss -0.3135\n",
      "2024-12-05 06:38:11.301572: Pseudo dice [0.7041]\n",
      "2024-12-05 06:38:11.311572: Epoch time: 131.05 s\n",
      "2024-12-05 06:38:12.501975: \n",
      "2024-12-05 06:38:12.501975: Epoch 63\n",
      "2024-12-05 06:38:12.501975: Current learning rate: 0.00943\n",
      "2024-12-05 06:40:23.475239: train_loss -0.648\n",
      "2024-12-05 06:40:23.475239: val_loss -0.2135\n",
      "2024-12-05 06:40:23.486497: Pseudo dice [0.642]\n",
      "2024-12-05 06:40:23.487743: Epoch time: 130.97 s\n",
      "2024-12-05 06:40:24.507204: \n",
      "2024-12-05 06:40:24.507204: Epoch 64\n",
      "2024-12-05 06:40:24.512852: Current learning rate: 0.00942\n",
      "2024-12-05 06:42:35.573244: train_loss -0.5664\n",
      "2024-12-05 06:42:35.573244: val_loss -0.363\n",
      "2024-12-05 06:42:35.583244: Pseudo dice [0.7373]\n",
      "2024-12-05 06:42:35.598387: Epoch time: 131.07 s\n",
      "2024-12-05 06:42:36.626279: \n",
      "2024-12-05 06:42:36.626279: Epoch 65\n",
      "2024-12-05 06:42:36.636278: Current learning rate: 0.00941\n",
      "2024-12-05 06:44:47.625935: train_loss -0.6346\n",
      "2024-12-05 06:44:47.625935: val_loss -0.3397\n",
      "2024-12-05 06:44:47.635935: Pseudo dice [0.7599]\n",
      "2024-12-05 06:44:47.635935: Epoch time: 131.0 s\n",
      "2024-12-05 06:44:47.645936: Yayy! New best EMA pseudo Dice: 0.7045\n",
      "2024-12-05 06:44:48.890060: \n",
      "2024-12-05 06:44:48.890060: Epoch 66\n",
      "2024-12-05 06:44:48.890060: Current learning rate: 0.0094\n",
      "2024-12-05 06:46:59.877655: train_loss -0.5818\n",
      "2024-12-05 06:46:59.877655: val_loss -0.299\n",
      "2024-12-05 06:46:59.990743: Pseudo dice [0.6995]\n",
      "2024-12-05 06:46:59.999746: Epoch time: 130.99 s\n",
      "2024-12-05 06:47:01.003638: \n",
      "2024-12-05 06:47:01.003638: Epoch 67\n",
      "2024-12-05 06:47:01.013637: Current learning rate: 0.00939\n",
      "2024-12-05 06:49:12.076557: train_loss -0.5795\n",
      "2024-12-05 06:49:12.076557: val_loss -0.3335\n",
      "2024-12-05 06:49:12.092558: Pseudo dice [0.7068]\n",
      "2024-12-05 06:49:12.100465: Epoch time: 131.07 s\n",
      "2024-12-05 06:49:13.117297: \n",
      "2024-12-05 06:49:13.117297: Epoch 68\n",
      "2024-12-05 06:49:13.127295: Current learning rate: 0.00939\n",
      "2024-12-05 06:51:24.156894: train_loss -0.6218\n",
      "2024-12-05 06:51:24.156894: val_loss -0.3068\n",
      "2024-12-05 06:51:24.166896: Pseudo dice [0.6932]\n",
      "2024-12-05 06:51:24.176897: Epoch time: 131.04 s\n",
      "2024-12-05 06:51:25.257681: \n",
      "2024-12-05 06:51:25.257681: Epoch 69\n",
      "2024-12-05 06:51:25.264312: Current learning rate: 0.00938\n",
      "2024-12-05 06:53:36.244440: train_loss -0.6473\n",
      "2024-12-05 06:53:36.244440: val_loss -0.2577\n",
      "2024-12-05 06:53:36.254441: Pseudo dice [0.7214]\n",
      "2024-12-05 06:53:36.254441: Epoch time: 130.99 s\n",
      "2024-12-05 06:53:36.264753: Yayy! New best EMA pseudo Dice: 0.705\n",
      "2024-12-05 06:53:37.744445: \n",
      "2024-12-05 06:53:37.744445: Epoch 70\n",
      "2024-12-05 06:53:37.753445: Current learning rate: 0.00937\n",
      "2024-12-05 06:55:48.780900: train_loss -0.6687\n",
      "2024-12-05 06:55:48.780900: val_loss -0.3777\n",
      "2024-12-05 06:55:48.797128: Pseudo dice [0.7222]\n",
      "2024-12-05 06:55:48.806128: Epoch time: 131.04 s\n",
      "2024-12-05 06:55:48.812240: Yayy! New best EMA pseudo Dice: 0.7067\n",
      "2024-12-05 06:55:50.141590: \n",
      "2024-12-05 06:55:50.141590: Epoch 71\n",
      "2024-12-05 06:55:50.151588: Current learning rate: 0.00936\n",
      "2024-12-05 06:58:01.060249: train_loss -0.6264\n",
      "2024-12-05 06:58:01.060249: val_loss -0.4648\n",
      "2024-12-05 06:58:01.071710: Pseudo dice [0.8246]\n",
      "2024-12-05 06:58:01.072736: Epoch time: 130.92 s\n",
      "2024-12-05 06:58:01.082748: Yayy! New best EMA pseudo Dice: 0.7185\n",
      "2024-12-05 06:58:02.384254: \n",
      "2024-12-05 06:58:02.384254: Epoch 72\n",
      "2024-12-05 06:58:02.388578: Current learning rate: 0.00935\n",
      "2024-12-05 07:00:13.389576: train_loss -0.6507\n",
      "2024-12-05 07:00:13.390575: val_loss -0.2831\n",
      "2024-12-05 07:00:13.402060: Pseudo dice [0.6849]\n",
      "2024-12-05 07:00:13.409624: Epoch time: 131.01 s\n",
      "2024-12-05 07:00:14.478923: \n",
      "2024-12-05 07:00:14.478923: Epoch 73\n",
      "2024-12-05 07:00:14.487557: Current learning rate: 0.00934\n",
      "2024-12-05 07:02:25.565034: train_loss -0.6048\n",
      "2024-12-05 07:02:25.565034: val_loss -0.4093\n",
      "2024-12-05 07:02:25.574738: Pseudo dice [0.6787]\n",
      "2024-12-05 07:02:25.578738: Epoch time: 131.08 s\n",
      "2024-12-05 07:02:26.709263: \n",
      "2024-12-05 07:02:26.709263: Epoch 74\n",
      "2024-12-05 07:02:26.715924: Current learning rate: 0.00933\n",
      "2024-12-05 07:04:37.691708: train_loss -0.6048\n",
      "2024-12-05 07:04:37.692708: val_loss -0.151\n",
      "2024-12-05 07:04:37.698050: Pseudo dice [0.6554]\n",
      "2024-12-05 07:04:37.708064: Epoch time: 130.98 s\n",
      "2024-12-05 07:04:38.762877: \n",
      "2024-12-05 07:04:38.762877: Epoch 75\n",
      "2024-12-05 07:04:38.772875: Current learning rate: 0.00932\n",
      "2024-12-05 07:06:49.709198: train_loss -0.5479\n",
      "2024-12-05 07:06:49.709198: val_loss -0.3949\n",
      "2024-12-05 07:06:49.719199: Pseudo dice [0.7216]\n",
      "2024-12-05 07:06:49.719199: Epoch time: 130.95 s\n",
      "2024-12-05 07:06:50.769857: \n",
      "2024-12-05 07:06:50.769857: Epoch 76\n",
      "2024-12-05 07:06:50.776510: Current learning rate: 0.00931\n",
      "2024-12-05 07:09:01.749515: train_loss -0.6183\n",
      "2024-12-05 07:09:01.749515: val_loss -0.346\n",
      "2024-12-05 07:09:01.764649: Pseudo dice [0.7818]\n",
      "2024-12-05 07:09:01.876184: Epoch time: 130.98 s\n",
      "2024-12-05 07:09:03.200209: \n",
      "2024-12-05 07:09:03.200209: Epoch 77\n",
      "2024-12-05 07:09:03.209125: Current learning rate: 0.0093\n",
      "2024-12-05 07:11:14.070335: train_loss -0.5918\n",
      "2024-12-05 07:11:14.070335: val_loss -0.3297\n",
      "2024-12-05 07:11:14.079838: Pseudo dice [0.7029]\n",
      "2024-12-05 07:11:14.089839: Epoch time: 130.87 s\n",
      "2024-12-05 07:11:15.230603: \n",
      "2024-12-05 07:11:15.230603: Epoch 78\n",
      "2024-12-05 07:11:15.237241: Current learning rate: 0.0093\n",
      "2024-12-05 07:13:26.079895: train_loss -0.6029\n",
      "2024-12-05 07:13:26.079895: val_loss -0.2606\n",
      "2024-12-05 07:13:26.091085: Pseudo dice [0.7044]\n",
      "2024-12-05 07:13:26.098086: Epoch time: 130.85 s\n",
      "2024-12-05 07:13:27.162127: \n",
      "2024-12-05 07:13:27.162127: Epoch 79\n",
      "2024-12-05 07:13:27.219034: Current learning rate: 0.00929\n",
      "2024-12-05 07:15:38.131005: train_loss -0.6198\n",
      "2024-12-05 07:15:38.132042: val_loss -0.4021\n",
      "2024-12-05 07:15:38.142484: Pseudo dice [0.735]\n",
      "2024-12-05 07:15:38.149725: Epoch time: 130.97 s\n",
      "2024-12-05 07:15:39.207878: \n",
      "2024-12-05 07:15:39.207878: Epoch 80\n",
      "2024-12-05 07:15:39.214519: Current learning rate: 0.00928\n",
      "2024-12-05 07:17:50.151149: train_loss -0.623\n",
      "2024-12-05 07:17:50.151149: val_loss -0.1559\n",
      "2024-12-05 07:17:50.161150: Pseudo dice [0.6182]\n",
      "2024-12-05 07:17:50.171149: Epoch time: 130.94 s\n",
      "2024-12-05 07:17:51.263664: \n",
      "2024-12-05 07:17:51.263664: Epoch 81\n",
      "2024-12-05 07:17:51.328163: Current learning rate: 0.00927\n",
      "2024-12-05 07:20:02.287570: train_loss -0.6323\n",
      "2024-12-05 07:20:02.287570: val_loss -0.4435\n",
      "2024-12-05 07:20:02.296716: Pseudo dice [0.7947]\n",
      "2024-12-05 07:20:02.304851: Epoch time: 131.02 s\n",
      "2024-12-05 07:20:03.468529: \n",
      "2024-12-05 07:20:03.468529: Epoch 82\n",
      "2024-12-05 07:20:03.477214: Current learning rate: 0.00926\n",
      "2024-12-05 07:22:14.398151: train_loss -0.6019\n",
      "2024-12-05 07:22:14.398151: val_loss -0.3668\n",
      "2024-12-05 07:22:14.418678: Pseudo dice [0.7463]\n",
      "2024-12-05 07:22:14.427065: Epoch time: 130.93 s\n",
      "2024-12-05 07:22:15.423513: \n",
      "2024-12-05 07:22:15.423513: Epoch 83\n",
      "2024-12-05 07:22:15.433015: Current learning rate: 0.00925\n",
      "2024-12-05 07:24:26.306374: train_loss -0.6537\n",
      "2024-12-05 07:24:26.306374: val_loss -0.4088\n",
      "2024-12-05 07:24:26.315377: Pseudo dice [0.747]\n",
      "2024-12-05 07:24:26.325014: Epoch time: 130.88 s\n",
      "2024-12-05 07:24:26.330015: Yayy! New best EMA pseudo Dice: 0.7204\n",
      "2024-12-05 07:24:27.731998: \n",
      "2024-12-05 07:24:27.732997: Epoch 84\n",
      "2024-12-05 07:24:27.739999: Current learning rate: 0.00924\n",
      "2024-12-05 07:26:38.668798: train_loss -0.6244\n",
      "2024-12-05 07:26:38.668798: val_loss -0.4186\n",
      "2024-12-05 07:26:38.678799: Pseudo dice [0.7747]\n",
      "2024-12-05 07:26:38.691085: Epoch time: 130.94 s\n",
      "2024-12-05 07:26:38.696119: Yayy! New best EMA pseudo Dice: 0.7258\n",
      "2024-12-05 07:26:39.944049: \n",
      "2024-12-05 07:26:39.944049: Epoch 85\n",
      "2024-12-05 07:26:39.949554: Current learning rate: 0.00923\n",
      "2024-12-05 07:28:50.975800: train_loss -0.6126\n",
      "2024-12-05 07:28:50.975800: val_loss -0.2604\n",
      "2024-12-05 07:28:50.987842: Pseudo dice [0.6621]\n",
      "2024-12-05 07:28:50.996388: Epoch time: 131.03 s\n",
      "2024-12-05 07:28:51.996476: \n",
      "2024-12-05 07:28:51.996476: Epoch 86\n",
      "2024-12-05 07:28:52.006474: Current learning rate: 0.00922\n",
      "2024-12-05 07:31:02.981950: train_loss -0.6432\n",
      "2024-12-05 07:31:02.981950: val_loss -0.2507\n",
      "2024-12-05 07:31:02.995360: Pseudo dice [0.6012]\n",
      "2024-12-05 07:31:03.002362: Epoch time: 130.99 s\n",
      "2024-12-05 07:31:03.994285: \n",
      "2024-12-05 07:31:03.994285: Epoch 87\n",
      "2024-12-05 07:31:03.995886: Current learning rate: 0.00921\n",
      "2024-12-05 07:33:14.898389: train_loss -0.5979\n",
      "2024-12-05 07:33:14.898389: val_loss -0.4096\n",
      "2024-12-05 07:33:14.910500: Pseudo dice [0.7404]\n",
      "2024-12-05 07:33:14.916569: Epoch time: 130.91 s\n",
      "2024-12-05 07:33:15.907177: \n",
      "2024-12-05 07:33:15.907177: Epoch 88\n",
      "2024-12-05 07:33:15.917176: Current learning rate: 0.0092\n",
      "2024-12-05 07:35:26.859975: train_loss -0.6126\n",
      "2024-12-05 07:35:26.859975: val_loss -0.3328\n",
      "2024-12-05 07:35:26.870632: Pseudo dice [0.728]\n",
      "2024-12-05 07:35:26.870632: Epoch time: 130.95 s\n",
      "2024-12-05 07:35:27.970863: \n",
      "2024-12-05 07:35:27.970863: Epoch 89\n",
      "2024-12-05 07:35:27.970863: Current learning rate: 0.0092\n",
      "2024-12-05 07:37:38.967202: train_loss -0.658\n",
      "2024-12-05 07:37:38.967202: val_loss -0.345\n",
      "2024-12-05 07:37:38.981610: Pseudo dice [0.7338]\n",
      "2024-12-05 07:37:38.990307: Epoch time: 131.0 s\n",
      "2024-12-05 07:37:40.012426: \n",
      "2024-12-05 07:37:40.017611: Epoch 90\n",
      "2024-12-05 07:37:40.019108: Current learning rate: 0.00919\n",
      "2024-12-05 07:39:50.929793: train_loss -0.6549\n",
      "2024-12-05 07:39:50.930794: val_loss -0.4227\n",
      "2024-12-05 07:39:50.938382: Pseudo dice [0.7626]\n",
      "2024-12-05 07:39:50.942383: Epoch time: 130.92 s\n",
      "2024-12-05 07:39:52.166781: \n",
      "2024-12-05 07:39:52.166781: Epoch 91\n",
      "2024-12-05 07:39:52.166781: Current learning rate: 0.00918\n",
      "2024-12-05 07:42:03.078288: train_loss -0.703\n",
      "2024-12-05 07:42:03.078288: val_loss -0.3934\n",
      "2024-12-05 07:42:03.087791: Pseudo dice [0.7247]\n",
      "2024-12-05 07:42:03.097793: Epoch time: 130.91 s\n",
      "2024-12-05 07:42:04.088488: \n",
      "2024-12-05 07:42:04.088488: Epoch 92\n",
      "2024-12-05 07:42:04.095122: Current learning rate: 0.00917\n",
      "2024-12-05 07:44:15.035267: train_loss -0.655\n",
      "2024-12-05 07:44:15.035267: val_loss -0.2313\n",
      "2024-12-05 07:44:15.045266: Pseudo dice [0.7278]\n",
      "2024-12-05 07:44:15.055267: Epoch time: 130.95 s\n",
      "2024-12-05 07:44:16.041924: \n",
      "2024-12-05 07:44:16.041924: Epoch 93\n",
      "2024-12-05 07:44:16.042190: Current learning rate: 0.00916\n",
      "2024-12-05 07:46:27.076696: train_loss -0.6385\n",
      "2024-12-05 07:46:27.077696: val_loss -0.4146\n",
      "2024-12-05 07:46:27.088939: Pseudo dice [0.7315]\n",
      "2024-12-05 07:46:27.091126: Epoch time: 131.04 s\n",
      "2024-12-05 07:46:28.072499: \n",
      "2024-12-05 07:46:28.072499: Epoch 94\n",
      "2024-12-05 07:46:28.082498: Current learning rate: 0.00915\n",
      "2024-12-05 07:48:39.059632: train_loss -0.6675\n",
      "2024-12-05 07:48:39.060631: val_loss -0.3725\n",
      "2024-12-05 07:48:39.069487: Pseudo dice [0.7328]\n",
      "2024-12-05 07:48:39.078991: Epoch time: 130.99 s\n",
      "2024-12-05 07:48:40.069254: \n",
      "2024-12-05 07:48:40.069254: Epoch 95\n",
      "2024-12-05 07:48:40.071469: Current learning rate: 0.00914\n",
      "2024-12-05 07:50:51.010721: train_loss -0.6355\n",
      "2024-12-05 07:50:51.010805: val_loss -0.3296\n",
      "2024-12-05 07:50:51.017706: Pseudo dice [0.703]\n",
      "2024-12-05 07:50:51.017706: Epoch time: 130.95 s\n",
      "2024-12-05 07:50:52.060853: \n",
      "2024-12-05 07:50:52.060853: Epoch 96\n",
      "2024-12-05 07:50:52.070853: Current learning rate: 0.00913\n",
      "2024-12-05 07:53:03.070429: train_loss -0.6409\n",
      "2024-12-05 07:53:03.070429: val_loss -0.2969\n",
      "2024-12-05 07:53:03.089276: Pseudo dice [0.7132]\n",
      "2024-12-05 07:53:03.095276: Epoch time: 131.01 s\n",
      "2024-12-05 07:53:04.090125: \n",
      "2024-12-05 07:53:04.090125: Epoch 97\n",
      "2024-12-05 07:53:04.096904: Current learning rate: 0.00912\n",
      "2024-12-05 07:55:15.044084: train_loss -0.6607\n",
      "2024-12-05 07:55:15.044084: val_loss -0.2412\n",
      "2024-12-05 07:55:15.054101: Pseudo dice [0.6653]\n",
      "2024-12-05 07:55:15.064100: Epoch time: 130.95 s\n",
      "2024-12-05 07:55:16.071523: \n",
      "2024-12-05 07:55:16.071523: Epoch 98\n",
      "2024-12-05 07:55:16.077128: Current learning rate: 0.00911\n",
      "2024-12-05 07:57:26.978939: train_loss -0.6697\n",
      "2024-12-05 07:57:26.978939: val_loss -0.2933\n",
      "2024-12-05 07:57:26.996601: Pseudo dice [0.7414]\n",
      "2024-12-05 07:57:27.003603: Epoch time: 130.91 s\n",
      "2024-12-05 07:57:28.285957: \n",
      "2024-12-05 07:57:28.290588: Epoch 99\n",
      "2024-12-05 07:57:28.291235: Current learning rate: 0.0091\n",
      "2024-12-05 07:59:39.230412: train_loss -0.7043\n",
      "2024-12-05 07:59:39.230412: val_loss -0.331\n",
      "2024-12-05 07:59:39.230412: Pseudo dice [0.777]\n",
      "2024-12-05 07:59:39.240414: Epoch time: 130.94 s\n",
      "2024-12-05 07:59:40.587792: \n",
      "2024-12-05 07:59:40.587792: Epoch 100\n",
      "2024-12-05 07:59:40.597791: Current learning rate: 0.0091\n",
      "2024-12-05 08:01:51.679043: train_loss -0.6686\n",
      "2024-12-05 08:01:51.679043: val_loss -0.4087\n",
      "2024-12-05 08:01:51.685045: Pseudo dice [0.7727]\n",
      "2024-12-05 08:01:51.692046: Epoch time: 131.09 s\n",
      "2024-12-05 08:01:51.698048: Yayy! New best EMA pseudo Dice: 0.7283\n",
      "2024-12-05 08:01:53.033967: \n",
      "2024-12-05 08:01:53.034967: Epoch 101\n",
      "2024-12-05 08:01:53.041969: Current learning rate: 0.00909\n",
      "2024-12-05 08:04:09.373364: train_loss -0.6762\n",
      "2024-12-05 08:04:09.374366: val_loss -0.2909\n",
      "2024-12-05 08:04:09.383367: Pseudo dice [0.6418]\n",
      "2024-12-05 08:04:09.390369: Epoch time: 136.34 s\n",
      "2024-12-05 08:04:10.505622: \n",
      "2024-12-05 08:04:10.512622: Epoch 102\n",
      "2024-12-05 08:04:10.518624: Current learning rate: 0.00908\n",
      "2024-12-05 08:06:24.718959: train_loss -0.6198\n",
      "2024-12-05 08:06:24.728961: val_loss -0.0685\n",
      "2024-12-05 08:06:24.738960: Pseudo dice [0.5761]\n",
      "2024-12-05 08:06:24.738960: Epoch time: 134.21 s\n",
      "2024-12-05 08:06:25.855503: \n",
      "2024-12-05 08:06:25.861751: Epoch 103\n",
      "2024-12-05 08:06:25.871799: Current learning rate: 0.00907\n",
      "2024-12-05 08:08:37.242444: train_loss -0.6467\n",
      "2024-12-05 08:08:37.252444: val_loss -0.3885\n",
      "2024-12-05 08:08:37.261259: Pseudo dice [0.7217]\n",
      "2024-12-05 08:08:37.261259: Epoch time: 131.39 s\n",
      "2024-12-05 08:08:38.326939: \n",
      "2024-12-05 08:08:38.341999: Epoch 104\n",
      "2024-12-05 08:08:38.342751: Current learning rate: 0.00906\n",
      "2024-12-05 08:10:49.589021: train_loss -0.6522\n",
      "2024-12-05 08:10:49.599334: val_loss -0.289\n",
      "2024-12-05 08:10:49.606031: Pseudo dice [0.6497]\n",
      "2024-12-05 08:10:49.606031: Epoch time: 131.26 s\n",
      "2024-12-05 08:10:50.606005: \n",
      "2024-12-05 08:10:50.616004: Epoch 105\n",
      "2024-12-05 08:10:50.624058: Current learning rate: 0.00905\n",
      "2024-12-05 08:13:01.938472: train_loss -0.6793\n",
      "2024-12-05 08:13:01.952976: val_loss -0.2072\n",
      "2024-12-05 08:13:01.962975: Pseudo dice [0.6763]\n",
      "2024-12-05 08:13:01.971030: Epoch time: 131.33 s\n",
      "2024-12-05 08:13:03.163807: \n",
      "2024-12-05 08:13:03.169578: Epoch 106\n",
      "2024-12-05 08:13:03.169578: Current learning rate: 0.00904\n",
      "2024-12-05 08:15:14.616976: train_loss -0.6919\n",
      "2024-12-05 08:15:14.626975: val_loss -0.4679\n",
      "2024-12-05 08:15:14.643312: Pseudo dice [0.7846]\n",
      "2024-12-05 08:15:14.643312: Epoch time: 131.45 s\n",
      "2024-12-05 08:15:15.684307: \n",
      "2024-12-05 08:15:15.700327: Epoch 107\n",
      "2024-12-05 08:15:15.700327: Current learning rate: 0.00903\n",
      "2024-12-05 08:17:27.113308: train_loss -0.6962\n",
      "2024-12-05 08:17:27.123174: val_loss -0.0851\n",
      "2024-12-05 08:17:27.132389: Pseudo dice [0.4726]\n",
      "2024-12-05 08:17:27.139472: Epoch time: 131.43 s\n",
      "2024-12-05 08:17:28.231685: \n",
      "2024-12-05 08:17:28.231685: Epoch 108\n",
      "2024-12-05 08:17:28.241188: Current learning rate: 0.00902\n",
      "2024-12-05 08:19:39.687295: train_loss -0.6868\n",
      "2024-12-05 08:19:39.693928: val_loss -0.3142\n",
      "2024-12-05 08:19:39.710613: Pseudo dice [0.6783]\n",
      "2024-12-05 08:19:39.710613: Epoch time: 131.46 s\n",
      "2024-12-05 08:19:40.770553: \n",
      "2024-12-05 08:19:40.777215: Epoch 109\n",
      "2024-12-05 08:19:40.777215: Current learning rate: 0.00901\n",
      "2024-12-05 08:21:52.108575: train_loss -0.6702\n",
      "2024-12-05 08:21:52.124788: val_loss -0.4002\n",
      "2024-12-05 08:21:52.134291: Pseudo dice [0.8052]\n",
      "2024-12-05 08:21:52.140924: Epoch time: 131.34 s\n",
      "2024-12-05 08:21:53.167518: \n",
      "2024-12-05 08:21:53.174191: Epoch 110\n",
      "2024-12-05 08:21:53.174191: Current learning rate: 0.009\n",
      "2024-12-05 08:24:04.337888: train_loss -0.7016\n",
      "2024-12-05 08:24:04.354617: val_loss -0.3636\n",
      "2024-12-05 08:24:04.354617: Pseudo dice [0.8144]\n",
      "2024-12-05 08:24:04.364616: Epoch time: 131.17 s\n",
      "2024-12-05 08:24:05.405988: \n",
      "2024-12-05 08:24:05.405988: Epoch 111\n",
      "2024-12-05 08:24:05.415491: Current learning rate: 0.009\n",
      "2024-12-05 08:26:20.406001: train_loss -0.6677\n",
      "2024-12-05 08:26:20.415003: val_loss -0.2159\n",
      "2024-12-05 08:26:20.421004: Pseudo dice [0.6396]\n",
      "2024-12-05 08:26:20.426005: Epoch time: 135.0 s\n",
      "2024-12-05 08:26:21.398225: \n",
      "2024-12-05 08:26:21.405226: Epoch 112\n",
      "2024-12-05 08:26:21.410228: Current learning rate: 0.00899\n",
      "2024-12-05 08:28:35.222510: train_loss -0.6857\n",
      "2024-12-05 08:28:35.230511: val_loss -0.2631\n",
      "2024-12-05 08:28:35.239515: Pseudo dice [0.6757]\n",
      "2024-12-05 08:28:35.244516: Epoch time: 133.83 s\n",
      "2024-12-05 08:28:36.405779: \n",
      "2024-12-05 08:28:36.412780: Epoch 113\n",
      "2024-12-05 08:28:36.417781: Current learning rate: 0.00898\n",
      "2024-12-05 08:30:47.499007: train_loss -0.6793\n",
      "2024-12-05 08:30:47.507009: val_loss -0.3517\n",
      "2024-12-05 08:30:47.515011: Pseudo dice [0.7506]\n",
      "2024-12-05 08:30:47.520012: Epoch time: 131.09 s\n",
      "2024-12-05 08:30:48.556951: \n",
      "2024-12-05 08:30:48.563953: Epoch 114\n",
      "2024-12-05 08:30:48.568954: Current learning rate: 0.00897\n",
      "2024-12-05 08:33:00.082942: train_loss -0.6623\n",
      "2024-12-05 08:33:00.090944: val_loss -0.3776\n",
      "2024-12-05 08:33:00.099947: Pseudo dice [0.751]\n",
      "2024-12-05 08:33:00.104947: Epoch time: 131.53 s\n",
      "2024-12-05 08:33:01.113175: \n",
      "2024-12-05 08:33:01.120177: Epoch 115\n",
      "2024-12-05 08:33:01.125178: Current learning rate: 0.00896\n",
      "2024-12-05 08:35:12.371016: train_loss -0.6889\n",
      "2024-12-05 08:35:12.379018: val_loss -0.4627\n",
      "2024-12-05 08:35:12.384019: Pseudo dice [0.8045]\n",
      "2024-12-05 08:35:12.392021: Epoch time: 131.26 s\n",
      "2024-12-05 08:35:13.473266: \n",
      "2024-12-05 08:35:13.481268: Epoch 116\n",
      "2024-12-05 08:35:13.487268: Current learning rate: 0.00895\n",
      "2024-12-05 08:37:24.380577: train_loss -0.7002\n",
      "2024-12-05 08:37:24.392579: val_loss -0.1417\n",
      "2024-12-05 08:37:24.399581: Pseudo dice [0.6677]\n",
      "2024-12-05 08:37:24.405582: Epoch time: 130.91 s\n",
      "2024-12-05 08:37:25.527835: \n",
      "2024-12-05 08:37:25.535837: Epoch 117\n",
      "2024-12-05 08:37:25.541839: Current learning rate: 0.00894\n",
      "2024-12-05 08:39:37.839529: train_loss -0.6261\n",
      "2024-12-05 08:39:37.848531: val_loss -0.1526\n",
      "2024-12-05 08:39:37.853531: Pseudo dice [0.5724]\n",
      "2024-12-05 08:39:37.857533: Epoch time: 132.31 s\n",
      "2024-12-05 08:39:38.951780: \n",
      "2024-12-05 08:39:38.959782: Epoch 118\n",
      "2024-12-05 08:39:38.964783: Current learning rate: 0.00893\n",
      "2024-12-05 08:42:16.333161: train_loss -0.6647\n",
      "2024-12-05 08:42:16.333161: val_loss 0.1553\n",
      "2024-12-05 08:42:16.342163: Pseudo dice [0.3989]\n",
      "2024-12-05 08:42:16.348165: Epoch time: 157.38 s\n",
      "2024-12-05 08:42:17.386400: \n",
      "2024-12-05 08:42:17.394705: Epoch 119\n",
      "2024-12-05 08:42:17.399705: Current learning rate: 0.00892\n",
      "2024-12-05 08:48:22.598224: train_loss -0.6127\n",
      "2024-12-05 08:48:22.609226: val_loss -0.2161\n",
      "2024-12-05 08:48:22.614228: Pseudo dice [0.7091]\n",
      "2024-12-05 08:48:22.619229: Epoch time: 365.21 s\n",
      "2024-12-05 08:48:23.873513: \n",
      "2024-12-05 08:48:23.882514: Epoch 120\n",
      "2024-12-05 08:48:23.887515: Current learning rate: 0.00891\n",
      "2024-12-05 08:54:34.252588: train_loss -0.6892\n",
      "2024-12-05 08:54:34.262590: val_loss -0.4295\n",
      "2024-12-05 08:54:34.268591: Pseudo dice [0.7561]\n",
      "2024-12-05 08:54:34.273593: Epoch time: 370.38 s\n",
      "2024-12-05 08:54:35.330108: \n",
      "2024-12-05 08:54:35.337109: Epoch 121\n",
      "2024-12-05 08:54:35.342110: Current learning rate: 0.0089\n",
      "2024-12-05 08:57:24.561069: train_loss -0.6869\n",
      "2024-12-05 08:57:24.571071: val_loss -0.3274\n",
      "2024-12-05 08:57:24.577072: Pseudo dice [0.7768]\n",
      "2024-12-05 08:57:24.584073: Epoch time: 169.23 s\n",
      "2024-12-05 08:57:25.700325: \n",
      "2024-12-05 08:57:25.707327: Epoch 122\n",
      "2024-12-05 08:57:25.712328: Current learning rate: 0.00889\n",
      "2024-12-05 08:59:35.320825: train_loss -0.6886\n",
      "2024-12-05 08:59:35.329827: val_loss -0.3862\n",
      "2024-12-05 08:59:35.338828: Pseudo dice [0.6816]\n",
      "2024-12-05 08:59:35.345830: Epoch time: 129.62 s\n",
      "2024-12-05 08:59:36.386066: \n",
      "2024-12-05 08:59:36.393068: Epoch 123\n",
      "2024-12-05 08:59:36.398069: Current learning rate: 0.00889\n",
      "2024-12-05 09:01:46.381879: train_loss -0.7031\n",
      "2024-12-05 09:01:46.391882: val_loss -0.3203\n",
      "2024-12-05 09:01:46.399883: Pseudo dice [0.7409]\n",
      "2024-12-05 09:01:46.406885: Epoch time: 130.0 s\n",
      "2024-12-05 09:01:47.483128: \n",
      "2024-12-05 09:01:47.490408: Epoch 124\n",
      "2024-12-05 09:01:47.495409: Current learning rate: 0.00888\n",
      "2024-12-05 09:03:58.092733: train_loss -0.6872\n",
      "2024-12-05 09:03:58.100735: val_loss -0.454\n",
      "2024-12-05 09:03:58.109737: Pseudo dice [0.7314]\n",
      "2024-12-05 09:03:58.115739: Epoch time: 130.61 s\n",
      "2024-12-05 09:03:59.236585: \n",
      "2024-12-05 09:03:59.244587: Epoch 125\n",
      "2024-12-05 09:03:59.249588: Current learning rate: 0.00887\n",
      "2024-12-05 09:06:11.649458: train_loss -0.6964\n",
      "2024-12-05 09:06:11.657459: val_loss -0.4123\n",
      "2024-12-05 09:06:11.662462: Pseudo dice [0.7904]\n",
      "2024-12-05 09:06:11.666463: Epoch time: 132.41 s\n",
      "2024-12-05 09:06:12.799299: \n",
      "2024-12-05 09:06:12.807301: Epoch 126\n",
      "2024-12-05 09:06:12.812302: Current learning rate: 0.00886\n",
      "2024-12-05 09:08:27.143356: train_loss -0.7068\n",
      "2024-12-05 09:08:27.152358: val_loss -0.219\n",
      "2024-12-05 09:08:27.161360: Pseudo dice [0.5561]\n",
      "2024-12-05 09:08:27.167361: Epoch time: 134.35 s\n",
      "2024-12-05 09:08:28.280252: \n",
      "2024-12-05 09:08:28.288255: Epoch 127\n",
      "2024-12-05 09:08:28.293256: Current learning rate: 0.00885\n",
      "2024-12-05 09:10:38.311668: train_loss -0.6447\n",
      "2024-12-05 09:10:38.321670: val_loss -0.3168\n",
      "2024-12-05 09:10:38.330673: Pseudo dice [0.6795]\n",
      "2024-12-05 09:10:38.336675: Epoch time: 130.03 s\n",
      "2024-12-05 09:10:39.642149: \n",
      "2024-12-05 09:10:39.650151: Epoch 128\n",
      "2024-12-05 09:10:39.655152: Current learning rate: 0.00884\n",
      "2024-12-05 09:12:51.781827: train_loss -0.7015\n",
      "2024-12-05 09:12:51.791830: val_loss -0.1576\n",
      "2024-12-05 09:12:51.798830: Pseudo dice [0.6417]\n",
      "2024-12-05 09:12:51.804832: Epoch time: 132.14 s\n",
      "2024-12-05 09:12:52.924622: \n",
      "2024-12-05 09:12:52.932624: Epoch 129\n",
      "2024-12-05 09:12:52.937625: Current learning rate: 0.00883\n",
      "2024-12-05 09:15:06.403524: train_loss -0.7018\n",
      "2024-12-05 09:15:06.413527: val_loss -0.2724\n",
      "2024-12-05 09:15:06.421528: Pseudo dice [0.7661]\n",
      "2024-12-05 09:15:06.427529: Epoch time: 133.48 s\n",
      "2024-12-05 09:15:07.487335: \n",
      "2024-12-05 09:15:07.497337: Epoch 130\n",
      "2024-12-05 09:15:07.504339: Current learning rate: 0.00882\n",
      "2024-12-05 09:17:18.884602: train_loss -0.7186\n",
      "2024-12-05 09:17:18.896605: val_loss -0.1677\n",
      "2024-12-05 09:17:18.905608: Pseudo dice [0.721]\n",
      "2024-12-05 09:17:18.910609: Epoch time: 131.4 s\n",
      "2024-12-05 09:17:19.951949: \n",
      "2024-12-05 09:17:19.958951: Epoch 131\n",
      "2024-12-05 09:17:19.962952: Current learning rate: 0.00881\n",
      "2024-12-05 09:19:29.741728: train_loss -0.7045\n",
      "2024-12-05 09:19:29.750731: val_loss -0.3165\n",
      "2024-12-05 09:19:29.755732: Pseudo dice [0.762]\n",
      "2024-12-05 09:19:29.759733: Epoch time: 129.79 s\n",
      "2024-12-05 09:19:30.815100: \n",
      "2024-12-05 09:19:30.822102: Epoch 132\n",
      "2024-12-05 09:19:30.827103: Current learning rate: 0.0088\n",
      "2024-12-05 09:21:45.890645: train_loss -0.7069\n",
      "2024-12-05 09:21:45.890645: val_loss -0.252\n",
      "2024-12-05 09:21:45.901648: Pseudo dice [0.7127]\n",
      "2024-12-05 09:21:45.909649: Epoch time: 135.08 s\n",
      "2024-12-05 09:21:47.052946: \n",
      "2024-12-05 09:21:47.060947: Epoch 133\n",
      "2024-12-05 09:21:47.066949: Current learning rate: 0.00879\n",
      "2024-12-05 09:24:01.422962: train_loss -0.6863\n",
      "2024-12-05 09:24:01.432961: val_loss -0.291\n",
      "2024-12-05 09:24:01.439426: Pseudo dice [0.7042]\n",
      "2024-12-05 09:24:01.449424: Epoch time: 134.37 s\n",
      "2024-12-05 09:24:02.489248: \n",
      "2024-12-05 09:24:02.499247: Epoch 134\n",
      "2024-12-05 09:24:02.505682: Current learning rate: 0.00879\n",
      "2024-12-05 09:26:13.869694: train_loss -0.7184\n",
      "2024-12-05 09:26:13.879692: val_loss 0.0203\n",
      "2024-12-05 09:26:13.886426: Pseudo dice [0.501]\n",
      "2024-12-05 09:26:13.886426: Epoch time: 131.38 s\n",
      "2024-12-05 09:26:15.135986: \n",
      "2024-12-05 09:26:15.137596: Epoch 135\n",
      "2024-12-05 09:26:15.147099: Current learning rate: 0.00878\n",
      "2024-12-05 09:28:26.393329: train_loss -0.6145\n",
      "2024-12-05 09:28:26.407187: val_loss 0.0839\n",
      "2024-12-05 09:28:26.413282: Pseudo dice [0.3973]\n",
      "2024-12-05 09:28:26.420539: Epoch time: 131.26 s\n",
      "2024-12-05 09:28:27.466552: \n",
      "2024-12-05 09:28:27.483226: Epoch 136\n",
      "2024-12-05 09:28:27.483226: Current learning rate: 0.00877\n",
      "2024-12-05 09:30:38.847455: train_loss -0.6595\n",
      "2024-12-05 09:30:38.857454: val_loss -0.1161\n",
      "2024-12-05 09:30:38.863629: Pseudo dice [0.6245]\n",
      "2024-12-05 09:30:38.873627: Epoch time: 131.38 s\n",
      "2024-12-05 09:30:39.923543: \n",
      "2024-12-05 09:30:39.930215: Epoch 137\n",
      "2024-12-05 09:30:39.930215: Current learning rate: 0.00876\n",
      "2024-12-05 09:32:51.277287: train_loss -0.6385\n",
      "2024-12-05 09:32:51.287286: val_loss -0.042\n",
      "2024-12-05 09:32:51.293894: Pseudo dice [0.4815]\n",
      "2024-12-05 09:32:51.303893: Epoch time: 131.35 s\n",
      "2024-12-05 09:32:52.378971: \n",
      "2024-12-05 09:32:52.388992: Epoch 138\n",
      "2024-12-05 09:32:52.394326: Current learning rate: 0.00875\n",
      "2024-12-05 09:35:03.557590: train_loss -0.6777\n",
      "2024-12-05 09:35:03.567588: val_loss -0.4201\n",
      "2024-12-05 09:35:03.576995: Pseudo dice [0.7466]\n",
      "2024-12-05 09:35:03.579379: Epoch time: 131.18 s\n",
      "2024-12-05 09:35:04.717523: \n",
      "2024-12-05 09:35:04.724181: Epoch 139\n",
      "2024-12-05 09:35:04.724181: Current learning rate: 0.00874\n",
      "2024-12-05 09:37:16.114578: train_loss -0.6759\n",
      "2024-12-05 09:37:16.121298: val_loss -0.426\n",
      "2024-12-05 09:37:16.131296: Pseudo dice [0.7921]\n",
      "2024-12-05 09:37:16.137977: Epoch time: 131.4 s\n",
      "2024-12-05 09:37:17.245953: \n",
      "2024-12-05 09:37:17.253036: Epoch 140\n",
      "2024-12-05 09:37:17.258466: Current learning rate: 0.00873\n",
      "2024-12-05 09:39:28.361682: train_loss -0.6935\n",
      "2024-12-05 09:39:28.368287: val_loss -0.4365\n",
      "2024-12-05 09:39:28.378285: Pseudo dice [0.7996]\n",
      "2024-12-05 09:39:28.385027: Epoch time: 131.12 s\n",
      "2024-12-05 09:39:29.511845: \n",
      "2024-12-05 09:39:29.519560: Epoch 141\n",
      "2024-12-05 09:39:29.519560: Current learning rate: 0.00872\n",
      "2024-12-05 09:41:40.858625: train_loss -0.6664\n",
      "2024-12-05 09:41:40.875234: val_loss -0.2818\n",
      "2024-12-05 09:41:40.881945: Pseudo dice [0.7174]\n",
      "2024-12-05 09:41:40.891943: Epoch time: 131.35 s\n",
      "2024-12-05 09:41:42.125410: \n",
      "2024-12-05 09:41:42.132287: Epoch 142\n",
      "2024-12-05 09:41:42.132287: Current learning rate: 0.00871\n",
      "2024-12-05 09:43:53.513234: train_loss -0.6606\n",
      "2024-12-05 09:43:53.529514: val_loss -0.3504\n",
      "2024-12-05 09:43:53.529514: Pseudo dice [0.7242]\n",
      "2024-12-05 09:43:53.539017: Epoch time: 131.4 s\n",
      "2024-12-05 09:43:54.595478: \n",
      "2024-12-05 09:43:54.605476: Epoch 143\n",
      "2024-12-05 09:43:54.612186: Current learning rate: 0.0087\n",
      "2024-12-05 09:46:05.852392: train_loss -0.67\n",
      "2024-12-05 09:46:05.859255: val_loss -0.3351\n",
      "2024-12-05 09:46:05.869254: Pseudo dice [0.7521]\n",
      "2024-12-05 09:46:05.875930: Epoch time: 131.26 s\n",
      "2024-12-05 09:46:06.975900: \n",
      "2024-12-05 09:46:06.992580: Epoch 144\n",
      "2024-12-05 09:46:06.992580: Current learning rate: 0.00869\n",
      "2024-12-05 09:48:18.306263: train_loss -0.7173\n",
      "2024-12-05 09:48:18.322870: val_loss -0.1516\n",
      "2024-12-05 09:48:18.332869: Pseudo dice [0.6201]\n",
      "2024-12-05 09:48:18.339546: Epoch time: 131.33 s\n",
      "2024-12-05 09:48:19.390211: \n",
      "2024-12-05 09:48:19.399714: Epoch 145\n",
      "2024-12-05 09:48:19.399714: Current learning rate: 0.00868\n",
      "2024-12-05 09:50:30.754781: train_loss -0.7014\n",
      "2024-12-05 09:50:30.769935: val_loss -0.3716\n",
      "2024-12-05 09:50:30.779933: Pseudo dice [0.7436]\n",
      "2024-12-05 09:50:30.786601: Epoch time: 131.36 s\n",
      "2024-12-05 09:50:31.836459: \n",
      "2024-12-05 09:50:31.846458: Epoch 146\n",
      "2024-12-05 09:50:31.853892: Current learning rate: 0.00868\n",
      "2024-12-05 09:52:43.134413: train_loss -0.6744\n",
      "2024-12-05 09:52:43.144412: val_loss -0.4456\n",
      "2024-12-05 09:52:43.150670: Pseudo dice [0.8017]\n",
      "2024-12-05 09:52:43.160174: Epoch time: 131.3 s\n",
      "2024-12-05 09:52:44.310990: \n",
      "2024-12-05 09:52:44.317320: Epoch 147\n",
      "2024-12-05 09:52:44.317320: Current learning rate: 0.00867\n",
      "2024-12-05 09:54:55.763906: train_loss -0.6685\n",
      "2024-12-05 09:54:55.780519: val_loss -0.4776\n",
      "2024-12-05 09:54:55.790516: Pseudo dice [0.7965]\n",
      "2024-12-05 09:54:55.797184: Epoch time: 131.45 s\n",
      "2024-12-05 09:54:56.863751: \n",
      "2024-12-05 09:54:56.873751: Epoch 148\n",
      "2024-12-05 09:54:56.880435: Current learning rate: 0.00866\n",
      "2024-12-05 09:57:08.295291: train_loss -0.706\n",
      "2024-12-05 09:57:08.311612: val_loss -0.5091\n",
      "2024-12-05 09:57:08.311612: Pseudo dice [0.7729]\n",
      "2024-12-05 09:57:08.321610: Epoch time: 131.43 s\n",
      "2024-12-05 09:57:09.570790: \n",
      "2024-12-05 09:57:09.577422: Epoch 149\n",
      "2024-12-05 09:57:09.587421: Current learning rate: 0.00865\n",
      "2024-12-05 09:59:20.776158: train_loss -0.7395\n",
      "2024-12-05 09:59:20.785661: val_loss -0.4768\n",
      "2024-12-05 09:59:20.791821: Pseudo dice [0.8112]\n",
      "2024-12-05 09:59:20.791821: Epoch time: 131.21 s\n",
      "2024-12-05 09:59:22.092177: \n",
      "2024-12-05 09:59:22.092177: Epoch 150\n",
      "2024-12-05 09:59:22.102175: Current learning rate: 0.00864\n",
      "2024-12-05 10:01:33.471454: train_loss -0.7309\n",
      "2024-12-05 10:01:33.488101: val_loss -0.4017\n",
      "2024-12-05 10:01:33.488101: Pseudo dice [0.7215]\n",
      "2024-12-05 10:01:33.498100: Epoch time: 131.38 s\n",
      "2024-12-05 10:01:34.555541: \n",
      "2024-12-05 10:01:34.571121: Epoch 151\n",
      "2024-12-05 10:01:34.571798: Current learning rate: 0.00863\n",
      "2024-12-05 10:03:45.751757: train_loss -0.7543\n",
      "2024-12-05 10:03:45.768463: val_loss -0.1398\n",
      "2024-12-05 10:03:45.778461: Pseudo dice [0.6127]\n",
      "2024-12-05 10:03:45.784823: Epoch time: 131.2 s\n",
      "2024-12-05 10:03:46.918399: \n",
      "2024-12-05 10:03:46.928401: Epoch 152\n",
      "2024-12-05 10:03:46.935087: Current learning rate: 0.00862\n",
      "2024-12-05 10:05:58.298788: train_loss -0.741\n",
      "2024-12-05 10:05:58.315426: val_loss -0.3721\n",
      "2024-12-05 10:05:58.325425: Pseudo dice [0.759]\n",
      "2024-12-05 10:05:58.332051: Epoch time: 131.38 s\n",
      "2024-12-05 10:05:59.448742: \n",
      "2024-12-05 10:05:59.458741: Epoch 153\n",
      "2024-12-05 10:05:59.465444: Current learning rate: 0.00861\n",
      "2024-12-05 10:08:10.914325: train_loss -0.7076\n",
      "2024-12-05 10:08:10.930272: val_loss -0.5058\n",
      "2024-12-05 10:08:10.930272: Pseudo dice [0.7655]\n",
      "2024-12-05 10:08:10.940270: Epoch time: 131.47 s\n",
      "2024-12-05 10:08:12.028991: \n",
      "2024-12-05 10:08:12.035073: Epoch 154\n",
      "2024-12-05 10:08:12.039146: Current learning rate: 0.0086\n",
      "2024-12-05 10:10:23.350841: train_loss -0.6947\n",
      "2024-12-05 10:10:23.359461: val_loss -0.162\n",
      "2024-12-05 10:10:23.368964: Pseudo dice [0.6232]\n",
      "2024-12-05 10:10:23.377885: Epoch time: 131.32 s\n",
      "2024-12-05 10:10:24.526022: \n",
      "2024-12-05 10:10:24.526022: Epoch 155\n",
      "2024-12-05 10:10:24.536021: Current learning rate: 0.00859\n",
      "2024-12-05 10:12:35.883015: train_loss -0.7097\n",
      "2024-12-05 10:12:35.900612: val_loss 0.4344\n",
      "2024-12-05 10:12:35.906820: Pseudo dice [0.235]\n",
      "2024-12-05 10:12:35.906820: Epoch time: 131.36 s\n",
      "2024-12-05 10:12:37.189810: \n",
      "2024-12-05 10:12:37.189810: Epoch 156\n",
      "2024-12-05 10:12:37.199809: Current learning rate: 0.00858\n",
      "2024-12-05 10:14:48.536985: train_loss -0.6538\n",
      "2024-12-05 10:14:48.546982: val_loss -0.2931\n",
      "2024-12-05 10:14:48.553336: Pseudo dice [0.7826]\n",
      "2024-12-05 10:14:48.563334: Epoch time: 131.35 s\n",
      "2024-12-05 10:14:49.637755: \n",
      "2024-12-05 10:14:49.653273: Epoch 157\n",
      "2024-12-05 10:14:49.653273: Current learning rate: 0.00858\n",
      "2024-12-05 10:17:00.917027: train_loss -0.7076\n",
      "2024-12-05 10:17:00.927026: val_loss -0.2899\n",
      "2024-12-05 10:17:00.933746: Pseudo dice [0.7099]\n",
      "2024-12-05 10:17:00.943744: Epoch time: 131.28 s\n",
      "2024-12-05 10:17:02.117143: \n",
      "2024-12-05 10:17:02.117143: Epoch 158\n",
      "2024-12-05 10:17:02.127140: Current learning rate: 0.00857\n",
      "2024-12-05 10:19:13.531506: train_loss -0.7043\n",
      "2024-12-05 10:19:13.541504: val_loss -0.2436\n",
      "2024-12-05 10:19:13.547323: Pseudo dice [0.6091]\n",
      "2024-12-05 10:19:13.547323: Epoch time: 131.41 s\n",
      "2024-12-05 10:19:14.680332: \n",
      "2024-12-05 10:19:14.681392: Epoch 159\n",
      "2024-12-05 10:19:14.691391: Current learning rate: 0.00856\n",
      "2024-12-05 10:21:26.021061: train_loss -0.733\n",
      "2024-12-05 10:21:26.038691: val_loss -0.3845\n",
      "2024-12-05 10:21:26.045483: Pseudo dice [0.7966]\n",
      "2024-12-05 10:21:26.050484: Epoch time: 131.35 s\n",
      "2024-12-05 10:21:27.161125: \n",
      "2024-12-05 10:21:27.161125: Epoch 160\n",
      "2024-12-05 10:21:27.171124: Current learning rate: 0.00855\n",
      "2024-12-05 10:23:38.324344: train_loss -0.7146\n",
      "2024-12-05 10:23:38.326620: val_loss -0.221\n",
      "2024-12-05 10:23:38.342221: Pseudo dice [0.6982]\n",
      "2024-12-05 10:23:38.342221: Epoch time: 131.16 s\n",
      "2024-12-05 10:23:39.541252: \n",
      "2024-12-05 10:23:39.551251: Epoch 161\n",
      "2024-12-05 10:23:39.557917: Current learning rate: 0.00854\n",
      "2024-12-05 10:25:50.948461: train_loss -0.75\n",
      "2024-12-05 10:25:50.955012: val_loss -0.1706\n",
      "2024-12-05 10:25:50.965011: Pseudo dice [0.665]\n",
      "2024-12-05 10:25:50.971691: Epoch time: 131.41 s\n",
      "2024-12-05 10:25:52.088226: \n",
      "2024-12-05 10:25:52.098224: Epoch 162\n",
      "2024-12-05 10:25:52.104908: Current learning rate: 0.00853\n",
      "2024-12-05 10:28:03.314736: train_loss -0.7\n",
      "2024-12-05 10:28:03.318656: val_loss -0.3417\n",
      "2024-12-05 10:28:03.328655: Pseudo dice [0.8085]\n",
      "2024-12-05 10:28:03.335306: Epoch time: 131.23 s\n",
      "2024-12-05 10:28:04.661908: \n",
      "2024-12-05 10:28:04.668521: Epoch 163\n",
      "2024-12-05 10:28:04.678520: Current learning rate: 0.00852\n",
      "2024-12-05 10:30:15.982394: train_loss -0.7035\n",
      "2024-12-05 10:30:15.992393: val_loss -0.3688\n",
      "2024-12-05 10:30:15.999873: Pseudo dice [0.7818]\n",
      "2024-12-05 10:30:15.999873: Epoch time: 131.32 s\n",
      "2024-12-05 10:30:17.092167: \n",
      "2024-12-05 10:30:17.098936: Epoch 164\n",
      "2024-12-05 10:30:17.098936: Current learning rate: 0.00851\n",
      "2024-12-05 10:32:28.478973: train_loss -0.7017\n",
      "2024-12-05 10:32:28.481211: val_loss -0.3308\n",
      "2024-12-05 10:32:28.495924: Pseudo dice [0.7608]\n",
      "2024-12-05 10:32:28.495924: Epoch time: 131.39 s\n",
      "2024-12-05 10:32:29.564019: \n",
      "2024-12-05 10:32:29.579223: Epoch 165\n",
      "2024-12-05 10:32:29.579223: Current learning rate: 0.0085\n",
      "2024-12-05 10:34:40.853723: train_loss -0.7411\n",
      "2024-12-05 10:34:40.861537: val_loss -0.2697\n",
      "2024-12-05 10:34:40.871535: Pseudo dice [0.7073]\n",
      "2024-12-05 10:34:40.876234: Epoch time: 131.29 s\n",
      "2024-12-05 10:34:41.945091: \n",
      "2024-12-05 10:34:41.945091: Epoch 166\n",
      "2024-12-05 10:34:41.954595: Current learning rate: 0.00849\n",
      "2024-12-05 10:36:53.206585: train_loss -0.7184\n",
      "2024-12-05 10:36:53.216584: val_loss -0.3162\n",
      "2024-12-05 10:36:53.216584: Pseudo dice [0.6856]\n",
      "2024-12-05 10:36:53.223180: Epoch time: 131.26 s\n",
      "2024-12-05 10:36:54.306838: \n",
      "2024-12-05 10:36:54.316340: Epoch 167\n",
      "2024-12-05 10:36:54.323153: Current learning rate: 0.00848\n",
      "2024-12-05 10:39:05.636867: train_loss -0.74\n",
      "2024-12-05 10:39:05.653535: val_loss -0.4589\n",
      "2024-12-05 10:39:05.653535: Pseudo dice [0.8106]\n",
      "2024-12-05 10:39:05.663533: Epoch time: 131.33 s\n",
      "2024-12-05 10:39:06.730151: \n",
      "2024-12-05 10:39:06.737464: Epoch 168\n",
      "2024-12-05 10:39:06.746967: Current learning rate: 0.00847\n",
      "2024-12-05 10:41:17.977222: train_loss -0.6625\n",
      "2024-12-05 10:41:17.983897: val_loss -0.0745\n",
      "2024-12-05 10:41:17.993896: Pseudo dice [0.448]\n",
      "2024-12-05 10:41:18.002491: Epoch time: 131.25 s\n",
      "2024-12-05 10:41:19.068679: \n",
      "2024-12-05 10:41:19.078182: Epoch 169\n",
      "2024-12-05 10:41:19.083878: Current learning rate: 0.00847\n",
      "2024-12-05 10:43:30.508529: train_loss -0.7016\n",
      "2024-12-05 10:43:30.514191: val_loss -0.1194\n",
      "2024-12-05 10:43:30.524189: Pseudo dice [0.7109]\n",
      "2024-12-05 10:43:30.530905: Epoch time: 131.44 s\n",
      "2024-12-05 10:43:31.790769: \n",
      "2024-12-05 10:43:31.798902: Epoch 170\n",
      "2024-12-05 10:43:31.808405: Current learning rate: 0.00846\n",
      "2024-12-05 10:45:43.204565: train_loss -0.7191\n",
      "2024-12-05 10:45:43.212209: val_loss -0.4435\n",
      "2024-12-05 10:45:43.222208: Pseudo dice [0.8048]\n",
      "2024-12-05 10:45:43.229175: Epoch time: 131.41 s\n",
      "2024-12-05 10:45:44.382317: \n",
      "2024-12-05 10:45:44.387820: Epoch 171\n",
      "2024-12-05 10:45:44.394893: Current learning rate: 0.00845\n",
      "2024-12-05 10:47:55.553333: train_loss -0.7411\n",
      "2024-12-05 10:47:55.558164: val_loss -0.3738\n",
      "2024-12-05 10:47:55.576833: Pseudo dice [0.6895]\n",
      "2024-12-05 10:47:55.576833: Epoch time: 131.17 s\n",
      "2024-12-05 10:47:56.718091: \n",
      "2024-12-05 10:47:56.724816: Epoch 172\n",
      "2024-12-05 10:47:56.724816: Current learning rate: 0.00844\n",
      "2024-12-05 10:50:08.131808: train_loss -0.6872\n",
      "2024-12-05 10:50:08.140631: val_loss -0.4444\n",
      "2024-12-05 10:50:08.156207: Pseudo dice [0.7519]\n",
      "2024-12-05 10:50:08.156207: Epoch time: 131.41 s\n",
      "2024-12-05 10:50:09.255051: \n",
      "2024-12-05 10:50:09.265051: Epoch 173\n",
      "2024-12-05 10:50:09.271799: Current learning rate: 0.00843\n",
      "2024-12-05 10:52:20.518936: train_loss -0.6837\n",
      "2024-12-05 10:52:20.528933: val_loss -0.2959\n",
      "2024-12-05 10:52:20.537255: Pseudo dice [0.6355]\n",
      "2024-12-05 10:52:20.537255: Epoch time: 131.26 s\n",
      "2024-12-05 10:52:21.618891: \n",
      "2024-12-05 10:52:21.618891: Epoch 174\n",
      "2024-12-05 10:52:21.628890: Current learning rate: 0.00842\n",
      "2024-12-05 10:54:32.959264: train_loss -0.7186\n",
      "2024-12-05 10:54:32.965825: val_loss -0.2677\n",
      "2024-12-05 10:54:32.982516: Pseudo dice [0.6527]\n",
      "2024-12-05 10:54:32.982516: Epoch time: 131.34 s\n",
      "2024-12-05 10:54:34.092385: \n",
      "2024-12-05 10:54:34.100582: Epoch 175\n",
      "2024-12-05 10:54:34.100582: Current learning rate: 0.00841\n",
      "2024-12-05 10:56:45.556155: train_loss -0.6975\n",
      "2024-12-05 10:56:45.563769: val_loss -0.3527\n",
      "2024-12-05 10:56:45.573767: Pseudo dice [0.712]\n",
      "2024-12-05 10:56:45.579871: Epoch time: 131.46 s\n",
      "2024-12-05 10:56:46.656037: \n",
      "2024-12-05 10:56:46.662719: Epoch 176\n",
      "2024-12-05 10:56:46.662719: Current learning rate: 0.0084\n",
      "2024-12-05 10:58:57.986410: train_loss -0.6603\n",
      "2024-12-05 10:58:57.993101: val_loss -0.2092\n",
      "2024-12-05 10:58:58.009773: Pseudo dice [0.6381]\n",
      "2024-12-05 10:58:58.009773: Epoch time: 131.33 s\n",
      "2024-12-05 10:58:59.359727: \n",
      "2024-12-05 10:58:59.369725: Epoch 177\n",
      "2024-12-05 10:58:59.376394: Current learning rate: 0.00839\n",
      "2024-12-05 11:01:10.707273: train_loss -0.6686\n",
      "2024-12-05 11:01:10.716776: val_loss -0.3612\n",
      "2024-12-05 11:01:10.723465: Pseudo dice [0.7888]\n",
      "2024-12-05 11:01:10.723465: Epoch time: 131.35 s\n",
      "2024-12-05 11:01:11.816682: \n",
      "2024-12-05 11:01:11.823340: Epoch 178\n",
      "2024-12-05 11:01:11.823340: Current learning rate: 0.00838\n",
      "2024-12-05 11:03:28.367008: train_loss -0.7188\n",
      "2024-12-05 11:03:28.376011: val_loss -0.092\n",
      "2024-12-05 11:03:28.385012: Pseudo dice [0.6026]\n",
      "2024-12-05 11:03:28.391013: Epoch time: 136.55 s\n",
      "2024-12-05 11:03:29.487552: \n",
      "2024-12-05 11:03:29.494555: Epoch 179\n",
      "2024-12-05 11:03:29.499555: Current learning rate: 0.00837\n",
      "2024-12-05 11:05:48.204427: train_loss -0.687\n",
      "2024-12-05 11:05:48.212429: val_loss -0.5149\n",
      "2024-12-05 11:05:48.221431: Pseudo dice [0.8079]\n",
      "2024-12-05 11:05:48.227433: Epoch time: 138.72 s\n",
      "2024-12-05 11:05:49.432707: \n",
      "2024-12-05 11:05:49.440708: Epoch 180\n",
      "2024-12-05 11:05:49.445709: Current learning rate: 0.00836\n",
      "2024-12-05 11:08:09.248142: train_loss -0.6918\n",
      "2024-12-05 11:08:09.256145: val_loss -0.3849\n",
      "2024-12-05 11:08:09.264146: Pseudo dice [0.7594]\n",
      "2024-12-05 11:08:09.269147: Epoch time: 139.82 s\n",
      "2024-12-05 11:08:10.415668: \n",
      "2024-12-05 11:08:10.424667: Epoch 181\n",
      "2024-12-05 11:08:10.429668: Current learning rate: 0.00836\n",
      "2024-12-05 11:10:30.144028: train_loss -0.7213\n",
      "2024-12-05 11:10:30.154029: val_loss -0.5006\n",
      "2024-12-05 11:10:30.164032: Pseudo dice [0.7864]\n",
      "2024-12-05 11:10:30.171033: Epoch time: 139.73 s\n",
      "2024-12-05 11:10:31.321294: \n",
      "2024-12-05 11:10:31.329296: Epoch 182\n",
      "2024-12-05 11:10:31.333297: Current learning rate: 0.00835\n",
      "2024-12-05 11:12:50.076140: train_loss -0.7339\n",
      "2024-12-05 11:12:50.086142: val_loss -0.4413\n",
      "2024-12-05 11:12:50.095145: Pseudo dice [0.7757]\n",
      "2024-12-05 11:12:50.101146: Epoch time: 138.76 s\n",
      "2024-12-05 11:12:51.282413: \n",
      "2024-12-05 11:12:51.290414: Epoch 183\n",
      "2024-12-05 11:12:51.296416: Current learning rate: 0.00834\n",
      "2024-12-05 11:15:11.085164: train_loss -0.6862\n",
      "2024-12-05 11:15:11.096167: val_loss -0.35\n",
      "2024-12-05 11:15:11.103167: Pseudo dice [0.7609]\n",
      "2024-12-05 11:15:11.111169: Epoch time: 139.8 s\n",
      "2024-12-05 11:15:12.420524: \n",
      "2024-12-05 11:15:12.428525: Epoch 184\n",
      "2024-12-05 11:15:12.433526: Current learning rate: 0.00833\n",
      "2024-12-05 11:17:30.836382: train_loss -0.6838\n",
      "2024-12-05 11:17:30.847385: val_loss -0.4587\n",
      "2024-12-05 11:17:30.853386: Pseudo dice [0.7253]\n",
      "2024-12-05 11:17:30.858387: Epoch time: 138.42 s\n",
      "2024-12-05 11:17:32.046655: \n",
      "2024-12-05 11:17:32.054657: Epoch 185\n",
      "2024-12-05 11:17:32.059659: Current learning rate: 0.00832\n",
      "2024-12-05 11:19:51.945726: train_loss -0.7188\n",
      "2024-12-05 11:19:51.955727: val_loss -0.3498\n",
      "2024-12-05 11:19:51.960729: Pseudo dice [0.6852]\n",
      "2024-12-05 11:19:51.965731: Epoch time: 139.9 s\n",
      "2024-12-05 11:19:53.107989: \n",
      "2024-12-05 11:19:53.115990: Epoch 186\n",
      "2024-12-05 11:19:53.120991: Current learning rate: 0.00831\n",
      "2024-12-05 11:22:13.461487: train_loss -0.7428\n",
      "2024-12-05 11:22:13.472489: val_loss -0.1578\n",
      "2024-12-05 11:22:13.481492: Pseudo dice [0.504]\n",
      "2024-12-05 11:22:13.486492: Epoch time: 140.35 s\n",
      "2024-12-05 11:22:14.626021: \n",
      "2024-12-05 11:22:14.634022: Epoch 187\n",
      "2024-12-05 11:22:14.639024: Current learning rate: 0.0083\n",
      "2024-12-05 11:24:33.205195: train_loss -0.7243\n",
      "2024-12-05 11:24:33.217198: val_loss -0.4078\n",
      "2024-12-05 11:24:33.225200: Pseudo dice [0.7905]\n",
      "2024-12-05 11:24:33.230201: Epoch time: 138.58 s\n",
      "2024-12-05 11:24:34.331450: \n",
      "2024-12-05 11:24:34.338451: Epoch 188\n",
      "2024-12-05 11:24:34.343452: Current learning rate: 0.00829\n",
      "2024-12-05 11:26:54.110867: train_loss -0.7301\n",
      "2024-12-05 11:26:54.122869: val_loss -0.4014\n",
      "2024-12-05 11:26:54.131871: Pseudo dice [0.7165]\n",
      "2024-12-05 11:26:54.137872: Epoch time: 139.78 s\n",
      "2024-12-05 11:26:55.219396: \n",
      "2024-12-05 11:26:55.226397: Epoch 189\n",
      "2024-12-05 11:26:55.231398: Current learning rate: 0.00828\n",
      "2024-12-05 11:29:13.900422: train_loss -0.7385\n",
      "2024-12-05 11:29:13.909424: val_loss -0.462\n",
      "2024-12-05 11:29:13.917426: Pseudo dice [0.7771]\n",
      "2024-12-05 11:29:13.924427: Epoch time: 138.68 s\n",
      "2024-12-05 11:29:15.091973: \n",
      "2024-12-05 11:29:15.099975: Epoch 190\n",
      "2024-12-05 11:29:15.105977: Current learning rate: 0.00827\n",
      "2024-12-05 11:31:34.629192: train_loss -0.7287\n",
      "2024-12-05 11:31:34.639195: val_loss 0.0282\n",
      "2024-12-05 11:31:34.645195: Pseudo dice [0.5372]\n",
      "2024-12-05 11:31:34.651197: Epoch time: 139.54 s\n",
      "2024-12-05 11:31:35.976496: \n",
      "2024-12-05 11:31:35.984498: Epoch 191\n",
      "2024-12-05 11:31:35.989499: Current learning rate: 0.00826\n",
      "2024-12-05 11:33:55.794418: train_loss -0.7529\n",
      "2024-12-05 11:33:55.806606: val_loss -0.3625\n",
      "2024-12-05 11:33:55.813765: Pseudo dice [0.7722]\n",
      "2024-12-05 11:33:55.819835: Epoch time: 139.82 s\n",
      "2024-12-05 11:33:56.971473: \n",
      "2024-12-05 11:33:56.979474: Epoch 192\n",
      "2024-12-05 11:33:56.984476: Current learning rate: 0.00825\n",
      "2024-12-05 11:36:15.824522: train_loss -0.758\n",
      "2024-12-05 11:36:15.835525: val_loss -0.3356\n",
      "2024-12-05 11:36:15.841526: Pseudo dice [0.7821]\n",
      "2024-12-05 11:36:15.847527: Epoch time: 138.85 s\n",
      "2024-12-05 11:36:17.051800: \n",
      "2024-12-05 11:36:17.059801: Epoch 193\n",
      "2024-12-05 11:36:17.065803: Current learning rate: 0.00824\n",
      "2024-12-05 11:38:36.537902: train_loss -0.7678\n",
      "2024-12-05 11:38:36.547904: val_loss -0.4751\n",
      "2024-12-05 11:38:36.552905: Pseudo dice [0.77]\n",
      "2024-12-05 11:38:36.557906: Epoch time: 139.49 s\n",
      "2024-12-05 11:38:37.679160: \n",
      "2024-12-05 11:38:37.686162: Epoch 194\n",
      "2024-12-05 11:38:37.691163: Current learning rate: 0.00824\n",
      "2024-12-05 11:40:49.146790: train_loss -0.7505\n",
      "2024-12-05 11:40:49.152580: val_loss -0.3036\n",
      "2024-12-05 11:40:49.169284: Pseudo dice [0.7205]\n",
      "2024-12-05 11:40:49.169284: Epoch time: 131.47 s\n",
      "2024-12-05 11:40:50.262693: \n",
      "2024-12-05 11:40:50.269190: Epoch 195\n",
      "2024-12-05 11:40:50.279190: Current learning rate: 0.00823\n",
      "2024-12-05 11:43:01.651631: train_loss -0.7539\n",
      "2024-12-05 11:43:01.661629: val_loss -0.564\n",
      "2024-12-05 11:43:01.666367: Pseudo dice [0.7993]\n",
      "2024-12-05 11:43:01.666367: Epoch time: 131.39 s\n",
      "2024-12-05 11:43:02.860373: \n",
      "2024-12-05 11:43:02.866801: Epoch 196\n",
      "2024-12-05 11:43:02.866801: Current learning rate: 0.00822\n",
      "2024-12-05 11:45:14.339938: train_loss -0.7447\n",
      "2024-12-05 11:45:14.346632: val_loss -0.3348\n",
      "2024-12-05 11:45:14.356630: Pseudo dice [0.7657]\n",
      "2024-12-05 11:45:14.363282: Epoch time: 131.49 s\n",
      "2024-12-05 11:45:14.363282: Yayy! New best EMA pseudo Dice: 0.7313\n",
      "2024-12-05 11:45:15.906368: \n",
      "2024-12-05 11:45:15.913162: Epoch 197\n",
      "2024-12-05 11:45:15.923161: Current learning rate: 0.00821\n",
      "2024-12-05 11:47:27.276844: train_loss -0.75\n",
      "2024-12-05 11:47:27.286843: val_loss -0.3243\n",
      "2024-12-05 11:47:27.294461: Pseudo dice [0.7758]\n",
      "2024-12-05 11:47:27.294461: Epoch time: 131.37 s\n",
      "2024-12-05 11:47:27.304460: Yayy! New best EMA pseudo Dice: 0.7357\n",
      "2024-12-05 11:47:28.710145: \n",
      "2024-12-05 11:47:28.720143: Epoch 198\n",
      "2024-12-05 11:47:28.728299: Current learning rate: 0.0082\n",
      "2024-12-05 11:49:40.010709: train_loss -0.7059\n",
      "2024-12-05 11:49:40.020853: val_loss -0.4028\n",
      "2024-12-05 11:49:40.028449: Pseudo dice [0.7778]\n",
      "2024-12-05 11:49:40.035452: Epoch time: 131.3 s\n",
      "2024-12-05 11:49:40.040567: Yayy! New best EMA pseudo Dice: 0.7399\n",
      "2024-12-05 11:49:41.475123: \n",
      "2024-12-05 11:49:41.475123: Epoch 199\n",
      "2024-12-05 11:49:41.484627: Current learning rate: 0.00819\n",
      "2024-12-05 11:51:52.956177: train_loss -0.7155\n",
      "2024-12-05 11:51:52.971274: val_loss -0.469\n",
      "2024-12-05 11:51:52.980778: Pseudo dice [0.8044]\n",
      "2024-12-05 11:51:52.987525: Epoch time: 131.48 s\n",
      "2024-12-05 11:51:53.247540: Yayy! New best EMA pseudo Dice: 0.7464\n",
      "2024-12-05 11:51:54.672996: \n",
      "2024-12-05 11:51:54.672996: Epoch 200\n",
      "2024-12-05 11:51:54.687456: Current learning rate: 0.00818\n",
      "2024-12-05 11:54:06.034507: train_loss -0.7062\n",
      "2024-12-05 11:54:06.051140: val_loss -0.0941\n",
      "2024-12-05 11:54:06.051140: Pseudo dice [0.5913]\n",
      "2024-12-05 11:54:06.061139: Epoch time: 131.36 s\n",
      "2024-12-05 11:54:07.151823: \n",
      "2024-12-05 11:54:07.161864: Epoch 201\n",
      "2024-12-05 11:54:07.168682: Current learning rate: 0.00817\n",
      "2024-12-05 11:56:18.616497: train_loss -0.7328\n",
      "2024-12-05 11:56:18.631434: val_loss -0.3699\n",
      "2024-12-05 11:56:18.641432: Pseudo dice [0.6696]\n",
      "2024-12-05 11:56:18.648246: Epoch time: 131.46 s\n",
      "2024-12-05 11:56:19.731388: \n",
      "2024-12-05 11:56:19.741388: Epoch 202\n",
      "2024-12-05 11:56:19.748062: Current learning rate: 0.00816\n",
      "2024-12-05 11:58:31.188345: train_loss -0.7261\n",
      "2024-12-05 11:58:31.195106: val_loss -0.3001\n",
      "2024-12-05 11:58:31.205104: Pseudo dice [0.7509]\n",
      "2024-12-05 11:58:31.212499: Epoch time: 131.46 s\n",
      "2024-12-05 11:58:32.413038: \n",
      "2024-12-05 11:58:32.428134: Epoch 203\n",
      "2024-12-05 11:58:32.428410: Current learning rate: 0.00815\n",
      "2024-12-05 12:00:43.692131: train_loss -0.6727\n",
      "2024-12-05 12:00:43.709463: val_loss -0.386\n",
      "2024-12-05 12:00:43.710321: Pseudo dice [0.7994]\n",
      "2024-12-05 12:00:43.725504: Epoch time: 131.28 s\n",
      "2024-12-05 12:00:45.068796: \n",
      "2024-12-05 12:00:45.076663: Epoch 204\n",
      "2024-12-05 12:00:45.076663: Current learning rate: 0.00814\n",
      "2024-12-05 12:02:56.472640: train_loss -0.693\n",
      "2024-12-05 12:02:56.482639: val_loss -0.3665\n",
      "2024-12-05 12:02:56.489047: Pseudo dice [0.7097]\n",
      "2024-12-05 12:02:56.499047: Epoch time: 131.4 s\n",
      "2024-12-05 12:02:57.623595: \n",
      "2024-12-05 12:02:57.633098: Epoch 205\n",
      "2024-12-05 12:02:57.633098: Current learning rate: 0.00813\n",
      "2024-12-05 12:05:08.946204: train_loss -0.711\n",
      "2024-12-05 12:05:08.952700: val_loss -0.4407\n",
      "2024-12-05 12:05:08.969076: Pseudo dice [0.7629]\n",
      "2024-12-05 12:05:08.969378: Epoch time: 131.32 s\n",
      "2024-12-05 12:05:10.111521: \n",
      "2024-12-05 12:05:10.119357: Epoch 206\n",
      "2024-12-05 12:05:10.119357: Current learning rate: 0.00813\n",
      "2024-12-05 12:07:21.400057: train_loss -0.7218\n",
      "2024-12-05 12:07:21.416338: val_loss -0.4129\n",
      "2024-12-05 12:07:21.426337: Pseudo dice [0.7362]\n",
      "2024-12-05 12:07:21.432005: Epoch time: 131.29 s\n",
      "2024-12-05 12:07:22.449601: \n",
      "2024-12-05 12:07:22.459600: Epoch 207\n",
      "2024-12-05 12:07:22.466239: Current learning rate: 0.00812\n",
      "2024-12-05 12:09:33.856708: train_loss -0.729\n",
      "2024-12-05 12:09:33.863312: val_loss -0.1923\n",
      "2024-12-05 12:09:33.880033: Pseudo dice [0.6943]\n",
      "2024-12-05 12:09:33.880033: Epoch time: 131.41 s\n",
      "2024-12-05 12:09:34.913249: \n",
      "2024-12-05 12:09:34.923247: Epoch 208\n",
      "2024-12-05 12:09:34.929902: Current learning rate: 0.00811\n",
      "2024-12-05 12:11:46.278298: train_loss -0.7262\n",
      "2024-12-05 12:11:46.293372: val_loss -0.2608\n",
      "2024-12-05 12:11:46.294131: Pseudo dice [0.6987]\n",
      "2024-12-05 12:11:46.303634: Epoch time: 131.37 s\n",
      "2024-12-05 12:11:47.370268: \n",
      "2024-12-05 12:11:47.376916: Epoch 209\n",
      "2024-12-05 12:11:47.376916: Current learning rate: 0.0081\n",
      "2024-12-05 12:13:58.669494: train_loss -0.738\n",
      "2024-12-05 12:13:58.674410: val_loss -0.4268\n",
      "2024-12-05 12:13:58.683913: Pseudo dice [0.7591]\n",
      "2024-12-05 12:13:58.690697: Epoch time: 131.3 s\n",
      "2024-12-05 12:13:59.817255: \n",
      "2024-12-05 12:13:59.825620: Epoch 210\n",
      "2024-12-05 12:13:59.835123: Current learning rate: 0.00809\n",
      "2024-12-05 12:16:11.238260: train_loss -0.7382\n",
      "2024-12-05 12:16:11.254284: val_loss -0.3929\n",
      "2024-12-05 12:16:11.264283: Pseudo dice [0.695]\n",
      "2024-12-05 12:16:11.271051: Epoch time: 131.42 s\n",
      "2024-12-05 12:16:12.487754: \n",
      "2024-12-05 12:16:12.487754: Epoch 211\n",
      "2024-12-05 12:16:12.497751: Current learning rate: 0.00808\n",
      "2024-12-05 12:18:23.661317: train_loss -0.7716\n",
      "2024-12-05 12:18:23.669351: val_loss -0.4511\n",
      "2024-12-05 12:18:23.678854: Pseudo dice [0.8086]\n",
      "2024-12-05 12:18:23.685414: Epoch time: 131.17 s\n",
      "2024-12-05 12:18:24.717907: \n",
      "2024-12-05 12:18:24.727905: Epoch 212\n",
      "2024-12-05 12:18:24.734538: Current learning rate: 0.00807\n",
      "2024-12-05 12:20:36.174891: train_loss -0.7702\n",
      "2024-12-05 12:20:36.181644: val_loss -0.271\n",
      "2024-12-05 12:20:36.191642: Pseudo dice [0.6566]\n",
      "2024-12-05 12:20:36.198325: Epoch time: 131.45 s\n",
      "2024-12-05 12:20:37.258182: \n",
      "2024-12-05 12:20:37.265696: Epoch 213\n",
      "2024-12-05 12:20:37.275696: Current learning rate: 0.00806\n",
      "2024-12-05 12:22:48.707128: train_loss -0.7558\n",
      "2024-12-05 12:22:48.712093: val_loss -0.3361\n",
      "2024-12-05 12:22:48.728575: Pseudo dice [0.7203]\n",
      "2024-12-05 12:22:48.728575: Epoch time: 131.45 s\n",
      "2024-12-05 12:22:49.845471: \n",
      "2024-12-05 12:22:49.845471: Epoch 214\n",
      "2024-12-05 12:22:49.855469: Current learning rate: 0.00805\n",
      "2024-12-05 12:25:01.125559: train_loss -0.7408\n",
      "2024-12-05 12:25:01.135557: val_loss -0.4771\n",
      "2024-12-05 12:25:01.146047: Pseudo dice [0.7555]\n",
      "2024-12-05 12:25:01.151047: Epoch time: 131.28 s\n",
      "2024-12-05 12:25:02.177059: \n",
      "2024-12-05 12:25:02.186562: Epoch 215\n",
      "2024-12-05 12:25:02.192222: Current learning rate: 0.00804\n",
      "2024-12-05 12:27:13.556337: train_loss -0.721\n",
      "2024-12-05 12:27:13.566336: val_loss -0.4649\n",
      "2024-12-05 12:27:13.574226: Pseudo dice [0.783]\n",
      "2024-12-05 12:27:13.583730: Epoch time: 131.38 s\n",
      "2024-12-05 12:27:14.622469: \n",
      "2024-12-05 12:27:14.632468: Epoch 216\n",
      "2024-12-05 12:27:14.640584: Current learning rate: 0.00803\n",
      "2024-12-05 12:29:25.981608: train_loss -0.7456\n",
      "2024-12-05 12:29:25.986219: val_loss -0.0608\n",
      "2024-12-05 12:29:26.002695: Pseudo dice [0.4913]\n",
      "2024-12-05 12:29:26.007717: Epoch time: 131.36 s\n",
      "2024-12-05 12:29:27.102718: \n",
      "2024-12-05 12:29:27.110759: Epoch 217\n",
      "2024-12-05 12:29:27.116760: Current learning rate: 0.00802\n",
      "2024-12-05 12:31:38.401608: train_loss -0.7505\n",
      "2024-12-05 12:31:38.416544: val_loss -0.3072\n",
      "2024-12-05 12:31:38.416544: Pseudo dice [0.7364]\n",
      "2024-12-05 12:31:38.432903: Epoch time: 131.31 s\n",
      "2024-12-05 12:31:39.643137: \n",
      "2024-12-05 12:31:39.649780: Epoch 218\n",
      "2024-12-05 12:31:39.649780: Current learning rate: 0.00801\n",
      "2024-12-05 12:33:51.080167: train_loss -0.755\n",
      "2024-12-05 12:33:51.090166: val_loss -0.5951\n",
      "2024-12-05 12:33:51.098685: Pseudo dice [0.8371]\n",
      "2024-12-05 12:33:51.108682: Epoch time: 131.45 s\n",
      "2024-12-05 12:33:52.181884: \n",
      "2024-12-05 12:33:52.182519: Epoch 219\n",
      "2024-12-05 12:33:52.192021: Current learning rate: 0.00801\n",
      "2024-12-05 12:36:03.587154: train_loss -0.7622\n",
      "2024-12-05 12:36:03.593825: val_loss -0.4139\n",
      "2024-12-05 12:36:03.603823: Pseudo dice [0.7825]\n",
      "2024-12-05 12:36:03.610512: Epoch time: 131.41 s\n",
      "2024-12-05 12:36:04.693756: \n",
      "2024-12-05 12:36:04.710210: Epoch 220\n",
      "2024-12-05 12:36:04.711975: Current learning rate: 0.008\n",
      "2024-12-05 12:38:15.990524: train_loss -0.7718\n",
      "2024-12-05 12:38:16.002682: val_loss -0.3905\n",
      "2024-12-05 12:38:16.007567: Pseudo dice [0.8034]\n",
      "2024-12-05 12:38:16.017565: Epoch time: 131.3 s\n",
      "2024-12-05 12:38:17.124099: \n",
      "2024-12-05 12:38:17.134097: Epoch 221\n",
      "2024-12-05 12:38:17.140824: Current learning rate: 0.00799\n",
      "2024-12-05 12:40:28.622819: train_loss -0.7133\n",
      "2024-12-05 12:40:28.632322: val_loss -0.201\n",
      "2024-12-05 12:40:28.638386: Pseudo dice [0.6989]\n",
      "2024-12-05 12:40:28.647889: Epoch time: 131.5 s\n",
      "2024-12-05 12:40:29.687926: \n",
      "2024-12-05 12:40:29.687926: Epoch 222\n",
      "2024-12-05 12:40:29.697925: Current learning rate: 0.00798\n",
      "2024-12-05 12:42:40.934927: train_loss -0.7077\n",
      "2024-12-05 12:42:40.944927: val_loss -0.4317\n",
      "2024-12-05 12:42:40.951678: Pseudo dice [0.7436]\n",
      "2024-12-05 12:42:40.951678: Epoch time: 131.25 s\n",
      "2024-12-05 12:42:42.034782: \n",
      "2024-12-05 12:42:42.044781: Epoch 223\n",
      "2024-12-05 12:42:42.051521: Current learning rate: 0.00797\n",
      "2024-12-05 12:44:53.491797: train_loss -0.7504\n",
      "2024-12-05 12:44:53.498509: val_loss -0.2868\n",
      "2024-12-05 12:44:53.508507: Pseudo dice [0.6411]\n",
      "2024-12-05 12:44:53.515195: Epoch time: 131.46 s\n",
      "2024-12-05 12:44:54.615090: \n",
      "2024-12-05 12:44:54.631770: Epoch 224\n",
      "2024-12-05 12:44:54.631770: Current learning rate: 0.00796\n",
      "2024-12-05 12:47:06.112153: train_loss -0.768\n",
      "2024-12-05 12:47:06.128845: val_loss -0.4879\n",
      "2024-12-05 12:47:06.138844: Pseudo dice [0.7625]\n",
      "2024-12-05 12:47:06.145508: Epoch time: 131.5 s\n",
      "2024-12-05 12:47:07.247789: \n",
      "2024-12-05 12:47:07.247789: Epoch 225\n",
      "2024-12-05 12:47:07.262112: Current learning rate: 0.00795\n",
      "2024-12-05 12:49:18.569072: train_loss -0.7809\n",
      "2024-12-05 12:49:18.585849: val_loss -0.3728\n",
      "2024-12-05 12:49:18.592509: Pseudo dice [0.7957]\n",
      "2024-12-05 12:49:18.592509: Epoch time: 131.32 s\n",
      "2024-12-05 12:49:19.792373: \n",
      "2024-12-05 12:49:19.808775: Epoch 226\n",
      "2024-12-05 12:49:19.809012: Current learning rate: 0.00794\n",
      "2024-12-05 12:51:31.156047: train_loss -0.7625\n",
      "2024-12-05 12:51:31.166045: val_loss -0.2251\n",
      "2024-12-05 12:51:31.172825: Pseudo dice [0.6589]\n",
      "2024-12-05 12:51:31.172825: Epoch time: 131.36 s\n",
      "2024-12-05 12:51:32.256367: \n",
      "2024-12-05 12:51:32.265870: Epoch 227\n",
      "2024-12-05 12:51:32.272661: Current learning rate: 0.00793\n",
      "2024-12-05 12:53:43.596420: train_loss -0.7728\n",
      "2024-12-05 12:53:43.609917: val_loss -0.2702\n",
      "2024-12-05 12:53:43.619422: Pseudo dice [0.7467]\n",
      "2024-12-05 12:53:43.622016: Epoch time: 131.34 s\n",
      "2024-12-05 12:53:44.637196: \n",
      "2024-12-05 12:53:44.637196: Epoch 228\n",
      "2024-12-05 12:53:44.647194: Current learning rate: 0.00792\n",
      "2024-12-05 12:55:55.967476: train_loss -0.739\n",
      "2024-12-05 12:55:55.978489: val_loss -0.4864\n",
      "2024-12-05 12:55:55.983440: Pseudo dice [0.7792]\n",
      "2024-12-05 12:55:55.993438: Epoch time: 131.33 s\n",
      "2024-12-05 12:55:57.034095: \n",
      "2024-12-05 12:55:57.034914: Epoch 229\n",
      "2024-12-05 12:55:57.044419: Current learning rate: 0.00791\n",
      "2024-12-05 12:58:08.523710: train_loss -0.7691\n",
      "2024-12-05 12:58:08.530446: val_loss -0.3548\n",
      "2024-12-05 12:58:08.540445: Pseudo dice [0.7088]\n",
      "2024-12-05 12:58:08.547165: Epoch time: 131.49 s\n",
      "2024-12-05 12:58:09.580326: \n",
      "2024-12-05 12:58:09.590325: Epoch 230\n",
      "2024-12-05 12:58:09.597733: Current learning rate: 0.0079\n",
      "2024-12-05 13:00:21.062598: train_loss -0.7476\n",
      "2024-12-05 13:00:21.078184: val_loss -0.3435\n",
      "2024-12-05 13:00:21.078184: Pseudo dice [0.6963]\n",
      "2024-12-05 13:00:21.088182: Epoch time: 131.48 s\n",
      "2024-12-05 13:00:22.110850: \n",
      "2024-12-05 13:00:22.110850: Epoch 231\n",
      "2024-12-05 13:00:22.120848: Current learning rate: 0.00789\n",
      "2024-12-05 13:02:33.441051: train_loss -0.6976\n",
      "2024-12-05 13:02:33.457741: val_loss -0.4713\n",
      "2024-12-05 13:02:33.457741: Pseudo dice [0.7484]\n",
      "2024-12-05 13:02:33.475400: Epoch time: 131.33 s\n",
      "2024-12-05 13:02:34.517607: \n",
      "2024-12-05 13:02:34.524283: Epoch 232\n",
      "2024-12-05 13:02:34.524283: Current learning rate: 0.00789\n",
      "2024-12-05 13:04:46.039190: train_loss -0.6863\n",
      "2024-12-05 13:04:46.056681: val_loss -0.3947\n",
      "2024-12-05 13:04:46.066679: Pseudo dice [0.7813]\n",
      "2024-12-05 13:04:46.071377: Epoch time: 131.52 s\n",
      "2024-12-05 13:04:47.331280: \n",
      "2024-12-05 13:04:47.339510: Epoch 233\n",
      "2024-12-05 13:04:47.349013: Current learning rate: 0.00788\n",
      "2024-12-05 13:06:58.627705: train_loss -0.7324\n",
      "2024-12-05 13:06:58.635078: val_loss 0.0779\n",
      "2024-12-05 13:06:58.651702: Pseudo dice [0.4131]\n",
      "2024-12-05 13:06:58.651702: Epoch time: 131.3 s\n",
      "2024-12-05 13:06:59.694915: \n",
      "2024-12-05 13:06:59.704438: Epoch 234\n",
      "2024-12-05 13:06:59.708439: Current learning rate: 0.00787\n",
      "2024-12-05 13:09:12.552519: train_loss -0.7277\n",
      "2024-12-05 13:09:12.552519: val_loss -0.4488\n",
      "2024-12-05 13:09:12.562522: Pseudo dice [0.7811]\n",
      "2024-12-05 13:09:12.569524: Epoch time: 132.86 s\n",
      "2024-12-05 13:09:13.629623: \n",
      "2024-12-05 13:09:13.630624: Epoch 235\n",
      "2024-12-05 13:09:13.637626: Current learning rate: 0.00786\n",
      "2024-12-05 13:11:27.261441: train_loss -0.743\n",
      "2024-12-05 13:11:27.261441: val_loss -0.4851\n",
      "2024-12-05 13:11:27.277391: Pseudo dice [0.7961]\n",
      "2024-12-05 13:11:27.281622: Epoch time: 133.63 s\n",
      "2024-12-05 13:11:28.401404: \n",
      "2024-12-05 13:11:28.411404: Epoch 236\n",
      "2024-12-05 13:11:28.421404: Current learning rate: 0.00785\n",
      "2024-12-05 13:13:39.178167: train_loss -0.7448\n",
      "2024-12-05 13:13:39.187196: val_loss -0.4892\n",
      "2024-12-05 13:13:39.195278: Pseudo dice [0.797]\n",
      "2024-12-05 13:13:39.201279: Epoch time: 130.78 s\n",
      "2024-12-05 13:13:40.242266: \n",
      "2024-12-05 13:13:40.251769: Epoch 237\n",
      "2024-12-05 13:13:40.261771: Current learning rate: 0.00784\n",
      "2024-12-05 13:15:52.291818: train_loss -0.743\n",
      "2024-12-05 13:15:52.300822: val_loss -0.3941\n",
      "2024-12-05 13:15:52.305823: Pseudo dice [0.7671]\n",
      "2024-12-05 13:15:52.310824: Epoch time: 132.05 s\n",
      "2024-12-05 13:15:53.306049: \n",
      "2024-12-05 13:15:53.313050: Epoch 238\n",
      "2024-12-05 13:15:53.318051: Current learning rate: 0.00783\n",
      "2024-12-05 13:18:03.962635: train_loss -0.7092\n",
      "2024-12-05 13:18:03.972636: val_loss -0.507\n",
      "2024-12-05 13:18:03.972636: Pseudo dice [0.8099]\n",
      "2024-12-05 13:18:03.982635: Epoch time: 130.66 s\n",
      "2024-12-05 13:18:04.972936: \n",
      "2024-12-05 13:18:04.972936: Epoch 239\n",
      "2024-12-05 13:18:04.982937: Current learning rate: 0.00782\n",
      "2024-12-05 13:20:15.705229: train_loss -0.7564\n",
      "2024-12-05 13:20:15.715229: val_loss -0.408\n",
      "2024-12-05 13:20:15.725229: Pseudo dice [0.7852]\n",
      "2024-12-05 13:20:15.735229: Epoch time: 130.74 s\n",
      "2024-12-05 13:20:16.745531: \n",
      "2024-12-05 13:20:16.755531: Epoch 240\n",
      "2024-12-05 13:20:16.755531: Current learning rate: 0.00781\n",
      "2024-12-05 13:22:27.464982: train_loss -0.7688\n",
      "2024-12-05 13:22:27.474982: val_loss -0.5083\n",
      "2024-12-05 13:22:27.484983: Pseudo dice [0.7699]\n",
      "2024-12-05 13:22:27.494982: Epoch time: 130.72 s\n",
      "2024-12-05 13:22:27.494982: Yayy! New best EMA pseudo Dice: 0.7466\n",
      "2024-12-05 13:22:28.936242: \n",
      "2024-12-05 13:22:28.946243: Epoch 241\n",
      "2024-12-05 13:22:28.946243: Current learning rate: 0.0078\n",
      "2024-12-05 13:24:39.675378: train_loss -0.7528\n",
      "2024-12-05 13:24:39.685378: val_loss -0.4647\n",
      "2024-12-05 13:24:39.695378: Pseudo dice [0.763]\n",
      "2024-12-05 13:24:39.695378: Epoch time: 130.74 s\n",
      "2024-12-05 13:24:39.705378: Yayy! New best EMA pseudo Dice: 0.7482\n",
      "2024-12-05 13:24:40.955407: \n",
      "2024-12-05 13:24:40.965407: Epoch 242\n",
      "2024-12-05 13:24:40.965407: Current learning rate: 0.00779\n",
      "2024-12-05 13:26:51.632358: train_loss -0.7532\n",
      "2024-12-05 13:26:51.642357: val_loss -0.3345\n",
      "2024-12-05 13:26:51.652358: Pseudo dice [0.7131]\n",
      "2024-12-05 13:26:51.652358: Epoch time: 130.68 s\n",
      "2024-12-05 13:26:52.662373: \n",
      "2024-12-05 13:26:52.662373: Epoch 243\n",
      "2024-12-05 13:26:52.672373: Current learning rate: 0.00778\n",
      "2024-12-05 13:29:03.443607: train_loss -0.7293\n",
      "2024-12-05 13:29:03.443607: val_loss -0.3838\n",
      "2024-12-05 13:29:03.453606: Pseudo dice [0.7153]\n",
      "2024-12-05 13:29:03.463607: Epoch time: 130.78 s\n",
      "2024-12-05 13:29:04.474458: \n",
      "2024-12-05 13:29:04.484458: Epoch 244\n",
      "2024-12-05 13:29:04.484458: Current learning rate: 0.00777\n",
      "2024-12-05 13:31:15.264015: train_loss -0.6998\n",
      "2024-12-05 13:31:15.274015: val_loss -0.4531\n",
      "2024-12-05 13:31:15.284015: Pseudo dice [0.7337]\n",
      "2024-12-05 13:31:15.294016: Epoch time: 130.79 s\n",
      "2024-12-05 13:31:16.304031: \n",
      "2024-12-05 13:31:16.304031: Epoch 245\n",
      "2024-12-05 13:31:16.314031: Current learning rate: 0.00777\n",
      "2024-12-05 13:33:27.068673: train_loss -0.7051\n",
      "2024-12-05 13:33:27.078836: val_loss -0.3066\n",
      "2024-12-05 13:33:27.078836: Pseudo dice [0.6371]\n",
      "2024-12-05 13:33:27.085841: Epoch time: 130.76 s\n",
      "2024-12-05 13:33:28.095857: \n",
      "2024-12-05 13:33:28.105859: Epoch 246\n",
      "2024-12-05 13:33:28.105859: Current learning rate: 0.00776\n",
      "2024-12-05 13:35:38.845521: train_loss -0.7246\n",
      "2024-12-05 13:35:38.855522: val_loss -0.2521\n",
      "2024-12-05 13:35:38.865522: Pseudo dice [0.6885]\n",
      "2024-12-05 13:35:38.875522: Epoch time: 130.75 s\n",
      "2024-12-05 13:35:39.875537: \n",
      "2024-12-05 13:35:39.885537: Epoch 247\n",
      "2024-12-05 13:35:39.885537: Current learning rate: 0.00775\n",
      "2024-12-05 13:37:50.582238: train_loss -0.7195\n",
      "2024-12-05 13:37:50.592238: val_loss -0.326\n",
      "2024-12-05 13:37:50.602238: Pseudo dice [0.6728]\n",
      "2024-12-05 13:37:50.612239: Epoch time: 130.71 s\n",
      "2024-12-05 13:37:51.792431: \n",
      "2024-12-05 13:37:51.802431: Epoch 248\n",
      "2024-12-05 13:37:51.802431: Current learning rate: 0.00774\n",
      "2024-12-05 13:40:02.501314: train_loss -0.719\n",
      "2024-12-05 13:40:02.511314: val_loss -0.3694\n",
      "2024-12-05 13:40:02.511314: Pseudo dice [0.7024]\n",
      "2024-12-05 13:40:02.521315: Epoch time: 130.71 s\n",
      "2024-12-05 13:40:03.531330: \n",
      "2024-12-05 13:40:03.531330: Epoch 249\n",
      "2024-12-05 13:40:03.541330: Current learning rate: 0.00773\n",
      "2024-12-05 13:42:14.209996: train_loss -0.7356\n",
      "2024-12-05 13:42:14.219996: val_loss -0.5114\n",
      "2024-12-05 13:42:14.229996: Pseudo dice [0.7841]\n",
      "2024-12-05 13:42:14.229996: Epoch time: 130.68 s\n",
      "2024-12-05 13:42:15.481268: \n",
      "2024-12-05 13:42:15.491268: Epoch 250\n",
      "2024-12-05 13:42:15.491268: Current learning rate: 0.00772\n",
      "2024-12-05 13:44:26.223830: train_loss -0.7065\n",
      "2024-12-05 13:44:26.233829: val_loss -0.3259\n",
      "2024-12-05 13:44:26.233829: Pseudo dice [0.6904]\n",
      "2024-12-05 13:44:26.243830: Epoch time: 130.74 s\n",
      "2024-12-05 13:44:27.244761: \n",
      "2024-12-05 13:44:27.254761: Epoch 251\n",
      "2024-12-05 13:44:27.254761: Current learning rate: 0.00771\n",
      "2024-12-05 13:46:37.963782: train_loss -0.721\n",
      "2024-12-05 13:46:37.983782: val_loss -0.2686\n",
      "2024-12-05 13:46:37.983782: Pseudo dice [0.6614]\n",
      "2024-12-05 13:46:37.993783: Epoch time: 130.72 s\n",
      "2024-12-05 13:46:39.004086: \n",
      "2024-12-05 13:46:39.004086: Epoch 252\n",
      "2024-12-05 13:46:39.014085: Current learning rate: 0.0077\n",
      "2024-12-05 13:48:49.721747: train_loss -0.7267\n",
      "2024-12-05 13:48:49.731747: val_loss -0.208\n",
      "2024-12-05 13:48:49.741748: Pseudo dice [0.7136]\n",
      "2024-12-05 13:48:49.751747: Epoch time: 130.72 s\n",
      "2024-12-05 13:48:50.761762: \n",
      "2024-12-05 13:48:50.761762: Epoch 253\n",
      "2024-12-05 13:48:50.771764: Current learning rate: 0.00769\n",
      "2024-12-05 13:51:01.469382: train_loss -0.7417\n",
      "2024-12-05 13:51:01.479383: val_loss -0.425\n",
      "2024-12-05 13:51:01.479383: Pseudo dice [0.724]\n",
      "2024-12-05 13:51:01.489383: Epoch time: 130.71 s\n",
      "2024-12-05 13:51:02.490050: \n",
      "2024-12-05 13:51:02.500050: Epoch 254\n",
      "2024-12-05 13:51:02.500050: Current learning rate: 0.00768\n",
      "2024-12-05 13:53:13.218153: train_loss -0.7089\n",
      "2024-12-05 13:53:13.228153: val_loss -0.4613\n",
      "2024-12-05 13:53:13.238154: Pseudo dice [0.7665]\n",
      "2024-12-05 13:53:13.238154: Epoch time: 130.73 s\n",
      "2024-12-05 13:53:14.418474: \n",
      "2024-12-05 13:53:14.428475: Epoch 255\n",
      "2024-12-05 13:53:14.428475: Current learning rate: 0.00767\n",
      "2024-12-05 13:55:25.149783: train_loss -0.7409\n",
      "2024-12-05 13:55:25.159783: val_loss -0.0595\n",
      "2024-12-05 13:55:25.159783: Pseudo dice [0.5186]\n",
      "2024-12-05 13:55:25.169783: Epoch time: 130.73 s\n",
      "2024-12-05 13:55:26.179800: \n",
      "2024-12-05 13:55:26.179800: Epoch 256\n",
      "2024-12-05 13:55:26.189799: Current learning rate: 0.00766\n",
      "2024-12-05 13:57:36.962853: train_loss -0.7591\n",
      "2024-12-05 13:57:36.972853: val_loss -0.2859\n",
      "2024-12-05 13:57:36.982853: Pseudo dice [0.5966]\n",
      "2024-12-05 13:57:36.982853: Epoch time: 130.78 s\n",
      "2024-12-05 13:57:37.992868: \n",
      "2024-12-05 13:57:38.002868: Epoch 257\n",
      "2024-12-05 13:57:38.002868: Current learning rate: 0.00765\n",
      "2024-12-05 13:59:48.723230: train_loss -0.7126\n",
      "2024-12-05 13:59:48.733230: val_loss -0.3677\n",
      "2024-12-05 13:59:48.733230: Pseudo dice [0.7189]\n",
      "2024-12-05 13:59:48.743231: Epoch time: 130.73 s\n",
      "2024-12-05 13:59:49.753246: \n",
      "2024-12-05 13:59:49.763246: Epoch 258\n",
      "2024-12-05 13:59:49.763246: Current learning rate: 0.00764\n",
      "2024-12-05 14:02:00.456022: train_loss -0.7451\n",
      "2024-12-05 14:02:00.476022: val_loss -0.245\n",
      "2024-12-05 14:02:00.476022: Pseudo dice [0.636]\n",
      "2024-12-05 14:02:00.486022: Epoch time: 130.7 s\n",
      "2024-12-05 14:02:01.496037: \n",
      "2024-12-05 14:02:01.506038: Epoch 259\n",
      "2024-12-05 14:02:01.506038: Current learning rate: 0.00764\n",
      "2024-12-05 14:04:12.286191: train_loss -0.6897\n",
      "2024-12-05 14:04:12.286191: val_loss -0.4938\n",
      "2024-12-05 14:04:12.296191: Pseudo dice [0.8143]\n",
      "2024-12-05 14:04:12.306192: Epoch time: 130.79 s\n",
      "2024-12-05 14:04:13.316207: \n",
      "2024-12-05 14:04:13.326206: Epoch 260\n",
      "2024-12-05 14:04:13.326206: Current learning rate: 0.00763\n",
      "2024-12-05 14:06:24.066275: train_loss -0.7155\n",
      "2024-12-05 14:06:24.076275: val_loss -0.4123\n",
      "2024-12-05 14:06:24.086275: Pseudo dice [0.6939]\n",
      "2024-12-05 14:06:24.096276: Epoch time: 130.75 s\n",
      "2024-12-05 14:06:25.116290: \n",
      "2024-12-05 14:06:25.116290: Epoch 261\n",
      "2024-12-05 14:06:25.126290: Current learning rate: 0.00762\n",
      "2024-12-05 14:08:35.893905: train_loss -0.7685\n",
      "2024-12-05 14:08:35.903904: val_loss -0.3878\n",
      "2024-12-05 14:08:35.903904: Pseudo dice [0.7393]\n",
      "2024-12-05 14:08:35.913905: Epoch time: 130.79 s\n",
      "2024-12-05 14:08:37.094238: \n",
      "2024-12-05 14:08:37.094238: Epoch 262\n",
      "2024-12-05 14:08:37.104238: Current learning rate: 0.00761\n",
      "2024-12-05 14:10:47.863378: train_loss -0.7894\n",
      "2024-12-05 14:10:47.873378: val_loss -0.2692\n",
      "2024-12-05 14:10:47.883378: Pseudo dice [0.6052]\n",
      "2024-12-05 14:10:47.893378: Epoch time: 130.78 s\n",
      "2024-12-05 14:10:48.903393: \n",
      "2024-12-05 14:10:48.913393: Epoch 263\n",
      "2024-12-05 14:10:48.913393: Current learning rate: 0.0076\n",
      "2024-12-05 14:12:59.660712: train_loss -0.7788\n",
      "2024-12-05 14:12:59.670712: val_loss -0.0943\n",
      "2024-12-05 14:12:59.670712: Pseudo dice [0.5142]\n",
      "2024-12-05 14:12:59.680712: Epoch time: 130.76 s\n",
      "2024-12-05 14:13:00.701017: \n",
      "2024-12-05 14:13:00.711016: Epoch 264\n",
      "2024-12-05 14:13:00.711016: Current learning rate: 0.00759\n",
      "2024-12-05 14:15:11.467458: train_loss -0.7706\n",
      "2024-12-05 14:15:11.477458: val_loss -0.2417\n",
      "2024-12-05 14:15:11.487458: Pseudo dice [0.6204]\n",
      "2024-12-05 14:15:11.487458: Epoch time: 130.77 s\n",
      "2024-12-05 14:15:12.508128: \n",
      "2024-12-05 14:15:12.508128: Epoch 265\n",
      "2024-12-05 14:15:12.518129: Current learning rate: 0.00758\n",
      "2024-12-05 14:17:23.237984: train_loss -0.7984\n",
      "2024-12-05 14:17:23.247984: val_loss -0.1701\n",
      "2024-12-05 14:17:23.257985: Pseudo dice [0.5636]\n",
      "2024-12-05 14:17:23.257985: Epoch time: 130.74 s\n",
      "2024-12-05 14:17:24.268000: \n",
      "2024-12-05 14:17:24.278001: Epoch 266\n",
      "2024-12-05 14:17:24.288001: Current learning rate: 0.00757\n",
      "2024-12-05 14:19:35.006627: train_loss -0.7739\n",
      "2024-12-05 14:19:35.016628: val_loss -0.4187\n",
      "2024-12-05 14:19:35.016628: Pseudo dice [0.6185]\n",
      "2024-12-05 14:19:35.026628: Epoch time: 130.74 s\n",
      "2024-12-05 14:19:36.036931: \n",
      "2024-12-05 14:19:36.046932: Epoch 267\n",
      "2024-12-05 14:19:36.056932: Current learning rate: 0.00756\n",
      "2024-12-05 14:21:46.857474: train_loss -0.7724\n",
      "2024-12-05 14:21:46.867474: val_loss -0.3098\n",
      "2024-12-05 14:21:46.877474: Pseudo dice [0.6983]\n",
      "2024-12-05 14:21:46.887474: Epoch time: 130.82 s\n",
      "2024-12-05 14:21:47.898277: \n",
      "2024-12-05 14:21:47.898277: Epoch 268\n",
      "2024-12-05 14:21:47.908277: Current learning rate: 0.00755\n",
      "2024-12-05 14:23:58.671407: train_loss -0.7689\n",
      "2024-12-05 14:23:58.691408: val_loss -0.4546\n",
      "2024-12-05 14:23:58.691408: Pseudo dice [0.8028]\n",
      "2024-12-05 14:23:58.701408: Epoch time: 130.77 s\n",
      "2024-12-05 14:23:59.721423: \n",
      "2024-12-05 14:23:59.731423: Epoch 269\n",
      "2024-12-05 14:23:59.731423: Current learning rate: 0.00754\n",
      "2024-12-05 14:26:10.404405: train_loss -0.7756\n",
      "2024-12-05 14:26:10.414405: val_loss -0.3283\n",
      "2024-12-05 14:26:10.424405: Pseudo dice [0.6988]\n",
      "2024-12-05 14:26:10.424405: Epoch time: 130.68 s\n",
      "2024-12-05 14:26:11.624423: \n",
      "2024-12-05 14:26:11.624423: Epoch 270\n",
      "2024-12-05 14:26:11.634423: Current learning rate: 0.00753\n",
      "2024-12-05 14:28:22.433868: train_loss -0.7781\n",
      "2024-12-05 14:28:22.443868: val_loss -0.302\n",
      "2024-12-05 14:28:22.443868: Pseudo dice [0.6419]\n",
      "2024-12-05 14:28:22.453868: Epoch time: 130.81 s\n",
      "2024-12-05 14:28:23.463884: \n",
      "2024-12-05 14:28:23.473884: Epoch 271\n",
      "2024-12-05 14:28:23.473884: Current learning rate: 0.00752\n",
      "2024-12-05 14:30:34.292795: train_loss -0.7364\n",
      "2024-12-05 14:30:34.302795: val_loss -0.4266\n",
      "2024-12-05 14:30:34.302795: Pseudo dice [0.768]\n",
      "2024-12-05 14:30:34.312795: Epoch time: 130.83 s\n",
      "2024-12-05 14:30:35.323095: \n",
      "2024-12-05 14:30:35.333097: Epoch 272\n",
      "2024-12-05 14:30:35.333097: Current learning rate: 0.00751\n",
      "2024-12-05 14:32:46.052916: train_loss -0.7314\n",
      "2024-12-05 14:32:46.062916: val_loss -0.5096\n",
      "2024-12-05 14:32:46.062916: Pseudo dice [0.8094]\n",
      "2024-12-05 14:32:46.072916: Epoch time: 130.73 s\n",
      "2024-12-05 14:32:47.092932: \n",
      "2024-12-05 14:32:47.092932: Epoch 273\n",
      "2024-12-05 14:32:47.102933: Current learning rate: 0.00751\n",
      "2024-12-05 14:34:57.882700: train_loss -0.7649\n",
      "2024-12-05 14:34:57.902700: val_loss 0.0511\n",
      "2024-12-05 14:34:57.902700: Pseudo dice [0.4858]\n",
      "2024-12-05 14:34:57.912700: Epoch time: 130.79 s\n",
      "2024-12-05 14:34:58.922715: \n",
      "2024-12-05 14:34:58.932716: Epoch 274\n",
      "2024-12-05 14:34:58.932716: Current learning rate: 0.0075\n",
      "2024-12-05 14:37:09.733483: train_loss -0.7831\n",
      "2024-12-05 14:37:09.743484: val_loss -0.4203\n",
      "2024-12-05 14:37:09.743484: Pseudo dice [0.7172]\n",
      "2024-12-05 14:37:09.753484: Epoch time: 130.81 s\n",
      "2024-12-05 14:37:10.763498: \n",
      "2024-12-05 14:37:10.773498: Epoch 275\n",
      "2024-12-05 14:37:10.773498: Current learning rate: 0.00749\n",
      "2024-12-05 14:39:21.495314: train_loss -0.7839\n",
      "2024-12-05 14:39:21.495314: val_loss -0.1617\n",
      "2024-12-05 14:39:21.505314: Pseudo dice [0.541]\n",
      "2024-12-05 14:39:21.515315: Epoch time: 130.73 s\n",
      "2024-12-05 14:39:22.545330: \n",
      "2024-12-05 14:39:22.545330: Epoch 276\n",
      "2024-12-05 14:39:22.555330: Current learning rate: 0.00748\n",
      "2024-12-05 14:41:33.263108: train_loss -0.7654\n",
      "2024-12-05 14:41:33.283108: val_loss -0.3615\n",
      "2024-12-05 14:41:33.283108: Pseudo dice [0.7623]\n",
      "2024-12-05 14:41:33.293108: Epoch time: 130.72 s\n",
      "2024-12-05 14:41:34.473424: \n",
      "2024-12-05 14:41:34.483424: Epoch 277\n",
      "2024-12-05 14:41:34.483424: Current learning rate: 0.00747\n",
      "2024-12-05 14:43:45.291579: train_loss -0.7405\n",
      "2024-12-05 14:43:45.301579: val_loss -0.3727\n",
      "2024-12-05 14:43:45.301579: Pseudo dice [0.7471]\n",
      "2024-12-05 14:43:45.311579: Epoch time: 130.82 s\n",
      "2024-12-05 14:43:46.321594: \n",
      "2024-12-05 14:43:46.331594: Epoch 278\n",
      "2024-12-05 14:43:46.331594: Current learning rate: 0.00746\n",
      "2024-12-05 14:45:56.988964: train_loss -0.7532\n",
      "2024-12-05 14:45:56.988964: val_loss -0.2162\n",
      "2024-12-05 14:45:56.998964: Pseudo dice [0.6834]\n",
      "2024-12-05 14:45:57.008964: Epoch time: 130.67 s\n",
      "2024-12-05 14:45:58.018980: \n",
      "2024-12-05 14:45:58.028980: Epoch 279\n",
      "2024-12-05 14:45:58.028980: Current learning rate: 0.00745\n",
      "2024-12-05 14:48:08.778092: train_loss -0.7704\n",
      "2024-12-05 14:48:08.788092: val_loss -0.3445\n",
      "2024-12-05 14:48:08.788092: Pseudo dice [0.6947]\n",
      "2024-12-05 14:48:08.798091: Epoch time: 130.76 s\n",
      "2024-12-05 14:48:09.808392: \n",
      "2024-12-05 14:48:09.818393: Epoch 280\n",
      "2024-12-05 14:48:09.818393: Current learning rate: 0.00744\n",
      "2024-12-05 14:50:20.565086: train_loss -0.7663\n",
      "2024-12-05 14:50:20.575085: val_loss -0.3129\n",
      "2024-12-05 14:50:20.585086: Pseudo dice [0.697]\n",
      "2024-12-05 14:50:20.585086: Epoch time: 130.76 s\n",
      "2024-12-05 14:50:21.595101: \n",
      "2024-12-05 14:50:21.605100: Epoch 281\n",
      "2024-12-05 14:50:21.605100: Current learning rate: 0.00743\n",
      "2024-12-05 14:52:32.323347: train_loss -0.7591\n",
      "2024-12-05 14:52:32.333347: val_loss -0.536\n",
      "2024-12-05 14:52:32.343348: Pseudo dice [0.7848]\n",
      "2024-12-05 14:52:32.343348: Epoch time: 130.73 s\n",
      "2024-12-05 14:52:33.363363: \n",
      "2024-12-05 14:52:33.363363: Epoch 282\n",
      "2024-12-05 14:52:33.373362: Current learning rate: 0.00742\n",
      "2024-12-05 14:54:44.190903: train_loss -0.772\n",
      "2024-12-05 14:54:44.210904: val_loss -0.3435\n",
      "2024-12-05 14:54:44.210904: Pseudo dice [0.7613]\n",
      "2024-12-05 14:54:44.220903: Epoch time: 130.83 s\n",
      "2024-12-05 14:54:45.231212: \n",
      "2024-12-05 14:54:45.241211: Epoch 283\n",
      "2024-12-05 14:54:45.251212: Current learning rate: 0.00741\n",
      "2024-12-05 14:56:55.956266: train_loss -0.7703\n",
      "2024-12-05 14:56:55.966267: val_loss -0.2881\n",
      "2024-12-05 14:56:55.976267: Pseudo dice [0.6615]\n",
      "2024-12-05 14:56:55.976267: Epoch time: 130.73 s\n",
      "2024-12-05 14:56:57.176285: \n",
      "2024-12-05 14:56:57.176285: Epoch 284\n",
      "2024-12-05 14:56:57.186285: Current learning rate: 0.0074\n",
      "2024-12-05 14:59:07.967768: train_loss -0.7738\n",
      "2024-12-05 14:59:07.977768: val_loss -0.4482\n",
      "2024-12-05 14:59:07.987769: Pseudo dice [0.7008]\n",
      "2024-12-05 14:59:07.997769: Epoch time: 130.79 s\n",
      "2024-12-05 14:59:09.007784: \n",
      "2024-12-05 14:59:09.007784: Epoch 285\n",
      "2024-12-05 14:59:09.017784: Current learning rate: 0.00739\n",
      "2024-12-05 15:01:19.680920: train_loss -0.747\n",
      "2024-12-05 15:01:19.690919: val_loss -0.2978\n",
      "2024-12-05 15:01:19.700920: Pseudo dice [0.7005]\n",
      "2024-12-05 15:01:19.700920: Epoch time: 130.67 s\n",
      "2024-12-05 15:01:20.720936: \n",
      "2024-12-05 15:01:20.730935: Epoch 286\n",
      "2024-12-05 15:01:20.730935: Current learning rate: 0.00738\n",
      "2024-12-05 15:03:31.461669: train_loss -0.7514\n",
      "2024-12-05 15:03:31.471668: val_loss -0.3175\n",
      "2024-12-05 15:03:31.481668: Pseudo dice [0.7247]\n",
      "2024-12-05 15:03:31.481668: Epoch time: 130.74 s\n",
      "2024-12-05 15:03:32.522779: \n",
      "2024-12-05 15:03:32.522779: Epoch 287\n",
      "2024-12-05 15:03:32.532779: Current learning rate: 0.00738\n",
      "2024-12-05 15:05:43.158050: train_loss -0.7852\n",
      "2024-12-05 15:05:43.168050: val_loss -0.3178\n",
      "2024-12-05 15:05:43.178050: Pseudo dice [0.7167]\n",
      "2024-12-05 15:05:43.178050: Epoch time: 130.64 s\n",
      "2024-12-05 15:05:44.218066: \n",
      "2024-12-05 15:05:44.218066: Epoch 288\n",
      "2024-12-05 15:05:44.228066: Current learning rate: 0.00737\n",
      "2024-12-05 15:07:55.007824: train_loss -0.769\n",
      "2024-12-05 15:07:55.017824: val_loss -0.175\n",
      "2024-12-05 15:07:55.017824: Pseudo dice [0.5639]\n",
      "2024-12-05 15:07:55.027824: Epoch time: 130.79 s\n",
      "2024-12-05 15:07:56.067873: \n",
      "2024-12-05 15:07:56.077873: Epoch 289\n",
      "2024-12-05 15:07:56.077873: Current learning rate: 0.00736\n",
      "2024-12-05 15:10:06.879076: train_loss -0.7762\n",
      "2024-12-05 15:10:06.889076: val_loss -0.4876\n",
      "2024-12-05 15:10:06.899077: Pseudo dice [0.7737]\n",
      "2024-12-05 15:10:06.899077: Epoch time: 130.81 s\n",
      "2024-12-05 15:10:07.939092: \n",
      "2024-12-05 15:10:07.939092: Epoch 290\n",
      "2024-12-05 15:10:07.949092: Current learning rate: 0.00735\n",
      "2024-12-05 15:12:18.698166: train_loss -0.7747\n",
      "2024-12-05 15:12:18.708164: val_loss -0.1073\n",
      "2024-12-05 15:12:18.708164: Pseudo dice [0.5427]\n",
      "2024-12-05 15:12:18.718164: Epoch time: 130.76 s\n",
      "2024-12-05 15:12:19.928183: \n",
      "2024-12-05 15:12:19.938182: Epoch 291\n",
      "2024-12-05 15:12:19.938182: Current learning rate: 0.00734\n",
      "2024-12-05 15:14:30.714335: train_loss -0.6963\n",
      "2024-12-05 15:14:30.724334: val_loss -0.1755\n",
      "2024-12-05 15:14:30.734335: Pseudo dice [0.6402]\n",
      "2024-12-05 15:14:30.734335: Epoch time: 130.79 s\n",
      "2024-12-05 15:14:31.765099: \n",
      "2024-12-05 15:14:31.765099: Epoch 292\n",
      "2024-12-05 15:14:31.775099: Current learning rate: 0.00733\n",
      "2024-12-05 15:16:42.605404: train_loss -0.7165\n",
      "2024-12-05 15:16:42.615404: val_loss -0.3818\n",
      "2024-12-05 15:16:42.625404: Pseudo dice [0.7561]\n",
      "2024-12-05 15:16:42.625404: Epoch time: 130.84 s\n",
      "2024-12-05 15:16:43.655419: \n",
      "2024-12-05 15:16:43.665420: Epoch 293\n",
      "2024-12-05 15:16:43.665420: Current learning rate: 0.00732\n",
      "2024-12-05 15:18:54.483448: train_loss -0.7468\n",
      "2024-12-05 15:18:54.493449: val_loss -0.4536\n",
      "2024-12-05 15:18:54.493449: Pseudo dice [0.7947]\n",
      "2024-12-05 15:18:54.503449: Epoch time: 130.83 s\n",
      "2024-12-05 15:18:55.533464: \n",
      "2024-12-05 15:18:55.543465: Epoch 294\n",
      "2024-12-05 15:18:55.543465: Current learning rate: 0.00731\n",
      "2024-12-05 15:21:06.311790: train_loss -0.7765\n",
      "2024-12-05 15:21:06.321790: val_loss -0.4122\n",
      "2024-12-05 15:21:06.331791: Pseudo dice [0.8257]\n",
      "2024-12-05 15:21:06.331791: Epoch time: 130.78 s\n",
      "2024-12-05 15:21:07.362086: \n",
      "2024-12-05 15:21:07.372086: Epoch 295\n",
      "2024-12-05 15:21:07.372086: Current learning rate: 0.0073\n",
      "2024-12-05 15:23:18.060139: train_loss -0.7898\n",
      "2024-12-05 15:23:18.080139: val_loss -0.1284\n",
      "2024-12-05 15:23:18.080139: Pseudo dice [0.536]\n",
      "2024-12-05 15:23:18.090139: Epoch time: 130.7 s\n",
      "2024-12-05 15:23:19.120445: \n",
      "2024-12-05 15:23:19.130445: Epoch 296\n",
      "2024-12-05 15:23:19.130445: Current learning rate: 0.00729\n",
      "2024-12-05 15:25:29.981158: train_loss -0.7923\n",
      "2024-12-05 15:25:29.991159: val_loss -0.2381\n",
      "2024-12-05 15:25:30.001159: Pseudo dice [0.7097]\n",
      "2024-12-05 15:25:30.011160: Epoch time: 130.86 s\n",
      "2024-12-05 15:25:31.031174: \n",
      "2024-12-05 15:25:31.041174: Epoch 297\n",
      "2024-12-05 15:25:31.051175: Current learning rate: 0.00728\n",
      "2024-12-05 15:27:41.766461: train_loss -0.787\n",
      "2024-12-05 15:27:41.786462: val_loss -0.3776\n",
      "2024-12-05 15:27:41.786462: Pseudo dice [0.7862]\n",
      "2024-12-05 15:27:41.796463: Epoch time: 130.74 s\n",
      "2024-12-05 15:27:42.826477: \n",
      "2024-12-05 15:27:42.836477: Epoch 298\n",
      "2024-12-05 15:27:42.836477: Current learning rate: 0.00727\n",
      "2024-12-05 15:29:53.522744: train_loss -0.7809\n",
      "2024-12-05 15:29:53.532744: val_loss -0.2669\n",
      "2024-12-05 15:29:53.532744: Pseudo dice [0.5408]\n",
      "2024-12-05 15:29:53.542745: Epoch time: 130.7 s\n",
      "2024-12-05 15:29:54.763905: \n",
      "2024-12-05 15:29:54.773904: Epoch 299\n",
      "2024-12-05 15:29:54.773904: Current learning rate: 0.00726\n",
      "2024-12-05 15:32:05.514982: train_loss -0.7828\n",
      "2024-12-05 15:32:05.524982: val_loss -0.3643\n",
      "2024-12-05 15:32:05.534983: Pseudo dice [0.6177]\n",
      "2024-12-05 15:32:05.534983: Epoch time: 130.75 s\n",
      "2024-12-05 15:32:06.815448: \n",
      "2024-12-05 15:32:06.825449: Epoch 300\n",
      "2024-12-05 15:32:06.825449: Current learning rate: 0.00725\n",
      "2024-12-05 15:34:17.635471: train_loss -0.7646\n",
      "2024-12-05 15:34:17.645472: val_loss -0.4959\n",
      "2024-12-05 15:34:17.655472: Pseudo dice [0.8062]\n",
      "2024-12-05 15:34:17.665472: Epoch time: 130.82 s\n",
      "2024-12-05 15:34:18.695487: \n",
      "2024-12-05 15:34:18.705487: Epoch 301\n",
      "2024-12-05 15:34:18.705487: Current learning rate: 0.00724\n",
      "2024-12-05 15:36:29.416039: train_loss -0.7623\n",
      "2024-12-05 15:36:29.426040: val_loss -0.0846\n",
      "2024-12-05 15:36:29.436040: Pseudo dice [0.4662]\n",
      "2024-12-05 15:36:29.446041: Epoch time: 130.72 s\n",
      "2024-12-05 15:36:30.476055: \n",
      "2024-12-05 15:36:30.486056: Epoch 302\n",
      "2024-12-05 15:36:30.486056: Current learning rate: 0.00724\n",
      "2024-12-05 15:38:41.264687: train_loss -0.7432\n",
      "2024-12-05 15:38:41.274687: val_loss -0.3017\n",
      "2024-12-05 15:38:41.284688: Pseudo dice [0.7205]\n",
      "2024-12-05 15:38:41.294687: Epoch time: 130.79 s\n",
      "2024-12-05 15:38:42.325806: \n",
      "2024-12-05 15:38:42.335806: Epoch 303\n",
      "2024-12-05 15:38:42.335806: Current learning rate: 0.00723\n",
      "2024-12-05 15:40:53.077183: train_loss -0.7128\n",
      "2024-12-05 15:40:53.097183: val_loss -0.4592\n",
      "2024-12-05 15:40:53.097183: Pseudo dice [0.8026]\n",
      "2024-12-05 15:40:53.107183: Epoch time: 130.75 s\n",
      "2024-12-05 15:40:54.137481: \n",
      "2024-12-05 15:40:54.147480: Epoch 304\n",
      "2024-12-05 15:40:54.147480: Current learning rate: 0.00722\n",
      "2024-12-05 15:43:04.884932: train_loss -0.7779\n",
      "2024-12-05 15:43:04.894934: val_loss -0.3309\n",
      "2024-12-05 15:43:04.894934: Pseudo dice [0.7683]\n",
      "2024-12-05 15:43:04.904934: Epoch time: 130.75 s\n",
      "2024-12-05 15:43:05.936250: \n",
      "2024-12-05 15:43:05.946252: Epoch 305\n",
      "2024-12-05 15:43:05.946252: Current learning rate: 0.00721\n",
      "2024-12-05 15:45:16.672354: train_loss -0.7673\n",
      "2024-12-05 15:45:16.682355: val_loss -0.3252\n",
      "2024-12-05 15:45:16.692355: Pseudo dice [0.786]\n",
      "2024-12-05 15:45:16.692355: Epoch time: 130.74 s\n",
      "2024-12-05 15:45:17.913270: \n",
      "2024-12-05 15:45:17.913270: Epoch 306\n",
      "2024-12-05 15:45:17.923270: Current learning rate: 0.0072\n",
      "2024-12-05 15:47:28.676830: train_loss -0.7302\n",
      "2024-12-05 15:47:28.686830: val_loss -0.4117\n",
      "2024-12-05 15:47:28.696830: Pseudo dice [0.7191]\n",
      "2024-12-05 15:47:28.696830: Epoch time: 130.77 s\n",
      "2024-12-05 15:47:29.727128: \n",
      "2024-12-05 15:47:29.737128: Epoch 307\n",
      "2024-12-05 15:47:29.737128: Current learning rate: 0.00719\n",
      "2024-12-05 15:49:40.416539: train_loss -0.7884\n",
      "2024-12-05 15:49:40.426539: val_loss -0.462\n",
      "2024-12-05 15:49:40.436539: Pseudo dice [0.8027]\n",
      "2024-12-05 15:49:40.436539: Epoch time: 130.69 s\n",
      "2024-12-05 15:49:41.466554: \n",
      "2024-12-05 15:49:41.476554: Epoch 308\n",
      "2024-12-05 15:49:41.476554: Current learning rate: 0.00718\n",
      "2024-12-05 15:51:52.202584: train_loss -0.787\n",
      "2024-12-05 15:51:52.212583: val_loss -0.3165\n",
      "2024-12-05 15:51:52.222583: Pseudo dice [0.6698]\n",
      "2024-12-05 15:51:52.222583: Epoch time: 130.74 s\n",
      "2024-12-05 15:51:53.252599: \n",
      "2024-12-05 15:51:53.262600: Epoch 309\n",
      "2024-12-05 15:51:53.262600: Current learning rate: 0.00717\n",
      "2024-12-05 15:54:04.150542: train_loss -0.7771\n",
      "2024-12-05 15:54:04.160542: val_loss -0.4433\n",
      "2024-12-05 15:54:04.170542: Pseudo dice [0.7673]\n",
      "2024-12-05 15:54:04.170542: Epoch time: 130.9 s\n",
      "2024-12-05 15:54:05.210558: \n",
      "2024-12-05 15:54:05.220557: Epoch 310\n",
      "2024-12-05 15:54:05.220557: Current learning rate: 0.00716\n",
      "2024-12-05 15:56:15.960542: train_loss -0.764\n",
      "2024-12-05 15:56:15.970542: val_loss -0.5843\n",
      "2024-12-05 15:56:15.970542: Pseudo dice [0.8112]\n",
      "2024-12-05 15:56:15.980542: Epoch time: 130.75 s\n",
      "2024-12-05 15:56:17.010558: \n",
      "2024-12-05 15:56:17.020558: Epoch 311\n",
      "2024-12-05 15:56:17.020558: Current learning rate: 0.00715\n",
      "2024-12-05 15:58:27.720993: train_loss -0.7404\n",
      "2024-12-05 15:58:27.730994: val_loss -0.1651\n",
      "2024-12-05 15:58:27.740993: Pseudo dice [0.5515]\n",
      "2024-12-05 15:58:27.740993: Epoch time: 130.71 s\n",
      "2024-12-05 15:58:28.771008: \n",
      "2024-12-05 15:58:28.771008: Epoch 312\n",
      "2024-12-05 15:58:28.781009: Current learning rate: 0.00714\n",
      "2024-12-05 16:00:39.420454: train_loss -0.7587\n",
      "2024-12-05 16:00:39.428457: val_loss -0.2208\n",
      "2024-12-05 16:00:39.438458: Pseudo dice [0.691]\n",
      "2024-12-05 16:00:39.448458: Epoch time: 130.65 s\n",
      "2024-12-05 16:00:40.658477: \n",
      "2024-12-05 16:00:40.668477: Epoch 313\n",
      "2024-12-05 16:00:40.668477: Current learning rate: 0.00713\n",
      "2024-12-05 16:02:51.350440: train_loss -0.7333\n",
      "2024-12-05 16:02:51.360441: val_loss -0.1734\n",
      "2024-12-05 16:02:51.370441: Pseudo dice [0.63]\n",
      "2024-12-05 16:02:51.380441: Epoch time: 130.69 s\n",
      "2024-12-05 16:02:52.420456: \n",
      "2024-12-05 16:02:52.430456: Epoch 314\n",
      "2024-12-05 16:02:52.430456: Current learning rate: 0.00712\n",
      "2024-12-05 16:05:03.148184: train_loss -0.7302\n",
      "2024-12-05 16:05:03.158184: val_loss -0.3209\n",
      "2024-12-05 16:05:03.168185: Pseudo dice [0.7335]\n",
      "2024-12-05 16:05:03.178185: Epoch time: 130.73 s\n",
      "2024-12-05 16:05:04.238200: \n",
      "2024-12-05 16:05:04.248200: Epoch 315\n",
      "2024-12-05 16:05:04.248200: Current learning rate: 0.00711\n",
      "2024-12-05 16:07:14.937541: train_loss -0.7762\n",
      "2024-12-05 16:07:14.947541: val_loss -0.411\n",
      "2024-12-05 16:07:14.957541: Pseudo dice [0.8528]\n",
      "2024-12-05 16:07:14.967541: Epoch time: 130.7 s\n",
      "2024-12-05 16:07:15.997556: \n",
      "2024-12-05 16:07:16.007557: Epoch 316\n",
      "2024-12-05 16:07:16.007557: Current learning rate: 0.0071\n",
      "2024-12-05 16:09:26.725194: train_loss -0.7438\n",
      "2024-12-05 16:09:26.735194: val_loss -0.3727\n",
      "2024-12-05 16:09:26.735194: Pseudo dice [0.7779]\n",
      "2024-12-05 16:09:26.745195: Epoch time: 130.73 s\n",
      "2024-12-05 16:09:27.785209: \n",
      "2024-12-05 16:09:27.785209: Epoch 317\n",
      "2024-12-05 16:09:27.795210: Current learning rate: 0.0071\n",
      "2024-12-05 16:11:38.594028: train_loss -0.749\n",
      "2024-12-05 16:11:38.604028: val_loss -0.2289\n",
      "2024-12-05 16:11:38.614028: Pseudo dice [0.6473]\n",
      "2024-12-05 16:11:38.614028: Epoch time: 130.81 s\n",
      "2024-12-05 16:11:39.654044: \n",
      "2024-12-05 16:11:39.664043: Epoch 318\n",
      "2024-12-05 16:11:39.664043: Current learning rate: 0.00709\n",
      "2024-12-05 16:13:50.369357: train_loss -0.7408\n",
      "2024-12-05 16:13:50.379357: val_loss -0.4495\n",
      "2024-12-05 16:13:50.389358: Pseudo dice [0.8064]\n",
      "2024-12-05 16:13:50.389358: Epoch time: 130.72 s\n",
      "2024-12-05 16:13:51.429024: \n",
      "2024-12-05 16:13:51.436115: Epoch 319\n",
      "2024-12-05 16:13:51.440181: Current learning rate: 0.00708\n",
      "2024-12-05 16:16:02.090608: train_loss -0.7566\n",
      "2024-12-05 16:16:02.110608: val_loss -0.4002\n",
      "2024-12-05 16:16:02.110608: Pseudo dice [0.7927]\n",
      "2024-12-05 16:16:02.120608: Epoch time: 130.66 s\n",
      "2024-12-05 16:16:03.341571: \n",
      "2024-12-05 16:16:03.341571: Epoch 320\n",
      "2024-12-05 16:16:03.351573: Current learning rate: 0.00707\n",
      "2024-12-05 16:18:14.100132: train_loss -0.7299\n",
      "2024-12-05 16:18:14.110132: val_loss -0.2918\n",
      "2024-12-05 16:18:14.120133: Pseudo dice [0.688]\n",
      "2024-12-05 16:18:14.120133: Epoch time: 130.77 s\n",
      "2024-12-05 16:18:15.160149: \n",
      "2024-12-05 16:18:15.170150: Epoch 321\n",
      "2024-12-05 16:18:15.170150: Current learning rate: 0.00706\n",
      "2024-12-05 16:20:25.959330: train_loss -0.7008\n",
      "2024-12-05 16:20:25.979330: val_loss -0.5243\n",
      "2024-12-05 16:20:25.979330: Pseudo dice [0.8054]\n",
      "2024-12-05 16:20:25.989330: Epoch time: 130.8 s\n",
      "2024-12-05 16:20:27.029345: \n",
      "2024-12-05 16:20:27.029345: Epoch 322\n",
      "2024-12-05 16:20:27.039345: Current learning rate: 0.00705\n",
      "2024-12-05 16:22:37.787802: train_loss -0.7489\n",
      "2024-12-05 16:22:37.797802: val_loss -0.5695\n",
      "2024-12-05 16:22:37.807804: Pseudo dice [0.7921]\n",
      "2024-12-05 16:22:37.807804: Epoch time: 130.76 s\n",
      "2024-12-05 16:22:38.848098: \n",
      "2024-12-05 16:22:38.858098: Epoch 323\n",
      "2024-12-05 16:22:38.858098: Current learning rate: 0.00704\n",
      "2024-12-05 16:24:49.562906: train_loss -0.7557\n",
      "2024-12-05 16:24:49.572906: val_loss -0.2668\n",
      "2024-12-05 16:24:49.572906: Pseudo dice [0.6162]\n",
      "2024-12-05 16:24:49.582906: Epoch time: 130.71 s\n",
      "2024-12-05 16:24:50.622921: \n",
      "2024-12-05 16:24:50.622921: Epoch 324\n",
      "2024-12-05 16:24:50.632921: Current learning rate: 0.00703\n",
      "2024-12-05 16:27:01.309303: train_loss -0.7226\n",
      "2024-12-05 16:27:01.319301: val_loss -0.3804\n",
      "2024-12-05 16:27:01.319301: Pseudo dice [0.6945]\n",
      "2024-12-05 16:27:01.329300: Epoch time: 130.69 s\n",
      "2024-12-05 16:27:02.370056: \n",
      "2024-12-05 16:27:02.370056: Epoch 325\n",
      "2024-12-05 16:27:02.380057: Current learning rate: 0.00702\n",
      "2024-12-05 16:29:13.902783: train_loss -0.7326\n",
      "2024-12-05 16:29:13.912784: val_loss -0.5069\n",
      "2024-12-05 16:29:13.922785: Pseudo dice [0.7984]\n",
      "2024-12-05 16:29:13.922785: Epoch time: 131.53 s\n",
      "2024-12-05 16:29:14.962798: \n",
      "2024-12-05 16:29:14.962798: Epoch 326\n",
      "2024-12-05 16:29:14.972800: Current learning rate: 0.00701\n",
      "2024-12-05 16:31:25.636472: train_loss -0.7806\n",
      "2024-12-05 16:31:25.646472: val_loss -0.5082\n",
      "2024-12-05 16:31:25.656472: Pseudo dice [0.8326]\n",
      "2024-12-05 16:31:25.666472: Epoch time: 130.67 s\n",
      "2024-12-05 16:31:26.876777: \n",
      "2024-12-05 16:31:26.886777: Epoch 327\n",
      "2024-12-05 16:31:26.886777: Current learning rate: 0.007\n",
      "2024-12-05 16:33:37.542933: train_loss -0.7768\n",
      "2024-12-05 16:33:37.552933: val_loss -0.3654\n",
      "2024-12-05 16:33:37.552933: Pseudo dice [0.8041]\n",
      "2024-12-05 16:33:37.562933: Epoch time: 130.67 s\n",
      "2024-12-05 16:33:37.562933: Yayy! New best EMA pseudo Dice: 0.7486\n",
      "2024-12-05 16:33:38.852952: \n",
      "2024-12-05 16:33:38.852952: Epoch 328\n",
      "2024-12-05 16:33:38.862952: Current learning rate: 0.00699\n",
      "2024-12-05 16:35:49.494794: train_loss -0.7771\n",
      "2024-12-05 16:35:49.504794: val_loss -0.3622\n",
      "2024-12-05 16:35:49.514795: Pseudo dice [0.6952]\n",
      "2024-12-05 16:35:49.514795: Epoch time: 130.65 s\n",
      "2024-12-05 16:35:50.565857: \n",
      "2024-12-05 16:35:50.565857: Epoch 329\n",
      "2024-12-05 16:35:50.575857: Current learning rate: 0.00698\n",
      "2024-12-05 16:38:01.246630: train_loss -0.7645\n",
      "2024-12-05 16:38:01.256631: val_loss -0.4076\n",
      "2024-12-05 16:38:01.256631: Pseudo dice [0.7732]\n",
      "2024-12-05 16:38:01.266631: Epoch time: 130.68 s\n",
      "2024-12-05 16:38:02.306646: \n",
      "2024-12-05 16:38:02.306646: Epoch 330\n",
      "2024-12-05 16:38:02.316646: Current learning rate: 0.00697\n",
      "2024-12-05 16:40:12.926793: train_loss -0.7885\n",
      "2024-12-05 16:40:12.936794: val_loss -0.3462\n",
      "2024-12-05 16:40:12.946794: Pseudo dice [0.6811]\n",
      "2024-12-05 16:40:12.956795: Epoch time: 130.63 s\n",
      "2024-12-05 16:40:13.986809: \n",
      "2024-12-05 16:40:13.996810: Epoch 331\n",
      "2024-12-05 16:40:13.996810: Current learning rate: 0.00696\n",
      "2024-12-05 16:42:24.682911: train_loss -0.772\n",
      "2024-12-05 16:42:24.702911: val_loss -0.4766\n",
      "2024-12-05 16:42:24.702911: Pseudo dice [0.7716]\n",
      "2024-12-05 16:42:24.712912: Epoch time: 130.7 s\n",
      "2024-12-05 16:42:25.743857: \n",
      "2024-12-05 16:42:25.753857: Epoch 332\n",
      "2024-12-05 16:42:25.753857: Current learning rate: 0.00696\n",
      "2024-12-05 16:44:36.366451: train_loss -0.7523\n",
      "2024-12-05 16:44:36.376451: val_loss -0.5289\n",
      "2024-12-05 16:44:36.386451: Pseudo dice [0.8018]\n",
      "2024-12-05 16:44:36.396451: Epoch time: 130.62 s\n",
      "2024-12-05 16:44:36.396451: Yayy! New best EMA pseudo Dice: 0.7488\n",
      "2024-12-05 16:44:37.686471: \n",
      "2024-12-05 16:44:37.686471: Epoch 333\n",
      "2024-12-05 16:44:37.696471: Current learning rate: 0.00695\n",
      "2024-12-05 16:46:48.426478: train_loss -0.7628\n",
      "2024-12-05 16:46:48.436478: val_loss 0.0449\n",
      "2024-12-05 16:46:48.446479: Pseudo dice [0.4358]\n",
      "2024-12-05 16:46:48.456478: Epoch time: 130.75 s\n",
      "2024-12-05 16:46:49.676497: \n",
      "2024-12-05 16:46:49.686497: Epoch 334\n",
      "2024-12-05 16:46:49.686497: Current learning rate: 0.00694\n",
      "2024-12-05 16:49:00.325392: train_loss -0.7586\n",
      "2024-12-05 16:49:00.335392: val_loss -0.3016\n",
      "2024-12-05 16:49:00.335392: Pseudo dice [0.6694]\n",
      "2024-12-05 16:49:00.345392: Epoch time: 130.65 s\n",
      "2024-12-05 16:49:01.395408: \n",
      "2024-12-05 16:49:01.405408: Epoch 335\n",
      "2024-12-05 16:49:01.405408: Current learning rate: 0.00693\n",
      "2024-12-05 16:51:12.127142: train_loss -0.7837\n",
      "2024-12-05 16:51:12.137142: val_loss -0.2751\n",
      "2024-12-05 16:51:12.147143: Pseudo dice [0.6882]\n",
      "2024-12-05 16:51:12.147143: Epoch time: 130.73 s\n",
      "2024-12-05 16:51:13.207159: \n",
      "2024-12-05 16:51:13.207159: Epoch 336\n",
      "2024-12-05 16:51:13.217158: Current learning rate: 0.00692\n",
      "2024-12-05 16:53:23.877168: train_loss -0.7657\n",
      "2024-12-05 16:53:23.887168: val_loss -0.2431\n",
      "2024-12-05 16:53:23.887168: Pseudo dice [0.7299]\n",
      "2024-12-05 16:53:23.897168: Epoch time: 130.67 s\n",
      "2024-12-05 16:53:24.948027: \n",
      "2024-12-05 16:53:24.958026: Epoch 337\n",
      "2024-12-05 16:53:24.958026: Current learning rate: 0.00691\n",
      "2024-12-05 16:55:35.608618: train_loss -0.7657\n",
      "2024-12-05 16:55:35.618618: val_loss -0.4634\n",
      "2024-12-05 16:55:35.618618: Pseudo dice [0.74]\n",
      "2024-12-05 16:55:35.628618: Epoch time: 130.66 s\n",
      "2024-12-05 16:55:36.678633: \n",
      "2024-12-05 16:55:36.688635: Epoch 338\n",
      "2024-12-05 16:55:36.688635: Current learning rate: 0.0069\n",
      "2024-12-05 16:57:47.441077: train_loss -0.7704\n",
      "2024-12-05 16:57:47.451078: val_loss -0.5405\n",
      "2024-12-05 16:57:47.451078: Pseudo dice [0.8222]\n",
      "2024-12-05 16:57:47.451078: Epoch time: 130.76 s\n",
      "2024-12-05 16:57:48.511093: \n",
      "2024-12-05 16:57:48.521093: Epoch 339\n",
      "2024-12-05 16:57:48.521093: Current learning rate: 0.00689\n",
      "2024-12-05 16:59:59.167282: train_loss -0.7946\n",
      "2024-12-05 16:59:59.177282: val_loss -0.4672\n",
      "2024-12-05 16:59:59.187281: Pseudo dice [0.7603]\n",
      "2024-12-05 16:59:59.187281: Epoch time: 130.66 s\n",
      "2024-12-05 17:00:00.248345: \n",
      "2024-12-05 17:00:00.248345: Epoch 340\n",
      "2024-12-05 17:00:00.258347: Current learning rate: 0.00688\n",
      "2024-12-05 17:02:10.956662: train_loss -0.7746\n",
      "2024-12-05 17:02:10.966662: val_loss -0.3593\n",
      "2024-12-05 17:02:10.976663: Pseudo dice [0.7381]\n",
      "2024-12-05 17:02:10.976663: Epoch time: 130.71 s\n",
      "2024-12-05 17:02:12.216681: \n",
      "2024-12-05 17:02:12.226682: Epoch 341\n",
      "2024-12-05 17:02:12.226682: Current learning rate: 0.00687\n",
      "2024-12-05 17:04:22.937427: train_loss -0.79\n",
      "2024-12-05 17:04:22.947426: val_loss -0.4716\n",
      "2024-12-05 17:04:22.957426: Pseudo dice [0.8064]\n",
      "2024-12-05 17:04:22.967426: Epoch time: 130.72 s\n",
      "2024-12-05 17:04:24.017739: \n",
      "2024-12-05 17:04:24.027739: Epoch 342\n",
      "2024-12-05 17:04:24.027739: Current learning rate: 0.00686\n",
      "2024-12-05 17:06:34.699189: train_loss -0.7855\n",
      "2024-12-05 17:06:34.719189: val_loss -0.1175\n",
      "2024-12-05 17:06:34.719189: Pseudo dice [0.4747]\n",
      "2024-12-05 17:06:34.729189: Epoch time: 130.68 s\n",
      "2024-12-05 17:06:35.779204: \n",
      "2024-12-05 17:06:35.779204: Epoch 343\n",
      "2024-12-05 17:06:35.789205: Current learning rate: 0.00685\n",
      "2024-12-05 17:08:46.451784: train_loss -0.7249\n",
      "2024-12-05 17:08:46.461785: val_loss -0.2383\n",
      "2024-12-05 17:08:46.471785: Pseudo dice [0.5947]\n",
      "2024-12-05 17:08:46.481785: Epoch time: 130.67 s\n",
      "2024-12-05 17:08:47.531799: \n",
      "2024-12-05 17:08:47.541801: Epoch 344\n",
      "2024-12-05 17:08:47.541801: Current learning rate: 0.00684\n",
      "2024-12-05 17:10:58.237979: train_loss -0.7908\n",
      "2024-12-05 17:10:58.247979: val_loss -0.2343\n",
      "2024-12-05 17:10:58.257980: Pseudo dice [0.6402]\n",
      "2024-12-05 17:10:58.267980: Epoch time: 130.71 s\n",
      "2024-12-05 17:10:59.317995: \n",
      "2024-12-05 17:10:59.327996: Epoch 345\n",
      "2024-12-05 17:10:59.327996: Current learning rate: 0.00683\n",
      "2024-12-05 17:13:10.096964: train_loss -0.7976\n",
      "2024-12-05 17:13:10.106964: val_loss -0.2995\n",
      "2024-12-05 17:13:10.116964: Pseudo dice [0.7319]\n",
      "2024-12-05 17:13:10.126965: Epoch time: 130.78 s\n",
      "2024-12-05 17:13:11.186980: \n",
      "2024-12-05 17:13:11.196980: Epoch 346\n",
      "2024-12-05 17:13:11.196980: Current learning rate: 0.00682\n",
      "2024-12-05 17:15:21.895441: train_loss -0.7668\n",
      "2024-12-05 17:15:21.905441: val_loss -0.1997\n",
      "2024-12-05 17:15:21.915442: Pseudo dice [0.5859]\n",
      "2024-12-05 17:15:21.925442: Epoch time: 130.71 s\n",
      "2024-12-05 17:15:22.975457: \n",
      "2024-12-05 17:15:22.985458: Epoch 347\n",
      "2024-12-05 17:15:22.985458: Current learning rate: 0.00681\n",
      "2024-12-05 17:17:33.687061: train_loss -0.7805\n",
      "2024-12-05 17:17:33.697060: val_loss -0.5053\n",
      "2024-12-05 17:17:33.707061: Pseudo dice [0.7997]\n",
      "2024-12-05 17:17:33.717062: Epoch time: 130.71 s\n",
      "2024-12-05 17:17:34.947390: \n",
      "2024-12-05 17:17:34.957390: Epoch 348\n",
      "2024-12-05 17:17:34.957390: Current learning rate: 0.0068\n",
      "2024-12-05 17:19:45.638433: train_loss -0.7663\n",
      "2024-12-05 17:19:45.648433: val_loss -0.2971\n",
      "2024-12-05 17:19:45.648433: Pseudo dice [0.7245]\n",
      "2024-12-05 17:19:45.658434: Epoch time: 130.69 s\n",
      "2024-12-05 17:19:46.708449: \n",
      "2024-12-05 17:19:46.718449: Epoch 349\n",
      "2024-12-05 17:19:46.718449: Current learning rate: 0.0068\n",
      "2024-12-05 17:21:57.451725: train_loss -0.731\n",
      "2024-12-05 17:21:57.461725: val_loss -0.4451\n",
      "2024-12-05 17:21:57.471725: Pseudo dice [0.8191]\n",
      "2024-12-05 17:21:57.471725: Epoch time: 130.74 s\n",
      "2024-12-05 17:21:58.771744: \n",
      "2024-12-05 17:21:58.781744: Epoch 350\n",
      "2024-12-05 17:21:58.791744: Current learning rate: 0.00679\n",
      "2024-12-05 17:24:09.532185: train_loss -0.7847\n",
      "2024-12-05 17:24:09.542186: val_loss -0.3889\n",
      "2024-12-05 17:24:09.542186: Pseudo dice [0.7252]\n",
      "2024-12-05 17:24:09.552186: Epoch time: 130.76 s\n",
      "2024-12-05 17:24:10.602494: \n",
      "2024-12-05 17:24:10.612494: Epoch 351\n",
      "2024-12-05 17:24:10.622494: Current learning rate: 0.00678\n",
      "2024-12-05 17:26:21.309465: train_loss -0.7708\n",
      "2024-12-05 17:26:21.319465: val_loss -0.167\n",
      "2024-12-05 17:26:21.319465: Pseudo dice [0.5987]\n",
      "2024-12-05 17:26:21.329467: Epoch time: 130.71 s\n",
      "2024-12-05 17:26:22.379481: \n",
      "2024-12-05 17:26:22.389481: Epoch 352\n",
      "2024-12-05 17:26:22.399481: Current learning rate: 0.00677\n",
      "2024-12-05 17:28:33.128383: train_loss -0.7778\n",
      "2024-12-05 17:28:33.138384: val_loss -0.2207\n",
      "2024-12-05 17:28:33.138384: Pseudo dice [0.6676]\n",
      "2024-12-05 17:28:33.148385: Epoch time: 130.75 s\n",
      "2024-12-05 17:28:34.198691: \n",
      "2024-12-05 17:28:34.208691: Epoch 353\n",
      "2024-12-05 17:28:34.218691: Current learning rate: 0.00676\n",
      "2024-12-05 17:30:44.979662: train_loss -0.7838\n",
      "2024-12-05 17:30:44.979662: val_loss -0.4058\n",
      "2024-12-05 17:30:44.989663: Pseudo dice [0.7909]\n",
      "2024-12-05 17:30:44.999663: Epoch time: 130.78 s\n",
      "2024-12-05 17:30:46.059965: \n",
      "2024-12-05 17:30:46.069965: Epoch 354\n",
      "2024-12-05 17:30:46.069965: Current learning rate: 0.00675\n",
      "2024-12-05 17:32:56.789692: train_loss -0.7758\n",
      "2024-12-05 17:32:56.799692: val_loss -0.3277\n",
      "2024-12-05 17:32:56.799692: Pseudo dice [0.7814]\n",
      "2024-12-05 17:32:56.809693: Epoch time: 130.73 s\n",
      "2024-12-05 17:32:58.040527: \n",
      "2024-12-05 17:32:58.050527: Epoch 355\n",
      "2024-12-05 17:32:58.050527: Current learning rate: 0.00674\n",
      "2024-12-05 17:35:08.765788: train_loss -0.7621\n",
      "2024-12-05 17:35:08.775789: val_loss -0.4127\n",
      "2024-12-05 17:35:08.785789: Pseudo dice [0.7261]\n",
      "2024-12-05 17:35:08.795789: Epoch time: 130.73 s\n",
      "2024-12-05 17:35:09.846112: \n",
      "2024-12-05 17:35:09.856113: Epoch 356\n",
      "2024-12-05 17:35:09.856113: Current learning rate: 0.00673\n",
      "2024-12-05 17:37:20.615292: train_loss -0.7613\n",
      "2024-12-05 17:37:20.625292: val_loss -0.1835\n",
      "2024-12-05 17:37:20.635291: Pseudo dice [0.5797]\n",
      "2024-12-05 17:37:20.635291: Epoch time: 130.77 s\n",
      "2024-12-05 17:37:21.695602: \n",
      "2024-12-05 17:37:21.705603: Epoch 357\n",
      "2024-12-05 17:37:21.705603: Current learning rate: 0.00672\n",
      "2024-12-05 17:39:32.452935: train_loss -0.7784\n",
      "2024-12-05 17:39:32.462935: val_loss -0.214\n",
      "2024-12-05 17:39:32.477211: Pseudo dice [0.7245]\n",
      "2024-12-05 17:39:32.482279: Epoch time: 130.76 s\n",
      "2024-12-05 17:39:33.533921: \n",
      "2024-12-05 17:39:33.543922: Epoch 358\n",
      "2024-12-05 17:39:33.543922: Current learning rate: 0.00671\n",
      "2024-12-05 17:41:44.321637: train_loss -0.7734\n",
      "2024-12-05 17:41:44.331637: val_loss -0.4503\n",
      "2024-12-05 17:41:44.341637: Pseudo dice [0.8014]\n",
      "2024-12-05 17:41:44.341637: Epoch time: 130.79 s\n",
      "2024-12-05 17:41:45.401973: \n",
      "2024-12-05 17:41:45.411973: Epoch 359\n",
      "2024-12-05 17:41:45.411973: Current learning rate: 0.0067\n",
      "2024-12-05 17:43:56.168565: train_loss -0.7315\n",
      "2024-12-05 17:43:56.178565: val_loss -0.3505\n",
      "2024-12-05 17:43:56.178565: Pseudo dice [0.6422]\n",
      "2024-12-05 17:43:56.188565: Epoch time: 130.77 s\n",
      "2024-12-05 17:43:57.248580: \n",
      "2024-12-05 17:43:57.248580: Epoch 360\n",
      "2024-12-05 17:43:57.258580: Current learning rate: 0.00669\n",
      "2024-12-05 17:46:08.056891: train_loss -0.6733\n",
      "2024-12-05 17:46:08.066891: val_loss -0.3984\n",
      "2024-12-05 17:46:08.076892: Pseudo dice [0.6881]\n",
      "2024-12-05 17:46:08.076892: Epoch time: 130.82 s\n",
      "2024-12-05 17:46:09.136907: \n",
      "2024-12-05 17:46:09.146908: Epoch 361\n",
      "2024-12-05 17:46:09.156909: Current learning rate: 0.00668\n",
      "2024-12-05 17:48:19.885426: train_loss -0.7558\n",
      "2024-12-05 17:48:19.895425: val_loss -0.3336\n",
      "2024-12-05 17:48:19.905426: Pseudo dice [0.722]\n",
      "2024-12-05 17:48:19.915426: Epoch time: 130.75 s\n",
      "2024-12-05 17:48:21.145445: \n",
      "2024-12-05 17:48:21.155446: Epoch 362\n",
      "2024-12-05 17:48:21.165445: Current learning rate: 0.00667\n",
      "2024-12-05 17:50:31.994181: train_loss -0.7728\n",
      "2024-12-05 17:50:32.004181: val_loss -0.4902\n",
      "2024-12-05 17:50:32.014181: Pseudo dice [0.8013]\n",
      "2024-12-05 17:50:32.024182: Epoch time: 130.85 s\n",
      "2024-12-05 17:50:33.074197: \n",
      "2024-12-05 17:50:33.084197: Epoch 363\n",
      "2024-12-05 17:50:33.084197: Current learning rate: 0.00666\n",
      "2024-12-05 17:52:43.840272: train_loss -0.7987\n",
      "2024-12-05 17:52:43.850272: val_loss -0.449\n",
      "2024-12-05 17:52:43.860273: Pseudo dice [0.8143]\n",
      "2024-12-05 17:52:43.860273: Epoch time: 130.77 s\n",
      "2024-12-05 17:52:44.920289: \n",
      "2024-12-05 17:52:44.930288: Epoch 364\n",
      "2024-12-05 17:52:44.930288: Current learning rate: 0.00665\n",
      "2024-12-05 17:54:55.711224: train_loss -0.7288\n",
      "2024-12-05 17:54:55.721224: val_loss -0.436\n",
      "2024-12-05 17:54:55.731225: Pseudo dice [0.7656]\n",
      "2024-12-05 17:54:55.741225: Epoch time: 130.79 s\n",
      "2024-12-05 17:54:56.802083: \n",
      "2024-12-05 17:54:56.802083: Epoch 365\n",
      "2024-12-05 17:54:56.812083: Current learning rate: 0.00665\n",
      "2024-12-05 17:57:07.572513: train_loss -0.761\n",
      "2024-12-05 17:57:07.582514: val_loss -0.3199\n",
      "2024-12-05 17:57:07.592514: Pseudo dice [0.7435]\n",
      "2024-12-05 17:57:07.602514: Epoch time: 130.77 s\n",
      "2024-12-05 17:57:08.662834: \n",
      "2024-12-05 17:57:08.672834: Epoch 366\n",
      "2024-12-05 17:57:08.672834: Current learning rate: 0.00664\n",
      "2024-12-05 17:59:19.443003: train_loss -0.7602\n",
      "2024-12-05 17:59:19.453002: val_loss -0.2223\n",
      "2024-12-05 17:59:19.455295: Pseudo dice [0.6309]\n",
      "2024-12-05 17:59:19.463299: Epoch time: 130.78 s\n",
      "2024-12-05 17:59:20.523317: \n",
      "2024-12-05 17:59:20.533318: Epoch 367\n",
      "2024-12-05 17:59:20.533318: Current learning rate: 0.00663\n",
      "2024-12-05 18:01:31.365473: train_loss -0.7177\n",
      "2024-12-05 18:01:31.375473: val_loss -0.5284\n",
      "2024-12-05 18:01:31.385473: Pseudo dice [0.805]\n",
      "2024-12-05 18:01:31.385473: Epoch time: 130.84 s\n",
      "2024-12-05 18:01:32.445489: \n",
      "2024-12-05 18:01:32.455489: Epoch 368\n",
      "2024-12-05 18:01:32.465489: Current learning rate: 0.00662\n",
      "2024-12-05 18:03:43.176531: train_loss -0.7631\n",
      "2024-12-05 18:03:43.186530: val_loss -0.5051\n",
      "2024-12-05 18:03:43.196531: Pseudo dice [0.799]\n",
      "2024-12-05 18:03:43.206531: Epoch time: 130.73 s\n",
      "2024-12-05 18:03:44.446833: \n",
      "2024-12-05 18:03:44.456833: Epoch 369\n",
      "2024-12-05 18:03:44.456833: Current learning rate: 0.00661\n",
      "2024-12-05 18:05:55.276549: train_loss -0.7918\n",
      "2024-12-05 18:05:55.286549: val_loss -0.3337\n",
      "2024-12-05 18:05:55.296550: Pseudo dice [0.7256]\n",
      "2024-12-05 18:05:55.296550: Epoch time: 130.83 s\n",
      "2024-12-05 18:05:56.366565: \n",
      "2024-12-05 18:05:56.366565: Epoch 370\n",
      "2024-12-05 18:05:56.376565: Current learning rate: 0.0066\n",
      "2024-12-05 18:08:07.108341: train_loss -0.7931\n",
      "2024-12-05 18:08:07.118341: val_loss -0.3425\n",
      "2024-12-05 18:08:07.128342: Pseudo dice [0.8017]\n",
      "2024-12-05 18:08:07.128342: Epoch time: 130.75 s\n",
      "2024-12-05 18:08:08.198357: \n",
      "2024-12-05 18:08:08.198357: Epoch 371\n",
      "2024-12-05 18:08:08.208357: Current learning rate: 0.00659\n",
      "2024-12-05 18:10:19.012784: train_loss -0.8034\n",
      "2024-12-05 18:10:19.032784: val_loss -0.3392\n",
      "2024-12-05 18:10:19.032784: Pseudo dice [0.7513]\n",
      "2024-12-05 18:10:19.042784: Epoch time: 130.82 s\n",
      "2024-12-05 18:10:20.093087: \n",
      "2024-12-05 18:10:20.103087: Epoch 372\n",
      "2024-12-05 18:10:20.103087: Current learning rate: 0.00658\n",
      "2024-12-05 18:12:30.941712: train_loss -0.7986\n",
      "2024-12-05 18:12:30.951713: val_loss -0.4194\n",
      "2024-12-05 18:12:30.951713: Pseudo dice [0.7435]\n",
      "2024-12-05 18:12:30.961713: Epoch time: 130.85 s\n",
      "2024-12-05 18:12:32.021728: \n",
      "2024-12-05 18:12:32.031728: Epoch 373\n",
      "2024-12-05 18:12:32.031728: Current learning rate: 0.00657\n",
      "2024-12-05 18:14:42.782523: train_loss -0.8009\n",
      "2024-12-05 18:14:42.792524: val_loss -0.5196\n",
      "2024-12-05 18:14:42.802523: Pseudo dice [0.8059]\n",
      "2024-12-05 18:14:42.812524: Epoch time: 130.76 s\n",
      "2024-12-05 18:14:42.812524: Yayy! New best EMA pseudo Dice: 0.7494\n",
      "2024-12-05 18:14:44.122543: \n",
      "2024-12-05 18:14:44.122543: Epoch 374\n",
      "2024-12-05 18:14:44.132543: Current learning rate: 0.00656\n",
      "2024-12-05 18:16:54.962719: train_loss -0.7743\n",
      "2024-12-05 18:16:54.972719: val_loss -0.4242\n",
      "2024-12-05 18:16:54.982719: Pseudo dice [0.7201]\n",
      "2024-12-05 18:16:54.993191: Epoch time: 130.84 s\n",
      "2024-12-05 18:16:56.053209: \n",
      "2024-12-05 18:16:56.053209: Epoch 375\n",
      "2024-12-05 18:16:56.063209: Current learning rate: 0.00655\n",
      "2024-12-05 18:19:06.801577: train_loss -0.7866\n",
      "2024-12-05 18:19:06.811577: val_loss -0.0046\n",
      "2024-12-05 18:19:06.811577: Pseudo dice [0.5344]\n",
      "2024-12-05 18:19:06.821579: Epoch time: 130.75 s\n",
      "2024-12-05 18:19:08.061595: \n",
      "2024-12-05 18:19:08.071595: Epoch 376\n",
      "2024-12-05 18:19:08.071595: Current learning rate: 0.00654\n",
      "2024-12-05 18:21:18.778584: train_loss -0.7649\n",
      "2024-12-05 18:21:18.798585: val_loss -0.3869\n",
      "2024-12-05 18:21:18.798585: Pseudo dice [0.7694]\n",
      "2024-12-05 18:21:18.808584: Epoch time: 130.72 s\n",
      "2024-12-05 18:21:19.878600: \n",
      "2024-12-05 18:21:19.878600: Epoch 377\n",
      "2024-12-05 18:21:19.888600: Current learning rate: 0.00653\n",
      "2024-12-05 18:23:30.686893: train_loss -0.7464\n",
      "2024-12-05 18:23:30.696894: val_loss -0.2957\n",
      "2024-12-05 18:23:30.706894: Pseudo dice [0.6445]\n",
      "2024-12-05 18:23:30.706894: Epoch time: 130.81 s\n",
      "2024-12-05 18:23:31.776911: \n",
      "2024-12-05 18:23:31.786911: Epoch 378\n",
      "2024-12-05 18:23:31.786911: Current learning rate: 0.00652\n",
      "2024-12-05 18:25:42.617546: train_loss -0.7518\n",
      "2024-12-05 18:25:42.627547: val_loss -0.4166\n",
      "2024-12-05 18:25:42.627547: Pseudo dice [0.7341]\n",
      "2024-12-05 18:25:42.637547: Epoch time: 130.84 s\n",
      "2024-12-05 18:25:43.697562: \n",
      "2024-12-05 18:25:43.697562: Epoch 379\n",
      "2024-12-05 18:25:43.707563: Current learning rate: 0.00651\n",
      "2024-12-05 18:27:54.433618: train_loss -0.8001\n",
      "2024-12-05 18:27:54.443619: val_loss -0.4398\n",
      "2024-12-05 18:27:54.453618: Pseudo dice [0.7916]\n",
      "2024-12-05 18:27:54.453618: Epoch time: 130.74 s\n",
      "2024-12-05 18:27:55.513634: \n",
      "2024-12-05 18:27:55.523635: Epoch 380\n",
      "2024-12-05 18:27:55.523635: Current learning rate: 0.0065\n",
      "2024-12-05 18:30:06.274314: train_loss -0.806\n",
      "2024-12-05 18:30:06.284315: val_loss -0.3463\n",
      "2024-12-05 18:30:06.294315: Pseudo dice [0.7024]\n",
      "2024-12-05 18:30:06.294315: Epoch time: 130.76 s\n",
      "2024-12-05 18:30:07.364457: \n",
      "2024-12-05 18:30:07.364457: Epoch 381\n",
      "2024-12-05 18:30:07.374458: Current learning rate: 0.00649\n",
      "2024-12-05 18:32:18.132861: train_loss -0.786\n",
      "2024-12-05 18:32:18.142862: val_loss -0.3967\n",
      "2024-12-05 18:32:18.142862: Pseudo dice [0.7848]\n",
      "2024-12-05 18:32:18.152861: Epoch time: 130.78 s\n",
      "2024-12-05 18:32:19.222877: \n",
      "2024-12-05 18:32:19.232878: Epoch 382\n",
      "2024-12-05 18:32:19.242877: Current learning rate: 0.00648\n",
      "2024-12-05 18:34:29.965654: train_loss -0.7724\n",
      "2024-12-05 18:34:29.975655: val_loss -0.419\n",
      "2024-12-05 18:34:29.975655: Pseudo dice [0.7657]\n",
      "2024-12-05 18:34:29.985655: Epoch time: 130.74 s\n",
      "2024-12-05 18:34:31.225673: \n",
      "2024-12-05 18:34:31.235674: Epoch 383\n",
      "2024-12-05 18:34:31.235674: Current learning rate: 0.00648\n",
      "2024-12-05 18:36:42.002302: train_loss -0.7781\n",
      "2024-12-05 18:36:42.012302: val_loss -0.2897\n",
      "2024-12-05 18:36:42.022302: Pseudo dice [0.6387]\n",
      "2024-12-05 18:36:42.032302: Epoch time: 130.78 s\n",
      "2024-12-05 18:36:43.112318: \n",
      "2024-12-05 18:36:43.112318: Epoch 384\n",
      "2024-12-05 18:36:43.122318: Current learning rate: 0.00647\n",
      "2024-12-05 18:38:53.874982: train_loss -0.737\n",
      "2024-12-05 18:38:53.884984: val_loss -0.3692\n",
      "2024-12-05 18:38:53.884984: Pseudo dice [0.6464]\n",
      "2024-12-05 18:38:53.894984: Epoch time: 130.76 s\n",
      "2024-12-05 18:38:54.975264: \n",
      "2024-12-05 18:38:54.985265: Epoch 385\n",
      "2024-12-05 18:38:54.985265: Current learning rate: 0.00646\n",
      "2024-12-05 18:41:05.814442: train_loss -0.7484\n",
      "2024-12-05 18:41:05.824442: val_loss -0.3502\n",
      "2024-12-05 18:41:05.824442: Pseudo dice [0.7639]\n",
      "2024-12-05 18:41:05.834442: Epoch time: 130.84 s\n",
      "2024-12-05 18:41:06.924603: \n",
      "2024-12-05 18:41:06.924603: Epoch 386\n",
      "2024-12-05 18:41:06.934604: Current learning rate: 0.00645\n",
      "2024-12-05 18:43:17.751472: train_loss -0.767\n",
      "2024-12-05 18:43:17.761473: val_loss -0.5853\n",
      "2024-12-05 18:43:17.761473: Pseudo dice [0.8332]\n",
      "2024-12-05 18:43:17.771473: Epoch time: 130.83 s\n",
      "2024-12-05 18:43:18.852198: \n",
      "2024-12-05 18:43:18.862200: Epoch 387\n",
      "2024-12-05 18:43:18.862200: Current learning rate: 0.00644\n",
      "2024-12-05 18:45:29.678675: train_loss -0.7707\n",
      "2024-12-05 18:45:29.688676: val_loss -0.322\n",
      "2024-12-05 18:45:29.688676: Pseudo dice [0.6821]\n",
      "2024-12-05 18:45:29.698676: Epoch time: 130.83 s\n",
      "2024-12-05 18:45:30.778989: \n",
      "2024-12-05 18:45:30.788990: Epoch 388\n",
      "2024-12-05 18:45:30.788990: Current learning rate: 0.00643\n",
      "2024-12-05 18:47:41.566704: train_loss -0.7638\n",
      "2024-12-05 18:47:41.576704: val_loss -0.384\n",
      "2024-12-05 18:47:41.586705: Pseudo dice [0.759]\n",
      "2024-12-05 18:47:41.596705: Epoch time: 130.79 s\n",
      "2024-12-05 18:47:42.677415: \n",
      "2024-12-05 18:47:42.677415: Epoch 389\n",
      "2024-12-05 18:47:42.687417: Current learning rate: 0.00642\n",
      "2024-12-05 18:49:53.358073: train_loss -0.7716\n",
      "2024-12-05 18:49:53.368074: val_loss -0.3443\n",
      "2024-12-05 18:49:53.378074: Pseudo dice [0.7504]\n",
      "2024-12-05 18:49:53.388074: Epoch time: 130.68 s\n",
      "2024-12-05 18:49:54.638384: \n",
      "2024-12-05 18:49:54.638384: Epoch 390\n",
      "2024-12-05 18:49:54.648385: Current learning rate: 0.00641\n",
      "2024-12-05 18:52:05.400989: train_loss -0.7973\n",
      "2024-12-05 18:52:05.410989: val_loss -0.4794\n",
      "2024-12-05 18:52:05.410989: Pseudo dice [0.8386]\n",
      "2024-12-05 18:52:05.420989: Epoch time: 130.76 s\n",
      "2024-12-05 18:52:06.501006: \n",
      "2024-12-05 18:52:06.511006: Epoch 391\n",
      "2024-12-05 18:52:06.511006: Current learning rate: 0.0064\n",
      "2024-12-05 18:54:17.279373: train_loss -0.8078\n",
      "2024-12-05 18:54:17.289374: val_loss -0.3527\n",
      "2024-12-05 18:54:17.289374: Pseudo dice [0.7108]\n",
      "2024-12-05 18:54:17.299373: Epoch time: 130.78 s\n",
      "2024-12-05 18:54:18.379389: \n",
      "2024-12-05 18:54:18.389390: Epoch 392\n",
      "2024-12-05 18:54:18.389390: Current learning rate: 0.00639\n",
      "2024-12-05 18:56:29.187775: train_loss -0.7811\n",
      "2024-12-05 18:56:29.197775: val_loss -0.0024\n",
      "2024-12-05 18:56:29.210071: Pseudo dice [0.3883]\n",
      "2024-12-05 18:56:29.210071: Epoch time: 130.81 s\n",
      "2024-12-05 18:56:30.318387: \n",
      "2024-12-05 18:56:30.328387: Epoch 393\n",
      "2024-12-05 18:56:30.328387: Current learning rate: 0.00638\n",
      "2024-12-05 18:58:41.040493: train_loss -0.7909\n",
      "2024-12-05 18:58:41.050494: val_loss -0.5131\n",
      "2024-12-05 18:58:41.060494: Pseudo dice [0.7948]\n",
      "2024-12-05 18:58:41.070495: Epoch time: 130.72 s\n",
      "2024-12-05 18:58:42.150511: \n",
      "2024-12-05 18:58:42.160510: Epoch 394\n",
      "2024-12-05 18:58:42.160510: Current learning rate: 0.00637\n",
      "2024-12-05 19:00:52.987606: train_loss -0.7999\n",
      "2024-12-05 19:00:52.997607: val_loss -0.4741\n",
      "2024-12-05 19:00:53.007607: Pseudo dice [0.7779]\n",
      "2024-12-05 19:00:53.007607: Epoch time: 130.84 s\n",
      "2024-12-05 19:00:54.117633: \n",
      "2024-12-05 19:00:54.127632: Epoch 395\n",
      "2024-12-05 19:00:54.127632: Current learning rate: 0.00636\n",
      "2024-12-05 19:03:04.923705: train_loss -0.7407\n",
      "2024-12-05 19:03:04.933704: val_loss -0.282\n",
      "2024-12-05 19:03:04.933704: Pseudo dice [0.7488]\n",
      "2024-12-05 19:03:04.943705: Epoch time: 130.81 s\n",
      "2024-12-05 19:03:06.033721: \n",
      "2024-12-05 19:03:06.043721: Epoch 396\n",
      "2024-12-05 19:03:06.053722: Current learning rate: 0.00635\n",
      "2024-12-05 19:05:16.893780: train_loss -0.7629\n",
      "2024-12-05 19:05:16.903781: val_loss -0.4977\n",
      "2024-12-05 19:05:16.913781: Pseudo dice [0.8418]\n",
      "2024-12-05 19:05:16.923781: Epoch time: 130.86 s\n",
      "2024-12-05 19:05:18.173799: \n",
      "2024-12-05 19:05:18.173799: Epoch 397\n",
      "2024-12-05 19:05:18.183800: Current learning rate: 0.00634\n",
      "2024-12-05 19:07:28.999841: train_loss -0.7987\n",
      "2024-12-05 19:07:29.019841: val_loss -0.3525\n",
      "2024-12-05 19:07:29.019841: Pseudo dice [0.6933]\n",
      "2024-12-05 19:07:29.029842: Epoch time: 130.84 s\n",
      "2024-12-05 19:07:30.110159: \n",
      "2024-12-05 19:07:30.120159: Epoch 398\n",
      "2024-12-05 19:07:30.120159: Current learning rate: 0.00633\n",
      "2024-12-05 19:09:40.889840: train_loss -0.7868\n",
      "2024-12-05 19:09:40.899839: val_loss -0.4245\n",
      "2024-12-05 19:09:40.909840: Pseudo dice [0.7544]\n",
      "2024-12-05 19:09:40.919841: Epoch time: 130.78 s\n",
      "2024-12-05 19:09:41.999856: \n",
      "2024-12-05 19:09:42.009856: Epoch 399\n",
      "2024-12-05 19:09:42.009856: Current learning rate: 0.00632\n",
      "2024-12-05 19:11:52.790495: train_loss -0.7667\n",
      "2024-12-05 19:11:52.800495: val_loss -0.3094\n",
      "2024-12-05 19:11:52.800495: Pseudo dice [0.6315]\n",
      "2024-12-05 19:11:52.810495: Epoch time: 130.79 s\n",
      "2024-12-05 19:11:54.140515: \n",
      "2024-12-05 19:11:54.150516: Epoch 400\n",
      "2024-12-05 19:11:54.150516: Current learning rate: 0.00631\n",
      "2024-12-05 19:14:04.918087: train_loss -0.795\n",
      "2024-12-05 19:14:04.928087: val_loss -0.3754\n",
      "2024-12-05 19:14:04.938087: Pseudo dice [0.7267]\n",
      "2024-12-05 19:14:04.948087: Epoch time: 130.78 s\n",
      "2024-12-05 19:14:06.028104: \n",
      "2024-12-05 19:14:06.038104: Epoch 401\n",
      "2024-12-05 19:14:06.038104: Current learning rate: 0.0063\n",
      "2024-12-05 19:16:16.845245: train_loss -0.7923\n",
      "2024-12-05 19:16:16.855247: val_loss -0.3383\n",
      "2024-12-05 19:16:16.865246: Pseudo dice [0.661]\n",
      "2024-12-05 19:16:16.875246: Epoch time: 130.82 s\n",
      "2024-12-05 19:16:17.956136: \n",
      "2024-12-05 19:16:17.966136: Epoch 402\n",
      "2024-12-05 19:16:17.966136: Current learning rate: 0.0063\n",
      "2024-12-05 19:18:28.801828: train_loss -0.7717\n",
      "2024-12-05 19:18:28.811828: val_loss -0.1365\n",
      "2024-12-05 19:18:28.811828: Pseudo dice [0.5111]\n",
      "2024-12-05 19:18:28.821827: Epoch time: 130.85 s\n",
      "2024-12-05 19:18:30.072140: \n",
      "2024-12-05 19:18:30.082139: Epoch 403\n",
      "2024-12-05 19:18:30.082139: Current learning rate: 0.00629\n",
      "2024-12-05 19:20:40.838123: train_loss -0.7901\n",
      "2024-12-05 19:20:40.848123: val_loss -0.5618\n",
      "2024-12-05 19:20:40.858124: Pseudo dice [0.8043]\n",
      "2024-12-05 19:20:40.858124: Epoch time: 130.77 s\n",
      "2024-12-05 19:20:41.948139: \n",
      "2024-12-05 19:20:41.958140: Epoch 404\n",
      "2024-12-05 19:20:41.958140: Current learning rate: 0.00628\n",
      "2024-12-05 19:22:52.766613: train_loss -0.8082\n",
      "2024-12-05 19:22:52.776613: val_loss -0.4238\n",
      "2024-12-05 19:22:52.786613: Pseudo dice [0.7906]\n",
      "2024-12-05 19:22:52.786613: Epoch time: 130.82 s\n",
      "2024-12-05 19:22:53.866629: \n",
      "2024-12-05 19:22:53.866629: Epoch 405\n",
      "2024-12-05 19:22:53.876630: Current learning rate: 0.00627\n",
      "2024-12-05 19:25:04.693334: train_loss -0.8011\n",
      "2024-12-05 19:25:04.703334: val_loss -0.459\n",
      "2024-12-05 19:25:04.703334: Pseudo dice [0.7705]\n",
      "2024-12-05 19:25:04.713334: Epoch time: 130.83 s\n",
      "2024-12-05 19:25:05.803350: \n",
      "2024-12-05 19:25:05.803350: Epoch 406\n",
      "2024-12-05 19:25:05.813351: Current learning rate: 0.00626\n",
      "2024-12-05 19:27:16.580602: train_loss -0.8225\n",
      "2024-12-05 19:27:16.590602: val_loss -0.2109\n",
      "2024-12-05 19:27:16.590602: Pseudo dice [0.6662]\n",
      "2024-12-05 19:27:16.600602: Epoch time: 130.78 s\n",
      "2024-12-05 19:27:17.680950: \n",
      "2024-12-05 19:27:17.680950: Epoch 407\n",
      "2024-12-05 19:27:17.690951: Current learning rate: 0.00625\n",
      "2024-12-05 19:29:28.435194: train_loss -0.82\n",
      "2024-12-05 19:29:28.445194: val_loss -0.4819\n",
      "2024-12-05 19:29:28.455195: Pseudo dice [0.7667]\n",
      "2024-12-05 19:29:28.455195: Epoch time: 130.75 s\n",
      "2024-12-05 19:29:29.537487: \n",
      "2024-12-05 19:29:29.545491: Epoch 408\n",
      "2024-12-05 19:29:29.545491: Current learning rate: 0.00624\n",
      "2024-12-05 19:31:40.334464: train_loss -0.7823\n",
      "2024-12-05 19:31:40.344464: val_loss -0.4624\n",
      "2024-12-05 19:31:40.354464: Pseudo dice [0.7789]\n",
      "2024-12-05 19:31:40.364464: Epoch time: 130.8 s\n",
      "2024-12-05 19:31:41.454480: \n",
      "2024-12-05 19:31:41.454480: Epoch 409\n",
      "2024-12-05 19:31:41.464481: Current learning rate: 0.00623\n",
      "2024-12-05 19:33:52.192780: train_loss -0.7689\n",
      "2024-12-05 19:33:52.202781: val_loss -0.512\n",
      "2024-12-05 19:33:52.212781: Pseudo dice [0.7517]\n",
      "2024-12-05 19:33:52.222782: Epoch time: 130.75 s\n",
      "2024-12-05 19:33:53.472800: \n",
      "2024-12-05 19:33:53.472800: Epoch 410\n",
      "2024-12-05 19:33:53.482800: Current learning rate: 0.00622\n",
      "2024-12-05 19:36:04.321942: train_loss -0.7714\n",
      "2024-12-05 19:36:04.331942: val_loss -0.425\n",
      "2024-12-05 19:36:04.331942: Pseudo dice [0.715]\n",
      "2024-12-05 19:36:04.343232: Epoch time: 130.85 s\n",
      "2024-12-05 19:36:05.353187: \n",
      "2024-12-05 19:36:05.363188: Epoch 411\n",
      "2024-12-05 19:36:05.363188: Current learning rate: 0.00621\n",
      "2024-12-05 19:38:16.150250: train_loss -0.7556\n",
      "2024-12-05 19:38:16.159390: val_loss -0.4382\n",
      "2024-12-05 19:38:16.161421: Pseudo dice [0.768]\n",
      "2024-12-05 19:38:16.171423: Epoch time: 130.8 s\n",
      "2024-12-05 19:38:17.191438: \n",
      "2024-12-05 19:38:17.201439: Epoch 412\n",
      "2024-12-05 19:38:17.201439: Current learning rate: 0.0062\n",
      "2024-12-05 19:40:27.902285: train_loss -0.7977\n",
      "2024-12-05 19:40:27.912286: val_loss -0.4296\n",
      "2024-12-05 19:40:27.922286: Pseudo dice [0.7409]\n",
      "2024-12-05 19:40:27.932287: Epoch time: 130.71 s\n",
      "2024-12-05 19:40:28.952301: \n",
      "2024-12-05 19:40:28.962301: Epoch 413\n",
      "2024-12-05 19:40:28.962301: Current learning rate: 0.00619\n",
      "2024-12-05 19:42:39.638957: train_loss -0.8051\n",
      "2024-12-05 19:42:39.648958: val_loss -0.3069\n",
      "2024-12-05 19:42:39.658958: Pseudo dice [0.6817]\n",
      "2024-12-05 19:42:39.668958: Epoch time: 130.69 s\n",
      "2024-12-05 19:42:40.688973: \n",
      "2024-12-05 19:42:40.698974: Epoch 414\n",
      "2024-12-05 19:42:40.698974: Current learning rate: 0.00618\n",
      "2024-12-05 19:44:51.386806: train_loss -0.7658\n",
      "2024-12-05 19:44:51.396806: val_loss 0.0553\n",
      "2024-12-05 19:44:51.406806: Pseudo dice [0.5038]\n",
      "2024-12-05 19:44:51.406806: Epoch time: 130.7 s\n",
      "2024-12-05 19:44:52.427099: \n",
      "2024-12-05 19:44:52.437100: Epoch 415\n",
      "2024-12-05 19:44:52.437100: Current learning rate: 0.00617\n",
      "2024-12-05 19:47:03.187882: train_loss -0.7242\n",
      "2024-12-05 19:47:03.197882: val_loss -0.2236\n",
      "2024-12-05 19:47:03.207882: Pseudo dice [0.5922]\n",
      "2024-12-05 19:47:03.217882: Epoch time: 130.76 s\n",
      "2024-12-05 19:47:04.237898: \n",
      "2024-12-05 19:47:04.247898: Epoch 416\n",
      "2024-12-05 19:47:04.247898: Current learning rate: 0.00616\n",
      "2024-12-05 19:49:14.944040: train_loss -0.7952\n",
      "2024-12-05 19:49:14.954040: val_loss -0.4061\n",
      "2024-12-05 19:49:14.964040: Pseudo dice [0.7751]\n",
      "2024-12-05 19:49:14.964040: Epoch time: 130.71 s\n",
      "2024-12-05 19:49:16.174059: \n",
      "2024-12-05 19:49:16.184059: Epoch 417\n",
      "2024-12-05 19:49:16.194058: Current learning rate: 0.00615\n",
      "2024-12-05 19:51:26.903095: train_loss -0.7891\n",
      "2024-12-05 19:51:26.913095: val_loss -0.3391\n",
      "2024-12-05 19:51:26.913095: Pseudo dice [0.7002]\n",
      "2024-12-05 19:51:26.923096: Epoch time: 130.73 s\n",
      "2024-12-05 19:51:27.943835: \n",
      "2024-12-05 19:51:27.953835: Epoch 418\n",
      "2024-12-05 19:51:27.953835: Current learning rate: 0.00614\n",
      "2024-12-05 19:53:38.715235: train_loss -0.7983\n",
      "2024-12-05 19:53:38.725235: val_loss -0.3012\n",
      "2024-12-05 19:53:38.725235: Pseudo dice [0.6844]\n",
      "2024-12-05 19:53:38.735235: Epoch time: 130.77 s\n",
      "2024-12-05 19:53:39.765251: \n",
      "2024-12-05 19:53:39.765251: Epoch 419\n",
      "2024-12-05 19:53:39.775251: Current learning rate: 0.00613\n",
      "2024-12-05 19:55:50.463253: train_loss -0.7852\n",
      "2024-12-05 19:55:50.473253: val_loss -0.3378\n",
      "2024-12-05 19:55:50.483253: Pseudo dice [0.7784]\n",
      "2024-12-05 19:55:50.483253: Epoch time: 130.7 s\n",
      "2024-12-05 19:55:51.513324: \n",
      "2024-12-05 19:55:51.523325: Epoch 420\n",
      "2024-12-05 19:55:51.523325: Current learning rate: 0.00612\n",
      "2024-12-05 19:58:02.232804: train_loss -0.7824\n",
      "2024-12-05 19:58:02.242804: val_loss -0.1884\n",
      "2024-12-05 19:58:02.242804: Pseudo dice [0.702]\n",
      "2024-12-05 19:58:02.252805: Epoch time: 130.72 s\n",
      "2024-12-05 19:58:03.272819: \n",
      "2024-12-05 19:58:03.282820: Epoch 421\n",
      "2024-12-05 19:58:03.282820: Current learning rate: 0.00612\n",
      "2024-12-05 20:00:14.071046: train_loss -0.7549\n",
      "2024-12-05 20:00:14.081046: val_loss -0.501\n",
      "2024-12-05 20:00:14.091046: Pseudo dice [0.8117]\n",
      "2024-12-05 20:00:14.101048: Epoch time: 130.8 s\n",
      "2024-12-05 20:00:15.121362: \n",
      "2024-12-05 20:00:15.131362: Epoch 422\n",
      "2024-12-05 20:00:15.131362: Current learning rate: 0.00611\n",
      "2024-12-05 20:02:25.880393: train_loss -0.7936\n",
      "2024-12-05 20:02:25.900393: val_loss -0.3975\n",
      "2024-12-05 20:02:25.900393: Pseudo dice [0.7565]\n",
      "2024-12-05 20:02:25.910394: Epoch time: 130.76 s\n",
      "2024-12-05 20:02:26.930409: \n",
      "2024-12-05 20:02:26.940409: Epoch 423\n",
      "2024-12-05 20:02:26.950409: Current learning rate: 0.0061\n",
      "2024-12-05 20:04:37.699364: train_loss -0.7846\n",
      "2024-12-05 20:04:37.709363: val_loss -0.5233\n",
      "2024-12-05 20:04:37.709363: Pseudo dice [0.7914]\n",
      "2024-12-05 20:04:37.719364: Epoch time: 130.77 s\n",
      "2024-12-05 20:04:38.749378: \n",
      "2024-12-05 20:04:38.749378: Epoch 424\n",
      "2024-12-05 20:04:38.759379: Current learning rate: 0.00609\n",
      "2024-12-05 20:06:49.530206: train_loss -0.7775\n",
      "2024-12-05 20:06:49.540206: val_loss -0.4515\n",
      "2024-12-05 20:06:49.550206: Pseudo dice [0.7811]\n",
      "2024-12-05 20:06:49.605140: Epoch time: 130.79 s\n",
      "2024-12-05 20:06:50.811164: \n",
      "2024-12-05 20:06:50.821164: Epoch 425\n",
      "2024-12-05 20:06:50.821164: Current learning rate: 0.00608\n",
      "2024-12-05 20:09:01.621350: train_loss -0.7727\n",
      "2024-12-05 20:09:01.631350: val_loss -0.2411\n",
      "2024-12-05 20:09:01.641351: Pseudo dice [0.5295]\n",
      "2024-12-05 20:09:01.651350: Epoch time: 130.81 s\n",
      "2024-12-05 20:09:02.672217: \n",
      "2024-12-05 20:09:02.682217: Epoch 426\n",
      "2024-12-05 20:09:02.682217: Current learning rate: 0.00607\n",
      "2024-12-05 20:11:13.519030: train_loss -0.7801\n",
      "2024-12-05 20:11:13.529030: val_loss -0.5668\n",
      "2024-12-05 20:11:13.539030: Pseudo dice [0.8723]\n",
      "2024-12-05 20:11:13.539030: Epoch time: 130.85 s\n",
      "2024-12-05 20:11:14.569046: \n",
      "2024-12-05 20:11:14.579046: Epoch 427\n",
      "2024-12-05 20:11:14.579046: Current learning rate: 0.00606\n",
      "2024-12-05 20:13:25.318648: train_loss -0.7903\n",
      "2024-12-05 20:13:25.328648: val_loss -0.5078\n",
      "2024-12-05 20:13:25.338648: Pseudo dice [0.793]\n",
      "2024-12-05 20:13:25.348648: Epoch time: 130.75 s\n",
      "2024-12-05 20:13:26.378665: \n",
      "2024-12-05 20:13:26.378665: Epoch 428\n",
      "2024-12-05 20:13:26.388664: Current learning rate: 0.00605\n",
      "2024-12-05 20:15:37.205473: train_loss -0.7979\n",
      "2024-12-05 20:15:37.215473: val_loss -0.4383\n",
      "2024-12-05 20:15:37.225473: Pseudo dice [0.8014]\n",
      "2024-12-05 20:15:37.235473: Epoch time: 130.84 s\n",
      "2024-12-05 20:15:38.265488: \n",
      "2024-12-05 20:15:38.265488: Epoch 429\n",
      "2024-12-05 20:15:38.275489: Current learning rate: 0.00604\n",
      "2024-12-05 20:17:49.004540: train_loss -0.7883\n",
      "2024-12-05 20:17:49.014540: val_loss -0.5466\n",
      "2024-12-05 20:17:49.024540: Pseudo dice [0.8]\n",
      "2024-12-05 20:17:49.034540: Epoch time: 130.75 s\n",
      "2024-12-05 20:17:50.064555: \n",
      "2024-12-05 20:17:50.074556: Epoch 430\n",
      "2024-12-05 20:17:50.074556: Current learning rate: 0.00603\n",
      "2024-12-05 20:20:00.834322: train_loss -0.7986\n",
      "2024-12-05 20:20:00.844322: val_loss -0.4879\n",
      "2024-12-05 20:20:00.844322: Pseudo dice [0.8183]\n",
      "2024-12-05 20:20:00.854322: Epoch time: 130.77 s\n",
      "2024-12-05 20:20:00.864322: Yayy! New best EMA pseudo Dice: 0.7551\n",
      "2024-12-05 20:20:02.144344: \n",
      "2024-12-05 20:20:02.144344: Epoch 431\n",
      "2024-12-05 20:20:02.154341: Current learning rate: 0.00602\n",
      "2024-12-05 20:22:12.923780: train_loss -0.7843\n",
      "2024-12-05 20:22:12.943781: val_loss -0.3545\n",
      "2024-12-05 20:22:12.953781: Pseudo dice [0.7416]\n",
      "2024-12-05 20:22:12.953781: Epoch time: 130.78 s\n",
      "2024-12-05 20:22:14.153799: \n",
      "2024-12-05 20:22:14.163799: Epoch 432\n",
      "2024-12-05 20:22:14.163799: Current learning rate: 0.00601\n",
      "2024-12-05 20:24:24.921451: train_loss -0.8011\n",
      "2024-12-05 20:24:24.931451: val_loss -0.3949\n",
      "2024-12-05 20:24:24.931451: Pseudo dice [0.6862]\n",
      "2024-12-05 20:24:24.941452: Epoch time: 130.77 s\n",
      "2024-12-05 20:24:25.962305: \n",
      "2024-12-05 20:24:25.972305: Epoch 433\n",
      "2024-12-05 20:24:25.972305: Current learning rate: 0.006\n",
      "2024-12-05 20:26:36.782193: train_loss -0.8171\n",
      "2024-12-05 20:26:36.792193: val_loss -0.4639\n",
      "2024-12-05 20:26:36.802193: Pseudo dice [0.7527]\n",
      "2024-12-05 20:26:36.812193: Epoch time: 130.82 s\n",
      "2024-12-05 20:26:37.832209: \n",
      "2024-12-05 20:26:37.842209: Epoch 434\n",
      "2024-12-05 20:26:37.852209: Current learning rate: 0.00599\n",
      "2024-12-05 20:28:48.610441: train_loss -0.8069\n",
      "2024-12-05 20:28:48.620441: val_loss -0.3502\n",
      "2024-12-05 20:28:48.630442: Pseudo dice [0.7439]\n",
      "2024-12-05 20:28:48.630442: Epoch time: 130.78 s\n",
      "2024-12-05 20:28:49.660457: \n",
      "2024-12-05 20:28:49.670458: Epoch 435\n",
      "2024-12-05 20:28:49.670458: Current learning rate: 0.00598\n",
      "2024-12-05 20:31:00.504964: train_loss -0.815\n",
      "2024-12-05 20:31:00.514964: val_loss -0.4633\n",
      "2024-12-05 20:31:00.524964: Pseudo dice [0.7904]\n",
      "2024-12-05 20:31:00.524964: Epoch time: 130.84 s\n",
      "2024-12-05 20:31:01.555806: \n",
      "2024-12-05 20:31:01.565807: Epoch 436\n",
      "2024-12-05 20:31:01.565807: Current learning rate: 0.00597\n",
      "2024-12-05 20:33:12.325892: train_loss -0.8125\n",
      "2024-12-05 20:33:12.335892: val_loss -0.5184\n",
      "2024-12-05 20:33:12.335892: Pseudo dice [0.7641]\n",
      "2024-12-05 20:33:12.345892: Epoch time: 130.77 s\n",
      "2024-12-05 20:33:13.375908: \n",
      "2024-12-05 20:33:13.385908: Epoch 437\n",
      "2024-12-05 20:33:13.385908: Current learning rate: 0.00596\n",
      "2024-12-05 20:35:24.192471: train_loss -0.8165\n",
      "2024-12-05 20:35:24.212472: val_loss -0.1985\n",
      "2024-12-05 20:35:24.212472: Pseudo dice [0.662]\n",
      "2024-12-05 20:35:24.273722: Epoch time: 130.82 s\n",
      "2024-12-05 20:35:25.293739: \n",
      "2024-12-05 20:35:25.303739: Epoch 438\n",
      "2024-12-05 20:35:25.303739: Current learning rate: 0.00595\n",
      "2024-12-05 20:37:36.022659: train_loss -0.8093\n",
      "2024-12-05 20:37:36.032660: val_loss 0.0212\n",
      "2024-12-05 20:37:36.042660: Pseudo dice [0.4704]\n",
      "2024-12-05 20:37:36.042660: Epoch time: 130.73 s\n",
      "2024-12-05 20:37:37.252921: \n",
      "2024-12-05 20:37:37.262917: Epoch 439\n",
      "2024-12-05 20:37:37.262917: Current learning rate: 0.00594\n",
      "2024-12-05 20:39:47.979888: train_loss -0.795\n",
      "2024-12-05 20:39:47.989887: val_loss -0.1696\n",
      "2024-12-05 20:39:47.999887: Pseudo dice [0.6877]\n",
      "2024-12-05 20:39:47.999887: Epoch time: 130.73 s\n",
      "2024-12-05 20:39:49.049905: \n",
      "2024-12-05 20:39:49.049905: Epoch 440\n",
      "2024-12-05 20:39:49.059902: Current learning rate: 0.00593\n",
      "2024-12-05 20:41:59.839654: train_loss -0.7919\n",
      "2024-12-05 20:41:59.859655: val_loss -0.2734\n",
      "2024-12-05 20:41:59.869655: Pseudo dice [0.6643]\n",
      "2024-12-05 20:41:59.869655: Epoch time: 130.79 s\n",
      "2024-12-05 20:42:00.899670: \n",
      "2024-12-05 20:42:00.899670: Epoch 441\n",
      "2024-12-05 20:42:00.909670: Current learning rate: 0.00592\n",
      "2024-12-05 20:44:11.666018: train_loss -0.7837\n",
      "2024-12-05 20:44:11.676018: val_loss -0.3192\n",
      "2024-12-05 20:44:11.686018: Pseudo dice [0.7008]\n",
      "2024-12-05 20:44:11.696019: Epoch time: 130.78 s\n",
      "2024-12-05 20:44:12.716034: \n",
      "2024-12-05 20:44:12.726036: Epoch 442\n",
      "2024-12-05 20:44:12.726036: Current learning rate: 0.00592\n",
      "2024-12-05 20:46:23.446404: train_loss -0.7693\n",
      "2024-12-05 20:46:23.456403: val_loss -0.305\n",
      "2024-12-05 20:46:23.466404: Pseudo dice [0.6904]\n",
      "2024-12-05 20:46:23.476404: Epoch time: 130.73 s\n",
      "2024-12-05 20:46:24.506764: \n",
      "2024-12-05 20:46:24.506764: Epoch 443\n",
      "2024-12-05 20:46:24.516765: Current learning rate: 0.00591\n",
      "2024-12-05 20:48:35.302684: train_loss -0.7746\n",
      "2024-12-05 20:48:35.312684: val_loss -0.4365\n",
      "2024-12-05 20:48:35.322684: Pseudo dice [0.7762]\n",
      "2024-12-05 20:48:35.332684: Epoch time: 130.8 s\n",
      "2024-12-05 20:48:36.352700: \n",
      "2024-12-05 20:48:36.362701: Epoch 444\n",
      "2024-12-05 20:48:36.362701: Current learning rate: 0.0059\n",
      "2024-12-05 20:50:47.142705: train_loss -0.7836\n",
      "2024-12-05 20:50:47.152704: val_loss 0.0943\n",
      "2024-12-05 20:50:47.152704: Pseudo dice [0.348]\n",
      "2024-12-05 20:50:47.162704: Epoch time: 130.79 s\n",
      "2024-12-05 20:50:48.182720: \n",
      "2024-12-05 20:50:48.192720: Epoch 445\n",
      "2024-12-05 20:50:48.192720: Current learning rate: 0.00589\n",
      "2024-12-05 20:52:58.890278: train_loss -0.7744\n",
      "2024-12-05 20:52:58.900278: val_loss -0.2356\n",
      "2024-12-05 20:52:58.910277: Pseudo dice [0.6122]\n",
      "2024-12-05 20:52:58.920278: Epoch time: 130.71 s\n",
      "2024-12-05 20:52:59.940578: \n",
      "2024-12-05 20:52:59.940578: Epoch 446\n",
      "2024-12-05 20:52:59.950578: Current learning rate: 0.00588\n",
      "2024-12-05 20:55:10.629951: train_loss -0.7512\n",
      "2024-12-05 20:55:10.639951: val_loss -0.3987\n",
      "2024-12-05 20:55:10.649951: Pseudo dice [0.7064]\n",
      "2024-12-05 20:55:10.659952: Epoch time: 130.69 s\n",
      "2024-12-05 20:55:11.860104: \n",
      "2024-12-05 20:55:11.870105: Epoch 447\n",
      "2024-12-05 20:55:11.870105: Current learning rate: 0.00587\n",
      "2024-12-05 20:57:22.591210: train_loss -0.7506\n",
      "2024-12-05 20:57:22.601210: val_loss -0.5275\n",
      "2024-12-05 20:57:22.601210: Pseudo dice [0.7693]\n",
      "2024-12-05 20:57:22.611210: Epoch time: 130.73 s\n",
      "2024-12-05 20:57:23.641226: \n",
      "2024-12-05 20:57:23.641226: Epoch 448\n",
      "2024-12-05 20:57:23.651225: Current learning rate: 0.00586\n",
      "2024-12-05 20:59:34.371605: train_loss -0.7663\n",
      "2024-12-05 20:59:34.391606: val_loss -0.4461\n",
      "2024-12-05 20:59:34.391606: Pseudo dice [0.8185]\n",
      "2024-12-05 20:59:34.401606: Epoch time: 130.74 s\n",
      "2024-12-05 20:59:35.431621: \n",
      "2024-12-05 20:59:35.431621: Epoch 449\n",
      "2024-12-05 20:59:35.441622: Current learning rate: 0.00585\n",
      "2024-12-05 21:01:46.254830: train_loss -0.7738\n",
      "2024-12-05 21:01:46.264830: val_loss -0.3744\n",
      "2024-12-05 21:01:46.274831: Pseudo dice [0.7907]\n",
      "2024-12-05 21:01:46.284831: Epoch time: 130.82 s\n",
      "2024-12-05 21:01:47.554850: \n",
      "2024-12-05 21:01:47.564849: Epoch 450\n",
      "2024-12-05 21:01:47.574849: Current learning rate: 0.00584\n",
      "2024-12-05 21:03:58.295605: train_loss -0.7771\n",
      "2024-12-05 21:03:58.305605: val_loss 0.0709\n",
      "2024-12-05 21:03:58.305605: Pseudo dice [0.4644]\n",
      "2024-12-05 21:03:58.315605: Epoch time: 130.74 s\n",
      "2024-12-05 21:03:59.345908: \n",
      "2024-12-05 21:03:59.345908: Epoch 451\n",
      "2024-12-05 21:03:59.355906: Current learning rate: 0.00583\n",
      "2024-12-05 21:06:10.165607: train_loss -0.7609\n",
      "2024-12-05 21:06:10.175607: val_loss -0.0918\n",
      "2024-12-05 21:06:10.185607: Pseudo dice [0.5433]\n",
      "2024-12-05 21:06:10.195607: Epoch time: 130.82 s\n",
      "2024-12-05 21:06:11.216371: \n",
      "2024-12-05 21:06:11.226371: Epoch 452\n",
      "2024-12-05 21:06:11.226371: Current learning rate: 0.00582\n",
      "2024-12-05 21:08:21.976068: train_loss -0.8011\n",
      "2024-12-05 21:08:21.976068: val_loss -0.4845\n",
      "2024-12-05 21:08:21.986068: Pseudo dice [0.7717]\n",
      "2024-12-05 21:08:21.996068: Epoch time: 130.76 s\n",
      "2024-12-05 21:08:23.026084: \n",
      "2024-12-05 21:08:23.026084: Epoch 453\n",
      "2024-12-05 21:08:23.036084: Current learning rate: 0.00581\n",
      "2024-12-05 21:10:33.754320: train_loss -0.7853\n",
      "2024-12-05 21:10:33.764321: val_loss -0.5584\n",
      "2024-12-05 21:10:33.774321: Pseudo dice [0.8445]\n",
      "2024-12-05 21:10:33.784322: Epoch time: 130.73 s\n",
      "2024-12-05 21:10:34.994620: \n",
      "2024-12-05 21:10:34.994620: Epoch 454\n",
      "2024-12-05 21:10:35.004620: Current learning rate: 0.0058\n",
      "2024-12-05 21:12:45.802711: train_loss -0.7993\n",
      "2024-12-05 21:12:45.812711: val_loss -0.3013\n",
      "2024-12-05 21:12:45.822711: Pseudo dice [0.7179]\n",
      "2024-12-05 21:12:45.832711: Epoch time: 130.82 s\n",
      "2024-12-05 21:12:46.843609: \n",
      "2024-12-05 21:12:46.853609: Epoch 455\n",
      "2024-12-05 21:12:46.853609: Current learning rate: 0.00579\n",
      "2024-12-05 21:14:57.642010: train_loss -0.7823\n",
      "2024-12-05 21:14:57.652009: val_loss -0.5254\n",
      "2024-12-05 21:14:57.652009: Pseudo dice [0.7302]\n",
      "2024-12-05 21:14:57.662010: Epoch time: 130.8 s\n",
      "2024-12-05 21:14:58.682025: \n",
      "2024-12-05 21:14:58.692025: Epoch 456\n",
      "2024-12-05 21:14:58.702025: Current learning rate: 0.00578\n",
      "2024-12-05 21:17:09.409163: train_loss -0.6783\n",
      "2024-12-05 21:17:09.419163: val_loss -0.0883\n",
      "2024-12-05 21:17:09.419163: Pseudo dice [0.5978]\n",
      "2024-12-05 21:17:09.429162: Epoch time: 130.73 s\n",
      "2024-12-05 21:17:10.459177: \n",
      "2024-12-05 21:17:10.469177: Epoch 457\n",
      "2024-12-05 21:17:10.469177: Current learning rate: 0.00577\n",
      "2024-12-05 21:19:21.264580: train_loss -0.7408\n",
      "2024-12-05 21:19:21.274580: val_loss -0.264\n",
      "2024-12-05 21:19:21.284580: Pseudo dice [0.6426]\n",
      "2024-12-05 21:19:21.294581: Epoch time: 130.81 s\n",
      "2024-12-05 21:19:22.315087: \n",
      "2024-12-05 21:19:22.325086: Epoch 458\n",
      "2024-12-05 21:19:22.335086: Current learning rate: 0.00576\n",
      "2024-12-05 21:21:33.076079: train_loss -0.7789\n",
      "2024-12-05 21:21:33.086079: val_loss -0.4103\n",
      "2024-12-05 21:21:33.096079: Pseudo dice [0.7666]\n",
      "2024-12-05 21:21:33.096079: Epoch time: 130.76 s\n",
      "2024-12-05 21:21:34.126095: \n",
      "2024-12-05 21:21:34.126095: Epoch 459\n",
      "2024-12-05 21:21:34.136095: Current learning rate: 0.00575\n",
      "2024-12-05 21:23:44.858756: train_loss -0.7999\n",
      "2024-12-05 21:23:44.868757: val_loss -0.4783\n",
      "2024-12-05 21:23:44.868757: Pseudo dice [0.7891]\n",
      "2024-12-05 21:23:44.878756: Epoch time: 130.73 s\n",
      "2024-12-05 21:23:45.898771: \n",
      "2024-12-05 21:23:45.908772: Epoch 460\n",
      "2024-12-05 21:23:45.918771: Current learning rate: 0.00574\n",
      "2024-12-05 21:25:56.616121: train_loss -0.7815\n",
      "2024-12-05 21:25:56.626122: val_loss -0.4073\n",
      "2024-12-05 21:25:56.636122: Pseudo dice [0.7572]\n",
      "2024-12-05 21:25:56.636122: Epoch time: 130.72 s\n",
      "2024-12-05 21:25:57.656178: \n",
      "2024-12-05 21:25:57.666178: Epoch 461\n",
      "2024-12-05 21:25:57.676178: Current learning rate: 0.00573\n",
      "2024-12-05 21:28:08.350643: train_loss -0.7715\n",
      "2024-12-05 21:28:08.360643: val_loss -0.4866\n",
      "2024-12-05 21:28:08.360643: Pseudo dice [0.794]\n",
      "2024-12-05 21:28:08.370642: Epoch time: 130.69 s\n",
      "2024-12-05 21:28:09.580951: \n",
      "2024-12-05 21:28:09.590950: Epoch 462\n",
      "2024-12-05 21:28:09.590950: Current learning rate: 0.00572\n",
      "2024-12-05 21:30:20.309752: train_loss -0.7902\n",
      "2024-12-05 21:30:20.319752: val_loss -0.0313\n",
      "2024-12-05 21:30:20.329752: Pseudo dice [0.5385]\n",
      "2024-12-05 21:30:20.339752: Epoch time: 130.73 s\n",
      "2024-12-05 21:30:21.349767: \n",
      "2024-12-05 21:30:21.359767: Epoch 463\n",
      "2024-12-05 21:30:21.359767: Current learning rate: 0.00571\n",
      "2024-12-05 21:32:32.098570: train_loss -0.7858\n",
      "2024-12-05 21:32:32.108570: val_loss -0.0151\n",
      "2024-12-05 21:32:32.118571: Pseudo dice [0.4769]\n",
      "2024-12-05 21:32:32.131830: Epoch time: 130.75 s\n",
      "2024-12-05 21:32:33.159584: \n",
      "2024-12-05 21:32:33.159584: Epoch 464\n",
      "2024-12-05 21:32:33.169585: Current learning rate: 0.0057\n",
      "2024-12-05 21:34:43.926386: train_loss -0.7296\n",
      "2024-12-05 21:34:43.936385: val_loss -0.523\n",
      "2024-12-05 21:34:43.956386: Pseudo dice [0.805]\n",
      "2024-12-05 21:34:43.956386: Epoch time: 130.77 s\n",
      "2024-12-05 21:34:44.976699: \n",
      "2024-12-05 21:34:44.986701: Epoch 465\n",
      "2024-12-05 21:34:44.986701: Current learning rate: 0.0057\n",
      "2024-12-05 21:36:55.638076: train_loss -0.7944\n",
      "2024-12-05 21:36:55.648076: val_loss -0.3948\n",
      "2024-12-05 21:36:55.658077: Pseudo dice [0.7933]\n",
      "2024-12-05 21:36:55.668077: Epoch time: 130.66 s\n",
      "2024-12-05 21:36:56.698092: \n",
      "2024-12-05 21:36:56.708093: Epoch 466\n",
      "2024-12-05 21:36:56.708093: Current learning rate: 0.00569\n",
      "2024-12-05 21:39:07.414733: train_loss -0.8084\n",
      "2024-12-05 21:39:07.424733: val_loss -0.3536\n",
      "2024-12-05 21:39:07.434733: Pseudo dice [0.7231]\n",
      "2024-12-05 21:39:07.434733: Epoch time: 130.72 s\n",
      "2024-12-05 21:39:08.464752: \n",
      "2024-12-05 21:39:08.464752: Epoch 467\n",
      "2024-12-05 21:39:08.474748: Current learning rate: 0.00568\n",
      "2024-12-05 21:41:19.174239: train_loss -0.7734\n",
      "2024-12-05 21:41:19.194239: val_loss -0.4062\n",
      "2024-12-05 21:41:19.194239: Pseudo dice [0.7233]\n",
      "2024-12-05 21:41:19.204239: Epoch time: 130.71 s\n",
      "2024-12-05 21:41:20.224557: \n",
      "2024-12-05 21:41:20.224557: Epoch 468\n",
      "2024-12-05 21:41:20.234557: Current learning rate: 0.00567\n",
      "2024-12-05 21:43:30.912269: train_loss -0.8166\n",
      "2024-12-05 21:43:30.922269: val_loss -0.5137\n",
      "2024-12-05 21:43:30.922269: Pseudo dice [0.7686]\n",
      "2024-12-05 21:43:30.932270: Epoch time: 130.69 s\n",
      "2024-12-05 21:43:32.122288: \n",
      "2024-12-05 21:43:32.132288: Epoch 469\n",
      "2024-12-05 21:43:32.132288: Current learning rate: 0.00566\n",
      "2024-12-05 21:45:42.875951: train_loss -0.7949\n",
      "2024-12-05 21:45:42.885952: val_loss -0.3921\n",
      "2024-12-05 21:45:42.895952: Pseudo dice [0.7606]\n",
      "2024-12-05 21:45:42.895952: Epoch time: 130.75 s\n",
      "2024-12-05 21:45:43.925967: \n",
      "2024-12-05 21:45:43.935966: Epoch 470\n",
      "2024-12-05 21:45:43.935966: Current learning rate: 0.00565\n",
      "2024-12-05 21:47:54.676254: train_loss -0.8005\n",
      "2024-12-05 21:47:54.686254: val_loss -0.504\n",
      "2024-12-05 21:47:54.686254: Pseudo dice [0.8066]\n",
      "2024-12-05 21:47:54.696255: Epoch time: 130.75 s\n",
      "2024-12-05 21:47:55.726273: \n",
      "2024-12-05 21:47:55.726273: Epoch 471\n",
      "2024-12-05 21:47:55.736270: Current learning rate: 0.00564\n",
      "2024-12-05 21:50:06.395038: train_loss -0.805\n",
      "2024-12-05 21:50:06.405038: val_loss -0.3015\n",
      "2024-12-05 21:50:06.415039: Pseudo dice [0.7448]\n",
      "2024-12-05 21:50:06.425039: Epoch time: 130.68 s\n",
      "2024-12-05 21:50:07.445054: \n",
      "2024-12-05 21:50:07.455054: Epoch 472\n",
      "2024-12-05 21:50:07.455054: Current learning rate: 0.00563\n",
      "2024-12-05 21:52:18.195031: train_loss -0.7884\n",
      "2024-12-05 21:52:18.205031: val_loss -0.4674\n",
      "2024-12-05 21:52:18.215030: Pseudo dice [0.7927]\n",
      "2024-12-05 21:52:18.215030: Epoch time: 130.75 s\n",
      "2024-12-05 21:52:19.245045: \n",
      "2024-12-05 21:52:19.255045: Epoch 473\n",
      "2024-12-05 21:52:19.255045: Current learning rate: 0.00562\n",
      "2024-12-05 21:54:29.879905: train_loss -0.7878\n",
      "2024-12-05 21:54:29.889904: val_loss -0.2319\n",
      "2024-12-05 21:54:29.899905: Pseudo dice [0.7605]\n",
      "2024-12-05 21:54:29.899905: Epoch time: 130.63 s\n",
      "2024-12-05 21:54:30.920201: \n",
      "2024-12-05 21:54:30.930201: Epoch 474\n",
      "2024-12-05 21:54:30.940200: Current learning rate: 0.00561\n",
      "2024-12-05 21:56:41.648517: train_loss -0.7957\n",
      "2024-12-05 21:56:41.658516: val_loss -0.3889\n",
      "2024-12-05 21:56:41.668516: Pseudo dice [0.8036]\n",
      "2024-12-05 21:56:41.668516: Epoch time: 130.73 s\n",
      "2024-12-05 21:56:42.699327: \n",
      "2024-12-05 21:56:42.699327: Epoch 475\n",
      "2024-12-05 21:56:42.709325: Current learning rate: 0.0056\n",
      "2024-12-05 21:58:53.425669: train_loss -0.7825\n",
      "2024-12-05 21:58:53.435669: val_loss -0.1606\n",
      "2024-12-05 21:58:53.445668: Pseudo dice [0.6493]\n",
      "2024-12-05 21:58:53.445668: Epoch time: 130.73 s\n",
      "2024-12-05 21:58:54.465972: \n",
      "2024-12-05 21:58:54.475972: Epoch 476\n",
      "2024-12-05 21:58:54.485972: Current learning rate: 0.00559\n",
      "2024-12-05 22:01:05.165044: train_loss -0.7786\n",
      "2024-12-05 22:01:05.175045: val_loss -0.3486\n",
      "2024-12-05 22:01:05.175045: Pseudo dice [0.7165]\n",
      "2024-12-05 22:01:05.185045: Epoch time: 130.7 s\n",
      "2024-12-05 22:01:06.385345: \n",
      "2024-12-05 22:01:06.395345: Epoch 477\n",
      "2024-12-05 22:01:06.395345: Current learning rate: 0.00558\n",
      "2024-12-05 22:03:17.126209: train_loss -0.7885\n",
      "2024-12-05 22:03:17.146209: val_loss -0.1046\n",
      "2024-12-05 22:03:17.146209: Pseudo dice [0.5473]\n",
      "2024-12-05 22:03:17.156211: Epoch time: 130.74 s\n",
      "2024-12-05 22:03:18.196224: \n",
      "2024-12-05 22:03:18.206224: Epoch 478\n",
      "2024-12-05 22:03:18.216224: Current learning rate: 0.00557\n",
      "2024-12-05 22:05:28.963354: train_loss -0.757\n",
      "2024-12-05 22:05:28.963354: val_loss -0.2185\n",
      "2024-12-05 22:05:28.973353: Pseudo dice [0.6038]\n",
      "2024-12-05 22:05:28.983355: Epoch time: 130.77 s\n",
      "2024-12-05 22:05:30.033670: \n",
      "2024-12-05 22:05:30.043668: Epoch 479\n",
      "2024-12-05 22:05:30.043668: Current learning rate: 0.00556\n",
      "2024-12-05 22:07:40.695340: train_loss -0.7886\n",
      "2024-12-05 22:07:40.705340: val_loss -0.4068\n",
      "2024-12-05 22:07:40.715340: Pseudo dice [0.6235]\n",
      "2024-12-05 22:07:40.725340: Epoch time: 130.66 s\n",
      "2024-12-05 22:07:41.766280: \n",
      "2024-12-05 22:07:41.766280: Epoch 480\n",
      "2024-12-05 22:07:41.776277: Current learning rate: 0.00555\n",
      "2024-12-05 22:09:52.482830: train_loss -0.7741\n",
      "2024-12-05 22:09:52.492830: val_loss -0.3784\n",
      "2024-12-05 22:09:52.492830: Pseudo dice [0.7206]\n",
      "2024-12-05 22:09:52.502830: Epoch time: 130.73 s\n",
      "2024-12-05 22:09:53.542845: \n",
      "2024-12-05 22:09:53.542845: Epoch 481\n",
      "2024-12-05 22:09:53.552845: Current learning rate: 0.00554\n",
      "2024-12-05 22:12:04.223197: train_loss -0.7786\n",
      "2024-12-05 22:12:04.233196: val_loss -0.2107\n",
      "2024-12-05 22:12:04.243196: Pseudo dice [0.6511]\n",
      "2024-12-05 22:12:04.253197: Epoch time: 130.68 s\n",
      "2024-12-05 22:12:05.293511: \n",
      "2024-12-05 22:12:05.303513: Epoch 482\n",
      "2024-12-05 22:12:05.303513: Current learning rate: 0.00553\n",
      "2024-12-05 22:14:16.042413: train_loss -0.7954\n",
      "2024-12-05 22:14:16.052413: val_loss -0.5482\n",
      "2024-12-05 22:14:16.062413: Pseudo dice [0.8142]\n",
      "2024-12-05 22:14:16.062413: Epoch time: 130.75 s\n",
      "2024-12-05 22:14:17.112429: \n",
      "2024-12-05 22:14:17.112429: Epoch 483\n",
      "2024-12-05 22:14:17.122430: Current learning rate: 0.00552\n",
      "2024-12-05 22:16:27.920719: train_loss -0.8042\n",
      "2024-12-05 22:16:27.930719: val_loss -0.2516\n",
      "2024-12-05 22:16:27.940719: Pseudo dice [0.65]\n",
      "2024-12-05 22:16:27.950719: Epoch time: 130.82 s\n",
      "2024-12-05 22:16:29.160738: \n",
      "2024-12-05 22:16:29.170737: Epoch 484\n",
      "2024-12-05 22:16:29.170737: Current learning rate: 0.00551\n",
      "2024-12-05 22:18:39.873198: train_loss -0.7778\n",
      "2024-12-05 22:18:39.883198: val_loss -0.3524\n",
      "2024-12-05 22:18:39.883198: Pseudo dice [0.7518]\n",
      "2024-12-05 22:18:39.893199: Epoch time: 130.71 s\n",
      "2024-12-05 22:18:40.933214: \n",
      "2024-12-05 22:18:40.943214: Epoch 485\n",
      "2024-12-05 22:18:40.943214: Current learning rate: 0.0055\n",
      "2024-12-05 22:20:51.653595: train_loss -0.801\n",
      "2024-12-05 22:20:51.663594: val_loss -0.4229\n",
      "2024-12-05 22:20:51.663594: Pseudo dice [0.6484]\n",
      "2024-12-05 22:20:51.673594: Epoch time: 130.72 s\n",
      "2024-12-05 22:20:52.713610: \n",
      "2024-12-05 22:20:52.713610: Epoch 486\n",
      "2024-12-05 22:20:52.723610: Current learning rate: 0.00549\n",
      "2024-12-05 22:23:03.432219: train_loss -0.7746\n",
      "2024-12-05 22:23:03.442219: val_loss -0.5152\n",
      "2024-12-05 22:23:03.442219: Pseudo dice [0.8561]\n",
      "2024-12-05 22:23:03.452219: Epoch time: 130.72 s\n",
      "2024-12-05 22:23:04.492235: \n",
      "2024-12-05 22:23:04.502235: Epoch 487\n",
      "2024-12-05 22:23:04.502235: Current learning rate: 0.00548\n",
      "2024-12-05 22:25:15.231778: train_loss -0.7754\n",
      "2024-12-05 22:25:15.241777: val_loss -0.449\n",
      "2024-12-05 22:25:15.251779: Pseudo dice [0.7799]\n",
      "2024-12-05 22:25:15.251779: Epoch time: 130.74 s\n",
      "2024-12-05 22:25:16.301794: \n",
      "2024-12-05 22:25:16.301794: Epoch 488\n",
      "2024-12-05 22:25:16.311793: Current learning rate: 0.00547\n",
      "2024-12-05 22:27:27.045942: train_loss -0.7692\n",
      "2024-12-05 22:27:27.055941: val_loss -0.3577\n",
      "2024-12-05 22:27:27.065941: Pseudo dice [0.7347]\n",
      "2024-12-05 22:27:27.075942: Epoch time: 130.75 s\n",
      "2024-12-05 22:27:28.126795: \n",
      "2024-12-05 22:27:28.136795: Epoch 489\n",
      "2024-12-05 22:27:28.136795: Current learning rate: 0.00546\n",
      "2024-12-05 22:29:38.832592: train_loss -0.8011\n",
      "2024-12-05 22:29:38.842592: val_loss -0.542\n",
      "2024-12-05 22:29:38.852593: Pseudo dice [0.805]\n",
      "2024-12-05 22:29:38.852593: Epoch time: 130.71 s\n",
      "2024-12-05 22:29:39.892608: \n",
      "2024-12-05 22:29:39.902608: Epoch 490\n",
      "2024-12-05 22:29:39.902608: Current learning rate: 0.00546\n",
      "2024-12-05 22:31:50.564250: train_loss -0.797\n",
      "2024-12-05 22:31:50.574251: val_loss -0.0044\n",
      "2024-12-05 22:31:50.645270: Pseudo dice [0.3944]\n",
      "2024-12-05 22:31:50.645270: Epoch time: 130.67 s\n",
      "2024-12-05 22:31:51.875290: \n",
      "2024-12-05 22:31:51.875290: Epoch 491\n",
      "2024-12-05 22:31:51.885290: Current learning rate: 0.00545\n",
      "2024-12-05 22:34:02.575284: train_loss -0.8012\n",
      "2024-12-05 22:34:02.585285: val_loss -0.2618\n",
      "2024-12-05 22:34:02.595285: Pseudo dice [0.6463]\n",
      "2024-12-05 22:34:02.605286: Epoch time: 130.71 s\n",
      "2024-12-05 22:34:03.645301: \n",
      "2024-12-05 22:34:03.655301: Epoch 492\n",
      "2024-12-05 22:34:03.655301: Current learning rate: 0.00544\n",
      "2024-12-05 22:36:14.341293: train_loss -0.8124\n",
      "2024-12-05 22:36:14.351293: val_loss -0.3272\n",
      "2024-12-05 22:36:14.361294: Pseudo dice [0.7522]\n",
      "2024-12-05 22:36:14.361294: Epoch time: 130.7 s\n",
      "2024-12-05 22:36:15.401310: \n",
      "2024-12-05 22:36:15.411310: Epoch 493\n",
      "2024-12-05 22:36:15.421310: Current learning rate: 0.00543\n",
      "2024-12-05 22:38:26.134211: train_loss -0.7565\n",
      "2024-12-05 22:38:26.134211: val_loss -0.435\n",
      "2024-12-05 22:38:26.144210: Pseudo dice [0.764]\n",
      "2024-12-05 22:38:26.154211: Epoch time: 130.73 s\n",
      "2024-12-05 22:38:27.205117: \n",
      "2024-12-05 22:38:27.215116: Epoch 494\n",
      "2024-12-05 22:38:27.215116: Current learning rate: 0.00542\n",
      "2024-12-05 22:40:38.012786: train_loss -0.7996\n",
      "2024-12-05 22:40:38.032786: val_loss -0.2818\n",
      "2024-12-05 22:40:38.032786: Pseudo dice [0.7239]\n",
      "2024-12-05 22:40:38.042787: Epoch time: 130.81 s\n",
      "2024-12-05 22:40:39.083084: \n",
      "2024-12-05 22:40:39.093084: Epoch 495\n",
      "2024-12-05 22:40:39.093084: Current learning rate: 0.00541\n",
      "2024-12-05 22:42:49.829333: train_loss -0.8021\n",
      "2024-12-05 22:42:49.849333: val_loss -0.1546\n",
      "2024-12-05 22:42:49.859333: Pseudo dice [0.4691]\n",
      "2024-12-05 22:42:49.859333: Epoch time: 130.75 s\n",
      "2024-12-05 22:42:50.909348: \n",
      "2024-12-05 22:42:50.919349: Epoch 496\n",
      "2024-12-05 22:42:50.919349: Current learning rate: 0.0054\n",
      "2024-12-05 22:45:01.682624: train_loss -0.8201\n",
      "2024-12-05 22:45:01.692624: val_loss -0.4301\n",
      "2024-12-05 22:45:01.702625: Pseudo dice [0.8051]\n",
      "2024-12-05 22:45:01.712624: Epoch time: 130.77 s\n",
      "2024-12-05 22:45:02.763527: \n",
      "2024-12-05 22:45:02.773526: Epoch 497\n",
      "2024-12-05 22:45:02.773526: Current learning rate: 0.00539\n",
      "2024-12-05 22:47:13.472319: train_loss -0.8069\n",
      "2024-12-05 22:47:13.492318: val_loss -0.3073\n",
      "2024-12-05 22:47:13.492318: Pseudo dice [0.7117]\n",
      "2024-12-05 22:47:13.502319: Epoch time: 130.71 s\n",
      "2024-12-05 22:47:14.552335: \n",
      "2024-12-05 22:47:14.562335: Epoch 498\n",
      "2024-12-05 22:47:14.562335: Current learning rate: 0.00538\n",
      "2024-12-05 22:49:25.252190: train_loss -0.8091\n",
      "2024-12-05 22:49:25.262191: val_loss -0.3142\n",
      "2024-12-05 22:49:25.262191: Pseudo dice [0.6127]\n",
      "2024-12-05 22:49:25.272191: Epoch time: 130.7 s\n",
      "2024-12-05 22:49:26.492209: \n",
      "2024-12-05 22:49:26.502210: Epoch 499\n",
      "2024-12-05 22:49:26.502210: Current learning rate: 0.00537\n",
      "2024-12-05 22:51:37.198586: train_loss -0.7943\n",
      "2024-12-05 22:51:37.208585: val_loss -0.4945\n",
      "2024-12-05 22:51:37.218585: Pseudo dice [0.7688]\n",
      "2024-12-05 22:51:37.228585: Epoch time: 130.71 s\n",
      "2024-12-05 22:51:38.518604: \n",
      "2024-12-05 22:51:38.528605: Epoch 500\n",
      "2024-12-05 22:51:38.528605: Current learning rate: 0.00536\n",
      "2024-12-05 22:53:49.346519: train_loss -0.826\n",
      "2024-12-05 22:53:49.356519: val_loss -0.4259\n",
      "2024-12-05 22:53:49.356519: Pseudo dice [0.7432]\n",
      "2024-12-05 22:53:49.366519: Epoch time: 130.83 s\n",
      "2024-12-05 22:53:50.406535: \n",
      "2024-12-05 22:53:50.416536: Epoch 501\n",
      "2024-12-05 22:53:50.416536: Current learning rate: 0.00535\n",
      "2024-12-05 22:56:01.104810: train_loss -0.8331\n",
      "2024-12-05 22:56:01.114810: val_loss -0.4508\n",
      "2024-12-05 22:56:01.114810: Pseudo dice [0.6919]\n",
      "2024-12-05 22:56:01.124810: Epoch time: 130.7 s\n",
      "2024-12-05 22:56:02.174834: \n",
      "2024-12-05 22:56:02.184833: Epoch 502\n",
      "2024-12-05 22:56:02.184833: Current learning rate: 0.00534\n",
      "2024-12-05 22:58:12.905077: train_loss -0.8253\n",
      "2024-12-05 22:58:12.915076: val_loss -0.5373\n",
      "2024-12-05 22:58:12.925077: Pseudo dice [0.8349]\n",
      "2024-12-05 22:58:12.925077: Epoch time: 130.73 s\n",
      "2024-12-05 22:58:13.975092: \n",
      "2024-12-05 22:58:13.985092: Epoch 503\n",
      "2024-12-05 22:58:13.985092: Current learning rate: 0.00533\n",
      "2024-12-05 23:00:24.772071: train_loss -0.8061\n",
      "2024-12-05 23:00:24.782071: val_loss -0.2727\n",
      "2024-12-05 23:00:24.782071: Pseudo dice [0.6693]\n",
      "2024-12-05 23:00:24.792071: Epoch time: 130.8 s\n",
      "2024-12-05 23:00:25.832088: \n",
      "2024-12-05 23:00:25.842088: Epoch 504\n",
      "2024-12-05 23:00:25.842088: Current learning rate: 0.00532\n",
      "2024-12-05 23:02:36.589586: train_loss -0.8292\n",
      "2024-12-05 23:02:36.599588: val_loss -0.3883\n",
      "2024-12-05 23:02:36.609588: Pseudo dice [0.7153]\n",
      "2024-12-05 23:02:36.619589: Epoch time: 130.76 s\n",
      "2024-12-05 23:02:37.659605: \n",
      "2024-12-05 23:02:37.669604: Epoch 505\n",
      "2024-12-05 23:02:37.669604: Current learning rate: 0.00531\n",
      "2024-12-05 23:04:48.327179: train_loss -0.8033\n",
      "2024-12-05 23:04:48.337180: val_loss -0.3759\n",
      "2024-12-05 23:04:48.347180: Pseudo dice [0.6871]\n",
      "2024-12-05 23:04:48.347180: Epoch time: 130.67 s\n",
      "2024-12-05 23:04:49.567207: \n",
      "2024-12-05 23:04:49.577198: Epoch 506\n",
      "2024-12-05 23:04:49.577198: Current learning rate: 0.0053\n",
      "2024-12-05 23:07:00.355772: train_loss -0.7968\n",
      "2024-12-05 23:07:00.365772: val_loss -0.473\n",
      "2024-12-05 23:07:00.375772: Pseudo dice [0.8025]\n",
      "2024-12-05 23:07:00.375772: Epoch time: 130.79 s\n",
      "2024-12-05 23:07:01.466652: \n",
      "2024-12-05 23:07:01.476652: Epoch 507\n",
      "2024-12-05 23:07:01.486652: Current learning rate: 0.00529\n",
      "2024-12-05 23:09:12.202437: train_loss -0.7932\n",
      "2024-12-05 23:09:12.212437: val_loss -0.5668\n",
      "2024-12-05 23:09:12.222437: Pseudo dice [0.8532]\n",
      "2024-12-05 23:09:12.222437: Epoch time: 130.74 s\n",
      "2024-12-05 23:09:13.272750: \n",
      "2024-12-05 23:09:13.282741: Epoch 508\n",
      "2024-12-05 23:09:13.282741: Current learning rate: 0.00528\n",
      "2024-12-05 23:11:24.110507: train_loss -0.8173\n",
      "2024-12-05 23:11:24.120507: val_loss -0.4467\n",
      "2024-12-05 23:11:24.130507: Pseudo dice [0.786]\n",
      "2024-12-05 23:11:24.130507: Epoch time: 130.84 s\n",
      "2024-12-05 23:11:25.171301: \n",
      "2024-12-05 23:11:25.181302: Epoch 509\n",
      "2024-12-05 23:11:25.191302: Current learning rate: 0.00527\n",
      "2024-12-05 23:13:35.930144: train_loss -0.8088\n",
      "2024-12-05 23:13:35.940145: val_loss -0.5004\n",
      "2024-12-05 23:13:35.950145: Pseudo dice [0.8064]\n",
      "2024-12-05 23:13:35.950145: Epoch time: 130.76 s\n",
      "2024-12-05 23:13:37.000289: \n",
      "2024-12-05 23:13:37.000289: Epoch 510\n",
      "2024-12-05 23:13:37.010289: Current learning rate: 0.00526\n",
      "2024-12-05 23:15:47.755774: train_loss -0.8295\n",
      "2024-12-05 23:15:47.765774: val_loss -0.3993\n",
      "2024-12-05 23:15:47.775774: Pseudo dice [0.7405]\n",
      "2024-12-05 23:15:47.785775: Epoch time: 130.76 s\n",
      "2024-12-05 23:15:48.825791: \n",
      "2024-12-05 23:15:48.835790: Epoch 511\n",
      "2024-12-05 23:15:48.835790: Current learning rate: 0.00525\n",
      "2024-12-05 23:17:59.633154: train_loss -0.8331\n",
      "2024-12-05 23:17:59.643154: val_loss -0.445\n",
      "2024-12-05 23:17:59.653154: Pseudo dice [0.7174]\n",
      "2024-12-05 23:17:59.663155: Epoch time: 130.81 s\n",
      "2024-12-05 23:18:00.703170: \n",
      "2024-12-05 23:18:00.713170: Epoch 512\n",
      "2024-12-05 23:18:00.713170: Current learning rate: 0.00524\n",
      "2024-12-05 23:20:11.509517: train_loss -0.8367\n",
      "2024-12-05 23:20:11.519518: val_loss -0.3215\n",
      "2024-12-05 23:20:11.529517: Pseudo dice [0.76]\n",
      "2024-12-05 23:20:11.529517: Epoch time: 130.81 s\n",
      "2024-12-05 23:20:12.760401: \n",
      "2024-12-05 23:20:12.760401: Epoch 513\n",
      "2024-12-05 23:20:12.770397: Current learning rate: 0.00523\n",
      "2024-12-05 23:22:23.498653: train_loss -0.8313\n",
      "2024-12-05 23:22:23.508654: val_loss -0.3411\n",
      "2024-12-05 23:22:23.518655: Pseudo dice [0.752]\n",
      "2024-12-05 23:22:23.518655: Epoch time: 130.74 s\n",
      "2024-12-05 23:22:24.578957: \n",
      "2024-12-05 23:22:24.578957: Epoch 514\n",
      "2024-12-05 23:22:24.588959: Current learning rate: 0.00522\n",
      "2024-12-05 23:24:35.395323: train_loss -0.8245\n",
      "2024-12-05 23:24:35.405324: val_loss -0.4645\n",
      "2024-12-05 23:24:35.415324: Pseudo dice [0.817]\n",
      "2024-12-05 23:24:35.415324: Epoch time: 130.82 s\n",
      "2024-12-05 23:24:36.465423: \n",
      "2024-12-05 23:24:36.468465: Epoch 515\n",
      "2024-12-05 23:24:36.475469: Current learning rate: 0.00521\n",
      "2024-12-05 23:26:47.252813: train_loss -0.8176\n",
      "2024-12-05 23:26:47.262813: val_loss -0.5016\n",
      "2024-12-05 23:26:47.272813: Pseudo dice [0.8335]\n",
      "2024-12-05 23:26:47.282813: Epoch time: 130.79 s\n",
      "2024-12-05 23:26:47.282813: Yayy! New best EMA pseudo Dice: 0.759\n",
      "2024-12-05 23:26:48.583522: \n",
      "2024-12-05 23:26:48.593522: Epoch 516\n",
      "2024-12-05 23:26:48.593522: Current learning rate: 0.0052\n",
      "2024-12-05 23:28:59.469940: train_loss -0.8097\n",
      "2024-12-05 23:28:59.479939: val_loss -0.2847\n",
      "2024-12-05 23:28:59.479939: Pseudo dice [0.7335]\n",
      "2024-12-05 23:28:59.489939: Epoch time: 130.89 s\n",
      "2024-12-05 23:29:00.539955: \n",
      "2024-12-05 23:29:00.539955: Epoch 517\n",
      "2024-12-05 23:29:00.549955: Current learning rate: 0.00519\n",
      "2024-12-05 23:31:11.336543: train_loss -0.828\n",
      "2024-12-05 23:31:11.346545: val_loss -0.1357\n",
      "2024-12-05 23:31:11.346545: Pseudo dice [0.6649]\n",
      "2024-12-05 23:31:11.356544: Epoch time: 130.8 s\n",
      "2024-12-05 23:31:12.396559: \n",
      "2024-12-05 23:31:12.411820: Epoch 518\n",
      "2024-12-05 23:31:12.416850: Current learning rate: 0.00518\n",
      "2024-12-05 23:33:23.174642: train_loss -0.8396\n",
      "2024-12-05 23:33:23.184642: val_loss -0.4444\n",
      "2024-12-05 23:33:23.184642: Pseudo dice [0.8126]\n",
      "2024-12-05 23:33:23.194643: Epoch time: 130.78 s\n",
      "2024-12-05 23:33:24.244658: \n",
      "2024-12-05 23:33:24.244658: Epoch 519\n",
      "2024-12-05 23:33:24.254658: Current learning rate: 0.00518\n",
      "2024-12-05 23:35:34.958488: train_loss -0.8177\n",
      "2024-12-05 23:35:34.968488: val_loss -0.1682\n",
      "2024-12-05 23:35:34.978495: Pseudo dice [0.5231]\n",
      "2024-12-05 23:35:34.978495: Epoch time: 130.72 s\n",
      "2024-12-05 23:35:36.208524: \n",
      "2024-12-05 23:35:36.218515: Epoch 520\n",
      "2024-12-05 23:35:36.218515: Current learning rate: 0.00517\n",
      "2024-12-05 23:37:47.056309: train_loss -0.8173\n",
      "2024-12-05 23:37:47.066309: val_loss -0.4206\n",
      "2024-12-05 23:37:47.066309: Pseudo dice [0.7869]\n",
      "2024-12-05 23:37:47.076309: Epoch time: 130.85 s\n",
      "2024-12-05 23:37:48.116325: \n",
      "2024-12-05 23:37:48.126326: Epoch 521\n",
      "2024-12-05 23:37:48.126326: Current learning rate: 0.00516\n",
      "2024-12-05 23:39:58.902032: train_loss -0.7905\n",
      "2024-12-05 23:39:58.912032: val_loss -0.3343\n",
      "2024-12-05 23:39:58.922032: Pseudo dice [0.6692]\n",
      "2024-12-05 23:39:58.922032: Epoch time: 130.79 s\n",
      "2024-12-05 23:39:59.972047: \n",
      "2024-12-05 23:39:59.982048: Epoch 522\n",
      "2024-12-05 23:39:59.982048: Current learning rate: 0.00515\n",
      "2024-12-05 23:42:10.789385: train_loss -0.8116\n",
      "2024-12-05 23:42:10.799385: val_loss -0.4168\n",
      "2024-12-05 23:42:10.799385: Pseudo dice [0.7714]\n",
      "2024-12-05 23:42:10.809385: Epoch time: 130.82 s\n",
      "2024-12-05 23:42:11.859400: \n",
      "2024-12-05 23:42:11.869401: Epoch 523\n",
      "2024-12-05 23:42:11.869401: Current learning rate: 0.00514\n",
      "2024-12-05 23:44:22.680244: train_loss -0.8304\n",
      "2024-12-05 23:44:22.700244: val_loss -0.4485\n",
      "2024-12-05 23:44:22.700244: Pseudo dice [0.7982]\n",
      "2024-12-05 23:44:22.710244: Epoch time: 130.82 s\n",
      "2024-12-05 23:44:23.760260: \n",
      "2024-12-05 23:44:23.760260: Epoch 524\n",
      "2024-12-05 23:44:23.770260: Current learning rate: 0.00513\n",
      "2024-12-05 23:46:34.522575: train_loss -0.8253\n",
      "2024-12-05 23:46:34.542576: val_loss -0.417\n",
      "2024-12-05 23:46:34.542576: Pseudo dice [0.7876]\n",
      "2024-12-05 23:46:34.552577: Epoch time: 130.76 s\n",
      "2024-12-05 23:46:35.592592: \n",
      "2024-12-05 23:46:35.602592: Epoch 525\n",
      "2024-12-05 23:46:35.612592: Current learning rate: 0.00512\n",
      "2024-12-05 23:48:46.471478: train_loss -0.809\n",
      "2024-12-05 23:48:46.481477: val_loss -0.4346\n",
      "2024-12-05 23:48:46.491477: Pseudo dice [0.7544]\n",
      "2024-12-05 23:48:46.501477: Epoch time: 130.88 s\n",
      "2024-12-05 23:48:47.542278: \n",
      "2024-12-05 23:48:47.552279: Epoch 526\n",
      "2024-12-05 23:48:47.562279: Current learning rate: 0.00511\n",
      "2024-12-05 23:50:58.391172: train_loss -0.829\n",
      "2024-12-05 23:50:58.401172: val_loss -0.2837\n",
      "2024-12-05 23:50:58.411172: Pseudo dice [0.7924]\n",
      "2024-12-05 23:50:58.411172: Epoch time: 130.85 s\n",
      "2024-12-05 23:50:59.641191: \n",
      "2024-12-05 23:50:59.641191: Epoch 527\n",
      "2024-12-05 23:50:59.651191: Current learning rate: 0.0051\n",
      "2024-12-05 23:53:10.399829: train_loss -0.798\n",
      "2024-12-05 23:53:10.409829: val_loss -0.515\n",
      "2024-12-05 23:53:10.419830: Pseudo dice [0.8526]\n",
      "2024-12-05 23:53:10.419830: Epoch time: 130.77 s\n",
      "2024-12-05 23:53:10.429830: Yayy! New best EMA pseudo Dice: 0.7608\n",
      "2024-12-05 23:53:11.739924: \n",
      "2024-12-05 23:53:11.739924: Epoch 528\n",
      "2024-12-05 23:53:11.749922: Current learning rate: 0.00509\n",
      "2024-12-05 23:55:22.630627: train_loss -0.7907\n",
      "2024-12-05 23:55:22.640627: val_loss -0.3028\n",
      "2024-12-05 23:55:22.650627: Pseudo dice [0.683]\n",
      "2024-12-05 23:55:22.650627: Epoch time: 130.89 s\n",
      "2024-12-05 23:55:23.700643: \n",
      "2024-12-05 23:55:23.700643: Epoch 529\n",
      "2024-12-05 23:55:23.710644: Current learning rate: 0.00508\n",
      "2024-12-05 23:57:34.472781: train_loss -0.808\n",
      "2024-12-05 23:57:34.472781: val_loss -0.5184\n",
      "2024-12-05 23:57:34.482782: Pseudo dice [0.8193]\n",
      "2024-12-05 23:57:34.492781: Epoch time: 130.77 s\n",
      "2024-12-05 23:57:35.542798: \n",
      "2024-12-05 23:57:35.552798: Epoch 530\n",
      "2024-12-05 23:57:35.552798: Current learning rate: 0.00507\n",
      "2024-12-05 23:59:46.281496: train_loss -0.831\n",
      "2024-12-05 23:59:46.291496: val_loss -0.2552\n",
      "2024-12-05 23:59:46.301497: Pseudo dice [0.6126]\n",
      "2024-12-05 23:59:46.301497: Epoch time: 130.74 s\n",
      "2024-12-05 23:59:47.351512: \n",
      "2024-12-05 23:59:47.361513: Epoch 531\n",
      "2024-12-05 23:59:47.361513: Current learning rate: 0.00506\n",
      "2024-12-06 00:01:58.180780: train_loss -0.8242\n",
      "2024-12-06 00:01:58.190780: val_loss -0.5665\n",
      "2024-12-06 00:01:58.200781: Pseudo dice [0.7929]\n",
      "2024-12-06 00:01:58.210780: Epoch time: 130.83 s\n",
      "2024-12-06 00:01:59.250797: \n",
      "2024-12-06 00:01:59.260797: Epoch 532\n",
      "2024-12-06 00:01:59.260797: Current learning rate: 0.00505\n",
      "2024-12-06 00:04:09.985054: train_loss -0.8166\n",
      "2024-12-06 00:04:09.995054: val_loss -0.5963\n",
      "2024-12-06 00:04:10.005054: Pseudo dice [0.8343]\n",
      "2024-12-06 00:04:10.015054: Epoch time: 130.73 s\n",
      "2024-12-06 00:04:11.065073: \n",
      "2024-12-06 00:04:11.065073: Epoch 533\n",
      "2024-12-06 00:04:11.075070: Current learning rate: 0.00504\n",
      "2024-12-06 00:06:21.805025: train_loss -0.7943\n",
      "2024-12-06 00:06:21.815025: val_loss -0.3228\n",
      "2024-12-06 00:06:21.825025: Pseudo dice [0.6316]\n",
      "2024-12-06 00:06:21.825025: Epoch time: 130.74 s\n",
      "2024-12-06 00:06:22.885044: \n",
      "2024-12-06 00:06:22.885044: Epoch 534\n",
      "2024-12-06 00:06:22.895041: Current learning rate: 0.00503\n",
      "2024-12-06 00:08:33.635022: train_loss -0.7734\n",
      "2024-12-06 00:08:33.645021: val_loss -0.4242\n",
      "2024-12-06 00:08:33.645021: Pseudo dice [0.7289]\n",
      "2024-12-06 00:08:33.655022: Epoch time: 130.75 s\n",
      "2024-12-06 00:08:34.885367: \n",
      "2024-12-06 00:08:34.895360: Epoch 535\n",
      "2024-12-06 00:08:34.905358: Current learning rate: 0.00502\n",
      "2024-12-06 00:10:45.612432: train_loss -0.809\n",
      "2024-12-06 00:10:45.622432: val_loss -0.292\n",
      "2024-12-06 00:10:45.632432: Pseudo dice [0.649]\n",
      "2024-12-06 00:10:45.642433: Epoch time: 130.73 s\n",
      "2024-12-06 00:10:46.692448: \n",
      "2024-12-06 00:10:46.702448: Epoch 536\n",
      "2024-12-06 00:10:46.702448: Current learning rate: 0.00501\n",
      "2024-12-06 00:12:57.539712: train_loss -0.8267\n",
      "2024-12-06 00:12:57.549713: val_loss -0.1734\n",
      "2024-12-06 00:12:57.559713: Pseudo dice [0.6236]\n",
      "2024-12-06 00:12:57.569713: Epoch time: 130.85 s\n",
      "2024-12-06 00:12:58.619728: \n",
      "2024-12-06 00:12:58.629728: Epoch 537\n",
      "2024-12-06 00:12:58.629728: Current learning rate: 0.005\n",
      "2024-12-06 00:15:09.376569: train_loss -0.8189\n",
      "2024-12-06 00:15:09.386569: val_loss -0.4429\n",
      "2024-12-06 00:15:09.386569: Pseudo dice [0.7347]\n",
      "2024-12-06 00:15:09.396569: Epoch time: 130.76 s\n",
      "2024-12-06 00:15:10.456890: \n",
      "2024-12-06 00:15:10.456890: Epoch 538\n",
      "2024-12-06 00:15:10.466878: Current learning rate: 0.00499\n",
      "2024-12-06 00:17:21.304755: train_loss -0.7849\n",
      "2024-12-06 00:17:21.314755: val_loss -0.4297\n",
      "2024-12-06 00:17:21.314755: Pseudo dice [0.7664]\n",
      "2024-12-06 00:17:21.324756: Epoch time: 130.86 s\n",
      "2024-12-06 00:17:22.375033: \n",
      "2024-12-06 00:17:22.385034: Epoch 539\n",
      "2024-12-06 00:17:22.395034: Current learning rate: 0.00498\n",
      "2024-12-06 00:19:33.173011: train_loss -0.7993\n",
      "2024-12-06 00:19:33.183012: val_loss -0.4771\n",
      "2024-12-06 00:19:33.183012: Pseudo dice [0.772]\n",
      "2024-12-06 00:19:33.193012: Epoch time: 130.8 s\n",
      "2024-12-06 00:19:34.243312: \n",
      "2024-12-06 00:19:34.253312: Epoch 540\n",
      "2024-12-06 00:19:34.253312: Current learning rate: 0.00497\n",
      "2024-12-06 00:21:44.963499: train_loss -0.7848\n",
      "2024-12-06 00:21:44.973500: val_loss -0.3146\n",
      "2024-12-06 00:21:44.983499: Pseudo dice [0.7218]\n",
      "2024-12-06 00:21:44.993500: Epoch time: 130.72 s\n",
      "2024-12-06 00:21:46.043515: \n",
      "2024-12-06 00:21:46.053516: Epoch 541\n",
      "2024-12-06 00:21:46.053516: Current learning rate: 0.00496\n",
      "2024-12-06 00:23:56.753731: train_loss -0.8127\n",
      "2024-12-06 00:23:56.763732: val_loss -0.3875\n",
      "2024-12-06 00:23:56.773732: Pseudo dice [0.7319]\n",
      "2024-12-06 00:23:56.773732: Epoch time: 130.71 s\n",
      "2024-12-06 00:23:58.013751: \n",
      "2024-12-06 00:23:58.023752: Epoch 542\n",
      "2024-12-06 00:23:58.023752: Current learning rate: 0.00495\n",
      "2024-12-06 00:26:08.843708: train_loss -0.8107\n",
      "2024-12-06 00:26:08.853709: val_loss -0.3291\n",
      "2024-12-06 00:26:08.863708: Pseudo dice [0.7014]\n",
      "2024-12-06 00:26:08.863708: Epoch time: 130.83 s\n",
      "2024-12-06 00:26:09.923733: \n",
      "2024-12-06 00:26:09.933724: Epoch 543\n",
      "2024-12-06 00:26:09.933724: Current learning rate: 0.00494\n",
      "2024-12-06 00:28:20.683689: train_loss -0.7503\n",
      "2024-12-06 00:28:20.703689: val_loss -0.4531\n",
      "2024-12-06 00:28:20.703689: Pseudo dice [0.7971]\n",
      "2024-12-06 00:28:20.713690: Epoch time: 130.76 s\n",
      "2024-12-06 00:28:21.773705: \n",
      "2024-12-06 00:28:21.783705: Epoch 544\n",
      "2024-12-06 00:28:21.783705: Current learning rate: 0.00493\n",
      "2024-12-06 00:30:32.546905: train_loss -0.7598\n",
      "2024-12-06 00:30:32.556906: val_loss -0.4153\n",
      "2024-12-06 00:30:32.566905: Pseudo dice [0.7437]\n",
      "2024-12-06 00:30:32.566905: Epoch time: 130.77 s\n",
      "2024-12-06 00:30:33.626922: \n",
      "2024-12-06 00:30:33.636922: Epoch 545\n",
      "2024-12-06 00:30:33.636922: Current learning rate: 0.00492\n",
      "2024-12-06 00:32:44.401615: train_loss -0.7907\n",
      "2024-12-06 00:32:44.411615: val_loss -0.2759\n",
      "2024-12-06 00:32:44.421616: Pseudo dice [0.6931]\n",
      "2024-12-06 00:32:44.431616: Epoch time: 130.77 s\n",
      "2024-12-06 00:32:45.481631: \n",
      "2024-12-06 00:32:45.481631: Epoch 546\n",
      "2024-12-06 00:32:45.491631: Current learning rate: 0.00491\n",
      "2024-12-06 00:34:56.268810: train_loss -0.772\n",
      "2024-12-06 00:34:56.278811: val_loss -0.1662\n",
      "2024-12-06 00:34:56.288809: Pseudo dice [0.6949]\n",
      "2024-12-06 00:34:56.288809: Epoch time: 130.79 s\n",
      "2024-12-06 00:34:57.339760: \n",
      "2024-12-06 00:34:57.349752: Epoch 547\n",
      "2024-12-06 00:34:57.349752: Current learning rate: 0.0049\n",
      "2024-12-06 00:37:08.017128: train_loss -0.767\n",
      "2024-12-06 00:37:08.037127: val_loss -0.2278\n",
      "2024-12-06 00:37:08.037127: Pseudo dice [0.6401]\n",
      "2024-12-06 00:37:08.047127: Epoch time: 130.68 s\n",
      "2024-12-06 00:37:09.097153: \n",
      "2024-12-06 00:37:09.097153: Epoch 548\n",
      "2024-12-06 00:37:09.107153: Current learning rate: 0.00489\n",
      "2024-12-06 00:39:19.805236: train_loss -0.787\n",
      "2024-12-06 00:39:19.815237: val_loss -0.5529\n",
      "2024-12-06 00:39:19.825237: Pseudo dice [0.8233]\n",
      "2024-12-06 00:39:19.835237: Epoch time: 130.71 s\n",
      "2024-12-06 00:39:21.066042: \n",
      "2024-12-06 00:39:21.076041: Epoch 549\n",
      "2024-12-06 00:39:21.076041: Current learning rate: 0.00488\n",
      "2024-12-06 00:41:31.706726: train_loss -0.7973\n",
      "2024-12-06 00:41:31.716726: val_loss -0.3971\n",
      "2024-12-06 00:41:31.726726: Pseudo dice [0.7597]\n",
      "2024-12-06 00:41:31.726726: Epoch time: 130.64 s\n",
      "2024-12-06 00:41:33.027550: \n",
      "2024-12-06 00:41:33.027550: Epoch 550\n",
      "2024-12-06 00:41:33.037549: Current learning rate: 0.00487\n",
      "2024-12-06 00:43:43.671489: train_loss -0.8006\n",
      "2024-12-06 00:43:43.681490: val_loss -0.3775\n",
      "2024-12-06 00:43:43.691489: Pseudo dice [0.7938]\n",
      "2024-12-06 00:43:43.691489: Epoch time: 130.64 s\n",
      "2024-12-06 00:43:44.741504: \n",
      "2024-12-06 00:43:44.751506: Epoch 551\n",
      "2024-12-06 00:43:44.751506: Current learning rate: 0.00486\n",
      "2024-12-06 00:45:55.411378: train_loss -0.7958\n",
      "2024-12-06 00:45:55.421378: val_loss -0.4088\n",
      "2024-12-06 00:45:55.431379: Pseudo dice [0.7448]\n",
      "2024-12-06 00:45:55.441379: Epoch time: 130.67 s\n",
      "2024-12-06 00:45:56.491395: \n",
      "2024-12-06 00:45:56.501395: Epoch 552\n",
      "2024-12-06 00:45:56.501395: Current learning rate: 0.00485\n",
      "2024-12-06 00:48:07.162405: train_loss -0.7846\n",
      "2024-12-06 00:48:07.172405: val_loss -0.4038\n",
      "2024-12-06 00:48:07.182405: Pseudo dice [0.8273]\n",
      "2024-12-06 00:48:07.192405: Epoch time: 130.67 s\n",
      "2024-12-06 00:48:08.242421: \n",
      "2024-12-06 00:48:08.252422: Epoch 553\n",
      "2024-12-06 00:48:08.252422: Current learning rate: 0.00484\n",
      "2024-12-06 00:50:18.933167: train_loss -0.7933\n",
      "2024-12-06 00:50:18.943167: val_loss -0.1079\n",
      "2024-12-06 00:50:18.953168: Pseudo dice [0.5568]\n",
      "2024-12-06 00:50:18.963168: Epoch time: 130.69 s\n",
      "2024-12-06 00:50:20.013184: \n",
      "2024-12-06 00:50:20.023184: Epoch 554\n",
      "2024-12-06 00:50:20.023184: Current learning rate: 0.00484\n",
      "2024-12-06 00:52:30.713880: train_loss -0.7808\n",
      "2024-12-06 00:52:30.723882: val_loss -0.2089\n",
      "2024-12-06 00:52:30.733881: Pseudo dice [0.6038]\n",
      "2024-12-06 00:52:30.743882: Epoch time: 130.7 s\n",
      "2024-12-06 00:52:31.793897: \n",
      "2024-12-06 00:52:31.793897: Epoch 555\n",
      "2024-12-06 00:52:31.803897: Current learning rate: 0.00483\n",
      "2024-12-06 00:54:42.482441: train_loss -0.7766\n",
      "2024-12-06 00:54:42.492441: val_loss -0.4406\n",
      "2024-12-06 00:54:42.492441: Pseudo dice [0.7401]\n",
      "2024-12-06 00:54:42.502442: Epoch time: 130.7 s\n",
      "2024-12-06 00:54:43.552458: \n",
      "2024-12-06 00:54:43.562458: Epoch 556\n",
      "2024-12-06 00:54:43.562458: Current learning rate: 0.00482\n",
      "2024-12-06 00:56:54.231188: train_loss -0.7976\n",
      "2024-12-06 00:56:54.241189: val_loss -0.1764\n",
      "2024-12-06 00:56:54.241189: Pseudo dice [0.5521]\n",
      "2024-12-06 00:56:54.251189: Epoch time: 130.68 s\n",
      "2024-12-06 00:56:55.472070: \n",
      "2024-12-06 00:56:55.482070: Epoch 557\n",
      "2024-12-06 00:56:55.492070: Current learning rate: 0.00481\n",
      "2024-12-06 00:59:06.192772: train_loss -0.8144\n",
      "2024-12-06 00:59:06.202770: val_loss -0.3416\n",
      "2024-12-06 00:59:06.202770: Pseudo dice [0.6812]\n",
      "2024-12-06 00:59:06.212769: Epoch time: 130.72 s\n",
      "2024-12-06 00:59:07.263035: \n",
      "2024-12-06 00:59:07.273035: Epoch 558\n",
      "2024-12-06 00:59:07.273035: Current learning rate: 0.0048\n",
      "2024-12-06 01:01:18.028109: train_loss -0.8191\n",
      "2024-12-06 01:01:18.038109: val_loss -0.0832\n",
      "2024-12-06 01:01:18.048110: Pseudo dice [0.5975]\n",
      "2024-12-06 01:01:18.048110: Epoch time: 130.77 s\n",
      "2024-12-06 01:01:19.108125: \n",
      "2024-12-06 01:01:19.118126: Epoch 559\n",
      "2024-12-06 01:01:19.118126: Current learning rate: 0.00479\n",
      "2024-12-06 01:03:29.797260: train_loss -0.8174\n",
      "2024-12-06 01:03:29.817260: val_loss -0.4796\n",
      "2024-12-06 01:03:29.817260: Pseudo dice [0.8273]\n",
      "2024-12-06 01:03:29.827260: Epoch time: 130.69 s\n",
      "2024-12-06 01:03:30.877284: \n",
      "2024-12-06 01:03:30.887285: Epoch 560\n",
      "2024-12-06 01:03:30.887285: Current learning rate: 0.00478\n",
      "2024-12-06 01:05:41.614425: train_loss -0.8242\n",
      "2024-12-06 01:05:41.624425: val_loss -0.4267\n",
      "2024-12-06 01:05:41.634426: Pseudo dice [0.6999]\n",
      "2024-12-06 01:05:41.634426: Epoch time: 130.74 s\n",
      "2024-12-06 01:05:42.684450: \n",
      "2024-12-06 01:05:42.694441: Epoch 561\n",
      "2024-12-06 01:05:42.704443: Current learning rate: 0.00477\n",
      "2024-12-06 01:07:53.413030: train_loss -0.8212\n",
      "2024-12-06 01:07:53.423030: val_loss -0.1376\n",
      "2024-12-06 01:07:53.433030: Pseudo dice [0.6796]\n",
      "2024-12-06 01:07:53.443030: Epoch time: 130.73 s\n",
      "2024-12-06 01:07:54.483046: \n",
      "2024-12-06 01:07:54.493047: Epoch 562\n",
      "2024-12-06 01:07:54.503047: Current learning rate: 0.00476\n",
      "2024-12-06 01:10:05.173879: train_loss -0.8067\n",
      "2024-12-06 01:10:05.234499: val_loss -0.254\n",
      "2024-12-06 01:10:05.244502: Pseudo dice [0.7573]\n",
      "2024-12-06 01:10:05.244502: Epoch time: 130.69 s\n",
      "2024-12-06 01:10:06.294526: \n",
      "2024-12-06 01:10:06.294526: Epoch 563\n",
      "2024-12-06 01:10:06.304518: Current learning rate: 0.00475\n",
      "2024-12-06 01:12:17.053732: train_loss -0.8343\n",
      "2024-12-06 01:12:17.063734: val_loss -0.3736\n",
      "2024-12-06 01:12:17.073732: Pseudo dice [0.7327]\n",
      "2024-12-06 01:12:17.073732: Epoch time: 130.76 s\n",
      "2024-12-06 01:12:18.304065: \n",
      "2024-12-06 01:12:18.314066: Epoch 564\n",
      "2024-12-06 01:12:18.324066: Current learning rate: 0.00474\n",
      "2024-12-06 01:14:29.049615: train_loss -0.8263\n",
      "2024-12-06 01:14:29.059615: val_loss -0.3751\n",
      "2024-12-06 01:14:29.059615: Pseudo dice [0.7516]\n",
      "2024-12-06 01:14:29.069616: Epoch time: 130.75 s\n",
      "2024-12-06 01:14:30.119632: \n",
      "2024-12-06 01:14:30.129632: Epoch 565\n",
      "2024-12-06 01:14:30.139633: Current learning rate: 0.00473\n",
      "2024-12-06 01:16:40.886945: train_loss -0.7807\n",
      "2024-12-06 01:16:40.896945: val_loss -0.3031\n",
      "2024-12-06 01:16:40.896945: Pseudo dice [0.7098]\n",
      "2024-12-06 01:16:40.906945: Epoch time: 130.77 s\n",
      "2024-12-06 01:16:41.956961: \n",
      "2024-12-06 01:16:41.956961: Epoch 566\n",
      "2024-12-06 01:16:41.966962: Current learning rate: 0.00472\n",
      "2024-12-06 01:18:52.793931: train_loss -0.8023\n",
      "2024-12-06 01:18:52.803931: val_loss -0.3644\n",
      "2024-12-06 01:18:52.813931: Pseudo dice [0.7788]\n",
      "2024-12-06 01:18:52.823931: Epoch time: 130.84 s\n",
      "2024-12-06 01:18:53.874244: \n",
      "2024-12-06 01:18:53.874244: Epoch 567\n",
      "2024-12-06 01:18:53.884243: Current learning rate: 0.00471\n",
      "2024-12-06 01:21:04.523750: train_loss -0.83\n",
      "2024-12-06 01:21:04.533750: val_loss -0.4649\n",
      "2024-12-06 01:21:04.543750: Pseudo dice [0.7587]\n",
      "2024-12-06 01:21:04.543750: Epoch time: 130.65 s\n",
      "2024-12-06 01:21:05.603766: \n",
      "2024-12-06 01:21:05.603766: Epoch 568\n",
      "2024-12-06 01:21:05.613767: Current learning rate: 0.0047\n",
      "2024-12-06 01:23:16.301352: train_loss -0.8366\n",
      "2024-12-06 01:23:16.311349: val_loss -0.5286\n",
      "2024-12-06 01:23:16.311349: Pseudo dice [0.8135]\n",
      "2024-12-06 01:23:16.321350: Epoch time: 130.71 s\n",
      "2024-12-06 01:23:17.372239: \n",
      "2024-12-06 01:23:17.382240: Epoch 569\n",
      "2024-12-06 01:23:17.392239: Current learning rate: 0.00469\n",
      "2024-12-06 01:25:28.055739: train_loss -0.8372\n",
      "2024-12-06 01:25:28.065740: val_loss -0.4129\n",
      "2024-12-06 01:25:28.075739: Pseudo dice [0.7846]\n",
      "2024-12-06 01:25:28.075739: Epoch time: 130.68 s\n",
      "2024-12-06 01:25:29.135756: \n",
      "2024-12-06 01:25:29.145755: Epoch 570\n",
      "2024-12-06 01:25:29.155756: Current learning rate: 0.00468\n",
      "2024-12-06 01:27:39.843566: train_loss -0.8168\n",
      "2024-12-06 01:27:39.853566: val_loss -0.2748\n",
      "2024-12-06 01:27:39.863565: Pseudo dice [0.6857]\n",
      "2024-12-06 01:27:39.863565: Epoch time: 130.71 s\n",
      "2024-12-06 01:27:41.094153: \n",
      "2024-12-06 01:27:41.104153: Epoch 571\n",
      "2024-12-06 01:27:41.104153: Current learning rate: 0.00467\n",
      "2024-12-06 01:29:51.836255: train_loss -0.8293\n",
      "2024-12-06 01:29:51.846255: val_loss -0.4248\n",
      "2024-12-06 01:29:51.846255: Pseudo dice [0.7987]\n",
      "2024-12-06 01:29:51.856255: Epoch time: 130.74 s\n",
      "2024-12-06 01:29:52.906280: \n",
      "2024-12-06 01:29:52.916271: Epoch 572\n",
      "2024-12-06 01:29:52.916271: Current learning rate: 0.00466\n",
      "2024-12-06 01:32:03.666115: train_loss -0.807\n",
      "2024-12-06 01:32:03.676115: val_loss -0.5089\n",
      "2024-12-06 01:32:03.676115: Pseudo dice [0.8274]\n",
      "2024-12-06 01:32:03.686115: Epoch time: 130.76 s\n",
      "2024-12-06 01:32:04.756135: \n",
      "2024-12-06 01:32:04.756135: Epoch 573\n",
      "2024-12-06 01:32:04.766131: Current learning rate: 0.00465\n",
      "2024-12-06 01:34:15.493671: train_loss -0.8105\n",
      "2024-12-06 01:34:15.503672: val_loss -0.3747\n",
      "2024-12-06 01:34:15.513672: Pseudo dice [0.7809]\n",
      "2024-12-06 01:34:15.513672: Epoch time: 130.74 s\n",
      "2024-12-06 01:34:16.583686: \n",
      "2024-12-06 01:34:16.593688: Epoch 574\n",
      "2024-12-06 01:34:16.593688: Current learning rate: 0.00464\n",
      "2024-12-06 01:36:27.411836: train_loss -0.8014\n",
      "2024-12-06 01:36:27.421835: val_loss -0.3017\n",
      "2024-12-06 01:36:27.431835: Pseudo dice [0.6733]\n",
      "2024-12-06 01:36:27.431835: Epoch time: 130.83 s\n",
      "2024-12-06 01:36:28.511852: \n",
      "2024-12-06 01:36:28.511852: Epoch 575\n",
      "2024-12-06 01:36:28.521852: Current learning rate: 0.00463\n",
      "2024-12-06 01:38:39.178376: train_loss -0.8137\n",
      "2024-12-06 01:38:39.188376: val_loss -0.3927\n",
      "2024-12-06 01:38:39.198376: Pseudo dice [0.7566]\n",
      "2024-12-06 01:38:39.208376: Epoch time: 130.67 s\n",
      "2024-12-06 01:38:40.278393: \n",
      "2024-12-06 01:38:40.288394: Epoch 576\n",
      "2024-12-06 01:38:40.288394: Current learning rate: 0.00462\n",
      "2024-12-06 01:40:51.097213: train_loss -0.832\n",
      "2024-12-06 01:40:51.107213: val_loss -0.4973\n",
      "2024-12-06 01:40:51.107213: Pseudo dice [0.7699]\n",
      "2024-12-06 01:40:51.117214: Epoch time: 130.82 s\n",
      "2024-12-06 01:40:52.187509: \n",
      "2024-12-06 01:40:52.197501: Epoch 577\n",
      "2024-12-06 01:40:52.197501: Current learning rate: 0.00461\n",
      "2024-12-06 01:43:02.841324: train_loss -0.8396\n",
      "2024-12-06 01:43:02.851324: val_loss -0.517\n",
      "2024-12-06 01:43:02.861324: Pseudo dice [0.8449]\n",
      "2024-12-06 01:43:02.871324: Epoch time: 130.65 s\n",
      "2024-12-06 01:43:04.122319: \n",
      "2024-12-06 01:43:04.122319: Epoch 578\n",
      "2024-12-06 01:43:04.132316: Current learning rate: 0.0046\n",
      "2024-12-06 01:45:14.806870: train_loss -0.8295\n",
      "2024-12-06 01:45:14.816870: val_loss -0.0908\n",
      "2024-12-06 01:45:14.826870: Pseudo dice [0.5104]\n",
      "2024-12-06 01:45:14.839156: Epoch time: 130.68 s\n",
      "2024-12-06 01:45:15.907176: \n",
      "2024-12-06 01:45:15.907176: Epoch 579\n",
      "2024-12-06 01:45:15.917177: Current learning rate: 0.00459\n",
      "2024-12-06 01:47:26.568388: train_loss -0.8136\n",
      "2024-12-06 01:47:26.588389: val_loss 0.1184\n",
      "2024-12-06 01:47:26.588389: Pseudo dice [0.3967]\n",
      "2024-12-06 01:47:26.598389: Epoch time: 130.66 s\n",
      "2024-12-06 01:47:27.669219: \n",
      "2024-12-06 01:47:27.669219: Epoch 580\n",
      "2024-12-06 01:47:27.679218: Current learning rate: 0.00458\n",
      "2024-12-06 01:49:38.296917: train_loss -0.8155\n",
      "2024-12-06 01:49:38.306918: val_loss -0.4877\n",
      "2024-12-06 01:49:38.316917: Pseudo dice [0.8104]\n",
      "2024-12-06 01:49:38.326918: Epoch time: 130.64 s\n",
      "2024-12-06 01:49:39.398022: \n",
      "2024-12-06 01:49:39.398022: Epoch 581\n",
      "2024-12-06 01:49:39.408022: Current learning rate: 0.00457\n",
      "2024-12-06 01:51:50.083650: train_loss -0.8101\n",
      "2024-12-06 01:51:50.103650: val_loss -0.3431\n",
      "2024-12-06 01:51:50.113650: Pseudo dice [0.748]\n",
      "2024-12-06 01:51:50.144472: Epoch time: 130.7 s\n",
      "2024-12-06 01:51:51.213493: \n",
      "2024-12-06 01:51:51.223494: Epoch 582\n",
      "2024-12-06 01:51:51.223494: Current learning rate: 0.00456\n",
      "2024-12-06 01:54:02.032575: train_loss -0.8094\n",
      "2024-12-06 01:54:02.042576: val_loss -0.0685\n",
      "2024-12-06 01:54:02.052575: Pseudo dice [0.5411]\n",
      "2024-12-06 01:54:02.062575: Epoch time: 130.82 s\n",
      "2024-12-06 01:54:03.132593: \n",
      "2024-12-06 01:54:03.132593: Epoch 583\n",
      "2024-12-06 01:54:03.142592: Current learning rate: 0.00455\n",
      "2024-12-06 01:56:13.849868: train_loss -0.7949\n",
      "2024-12-06 01:56:13.859868: val_loss -0.4134\n",
      "2024-12-06 01:56:13.869868: Pseudo dice [0.7375]\n",
      "2024-12-06 01:56:13.869868: Epoch time: 130.72 s\n",
      "2024-12-06 01:56:14.949887: \n",
      "2024-12-06 01:56:14.949887: Epoch 584\n",
      "2024-12-06 01:56:14.959884: Current learning rate: 0.00454\n",
      "2024-12-06 01:58:25.718998: train_loss -0.7936\n",
      "2024-12-06 01:58:25.738998: val_loss -0.4845\n",
      "2024-12-06 01:58:25.738998: Pseudo dice [0.8031]\n",
      "2024-12-06 01:58:25.748999: Epoch time: 130.77 s\n",
      "2024-12-06 01:58:27.012698: \n",
      "2024-12-06 01:58:27.019765: Epoch 585\n",
      "2024-12-06 01:58:27.023831: Current learning rate: 0.00453\n",
      "2024-12-06 02:00:37.726910: train_loss -0.7849\n",
      "2024-12-06 02:00:37.736910: val_loss -0.4421\n",
      "2024-12-06 02:00:37.736910: Pseudo dice [0.7699]\n",
      "2024-12-06 02:00:37.746910: Epoch time: 130.72 s\n",
      "2024-12-06 02:00:38.817233: \n",
      "2024-12-06 02:00:38.827232: Epoch 586\n",
      "2024-12-06 02:00:38.827232: Current learning rate: 0.00452\n",
      "2024-12-06 02:02:49.556240: train_loss -0.7935\n",
      "2024-12-06 02:02:49.566239: val_loss -0.3891\n",
      "2024-12-06 02:02:49.566239: Pseudo dice [0.7606]\n",
      "2024-12-06 02:02:49.576239: Epoch time: 130.74 s\n",
      "2024-12-06 02:02:50.646256: \n",
      "2024-12-06 02:02:50.656256: Epoch 587\n",
      "2024-12-06 02:02:50.656256: Current learning rate: 0.00451\n",
      "2024-12-06 02:05:01.372993: train_loss -0.7826\n",
      "2024-12-06 02:05:01.382993: val_loss -0.5145\n",
      "2024-12-06 02:05:01.382993: Pseudo dice [0.8494]\n",
      "2024-12-06 02:05:01.392994: Epoch time: 130.73 s\n",
      "2024-12-06 02:05:02.463840: \n",
      "2024-12-06 02:05:02.463840: Epoch 588\n",
      "2024-12-06 02:05:02.473840: Current learning rate: 0.0045\n",
      "2024-12-06 02:07:13.163810: train_loss -0.8336\n",
      "2024-12-06 02:07:13.173810: val_loss -0.4342\n",
      "2024-12-06 02:07:13.183810: Pseudo dice [0.7882]\n",
      "2024-12-06 02:07:13.193810: Epoch time: 130.7 s\n",
      "2024-12-06 02:07:14.263826: \n",
      "2024-12-06 02:07:14.263826: Epoch 589\n",
      "2024-12-06 02:07:14.273827: Current learning rate: 0.00449\n",
      "2024-12-06 02:09:24.942716: train_loss -0.8198\n",
      "2024-12-06 02:09:24.952717: val_loss -0.4855\n",
      "2024-12-06 02:09:24.962715: Pseudo dice [0.8073]\n",
      "2024-12-06 02:09:24.962715: Epoch time: 130.69 s\n",
      "2024-12-06 02:09:26.042731: \n",
      "2024-12-06 02:09:26.042731: Epoch 590\n",
      "2024-12-06 02:09:26.052732: Current learning rate: 0.00448\n",
      "2024-12-06 02:11:36.762923: train_loss -0.8334\n",
      "2024-12-06 02:11:36.772922: val_loss -0.3982\n",
      "2024-12-06 02:11:36.772922: Pseudo dice [0.7471]\n",
      "2024-12-06 02:11:36.782923: Epoch time: 130.72 s\n",
      "2024-12-06 02:11:37.852939: \n",
      "2024-12-06 02:11:37.862939: Epoch 591\n",
      "2024-12-06 02:11:37.862939: Current learning rate: 0.00447\n",
      "2024-12-06 02:13:48.658677: train_loss -0.8046\n",
      "2024-12-06 02:13:48.668678: val_loss -0.3196\n",
      "2024-12-06 02:13:48.668678: Pseudo dice [0.73]\n",
      "2024-12-06 02:13:48.678677: Epoch time: 130.81 s\n",
      "2024-12-06 02:13:49.748984: \n",
      "2024-12-06 02:13:49.758984: Epoch 592\n",
      "2024-12-06 02:13:49.758984: Current learning rate: 0.00446\n",
      "2024-12-06 02:16:00.527082: train_loss -0.7928\n",
      "2024-12-06 02:16:00.537083: val_loss -0.4169\n",
      "2024-12-06 02:16:00.547082: Pseudo dice [0.761]\n",
      "2024-12-06 02:16:00.557083: Epoch time: 130.78 s\n",
      "2024-12-06 02:16:01.627099: \n",
      "2024-12-06 02:16:01.637099: Epoch 593\n",
      "2024-12-06 02:16:01.637099: Current learning rate: 0.00445\n",
      "2024-12-06 02:18:12.345442: train_loss -0.8156\n",
      "2024-12-06 02:18:12.355442: val_loss -0.4839\n",
      "2024-12-06 02:18:12.355442: Pseudo dice [0.7907]\n",
      "2024-12-06 02:18:12.365443: Epoch time: 130.72 s\n",
      "2024-12-06 02:18:13.435458: \n",
      "2024-12-06 02:18:13.445458: Epoch 594\n",
      "2024-12-06 02:18:13.455459: Current learning rate: 0.00444\n",
      "2024-12-06 02:20:24.113103: train_loss -0.8274\n",
      "2024-12-06 02:20:24.123103: val_loss -0.3648\n",
      "2024-12-06 02:20:24.133103: Pseudo dice [0.75]\n",
      "2024-12-06 02:20:24.143103: Epoch time: 130.68 s\n",
      "2024-12-06 02:20:25.213831: \n",
      "2024-12-06 02:20:25.223822: Epoch 595\n",
      "2024-12-06 02:20:25.223822: Current learning rate: 0.00443\n",
      "2024-12-06 02:22:36.003270: train_loss -0.7967\n",
      "2024-12-06 02:22:36.013271: val_loss -0.3877\n",
      "2024-12-06 02:22:36.013271: Pseudo dice [0.7089]\n",
      "2024-12-06 02:22:36.023272: Epoch time: 130.79 s\n",
      "2024-12-06 02:22:37.093826: \n",
      "2024-12-06 02:22:37.103818: Epoch 596\n",
      "2024-12-06 02:22:37.103818: Current learning rate: 0.00442\n",
      "2024-12-06 02:24:47.910423: train_loss -0.8032\n",
      "2024-12-06 02:24:47.920424: val_loss -0.3504\n",
      "2024-12-06 02:24:47.930424: Pseudo dice [0.7379]\n",
      "2024-12-06 02:24:47.930424: Epoch time: 130.82 s\n",
      "2024-12-06 02:24:49.010440: \n",
      "2024-12-06 02:24:49.020441: Epoch 597\n",
      "2024-12-06 02:24:49.020441: Current learning rate: 0.00441\n",
      "2024-12-06 02:26:59.839508: train_loss -0.8367\n",
      "2024-12-06 02:26:59.849508: val_loss -0.2098\n",
      "2024-12-06 02:26:59.849508: Pseudo dice [0.5248]\n",
      "2024-12-06 02:26:59.859509: Epoch time: 130.83 s\n",
      "2024-12-06 02:27:00.930377: \n",
      "2024-12-06 02:27:00.940377: Epoch 598\n",
      "2024-12-06 02:27:00.940377: Current learning rate: 0.0044\n",
      "2024-12-06 02:29:11.785863: train_loss -0.7962\n",
      "2024-12-06 02:29:11.785863: val_loss -0.3868\n",
      "2024-12-06 02:29:11.795863: Pseudo dice [0.8018]\n",
      "2024-12-06 02:29:11.805863: Epoch time: 130.86 s\n",
      "2024-12-06 02:29:12.875879: \n",
      "2024-12-06 02:29:12.885879: Epoch 599\n",
      "2024-12-06 02:29:12.885879: Current learning rate: 0.00439\n",
      "2024-12-06 02:31:23.646188: train_loss -0.7973\n",
      "2024-12-06 02:31:23.656188: val_loss -0.4191\n",
      "2024-12-06 02:31:23.656188: Pseudo dice [0.7602]\n",
      "2024-12-06 02:31:23.666188: Epoch time: 130.77 s\n",
      "2024-12-06 02:31:25.177399: \n",
      "2024-12-06 02:31:25.187398: Epoch 600\n",
      "2024-12-06 02:31:25.187398: Current learning rate: 0.00438\n",
      "2024-12-06 02:33:35.897199: train_loss -0.7867\n",
      "2024-12-06 02:33:35.907199: val_loss -0.5336\n",
      "2024-12-06 02:33:35.917199: Pseudo dice [0.8308]\n",
      "2024-12-06 02:33:35.917199: Epoch time: 130.72 s\n",
      "2024-12-06 02:33:36.987598: \n",
      "2024-12-06 02:33:36.997597: Epoch 601\n",
      "2024-12-06 02:33:37.007597: Current learning rate: 0.00437\n",
      "2024-12-06 02:35:47.766561: train_loss -0.8062\n",
      "2024-12-06 02:35:47.776563: val_loss -0.489\n",
      "2024-12-06 02:35:47.786563: Pseudo dice [0.7827]\n",
      "2024-12-06 02:35:47.786563: Epoch time: 130.78 s\n",
      "2024-12-06 02:35:48.866579: \n",
      "2024-12-06 02:35:48.866579: Epoch 602\n",
      "2024-12-06 02:35:48.876580: Current learning rate: 0.00436\n",
      "2024-12-06 02:37:59.533334: train_loss -0.8053\n",
      "2024-12-06 02:37:59.543334: val_loss -0.189\n",
      "2024-12-06 02:37:59.553334: Pseudo dice [0.7057]\n",
      "2024-12-06 02:37:59.553334: Epoch time: 130.67 s\n",
      "2024-12-06 02:38:00.633643: \n",
      "2024-12-06 02:38:00.643643: Epoch 603\n",
      "2024-12-06 02:38:00.643643: Current learning rate: 0.00435\n",
      "2024-12-06 02:40:11.339469: train_loss -0.8343\n",
      "2024-12-06 02:40:11.349470: val_loss -0.0164\n",
      "2024-12-06 02:40:11.359470: Pseudo dice [0.5478]\n",
      "2024-12-06 02:40:11.359470: Epoch time: 130.71 s\n",
      "2024-12-06 02:40:12.440304: \n",
      "2024-12-06 02:40:12.450305: Epoch 604\n",
      "2024-12-06 02:40:12.450305: Current learning rate: 0.00434\n",
      "2024-12-06 02:42:23.272279: train_loss -0.8178\n",
      "2024-12-06 02:42:23.282278: val_loss -0.5295\n",
      "2024-12-06 02:42:23.282278: Pseudo dice [0.8233]\n",
      "2024-12-06 02:42:23.292279: Epoch time: 130.83 s\n",
      "2024-12-06 02:42:24.362294: \n",
      "2024-12-06 02:42:24.372294: Epoch 605\n",
      "2024-12-06 02:42:24.382294: Current learning rate: 0.00433\n",
      "2024-12-06 02:44:35.175536: train_loss -0.827\n",
      "2024-12-06 02:44:35.185536: val_loss -0.2785\n",
      "2024-12-06 02:44:35.195536: Pseudo dice [0.6613]\n",
      "2024-12-06 02:44:35.205537: Epoch time: 130.81 s\n",
      "2024-12-06 02:44:36.448625: \n",
      "2024-12-06 02:44:36.456739: Epoch 606\n",
      "2024-12-06 02:44:36.460788: Current learning rate: 0.00432\n",
      "2024-12-06 02:46:47.258461: train_loss -0.791\n",
      "2024-12-06 02:46:47.268461: val_loss -0.233\n",
      "2024-12-06 02:46:47.278461: Pseudo dice [0.7334]\n",
      "2024-12-06 02:46:47.278461: Epoch time: 130.81 s\n",
      "2024-12-06 02:46:48.358478: \n",
      "2024-12-06 02:46:48.368478: Epoch 607\n",
      "2024-12-06 02:46:48.368478: Current learning rate: 0.00431\n",
      "2024-12-06 02:48:59.151658: train_loss -0.7775\n",
      "2024-12-06 02:48:59.171658: val_loss -0.3843\n",
      "2024-12-06 02:48:59.171658: Pseudo dice [0.6714]\n",
      "2024-12-06 02:48:59.181659: Epoch time: 130.79 s\n",
      "2024-12-06 02:49:00.252506: \n",
      "2024-12-06 02:49:00.262507: Epoch 608\n",
      "2024-12-06 02:49:00.262507: Current learning rate: 0.0043\n",
      "2024-12-06 02:51:11.157377: train_loss -0.807\n",
      "2024-12-06 02:51:11.167378: val_loss -0.3996\n",
      "2024-12-06 02:51:11.177377: Pseudo dice [0.6793]\n",
      "2024-12-06 02:51:11.177377: Epoch time: 130.9 s\n",
      "2024-12-06 02:51:12.258365: \n",
      "2024-12-06 02:51:12.268356: Epoch 609\n",
      "2024-12-06 02:51:12.268356: Current learning rate: 0.00429\n",
      "2024-12-06 02:53:23.096863: train_loss -0.7975\n",
      "2024-12-06 02:53:23.106862: val_loss -0.3075\n",
      "2024-12-06 02:53:23.116863: Pseudo dice [0.5513]\n",
      "2024-12-06 02:53:23.126862: Epoch time: 130.84 s\n",
      "2024-12-06 02:53:24.196879: \n",
      "2024-12-06 02:53:24.206879: Epoch 610\n",
      "2024-12-06 02:53:24.216879: Current learning rate: 0.00429\n",
      "2024-12-06 02:55:34.998317: train_loss -0.8122\n",
      "2024-12-06 02:55:35.008317: val_loss -0.5846\n",
      "2024-12-06 02:55:35.018318: Pseudo dice [0.8273]\n",
      "2024-12-06 02:55:35.018318: Epoch time: 130.8 s\n",
      "2024-12-06 02:55:36.098335: \n",
      "2024-12-06 02:55:36.108335: Epoch 611\n",
      "2024-12-06 02:55:36.108335: Current learning rate: 0.00428\n",
      "2024-12-06 02:57:46.895256: train_loss -0.8083\n",
      "2024-12-06 02:57:46.905256: val_loss -0.4149\n",
      "2024-12-06 02:57:46.915256: Pseudo dice [0.766]\n",
      "2024-12-06 02:57:46.925257: Epoch time: 130.8 s\n",
      "2024-12-06 02:57:48.006038: \n",
      "2024-12-06 02:57:48.006038: Epoch 612\n",
      "2024-12-06 02:57:48.016038: Current learning rate: 0.00427\n",
      "2024-12-06 02:59:58.753290: train_loss -0.8202\n",
      "2024-12-06 02:59:58.763290: val_loss -0.2613\n",
      "2024-12-06 02:59:58.763290: Pseudo dice [0.6514]\n",
      "2024-12-06 02:59:58.773290: Epoch time: 130.76 s\n",
      "2024-12-06 03:00:00.043589: \n",
      "2024-12-06 03:00:00.043589: Epoch 613\n",
      "2024-12-06 03:00:00.053587: Current learning rate: 0.00426\n",
      "2024-12-06 03:02:10.853681: train_loss -0.8206\n",
      "2024-12-06 03:02:10.863682: val_loss -0.3849\n",
      "2024-12-06 03:02:10.873682: Pseudo dice [0.6961]\n",
      "2024-12-06 03:02:10.883682: Epoch time: 130.81 s\n",
      "2024-12-06 03:02:11.954004: \n",
      "2024-12-06 03:02:11.963995: Epoch 614\n",
      "2024-12-06 03:02:11.963995: Current learning rate: 0.00425\n",
      "2024-12-06 03:04:22.759805: train_loss -0.7852\n",
      "2024-12-06 03:04:22.769805: val_loss -0.2351\n",
      "2024-12-06 03:04:22.779805: Pseudo dice [0.6516]\n",
      "2024-12-06 03:04:22.779805: Epoch time: 130.81 s\n",
      "2024-12-06 03:04:23.859822: \n",
      "2024-12-06 03:04:23.869822: Epoch 615\n",
      "2024-12-06 03:04:23.869822: Current learning rate: 0.00424\n",
      "2024-12-06 03:06:34.629273: train_loss -0.8044\n",
      "2024-12-06 03:06:34.639273: val_loss 0.0486\n",
      "2024-12-06 03:06:34.649273: Pseudo dice [0.479]\n",
      "2024-12-06 03:06:34.649273: Epoch time: 130.77 s\n",
      "2024-12-06 03:06:35.729582: \n",
      "2024-12-06 03:06:35.739573: Epoch 616\n",
      "2024-12-06 03:06:35.739573: Current learning rate: 0.00423\n",
      "2024-12-06 03:08:46.532634: train_loss -0.7979\n",
      "2024-12-06 03:08:46.552634: val_loss -0.4761\n",
      "2024-12-06 03:08:46.552634: Pseudo dice [0.7765]\n",
      "2024-12-06 03:08:46.562634: Epoch time: 130.8 s\n",
      "2024-12-06 03:08:47.643514: \n",
      "2024-12-06 03:08:47.643514: Epoch 617\n",
      "2024-12-06 03:08:47.653512: Current learning rate: 0.00422\n",
      "2024-12-06 03:10:58.442832: train_loss -0.7997\n",
      "2024-12-06 03:10:58.452832: val_loss -0.3802\n",
      "2024-12-06 03:10:58.452832: Pseudo dice [0.6869]\n",
      "2024-12-06 03:10:58.462833: Epoch time: 130.8 s\n",
      "2024-12-06 03:10:59.543133: \n",
      "2024-12-06 03:10:59.543133: Epoch 618\n",
      "2024-12-06 03:10:59.553133: Current learning rate: 0.00421\n",
      "2024-12-06 03:13:10.242511: train_loss -0.8067\n",
      "2024-12-06 03:13:10.252511: val_loss -0.4986\n",
      "2024-12-06 03:13:10.252511: Pseudo dice [0.7931]\n",
      "2024-12-06 03:13:10.262512: Epoch time: 130.71 s\n",
      "2024-12-06 03:13:11.342527: \n",
      "2024-12-06 03:13:11.352528: Epoch 619\n",
      "2024-12-06 03:13:11.352528: Current learning rate: 0.0042\n",
      "2024-12-06 03:15:22.129835: train_loss -0.8244\n",
      "2024-12-06 03:15:22.139835: val_loss -0.4296\n",
      "2024-12-06 03:15:22.149835: Pseudo dice [0.7501]\n",
      "2024-12-06 03:15:22.155838: Epoch time: 130.79 s\n",
      "2024-12-06 03:15:23.419863: \n",
      "2024-12-06 03:15:23.419863: Epoch 620\n",
      "2024-12-06 03:15:23.429862: Current learning rate: 0.00419\n",
      "2024-12-06 03:17:34.126895: train_loss -0.8317\n",
      "2024-12-06 03:17:34.136895: val_loss -0.4014\n",
      "2024-12-06 03:17:34.146895: Pseudo dice [0.7621]\n",
      "2024-12-06 03:17:34.146895: Epoch time: 130.72 s\n",
      "2024-12-06 03:17:35.226912: \n",
      "2024-12-06 03:17:35.236913: Epoch 621\n",
      "2024-12-06 03:17:35.246913: Current learning rate: 0.00418\n",
      "2024-12-06 03:19:45.904585: train_loss -0.8309\n",
      "2024-12-06 03:19:45.924587: val_loss -0.3936\n",
      "2024-12-06 03:19:45.981149: Pseudo dice [0.7551]\n",
      "2024-12-06 03:19:45.985653: Epoch time: 130.68 s\n",
      "2024-12-06 03:19:47.055671: \n",
      "2024-12-06 03:19:47.065671: Epoch 622\n",
      "2024-12-06 03:19:47.065671: Current learning rate: 0.00417\n",
      "2024-12-06 03:21:57.760924: train_loss -0.8371\n",
      "2024-12-06 03:21:57.770924: val_loss -0.5132\n",
      "2024-12-06 03:21:57.780924: Pseudo dice [0.7777]\n",
      "2024-12-06 03:21:57.780924: Epoch time: 130.71 s\n",
      "2024-12-06 03:21:58.871239: \n",
      "2024-12-06 03:21:58.871239: Epoch 623\n",
      "2024-12-06 03:21:58.881239: Current learning rate: 0.00416\n",
      "2024-12-06 03:24:11.501789: train_loss -0.8437\n",
      "2024-12-06 03:24:11.501789: val_loss -0.5231\n",
      "2024-12-06 03:24:11.509792: Pseudo dice [0.8103]\n",
      "2024-12-06 03:24:11.514793: Epoch time: 132.64 s\n",
      "2024-12-06 03:24:12.686317: \n",
      "2024-12-06 03:24:12.686317: Epoch 624\n",
      "2024-12-06 03:24:12.694319: Current learning rate: 0.00415\n",
      "2024-12-06 03:26:22.544311: train_loss -0.8447\n",
      "2024-12-06 03:26:22.544311: val_loss -0.4468\n",
      "2024-12-06 03:26:22.554312: Pseudo dice [0.8032]\n",
      "2024-12-06 03:26:22.562314: Epoch time: 129.86 s\n",
      "2024-12-06 03:26:23.804873: \n",
      "2024-12-06 03:26:23.804873: Epoch 625\n",
      "2024-12-06 03:26:23.813875: Current learning rate: 0.00414\n",
      "2024-12-06 03:28:33.452159: train_loss -0.8403\n",
      "2024-12-06 03:28:33.460161: val_loss -0.5477\n",
      "2024-12-06 03:28:33.465163: Pseudo dice [0.823]\n",
      "2024-12-06 03:28:33.470164: Epoch time: 129.65 s\n",
      "2024-12-06 03:28:34.628697: \n",
      "2024-12-06 03:28:34.628697: Epoch 626\n",
      "2024-12-06 03:28:34.637698: Current learning rate: 0.00413\n",
      "2024-12-06 03:30:44.278641: train_loss -0.8344\n",
      "2024-12-06 03:30:44.278641: val_loss -0.2803\n",
      "2024-12-06 03:30:44.290644: Pseudo dice [0.7133]\n",
      "2024-12-06 03:30:44.298646: Epoch time: 129.65 s\n",
      "2024-12-06 03:30:45.687219: \n",
      "2024-12-06 03:30:45.687219: Epoch 627\n",
      "2024-12-06 03:30:45.695223: Current learning rate: 0.00412\n",
      "2024-12-06 03:32:55.447231: train_loss -0.7596\n",
      "2024-12-06 03:32:55.448231: val_loss -0.4211\n",
      "2024-12-06 03:32:55.456232: Pseudo dice [0.7989]\n",
      "2024-12-06 03:32:55.461233: Epoch time: 129.76 s\n",
      "2024-12-06 03:32:56.581511: \n",
      "2024-12-06 03:32:56.581511: Epoch 628\n",
      "2024-12-06 03:32:56.589513: Current learning rate: 0.00411\n",
      "2024-12-06 03:35:12.535552: train_loss -0.7975\n",
      "2024-12-06 03:35:12.535552: val_loss -0.4288\n",
      "2024-12-06 03:35:12.547556: Pseudo dice [0.7868]\n",
      "2024-12-06 03:35:12.554556: Epoch time: 135.96 s\n",
      "2024-12-06 03:35:13.703816: \n",
      "2024-12-06 03:35:13.711819: Epoch 629\n",
      "2024-12-06 03:35:13.717819: Current learning rate: 0.0041\n",
      "2024-12-06 03:37:33.317026: train_loss -0.8227\n",
      "2024-12-06 03:37:33.328029: val_loss -0.3048\n",
      "2024-12-06 03:37:33.338031: Pseudo dice [0.6751]\n",
      "2024-12-06 03:37:33.345033: Epoch time: 139.61 s\n",
      "2024-12-06 03:37:34.529300: \n",
      "2024-12-06 03:37:34.541306: Epoch 630\n",
      "2024-12-06 03:37:34.547307: Current learning rate: 0.00409\n",
      "2024-12-06 03:39:54.932380: train_loss -0.8211\n",
      "2024-12-06 03:39:54.944384: val_loss -0.5573\n",
      "2024-12-06 03:39:54.950385: Pseudo dice [0.8039]\n",
      "2024-12-06 03:39:54.955385: Epoch time: 140.4 s\n",
      "2024-12-06 03:39:56.141655: \n",
      "2024-12-06 03:39:56.149656: Epoch 631\n",
      "2024-12-06 03:39:56.154658: Current learning rate: 0.00408\n",
      "2024-12-06 03:42:16.479779: train_loss -0.8291\n",
      "2024-12-06 03:42:16.488781: val_loss -0.4985\n",
      "2024-12-06 03:42:16.498783: Pseudo dice [0.7991]\n",
      "2024-12-06 03:42:16.505785: Epoch time: 140.34 s\n",
      "2024-12-06 03:42:17.720059: \n",
      "2024-12-06 03:42:17.728061: Epoch 632\n",
      "2024-12-06 03:42:17.733063: Current learning rate: 0.00407\n",
      "2024-12-06 03:44:37.361367: train_loss -0.8361\n",
      "2024-12-06 03:44:37.370369: val_loss -0.6392\n",
      "2024-12-06 03:44:37.380372: Pseudo dice [0.8627]\n",
      "2024-12-06 03:44:37.386373: Epoch time: 139.64 s\n",
      "2024-12-06 03:44:37.394375: Yayy! New best EMA pseudo Dice: 0.7664\n",
      "2024-12-06 03:44:38.831731: \n",
      "2024-12-06 03:44:38.840733: Epoch 633\n",
      "2024-12-06 03:44:38.845734: Current learning rate: 0.00406\n",
      "2024-12-06 03:46:58.469342: train_loss -0.83\n",
      "2024-12-06 03:46:58.480345: val_loss -0.4655\n",
      "2024-12-06 03:46:58.485346: Pseudo dice [0.7635]\n",
      "2024-12-06 03:46:58.495349: Epoch time: 139.64 s\n",
      "2024-12-06 03:46:59.835651: \n",
      "2024-12-06 03:46:59.843654: Epoch 634\n",
      "2024-12-06 03:46:59.849655: Current learning rate: 0.00405\n",
      "2024-12-06 03:49:18.673683: train_loss -0.7989\n",
      "2024-12-06 03:49:18.684687: val_loss -0.3476\n",
      "2024-12-06 03:49:18.694688: Pseudo dice [0.7906]\n",
      "2024-12-06 03:49:18.702690: Epoch time: 138.84 s\n",
      "2024-12-06 03:49:18.708693: Yayy! New best EMA pseudo Dice: 0.7685\n",
      "2024-12-06 03:49:20.165541: \n",
      "2024-12-06 03:49:20.173543: Epoch 635\n",
      "2024-12-06 03:49:20.179545: Current learning rate: 0.00404\n",
      "2024-12-06 03:51:39.866510: train_loss -0.8042\n",
      "2024-12-06 03:51:39.876512: val_loss -0.5366\n",
      "2024-12-06 03:51:39.886514: Pseudo dice [0.7919]\n",
      "2024-12-06 03:51:39.894515: Epoch time: 139.7 s\n",
      "2024-12-06 03:51:39.900517: Yayy! New best EMA pseudo Dice: 0.7709\n",
      "2024-12-06 03:51:41.358542: \n",
      "2024-12-06 03:51:41.366543: Epoch 636\n",
      "2024-12-06 03:51:41.372545: Current learning rate: 0.00403\n",
      "2024-12-06 03:54:01.783145: train_loss -0.841\n",
      "2024-12-06 03:54:01.795148: val_loss 0.0184\n",
      "2024-12-06 03:54:01.803150: Pseudo dice [0.5364]\n",
      "2024-12-06 03:54:01.810151: Epoch time: 140.43 s\n",
      "2024-12-06 03:54:02.995421: \n",
      "2024-12-06 03:54:03.004422: Epoch 637\n",
      "2024-12-06 03:54:03.010424: Current learning rate: 0.00402\n",
      "2024-12-06 03:56:22.246414: train_loss -0.8116\n",
      "2024-12-06 03:56:22.257416: val_loss -0.3545\n",
      "2024-12-06 03:56:22.267418: Pseudo dice [0.7877]\n",
      "2024-12-06 03:56:22.273419: Epoch time: 139.25 s\n",
      "2024-12-06 03:56:23.405675: \n",
      "2024-12-06 03:56:23.413678: Epoch 638\n",
      "2024-12-06 03:56:23.419679: Current learning rate: 0.00401\n",
      "2024-12-06 03:58:42.775179: train_loss -0.8346\n",
      "2024-12-06 03:58:42.786181: val_loss -0.4618\n",
      "2024-12-06 03:58:42.796183: Pseudo dice [0.8199]\n",
      "2024-12-06 03:58:42.801184: Epoch time: 139.37 s\n",
      "2024-12-06 03:58:43.968449: \n",
      "2024-12-06 03:58:43.976450: Epoch 639\n",
      "2024-12-06 03:58:43.982452: Current learning rate: 0.004\n",
      "2024-12-06 04:01:03.119154: train_loss -0.8344\n",
      "2024-12-06 04:01:03.130156: val_loss -0.3551\n",
      "2024-12-06 04:01:03.140159: Pseudo dice [0.7325]\n",
      "2024-12-06 04:01:03.146160: Epoch time: 139.15 s\n",
      "2024-12-06 04:01:04.335428: \n",
      "2024-12-06 04:01:04.343431: Epoch 640\n",
      "2024-12-06 04:01:04.349432: Current learning rate: 0.00399\n",
      "2024-12-06 04:03:23.534388: train_loss -0.8269\n",
      "2024-12-06 04:03:23.543391: val_loss -0.3317\n",
      "2024-12-06 04:03:23.551392: Pseudo dice [0.7222]\n",
      "2024-12-06 04:03:23.558394: Epoch time: 139.2 s\n",
      "2024-12-06 04:03:24.972033: \n",
      "2024-12-06 04:03:24.981035: Epoch 641\n",
      "2024-12-06 04:03:24.987037: Current learning rate: 0.00398\n",
      "2024-12-06 04:05:45.167578: train_loss -0.8153\n",
      "2024-12-06 04:05:45.178580: val_loss -0.3733\n",
      "2024-12-06 04:05:45.184581: Pseudo dice [0.8001]\n",
      "2024-12-06 04:05:45.192582: Epoch time: 140.2 s\n",
      "2024-12-06 04:05:46.385129: \n",
      "2024-12-06 04:05:46.393132: Epoch 642\n",
      "2024-12-06 04:05:46.399133: Current learning rate: 0.00397\n",
      "2024-12-06 04:08:06.017053: train_loss -0.8397\n",
      "2024-12-06 04:08:06.028055: val_loss -0.539\n",
      "2024-12-06 04:08:06.033057: Pseudo dice [0.7956]\n",
      "2024-12-06 04:08:06.043059: Epoch time: 139.63 s\n",
      "2024-12-06 04:08:07.179316: \n",
      "2024-12-06 04:08:07.187318: Epoch 643\n",
      "2024-12-06 04:08:07.191318: Current learning rate: 0.00396\n",
      "2024-12-06 04:10:26.120762: train_loss -0.8315\n",
      "2024-12-06 04:10:26.133765: val_loss -0.3344\n",
      "2024-12-06 04:10:26.142767: Pseudo dice [0.685]\n",
      "2024-12-06 04:10:26.148769: Epoch time: 138.94 s\n",
      "2024-12-06 04:10:27.359325: \n",
      "2024-12-06 04:10:27.367327: Epoch 644\n",
      "2024-12-06 04:10:27.373328: Current learning rate: 0.00395\n",
      "2024-12-06 04:12:46.933509: train_loss -0.8201\n",
      "2024-12-06 04:12:46.945513: val_loss -0.4233\n",
      "2024-12-06 04:12:46.956515: Pseudo dice [0.7463]\n",
      "2024-12-06 04:12:46.962516: Epoch time: 139.58 s\n",
      "2024-12-06 04:12:48.158786: \n",
      "2024-12-06 04:12:48.166788: Epoch 645\n",
      "2024-12-06 04:12:48.172790: Current learning rate: 0.00394\n",
      "2024-12-06 04:15:07.072904: train_loss -0.838\n",
      "2024-12-06 04:15:07.084907: val_loss -0.1223\n",
      "2024-12-06 04:15:07.092909: Pseudo dice [0.6478]\n",
      "2024-12-06 04:15:07.099910: Epoch time: 138.92 s\n",
      "2024-12-06 04:15:08.350194: \n",
      "2024-12-06 04:15:08.359195: Epoch 646\n",
      "2024-12-06 04:15:08.365196: Current learning rate: 0.00393\n",
      "2024-12-06 04:17:28.284692: train_loss -0.805\n",
      "2024-12-06 04:17:28.298695: val_loss -0.4558\n",
      "2024-12-06 04:17:28.308698: Pseudo dice [0.7993]\n",
      "2024-12-06 04:17:28.314698: Epoch time: 139.94 s\n",
      "2024-12-06 04:17:29.482963: \n",
      "2024-12-06 04:17:29.490964: Epoch 647\n",
      "2024-12-06 04:17:29.496966: Current learning rate: 0.00392\n",
      "2024-12-06 04:19:49.098205: train_loss -0.8019\n",
      "2024-12-06 04:19:49.109206: val_loss -0.4033\n",
      "2024-12-06 04:19:49.122210: Pseudo dice [0.7324]\n",
      "2024-12-06 04:19:49.128211: Epoch time: 139.62 s\n",
      "2024-12-06 04:19:50.486519: \n",
      "2024-12-06 04:19:50.494520: Epoch 648\n",
      "2024-12-06 04:19:50.500522: Current learning rate: 0.00391\n",
      "2024-12-06 04:22:09.195467: train_loss -0.8064\n",
      "2024-12-06 04:22:09.205470: val_loss -0.4054\n",
      "2024-12-06 04:22:09.210470: Pseudo dice [0.7106]\n",
      "2024-12-06 04:22:09.215472: Epoch time: 138.71 s\n",
      "2024-12-06 04:22:10.394738: \n",
      "2024-12-06 04:22:10.402740: Epoch 649\n",
      "2024-12-06 04:22:10.408741: Current learning rate: 0.0039\n",
      "2024-12-06 04:24:30.203321: train_loss -0.8322\n",
      "2024-12-06 04:24:30.214323: val_loss -0.4693\n",
      "2024-12-06 04:24:30.223324: Pseudo dice [0.8215]\n",
      "2024-12-06 04:24:30.231327: Epoch time: 139.81 s\n",
      "2024-12-06 04:24:31.611514: \n",
      "2024-12-06 04:24:31.619515: Epoch 650\n",
      "2024-12-06 04:24:31.624517: Current learning rate: 0.00389\n",
      "2024-12-06 04:26:50.145073: train_loss -0.832\n",
      "2024-12-06 04:26:50.155075: val_loss -0.5407\n",
      "2024-12-06 04:26:50.165077: Pseudo dice [0.8346]\n",
      "2024-12-06 04:26:50.172079: Epoch time: 138.53 s\n",
      "2024-12-06 04:26:51.419361: \n",
      "2024-12-06 04:26:51.427363: Epoch 651\n",
      "2024-12-06 04:26:51.432364: Current learning rate: 0.00388\n",
      "2024-12-06 04:29:11.214414: train_loss -0.8141\n",
      "2024-12-06 04:29:11.222416: val_loss -0.3712\n",
      "2024-12-06 04:29:11.228417: Pseudo dice [0.7597]\n",
      "2024-12-06 04:29:11.234418: Epoch time: 139.8 s\n",
      "2024-12-06 04:29:12.391680: \n",
      "2024-12-06 04:29:12.392680: Epoch 652\n",
      "2024-12-06 04:29:12.400682: Current learning rate: 0.00387\n",
      "2024-12-06 04:31:22.491626: train_loss -0.8205\n",
      "2024-12-06 04:31:22.492626: val_loss -0.4468\n",
      "2024-12-06 04:31:22.502629: Pseudo dice [0.745]\n",
      "2024-12-06 04:31:22.509630: Epoch time: 130.1 s\n",
      "2024-12-06 04:31:23.643886: \n",
      "2024-12-06 04:31:23.643886: Epoch 653\n",
      "2024-12-06 04:31:23.650888: Current learning rate: 0.00386\n",
      "2024-12-06 04:33:40.295360: train_loss -0.811\n",
      "2024-12-06 04:33:40.295360: val_loss -0.1975\n",
      "2024-12-06 04:33:40.305362: Pseudo dice [0.5757]\n",
      "2024-12-06 04:33:40.310362: Epoch time: 136.65 s\n",
      "2024-12-06 04:33:41.432616: \n",
      "2024-12-06 04:33:41.440618: Epoch 654\n",
      "2024-12-06 04:33:41.445619: Current learning rate: 0.00385\n",
      "2024-12-06 04:36:01.733943: train_loss -0.8251\n",
      "2024-12-06 04:36:01.742944: val_loss -0.311\n",
      "2024-12-06 04:36:01.748946: Pseudo dice [0.7222]\n",
      "2024-12-06 04:36:01.753947: Epoch time: 140.3 s\n",
      "2024-12-06 04:36:03.122256: \n",
      "2024-12-06 04:36:03.129258: Epoch 655\n",
      "2024-12-06 04:36:03.137263: Current learning rate: 0.00384\n",
      "2024-12-06 04:38:22.650726: train_loss -0.8015\n",
      "2024-12-06 04:38:22.658598: val_loss -0.198\n",
      "2024-12-06 04:38:22.668596: Pseudo dice [0.5842]\n",
      "2024-12-06 04:38:22.668596: Epoch time: 139.53 s\n",
      "2024-12-06 04:38:23.791992: \n",
      "2024-12-06 04:38:23.791992: Epoch 656\n",
      "2024-12-06 04:38:23.801991: Current learning rate: 0.00383\n",
      "2024-12-06 04:40:35.205288: train_loss -0.7902\n",
      "2024-12-06 04:40:35.206573: val_loss -0.0923\n",
      "2024-12-06 04:40:35.222276: Pseudo dice [0.577]\n",
      "2024-12-06 04:40:35.222276: Epoch time: 131.41 s\n",
      "2024-12-06 04:40:36.349650: \n",
      "2024-12-06 04:40:36.356443: Epoch 657\n",
      "2024-12-06 04:40:36.356443: Current learning rate: 0.00382\n",
      "2024-12-06 04:42:47.819275: train_loss -0.8174\n",
      "2024-12-06 04:42:47.829273: val_loss -0.2792\n",
      "2024-12-06 04:42:47.835909: Pseudo dice [0.6388]\n",
      "2024-12-06 04:42:47.835909: Epoch time: 131.47 s\n",
      "2024-12-06 04:42:49.045821: \n",
      "2024-12-06 04:42:49.052449: Epoch 658\n",
      "2024-12-06 04:42:49.062448: Current learning rate: 0.00381\n",
      "2024-12-06 04:45:00.376246: train_loss -0.8313\n",
      "2024-12-06 04:45:00.387721: val_loss 0.2863\n",
      "2024-12-06 04:45:00.394720: Pseudo dice [0.321]\n",
      "2024-12-06 04:45:00.400288: Epoch time: 131.33 s\n",
      "2024-12-06 04:45:01.509562: \n",
      "2024-12-06 04:45:01.516149: Epoch 659\n",
      "2024-12-06 04:45:01.516149: Current learning rate: 0.0038\n",
      "2024-12-06 04:47:12.806600: train_loss -0.8302\n",
      "2024-12-06 04:47:12.813236: val_loss -0.5261\n",
      "2024-12-06 04:47:12.823234: Pseudo dice [0.8118]\n",
      "2024-12-06 04:47:12.829910: Epoch time: 131.3 s\n",
      "2024-12-06 04:47:14.056564: \n",
      "2024-12-06 04:47:14.063204: Epoch 660\n",
      "2024-12-06 04:47:14.073203: Current learning rate: 0.00379\n",
      "2024-12-06 04:49:25.444427: train_loss -0.8345\n",
      "2024-12-06 04:49:25.454428: val_loss -0.3841\n",
      "2024-12-06 04:49:25.463919: Pseudo dice [0.6706]\n",
      "2024-12-06 04:49:25.465488: Epoch time: 131.39 s\n",
      "2024-12-06 04:49:26.620191: \n",
      "2024-12-06 04:49:26.628502: Epoch 661\n",
      "2024-12-06 04:49:26.638005: Current learning rate: 0.00378\n",
      "2024-12-06 04:51:37.857718: train_loss -0.806\n",
      "2024-12-06 04:51:37.867221: val_loss -0.2727\n",
      "2024-12-06 04:51:37.883857: Pseudo dice [0.734]\n",
      "2024-12-06 04:51:37.891256: Epoch time: 131.24 s\n",
      "2024-12-06 04:51:39.207397: \n",
      "2024-12-06 04:51:39.207397: Epoch 662\n",
      "2024-12-06 04:51:39.216902: Current learning rate: 0.00377\n",
      "2024-12-06 04:53:50.670870: train_loss -0.825\n",
      "2024-12-06 04:53:50.670870: val_loss -0.4083\n",
      "2024-12-06 04:53:50.687597: Pseudo dice [0.6995]\n",
      "2024-12-06 04:53:50.687597: Epoch time: 131.46 s\n",
      "2024-12-06 04:53:51.820997: \n",
      "2024-12-06 04:53:51.830996: Epoch 663\n",
      "2024-12-06 04:53:51.830996: Current learning rate: 0.00376\n",
      "2024-12-06 04:56:03.301311: train_loss -0.817\n",
      "2024-12-06 04:56:03.317897: val_loss -0.5499\n",
      "2024-12-06 04:56:03.317897: Pseudo dice [0.8528]\n",
      "2024-12-06 04:56:03.327896: Epoch time: 131.48 s\n",
      "2024-12-06 04:56:04.494447: \n",
      "2024-12-06 04:56:04.502154: Epoch 664\n",
      "2024-12-06 04:56:04.502154: Current learning rate: 0.00375\n",
      "2024-12-06 04:58:15.741543: train_loss -0.8203\n",
      "2024-12-06 04:58:15.748180: val_loss -0.2936\n",
      "2024-12-06 04:58:15.764836: Pseudo dice [0.6708]\n",
      "2024-12-06 04:58:15.764836: Epoch time: 131.25 s\n",
      "2024-12-06 04:58:16.999061: \n",
      "2024-12-06 04:58:17.009060: Epoch 665\n",
      "2024-12-06 04:58:17.014808: Current learning rate: 0.00374\n",
      "2024-12-06 05:00:28.455304: train_loss -0.8308\n",
      "2024-12-06 05:00:28.461833: val_loss -0.1525\n",
      "2024-12-06 05:00:28.471832: Pseudo dice [0.591]\n",
      "2024-12-06 05:00:28.478524: Epoch time: 131.46 s\n",
      "2024-12-06 05:00:29.678409: \n",
      "2024-12-06 05:00:29.688408: Epoch 666\n",
      "2024-12-06 05:00:29.695835: Current learning rate: 0.00373\n",
      "2024-12-06 05:02:40.918815: train_loss -0.8423\n",
      "2024-12-06 05:02:40.925543: val_loss -0.4956\n",
      "2024-12-06 05:02:40.943030: Pseudo dice [0.7957]\n",
      "2024-12-06 05:02:40.949032: Epoch time: 131.24 s\n",
      "2024-12-06 05:02:42.075415: \n",
      "2024-12-06 05:02:42.085415: Epoch 667\n",
      "2024-12-06 05:02:42.092094: Current learning rate: 0.00372\n",
      "2024-12-06 05:04:53.406466: train_loss -0.8378\n",
      "2024-12-06 05:04:53.415969: val_loss -0.1063\n",
      "2024-12-06 05:04:53.422575: Pseudo dice [0.6281]\n",
      "2024-12-06 05:04:53.432574: Epoch time: 131.33 s\n",
      "2024-12-06 05:04:54.605863: \n",
      "2024-12-06 05:04:54.605863: Epoch 668\n",
      "2024-12-06 05:04:54.615862: Current learning rate: 0.00371\n",
      "2024-12-06 05:07:06.036158: train_loss -0.8383\n",
      "2024-12-06 05:07:06.046157: val_loss -0.4436\n",
      "2024-12-06 05:07:06.052878: Pseudo dice [0.8142]\n",
      "2024-12-06 05:07:06.062877: Epoch time: 131.43 s\n",
      "2024-12-06 05:07:07.396066: \n",
      "2024-12-06 05:07:07.402734: Epoch 669\n",
      "2024-12-06 05:07:07.402734: Current learning rate: 0.0037\n",
      "2024-12-06 05:09:18.697954: train_loss -0.8386\n",
      "2024-12-06 05:09:18.701908: val_loss -0.0792\n",
      "2024-12-06 05:09:18.716182: Pseudo dice [0.4226]\n",
      "2024-12-06 05:09:18.718349: Epoch time: 131.3 s\n",
      "2024-12-06 05:09:19.849765: \n",
      "2024-12-06 05:09:19.859765: Epoch 670\n",
      "2024-12-06 05:09:19.868170: Current learning rate: 0.00369\n",
      "2024-12-06 05:11:31.147510: train_loss -0.8171\n",
      "2024-12-06 05:11:31.157012: val_loss 0.05\n",
      "2024-12-06 05:11:31.163471: Pseudo dice [0.4668]\n",
      "2024-12-06 05:11:31.163471: Epoch time: 131.3 s\n",
      "2024-12-06 05:11:32.313506: \n",
      "2024-12-06 05:11:32.323505: Epoch 671\n",
      "2024-12-06 05:11:32.323505: Current learning rate: 0.00368\n",
      "2024-12-06 05:13:43.677109: train_loss -0.8411\n",
      "2024-12-06 05:13:43.694520: val_loss -0.5076\n",
      "2024-12-06 05:13:43.695921: Pseudo dice [0.8253]\n",
      "2024-12-06 05:13:43.705919: Epoch time: 131.36 s\n",
      "2024-12-06 05:13:44.846612: \n",
      "2024-12-06 05:13:44.853614: Epoch 672\n",
      "2024-12-06 05:13:44.858615: Current learning rate: 0.00367\n",
      "2024-12-06 05:15:56.090934: train_loss -0.8257\n",
      "2024-12-06 05:15:56.100932: val_loss -0.4233\n",
      "2024-12-06 05:15:56.107490: Pseudo dice [0.7609]\n",
      "2024-12-06 05:15:56.107490: Epoch time: 131.25 s\n",
      "2024-12-06 05:15:57.257393: \n",
      "2024-12-06 05:15:57.267393: Epoch 673\n",
      "2024-12-06 05:15:57.273827: Current learning rate: 0.00366\n",
      "2024-12-06 05:18:08.687876: train_loss -0.8231\n",
      "2024-12-06 05:18:08.704532: val_loss -0.3963\n",
      "2024-12-06 05:18:08.714530: Pseudo dice [0.7457]\n",
      "2024-12-06 05:18:08.721177: Epoch time: 131.43 s\n",
      "2024-12-06 05:18:09.864422: \n",
      "2024-12-06 05:18:09.871023: Epoch 674\n",
      "2024-12-06 05:18:09.881022: Current learning rate: 0.00365\n",
      "2024-12-06 05:20:21.328161: train_loss -0.8141\n",
      "2024-12-06 05:20:21.336000: val_loss -0.1899\n",
      "2024-12-06 05:20:21.345999: Pseudo dice [0.6209]\n",
      "2024-12-06 05:20:21.352525: Epoch time: 131.46 s\n",
      "2024-12-06 05:20:22.628107: \n",
      "2024-12-06 05:20:22.634763: Epoch 675\n",
      "2024-12-06 05:20:22.634763: Current learning rate: 0.00364\n",
      "2024-12-06 05:22:33.908449: train_loss -0.8104\n",
      "2024-12-06 05:22:33.915240: val_loss -0.2803\n",
      "2024-12-06 05:22:33.925239: Pseudo dice [0.7247]\n",
      "2024-12-06 05:22:33.931781: Epoch time: 131.28 s\n",
      "2024-12-06 05:22:35.358413: \n",
      "2024-12-06 05:22:35.366676: Epoch 676\n",
      "2024-12-06 05:22:35.366676: Current learning rate: 0.00363\n",
      "2024-12-06 05:24:46.755468: train_loss -0.8289\n",
      "2024-12-06 05:24:46.763198: val_loss -0.6082\n",
      "2024-12-06 05:24:46.779307: Pseudo dice [0.8644]\n",
      "2024-12-06 05:24:46.779307: Epoch time: 131.4 s\n",
      "2024-12-06 05:24:47.929682: \n",
      "2024-12-06 05:24:47.946157: Epoch 677\n",
      "2024-12-06 05:24:47.946423: Current learning rate: 0.00362\n",
      "2024-12-06 05:26:59.247101: train_loss -0.8233\n",
      "2024-12-06 05:26:59.257103: val_loss -0.3506\n",
      "2024-12-06 05:26:59.259145: Pseudo dice [0.7573]\n",
      "2024-12-06 05:26:59.269143: Epoch time: 131.32 s\n",
      "2024-12-06 05:27:00.409043: \n",
      "2024-12-06 05:27:00.419043: Epoch 678\n",
      "2024-12-06 05:27:00.425723: Current learning rate: 0.00361\n",
      "2024-12-06 05:29:11.766186: train_loss -0.8306\n",
      "2024-12-06 05:29:11.775512: val_loss -0.5232\n",
      "2024-12-06 05:29:11.775512: Pseudo dice [0.8326]\n",
      "2024-12-06 05:29:11.789162: Epoch time: 131.36 s\n",
      "2024-12-06 05:29:12.922708: \n",
      "2024-12-06 05:29:12.932707: Epoch 679\n",
      "2024-12-06 05:29:12.941308: Current learning rate: 0.0036\n",
      "2024-12-06 05:31:24.396526: train_loss -0.8154\n",
      "2024-12-06 05:31:24.404804: val_loss -0.3329\n",
      "2024-12-06 05:31:24.419890: Pseudo dice [0.5748]\n",
      "2024-12-06 05:31:24.419890: Epoch time: 131.47 s\n",
      "2024-12-06 05:31:25.613032: \n",
      "2024-12-06 05:31:25.619685: Epoch 680\n",
      "2024-12-06 05:31:25.619685: Current learning rate: 0.00359\n",
      "2024-12-06 05:33:36.997267: train_loss -0.8315\n",
      "2024-12-06 05:33:37.002173: val_loss -0.3162\n",
      "2024-12-06 05:33:37.017491: Pseudo dice [0.6697]\n",
      "2024-12-06 05:33:37.018244: Epoch time: 131.38 s\n",
      "2024-12-06 05:33:38.167449: \n",
      "2024-12-06 05:33:38.168350: Epoch 681\n",
      "2024-12-06 05:33:38.177853: Current learning rate: 0.00358\n",
      "2024-12-06 05:35:49.447208: train_loss -0.8309\n",
      "2024-12-06 05:35:49.465483: val_loss -0.5427\n",
      "2024-12-06 05:35:49.465657: Pseudo dice [0.8362]\n",
      "2024-12-06 05:35:49.475656: Epoch time: 131.28 s\n",
      "2024-12-06 05:35:50.630347: \n",
      "2024-12-06 05:35:50.647800: Epoch 682\n",
      "2024-12-06 05:35:50.648752: Current learning rate: 0.00357\n",
      "2024-12-06 05:38:02.094857: train_loss -0.8367\n",
      "2024-12-06 05:38:02.095603: val_loss -0.4427\n",
      "2024-12-06 05:38:02.105107: Pseudo dice [0.7689]\n",
      "2024-12-06 05:38:02.111307: Epoch time: 131.46 s\n",
      "2024-12-06 05:38:03.427106: \n",
      "2024-12-06 05:38:03.428738: Epoch 683\n",
      "2024-12-06 05:38:03.438241: Current learning rate: 0.00356\n",
      "2024-12-06 05:40:14.657834: train_loss -0.8433\n",
      "2024-12-06 05:40:14.667833: val_loss -0.4379\n",
      "2024-12-06 05:40:14.674462: Pseudo dice [0.7366]\n",
      "2024-12-06 05:40:14.674462: Epoch time: 131.24 s\n",
      "2024-12-06 05:40:15.807817: \n",
      "2024-12-06 05:40:15.817816: Epoch 684\n",
      "2024-12-06 05:40:15.824349: Current learning rate: 0.00355\n",
      "2024-12-06 05:42:27.304832: train_loss -0.836\n",
      "2024-12-06 05:42:27.321495: val_loss -0.4681\n",
      "2024-12-06 05:42:27.321495: Pseudo dice [0.7385]\n",
      "2024-12-06 05:42:27.331493: Epoch time: 131.5 s\n",
      "2024-12-06 05:42:28.531377: \n",
      "2024-12-06 05:42:28.538033: Epoch 685\n",
      "2024-12-06 05:42:28.548032: Current learning rate: 0.00354\n",
      "2024-12-06 05:44:39.963908: train_loss -0.8428\n",
      "2024-12-06 05:44:39.969241: val_loss -0.3428\n",
      "2024-12-06 05:44:39.985578: Pseudo dice [0.6627]\n",
      "2024-12-06 05:44:39.995081: Epoch time: 131.43 s\n",
      "2024-12-06 05:44:41.236778: \n",
      "2024-12-06 05:44:41.236778: Epoch 686\n",
      "2024-12-06 05:44:41.246803: Current learning rate: 0.00353\n",
      "2024-12-06 05:46:52.500457: train_loss -0.8375\n",
      "2024-12-06 05:46:52.510456: val_loss -0.3686\n",
      "2024-12-06 05:46:52.515382: Pseudo dice [0.73]\n",
      "2024-12-06 05:46:52.525380: Epoch time: 131.26 s\n",
      "2024-12-06 05:46:53.698719: \n",
      "2024-12-06 05:46:53.708718: Epoch 687\n",
      "2024-12-06 05:46:53.715338: Current learning rate: 0.00352\n",
      "2024-12-06 05:49:05.112476: train_loss -0.8277\n",
      "2024-12-06 05:49:05.122476: val_loss -0.4034\n",
      "2024-12-06 05:49:05.129102: Pseudo dice [0.7561]\n",
      "2024-12-06 05:49:05.139101: Epoch time: 131.41 s\n",
      "2024-12-06 05:49:06.329013: \n",
      "2024-12-06 05:49:06.339012: Epoch 688\n",
      "2024-12-06 05:49:06.347307: Current learning rate: 0.00351\n",
      "2024-12-06 05:51:17.668922: train_loss -0.8443\n",
      "2024-12-06 05:51:17.676095: val_loss -0.2663\n",
      "2024-12-06 05:51:17.686093: Pseudo dice [0.7089]\n",
      "2024-12-06 05:51:17.692814: Epoch time: 131.34 s\n",
      "2024-12-06 05:51:18.835981: \n",
      "2024-12-06 05:51:18.846482: Epoch 689\n",
      "2024-12-06 05:51:18.850483: Current learning rate: 0.0035\n",
      "2024-12-06 05:53:30.166377: train_loss -0.845\n",
      "2024-12-06 05:53:30.173117: val_loss -0.583\n",
      "2024-12-06 05:53:30.183115: Pseudo dice [0.8577]\n",
      "2024-12-06 05:53:30.189423: Epoch time: 131.33 s\n",
      "2024-12-06 05:53:31.606331: \n",
      "2024-12-06 05:53:31.616330: Epoch 690\n",
      "2024-12-06 05:53:31.622985: Current learning rate: 0.00349\n",
      "2024-12-06 05:55:43.080024: train_loss -0.8302\n",
      "2024-12-06 05:55:43.086733: val_loss -0.1499\n",
      "2024-12-06 05:55:43.096732: Pseudo dice [0.6265]\n",
      "2024-12-06 05:55:43.096732: Epoch time: 131.47 s\n",
      "2024-12-06 05:55:44.296658: \n",
      "2024-12-06 05:55:44.303328: Epoch 691\n",
      "2024-12-06 05:55:44.303328: Current learning rate: 0.00348\n",
      "2024-12-06 05:57:55.697507: train_loss -0.8332\n",
      "2024-12-06 05:57:55.702786: val_loss -0.3661\n",
      "2024-12-06 05:57:55.712290: Pseudo dice [0.6877]\n",
      "2024-12-06 05:57:55.717096: Epoch time: 131.4 s\n",
      "2024-12-06 05:57:56.926990: \n",
      "2024-12-06 05:57:56.933639: Epoch 692\n",
      "2024-12-06 05:57:56.943638: Current learning rate: 0.00346\n",
      "2024-12-06 06:00:08.207435: train_loss -0.8312\n",
      "2024-12-06 06:00:08.214037: val_loss -0.177\n",
      "2024-12-06 06:00:08.224034: Pseudo dice [0.6877]\n",
      "2024-12-06 06:00:08.231696: Epoch time: 131.28 s\n",
      "2024-12-06 06:00:09.497535: \n",
      "2024-12-06 06:00:09.507040: Epoch 693\n",
      "2024-12-06 06:00:09.507040: Current learning rate: 0.00345\n",
      "2024-12-06 06:02:21.011067: train_loss -0.832\n",
      "2024-12-06 06:02:21.021065: val_loss -0.0959\n",
      "2024-12-06 06:02:21.029481: Pseudo dice [0.5497]\n",
      "2024-12-06 06:02:21.029481: Epoch time: 131.51 s\n",
      "2024-12-06 06:02:22.277745: \n",
      "2024-12-06 06:02:22.277745: Epoch 694\n",
      "2024-12-06 06:02:22.287745: Current learning rate: 0.00344\n",
      "2024-12-06 06:04:33.526540: train_loss -0.851\n",
      "2024-12-06 06:04:33.545189: val_loss -0.5023\n",
      "2024-12-06 06:04:33.554191: Pseudo dice [0.8045]\n",
      "2024-12-06 06:04:33.558054: Epoch time: 131.25 s\n",
      "2024-12-06 06:04:34.757913: \n",
      "2024-12-06 06:04:34.767912: Epoch 695\n",
      "2024-12-06 06:04:34.774560: Current learning rate: 0.00343\n",
      "2024-12-06 06:06:46.250227: train_loss -0.8336\n",
      "2024-12-06 06:06:46.255843: val_loss -0.3097\n",
      "2024-12-06 06:06:46.271713: Pseudo dice [0.6473]\n",
      "2024-12-06 06:06:46.271713: Epoch time: 131.49 s\n",
      "2024-12-06 06:06:47.488261: \n",
      "2024-12-06 06:06:47.498260: Epoch 696\n",
      "2024-12-06 06:06:47.504880: Current learning rate: 0.00342\n",
      "2024-12-06 06:08:58.945329: train_loss -0.8536\n",
      "2024-12-06 06:08:58.951975: val_loss -0.4049\n",
      "2024-12-06 06:08:58.961974: Pseudo dice [0.7487]\n",
      "2024-12-06 06:08:58.968695: Epoch time: 131.46 s\n",
      "2024-12-06 06:09:00.345245: \n",
      "2024-12-06 06:09:00.352869: Epoch 697\n",
      "2024-12-06 06:09:00.352869: Current learning rate: 0.00341\n",
      "2024-12-06 06:11:11.627658: train_loss -0.8499\n",
      "2024-12-06 06:11:11.632835: val_loss -0.3962\n",
      "2024-12-06 06:11:11.642338: Pseudo dice [0.6992]\n",
      "2024-12-06 06:11:11.648945: Epoch time: 131.28 s\n",
      "2024-12-06 06:11:12.798931: \n",
      "2024-12-06 06:11:12.808929: Epoch 698\n",
      "2024-12-06 06:11:12.815528: Current learning rate: 0.0034\n",
      "2024-12-06 06:13:24.178974: train_loss -0.8449\n",
      "2024-12-06 06:13:24.181555: val_loss -0.1322\n",
      "2024-12-06 06:13:24.191057: Pseudo dice [0.6262]\n",
      "2024-12-06 06:13:24.196524: Epoch time: 131.38 s\n",
      "2024-12-06 06:13:25.389188: \n",
      "2024-12-06 06:13:25.395854: Epoch 699\n",
      "2024-12-06 06:13:25.405853: Current learning rate: 0.00339\n",
      "2024-12-06 06:15:36.792632: train_loss -0.8229\n",
      "2024-12-06 06:15:36.793863: val_loss -0.4525\n",
      "2024-12-06 06:15:36.810188: Pseudo dice [0.7097]\n",
      "2024-12-06 06:15:36.810188: Epoch time: 131.4 s\n",
      "2024-12-06 06:15:38.219507: \n",
      "2024-12-06 06:15:38.226170: Epoch 700\n",
      "2024-12-06 06:15:38.226170: Current learning rate: 0.00338\n",
      "2024-12-06 06:17:49.506664: train_loss -0.8478\n",
      "2024-12-06 06:17:49.516663: val_loss -0.4502\n",
      "2024-12-06 06:17:49.524418: Pseudo dice [0.7155]\n",
      "2024-12-06 06:17:49.524418: Epoch time: 131.29 s\n",
      "2024-12-06 06:17:50.656533: \n",
      "2024-12-06 06:17:50.673913: Epoch 701\n",
      "2024-12-06 06:17:50.674210: Current learning rate: 0.00337\n",
      "2024-12-06 06:20:02.096917: train_loss -0.844\n",
      "2024-12-06 06:20:02.105676: val_loss -0.6354\n",
      "2024-12-06 06:20:02.115674: Pseudo dice [0.8354]\n",
      "2024-12-06 06:20:02.121008: Epoch time: 131.44 s\n",
      "2024-12-06 06:20:03.253502: \n",
      "2024-12-06 06:20:03.263499: Epoch 702\n",
      "2024-12-06 06:20:03.271984: Current learning rate: 0.00336\n",
      "2024-12-06 06:22:14.660619: train_loss -0.8256\n",
      "2024-12-06 06:22:14.667274: val_loss -0.4883\n",
      "2024-12-06 06:22:14.683671: Pseudo dice [0.775]\n",
      "2024-12-06 06:22:14.690351: Epoch time: 131.41 s\n",
      "2024-12-06 06:22:15.950661: \n",
      "2024-12-06 06:22:15.950661: Epoch 703\n",
      "2024-12-06 06:22:15.960659: Current learning rate: 0.00335\n",
      "2024-12-06 06:24:27.130913: train_loss -0.8246\n",
      "2024-12-06 06:24:27.140910: val_loss -0.4777\n",
      "2024-12-06 06:24:27.147659: Pseudo dice [0.8]\n",
      "2024-12-06 06:24:27.147659: Epoch time: 131.18 s\n",
      "2024-12-06 06:24:28.414380: \n",
      "2024-12-06 06:24:28.414380: Epoch 704\n",
      "2024-12-06 06:24:28.424378: Current learning rate: 0.00334\n",
      "2024-12-06 06:26:39.861151: train_loss -0.7915\n",
      "2024-12-06 06:26:39.871150: val_loss -0.315\n",
      "2024-12-06 06:26:39.877836: Pseudo dice [0.6945]\n",
      "2024-12-06 06:26:39.877836: Epoch time: 131.45 s\n",
      "2024-12-06 06:26:41.046130: \n",
      "2024-12-06 06:26:41.055633: Epoch 705\n",
      "2024-12-06 06:26:41.061222: Current learning rate: 0.00333\n",
      "2024-12-06 06:28:52.241289: train_loss -0.7982\n",
      "2024-12-06 06:28:52.243780: val_loss -0.4113\n",
      "2024-12-06 06:28:52.258278: Pseudo dice [0.7349]\n",
      "2024-12-06 06:28:52.258278: Epoch time: 131.2 s\n",
      "2024-12-06 06:28:53.501517: \n",
      "2024-12-06 06:28:53.509768: Epoch 706\n",
      "2024-12-06 06:28:53.509768: Current learning rate: 0.00332\n",
      "2024-12-06 06:31:04.872636: train_loss -0.8224\n",
      "2024-12-06 06:31:04.882960: val_loss -0.519\n",
      "2024-12-06 06:31:04.888246: Pseudo dice [0.8109]\n",
      "2024-12-06 06:31:04.889200: Epoch time: 131.37 s\n",
      "2024-12-06 06:31:06.132731: \n",
      "2024-12-06 06:31:06.138585: Epoch 707\n",
      "2024-12-06 06:31:06.138585: Current learning rate: 0.00331\n",
      "2024-12-06 06:33:17.586018: train_loss -0.8205\n",
      "2024-12-06 06:33:17.596017: val_loss -0.5241\n",
      "2024-12-06 06:33:17.602207: Pseudo dice [0.8094]\n",
      "2024-12-06 06:33:17.602207: Epoch time: 131.46 s\n",
      "2024-12-06 06:33:18.812085: \n",
      "2024-12-06 06:33:18.818830: Epoch 708\n",
      "2024-12-06 06:33:18.818830: Current learning rate: 0.0033\n",
      "2024-12-06 06:35:30.115947: train_loss -0.8171\n",
      "2024-12-06 06:35:30.125945: val_loss -0.4239\n",
      "2024-12-06 06:35:30.132535: Pseudo dice [0.7742]\n",
      "2024-12-06 06:35:30.142533: Epoch time: 131.31 s\n",
      "2024-12-06 06:35:31.284408: \n",
      "2024-12-06 06:35:31.291409: Epoch 709\n",
      "2024-12-06 06:35:31.296410: Current learning rate: 0.00329\n",
      "2024-12-06 06:37:42.596189: train_loss -0.8211\n",
      "2024-12-06 06:37:42.606188: val_loss -0.3225\n",
      "2024-12-06 06:37:42.612891: Pseudo dice [0.74]\n",
      "2024-12-06 06:37:42.612891: Epoch time: 131.31 s\n",
      "2024-12-06 06:37:44.062517: \n",
      "2024-12-06 06:37:44.063332: Epoch 710\n",
      "2024-12-06 06:37:44.072835: Current learning rate: 0.00328\n",
      "2024-12-06 06:39:55.411352: train_loss -0.8095\n",
      "2024-12-06 06:39:55.420855: val_loss -0.5286\n",
      "2024-12-06 06:39:55.426534: Pseudo dice [0.8085]\n",
      "2024-12-06 06:39:55.436532: Epoch time: 131.35 s\n",
      "2024-12-06 06:39:56.676432: \n",
      "2024-12-06 06:39:56.686430: Epoch 711\n",
      "2024-12-06 06:39:56.693073: Current learning rate: 0.00327\n",
      "2024-12-06 06:42:07.940668: train_loss -0.8243\n",
      "2024-12-06 06:42:07.956795: val_loss -0.4933\n",
      "2024-12-06 06:42:07.956795: Pseudo dice [0.8338]\n",
      "2024-12-06 06:42:07.966795: Epoch time: 131.26 s\n",
      "2024-12-06 06:42:09.156789: \n",
      "2024-12-06 06:42:09.173158: Epoch 712\n",
      "2024-12-06 06:42:09.173409: Current learning rate: 0.00326\n",
      "2024-12-06 06:44:20.570467: train_loss -0.8453\n",
      "2024-12-06 06:44:20.587212: val_loss -0.5113\n",
      "2024-12-06 06:44:20.653757: Pseudo dice [0.8133]\n",
      "2024-12-06 06:44:20.653757: Epoch time: 131.41 s\n",
      "2024-12-06 06:44:21.903812: \n",
      "2024-12-06 06:44:21.920488: Epoch 713\n",
      "2024-12-06 06:44:21.920488: Current learning rate: 0.00325\n",
      "2024-12-06 06:46:33.334573: train_loss -0.8289\n",
      "2024-12-06 06:46:33.344571: val_loss -0.4741\n",
      "2024-12-06 06:46:33.350814: Pseudo dice [0.7988]\n",
      "2024-12-06 06:46:33.360813: Epoch time: 131.43 s\n",
      "2024-12-06 06:46:34.544996: \n",
      "2024-12-06 06:46:34.551175: Epoch 714\n",
      "2024-12-06 06:46:34.551175: Current learning rate: 0.00324\n",
      "2024-12-06 06:48:45.764468: train_loss -0.827\n",
      "2024-12-06 06:48:45.780830: val_loss -0.5794\n",
      "2024-12-06 06:48:45.783231: Pseudo dice [0.855]\n",
      "2024-12-06 06:48:45.797875: Epoch time: 131.22 s\n",
      "2024-12-06 06:48:45.797875: Yayy! New best EMA pseudo Dice: 0.7771\n",
      "2024-12-06 06:48:47.231059: \n",
      "2024-12-06 06:48:47.241058: Epoch 715\n",
      "2024-12-06 06:48:47.247781: Current learning rate: 0.00323\n",
      "2024-12-06 06:50:58.721420: train_loss -0.8406\n",
      "2024-12-06 06:50:58.728080: val_loss -0.4465\n",
      "2024-12-06 06:50:58.744604: Pseudo dice [0.7854]\n",
      "2024-12-06 06:50:58.746443: Epoch time: 131.49 s\n",
      "2024-12-06 06:50:58.746443: Yayy! New best EMA pseudo Dice: 0.778\n",
      "2024-12-06 06:51:00.221398: \n",
      "2024-12-06 06:51:00.229737: Epoch 716\n",
      "2024-12-06 06:51:00.229737: Current learning rate: 0.00322\n",
      "2024-12-06 06:53:11.468432: train_loss -0.8296\n",
      "2024-12-06 06:53:11.475106: val_loss -0.1871\n",
      "2024-12-06 06:53:11.485105: Pseudo dice [0.7323]\n",
      "2024-12-06 06:53:11.491830: Epoch time: 131.25 s\n",
      "2024-12-06 06:53:12.818374: \n",
      "2024-12-06 06:53:12.825007: Epoch 717\n",
      "2024-12-06 06:53:12.825007: Current learning rate: 0.00321\n",
      "2024-12-06 06:55:24.190266: train_loss -0.8329\n",
      "2024-12-06 06:55:24.205121: val_loss -0.3471\n",
      "2024-12-06 06:55:24.207245: Pseudo dice [0.7816]\n",
      "2024-12-06 06:55:24.217244: Epoch time: 131.37 s\n",
      "2024-12-06 06:55:25.366219: \n",
      "2024-12-06 06:55:25.372945: Epoch 718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nnunetv2\\training\\nnUNetTrainer\\nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
      "C:\\Users\\PC\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 06:55:25.382945: Current learning rate: 0.0032\n",
      "2024-12-06 06:57:36.802444: train_loss -0.7933\n",
      "2024-12-06 06:57:36.819063: val_loss -0.4051\n",
      "2024-12-06 06:57:36.829061: Pseudo dice [0.7403]\n",
      "2024-12-06 06:57:36.835720: Epoch time: 131.44 s\n",
      "2024-12-06 06:57:37.979007: \n",
      "2024-12-06 06:57:37.985658: Epoch 719\n",
      "2024-12-06 06:57:37.985658: Current learning rate: 0.00319\n",
      "2024-12-06 06:59:49.309460: train_loss -0.8321\n",
      "2024-12-06 06:59:49.317988: val_loss -0.5259\n",
      "2024-12-06 06:59:49.327988: Pseudo dice [0.795]\n",
      "2024-12-06 06:59:49.332741: Epoch time: 131.33 s\n",
      "2024-12-06 06:59:50.532680: \n",
      "2024-12-06 06:59:50.542679: Epoch 720\n",
      "2024-12-06 06:59:50.549328: Current learning rate: 0.00318\n",
      "2024-12-06 07:02:01.913169: train_loss -0.842\n",
      "2024-12-06 07:02:01.923168: val_loss -0.3954\n",
      "2024-12-06 07:02:01.931404: Pseudo dice [0.7439]\n",
      "2024-12-06 07:02:01.931404: Epoch time: 131.38 s\n",
      "2024-12-06 07:02:03.096313: \n",
      "2024-12-06 07:02:03.106312: Epoch 721\n",
      "2024-12-06 07:02:03.114692: Current learning rate: 0.00317\n",
      "2024-12-06 07:04:14.449196: train_loss -0.8467\n",
      "2024-12-06 07:04:14.459762: val_loss -0.488\n",
      "2024-12-06 07:04:14.461390: Pseudo dice [0.7945]\n",
      "2024-12-06 07:04:14.461390: Epoch time: 131.35 s\n",
      "2024-12-06 07:04:15.636628: \n",
      "2024-12-06 07:04:15.644910: Epoch 722\n",
      "2024-12-06 07:04:15.644910: Current learning rate: 0.00316\n",
      "2024-12-06 07:06:26.906737: train_loss -0.841\n",
      "2024-12-06 07:06:26.918870: val_loss -0.4051\n",
      "2024-12-06 07:06:26.923717: Pseudo dice [0.7411]\n",
      "2024-12-06 07:06:26.923717: Epoch time: 131.27 s\n",
      "2024-12-06 07:06:28.133676: \n",
      "2024-12-06 07:06:28.140415: Epoch 723\n",
      "2024-12-06 07:06:28.140415: Current learning rate: 0.00315\n",
      "2024-12-06 07:08:39.680722: train_loss -0.8311\n",
      "2024-12-06 07:08:39.688989: val_loss -0.3682\n",
      "2024-12-06 07:08:39.698492: Pseudo dice [0.7996]\n",
      "2024-12-06 07:08:39.704138: Epoch time: 131.55 s\n",
      "2024-12-06 07:08:41.037283: \n",
      "2024-12-06 07:08:41.047282: Epoch 724\n",
      "2024-12-06 07:08:41.055803: Current learning rate: 0.00314\n",
      "2024-12-06 07:10:52.477807: train_loss -0.8206\n",
      "2024-12-06 07:10:52.486027: val_loss -0.1588\n",
      "2024-12-06 07:10:52.495532: Pseudo dice [0.5626]\n",
      "2024-12-06 07:10:52.501663: Epoch time: 131.44 s\n",
      "2024-12-06 07:10:53.753266: \n",
      "2024-12-06 07:10:53.760772: Epoch 725\n",
      "2024-12-06 07:10:53.768355: Current learning rate: 0.00313\n",
      "2024-12-06 07:13:04.965322: train_loss -0.8437\n",
      "2024-12-06 07:13:04.975354: val_loss -0.4028\n",
      "2024-12-06 07:13:04.985183: Pseudo dice [0.7087]\n",
      "2024-12-06 07:13:04.990184: Epoch time: 131.21 s\n",
      "2024-12-06 07:13:06.209183: \n",
      "2024-12-06 07:13:06.216415: Epoch 726\n",
      "2024-12-06 07:13:06.216415: Current learning rate: 0.00312\n",
      "2024-12-06 07:15:17.621657: train_loss -0.8478\n",
      "2024-12-06 07:15:17.629474: val_loss -0.3516\n",
      "2024-12-06 07:15:17.646697: Pseudo dice [0.7007]\n",
      "2024-12-06 07:15:17.648825: Epoch time: 131.41 s\n",
      "2024-12-06 07:15:18.861841: \n",
      "2024-12-06 07:15:18.861841: Epoch 727\n",
      "2024-12-06 07:15:18.871840: Current learning rate: 0.00311\n",
      "2024-12-06 07:17:30.075279: train_loss -0.8444\n",
      "2024-12-06 07:17:30.085277: val_loss -0.329\n",
      "2024-12-06 07:17:30.092125: Pseudo dice [0.7386]\n",
      "2024-12-06 07:17:30.102123: Epoch time: 131.21 s\n",
      "2024-12-06 07:17:31.353866: \n",
      "2024-12-06 07:17:31.360128: Epoch 728\n",
      "2024-12-06 07:17:31.360128: Current learning rate: 0.0031\n",
      "2024-12-06 07:19:42.732347: train_loss -0.8476\n",
      "2024-12-06 07:19:42.739014: val_loss -0.4661\n",
      "2024-12-06 07:19:42.749013: Pseudo dice [0.8297]\n",
      "2024-12-06 07:19:42.755684: Epoch time: 131.38 s\n",
      "2024-12-06 07:19:43.905593: \n",
      "2024-12-06 07:19:43.915592: Epoch 729\n",
      "2024-12-06 07:19:43.922242: Current learning rate: 0.00309\n",
      "2024-12-06 07:21:55.402776: train_loss -0.8423\n",
      "2024-12-06 07:21:55.419371: val_loss -0.3726\n",
      "2024-12-06 07:21:55.429370: Pseudo dice [0.7084]\n",
      "2024-12-06 07:21:55.436006: Epoch time: 131.5 s\n",
      "2024-12-06 07:21:56.702612: \n",
      "2024-12-06 07:21:56.712611: Epoch 730\n",
      "2024-12-06 07:21:56.719299: Current learning rate: 0.00308\n",
      "2024-12-06 07:24:08.126313: train_loss -0.8259\n",
      "2024-12-06 07:24:08.143812: val_loss -0.1526\n",
      "2024-12-06 07:24:08.150589: Pseudo dice [0.6411]\n",
      "2024-12-06 07:24:08.160588: Epoch time: 131.42 s\n",
      "2024-12-06 07:24:09.549581: \n",
      "2024-12-06 07:24:09.559580: Epoch 731\n",
      "2024-12-06 07:24:09.566197: Current learning rate: 0.00307\n",
      "2024-12-06 07:26:20.905142: train_loss -0.834\n",
      "2024-12-06 07:26:20.915142: val_loss -0.516\n",
      "2024-12-06 07:26:20.929733: Pseudo dice [0.8312]\n",
      "2024-12-06 07:26:20.939742: Epoch time: 131.36 s\n",
      "2024-12-06 07:26:22.159712: \n",
      "2024-12-06 07:26:22.169712: Epoch 732\n",
      "2024-12-06 07:26:22.179713: Current learning rate: 0.00306\n",
      "2024-12-06 07:28:33.610797: train_loss -0.8437\n",
      "2024-12-06 07:28:33.620302: val_loss -0.3229\n",
      "2024-12-06 07:28:33.627663: Pseudo dice [0.7374]\n",
      "2024-12-06 07:28:33.629020: Epoch time: 131.45 s\n",
      "2024-12-06 07:28:34.771158: \n",
      "2024-12-06 07:28:34.777381: Epoch 733\n",
      "2024-12-06 07:28:34.786885: Current learning rate: 0.00305\n",
      "2024-12-06 07:30:46.106981: train_loss -0.8402\n",
      "2024-12-06 07:30:46.107376: val_loss -0.4774\n",
      "2024-12-06 07:30:46.123994: Pseudo dice [0.8457]\n",
      "2024-12-06 07:30:46.123994: Epoch time: 131.34 s\n",
      "2024-12-06 07:30:47.273877: \n",
      "2024-12-06 07:30:47.283875: Epoch 734\n",
      "2024-12-06 07:30:47.290518: Current learning rate: 0.00304\n",
      "2024-12-06 07:32:58.799693: train_loss -0.8464\n",
      "2024-12-06 07:32:58.805222: val_loss -0.4991\n",
      "2024-12-06 07:32:58.821004: Pseudo dice [0.853]\n",
      "2024-12-06 07:32:58.821004: Epoch time: 131.53 s\n",
      "2024-12-06 07:33:00.037579: \n",
      "2024-12-06 07:33:00.047578: Epoch 735\n",
      "2024-12-06 07:33:00.054198: Current learning rate: 0.00303\n",
      "2024-12-06 07:35:11.594577: train_loss -0.8275\n",
      "2024-12-06 07:35:11.601444: val_loss -0.3194\n",
      "2024-12-06 07:35:11.601444: Pseudo dice [0.7522]\n",
      "2024-12-06 07:35:11.618645: Epoch time: 131.56 s\n",
      "2024-12-06 07:35:12.761190: \n",
      "2024-12-06 07:35:12.767867: Epoch 736\n",
      "2024-12-06 07:35:12.777866: Current learning rate: 0.00302\n",
      "2024-12-06 07:37:24.047957: train_loss -0.8294\n",
      "2024-12-06 07:37:24.058188: val_loss -0.2585\n",
      "2024-12-06 07:37:24.064979: Pseudo dice [0.5658]\n",
      "2024-12-06 07:37:24.064979: Epoch time: 131.29 s\n",
      "2024-12-06 07:37:25.214898: \n",
      "2024-12-06 07:37:25.231554: Epoch 737\n",
      "2024-12-06 07:37:25.231554: Current learning rate: 0.00301\n",
      "2024-12-06 07:39:36.778690: train_loss -0.8255\n",
      "2024-12-06 07:39:36.788690: val_loss -0.6009\n",
      "2024-12-06 07:39:36.795286: Pseudo dice [0.8573]\n",
      "2024-12-06 07:39:36.805285: Epoch time: 131.56 s\n",
      "2024-12-06 07:39:38.145187: \n",
      "2024-12-06 07:39:38.161591: Epoch 738\n",
      "2024-12-06 07:39:38.162849: Current learning rate: 0.003\n",
      "2024-12-06 07:41:49.508979: train_loss -0.8443\n",
      "2024-12-06 07:41:49.525720: val_loss -0.5289\n",
      "2024-12-06 07:41:49.535719: Pseudo dice [0.8575]\n",
      "2024-12-06 07:41:49.544075: Epoch time: 131.36 s\n",
      "2024-12-06 07:41:50.726569: \n",
      "2024-12-06 07:41:50.736567: Epoch 739\n",
      "2024-12-06 07:41:50.736567: Current learning rate: 0.00299\n",
      "2024-12-06 07:44:02.139203: train_loss -0.8314\n",
      "2024-12-06 07:44:02.156594: val_loss -0.2887\n",
      "2024-12-06 07:44:02.157896: Pseudo dice [0.5717]\n",
      "2024-12-06 07:44:02.167892: Epoch time: 131.41 s\n",
      "2024-12-06 07:44:03.399148: \n",
      "2024-12-06 07:44:03.405795: Epoch 740\n",
      "2024-12-06 07:44:03.405795: Current learning rate: 0.00297\n",
      "2024-12-06 07:46:14.922123: train_loss -0.8363\n",
      "2024-12-06 07:46:14.936301: val_loss 0.4483\n",
      "2024-12-06 07:46:14.952887: Pseudo dice [0.249]\n",
      "2024-12-06 07:46:14.952887: Epoch time: 131.52 s\n",
      "2024-12-06 07:46:16.196164: \n",
      "2024-12-06 07:46:16.204320: Epoch 741\n",
      "2024-12-06 07:46:16.204320: Current learning rate: 0.00296\n",
      "2024-12-06 07:48:27.633305: train_loss -0.8073\n",
      "2024-12-06 07:48:27.649952: val_loss -0.343\n",
      "2024-12-06 07:48:27.659950: Pseudo dice [0.6825]\n",
      "2024-12-06 07:48:27.666611: Epoch time: 131.44 s\n",
      "2024-12-06 07:48:28.900802: \n",
      "2024-12-06 07:48:28.917027: Epoch 742\n",
      "2024-12-06 07:48:28.917027: Current learning rate: 0.00295\n",
      "2024-12-06 07:50:40.256930: train_loss -0.8455\n",
      "2024-12-06 07:50:40.263499: val_loss -0.2857\n",
      "2024-12-06 07:50:40.273498: Pseudo dice [0.6961]\n",
      "2024-12-06 07:50:40.280914: Epoch time: 131.36 s\n",
      "2024-12-06 07:50:41.440149: \n",
      "2024-12-06 07:50:41.446826: Epoch 743\n",
      "2024-12-06 07:50:41.456825: Current learning rate: 0.00294\n",
      "2024-12-06 07:52:52.827125: train_loss -0.8343\n",
      "2024-12-06 07:52:52.837125: val_loss -0.5334\n",
      "2024-12-06 07:52:52.843553: Pseudo dice [0.7895]\n",
      "2024-12-06 07:52:52.852735: Epoch time: 131.39 s\n",
      "2024-12-06 07:52:54.220562: \n",
      "2024-12-06 07:52:54.227109: Epoch 744\n",
      "2024-12-06 07:52:54.227109: Current learning rate: 0.00293\n",
      "2024-12-06 07:55:05.400869: train_loss -0.8378\n",
      "2024-12-06 07:55:05.407519: val_loss -0.4199\n",
      "2024-12-06 07:55:05.417518: Pseudo dice [0.7427]\n",
      "2024-12-06 07:55:05.426025: Epoch time: 131.18 s\n",
      "2024-12-06 07:55:06.573860: \n",
      "2024-12-06 07:55:06.574091: Epoch 745\n",
      "2024-12-06 07:55:06.584089: Current learning rate: 0.00292\n",
      "2024-12-06 07:57:18.037802: train_loss -0.8441\n",
      "2024-12-06 07:57:18.054206: val_loss -0.4733\n",
      "2024-12-06 07:57:18.056788: Pseudo dice [0.7584]\n",
      "2024-12-06 07:57:18.066290: Epoch time: 131.47 s\n",
      "2024-12-06 07:57:19.248792: \n",
      "2024-12-06 07:57:19.254410: Epoch 746\n",
      "2024-12-06 07:57:19.254410: Current learning rate: 0.00291\n",
      "2024-12-06 07:59:30.684839: train_loss -0.8402\n",
      "2024-12-06 07:59:30.701504: val_loss -0.4084\n",
      "2024-12-06 07:59:30.711503: Pseudo dice [0.7509]\n",
      "2024-12-06 07:59:30.718179: Epoch time: 131.44 s\n",
      "2024-12-06 07:59:31.911420: \n",
      "2024-12-06 07:59:31.919453: Epoch 747\n",
      "2024-12-06 07:59:31.928956: Current learning rate: 0.0029\n",
      "2024-12-06 08:01:43.195671: train_loss -0.8547\n",
      "2024-12-06 08:01:43.198562: val_loss -0.5288\n",
      "2024-12-06 08:01:43.215233: Pseudo dice [0.8267]\n",
      "2024-12-06 08:01:43.215233: Epoch time: 131.28 s\n",
      "2024-12-06 08:01:44.408467: \n",
      "2024-12-06 08:01:44.415092: Epoch 748\n",
      "2024-12-06 08:01:44.415092: Current learning rate: 0.00289\n",
      "2024-12-06 08:03:55.822182: train_loss -0.8504\n",
      "2024-12-06 08:03:55.828886: val_loss -0.4865\n",
      "2024-12-06 08:03:55.838885: Pseudo dice [0.8039]\n",
      "2024-12-06 08:03:55.845486: Epoch time: 131.41 s\n",
      "2024-12-06 08:03:57.112938: \n",
      "2024-12-06 08:03:57.122936: Epoch 749\n",
      "2024-12-06 08:03:57.122936: Current learning rate: 0.00288\n",
      "2024-12-06 08:06:08.435800: train_loss -0.8299\n",
      "2024-12-06 08:06:08.447303: val_loss -0.5089\n",
      "2024-12-06 08:06:08.455305: Pseudo dice [0.8405]\n",
      "2024-12-06 08:06:08.459165: Epoch time: 131.32 s\n",
      "2024-12-06 08:06:10.019132: \n",
      "2024-12-06 08:06:10.026901: Epoch 750\n",
      "2024-12-06 08:06:10.026901: Current learning rate: 0.00287\n",
      "2024-12-06 08:08:21.374037: train_loss -0.8447\n",
      "2024-12-06 08:08:21.383540: val_loss -0.3946\n",
      "2024-12-06 08:08:21.390200: Pseudo dice [0.7388]\n",
      "2024-12-06 08:08:21.399703: Epoch time: 131.36 s\n",
      "2024-12-06 08:08:22.866064: \n",
      "2024-12-06 08:08:22.873670: Epoch 751\n",
      "2024-12-06 08:08:22.873670: Current learning rate: 0.00286\n",
      "2024-12-06 08:10:34.329956: train_loss -0.8618\n",
      "2024-12-06 08:10:34.336554: val_loss -0.4829\n",
      "2024-12-06 08:10:34.346553: Pseudo dice [0.8036]\n",
      "2024-12-06 08:10:34.353207: Epoch time: 131.46 s\n",
      "2024-12-06 08:10:35.603059: \n",
      "2024-12-06 08:10:35.613058: Epoch 752\n",
      "2024-12-06 08:10:35.620831: Current learning rate: 0.00285\n",
      "2024-12-06 08:12:46.986278: train_loss -0.8566\n",
      "2024-12-06 08:12:46.996281: val_loss -0.464\n",
      "2024-12-06 08:12:47.000099: Pseudo dice [0.8397]\n",
      "2024-12-06 08:12:47.009602: Epoch time: 131.38 s\n",
      "2024-12-06 08:12:48.176725: \n",
      "2024-12-06 08:12:48.187221: Epoch 753\n",
      "2024-12-06 08:12:48.192222: Current learning rate: 0.00284\n",
      "2024-12-06 08:14:59.447265: train_loss -0.8421\n",
      "2024-12-06 08:14:59.466002: val_loss -0.463\n",
      "2024-12-06 08:14:59.466002: Pseudo dice [0.7821]\n",
      "2024-12-06 08:14:59.475505: Epoch time: 131.27 s\n",
      "2024-12-06 08:15:00.757907: \n",
      "2024-12-06 08:15:00.763668: Epoch 754\n",
      "2024-12-06 08:15:00.763668: Current learning rate: 0.00283\n",
      "2024-12-06 08:17:12.227381: train_loss -0.831\n",
      "2024-12-06 08:17:12.244934: val_loss -0.3548\n",
      "2024-12-06 08:17:12.253936: Pseudo dice [0.7508]\n",
      "2024-12-06 08:17:12.258937: Epoch time: 131.47 s\n",
      "2024-12-06 08:17:13.487360: \n",
      "2024-12-06 08:17:13.494080: Epoch 755\n",
      "2024-12-06 08:17:13.494080: Current learning rate: 0.00282\n",
      "2024-12-06 08:19:24.701093: train_loss -0.8411\n",
      "2024-12-06 08:19:24.707826: val_loss -0.0884\n",
      "2024-12-06 08:19:24.724102: Pseudo dice [0.5458]\n",
      "2024-12-06 08:19:24.724450: Epoch time: 131.21 s\n",
      "2024-12-06 08:19:25.934320: \n",
      "2024-12-06 08:19:25.942595: Epoch 756\n",
      "2024-12-06 08:19:25.942595: Current learning rate: 0.00281\n",
      "2024-12-06 08:21:37.356727: train_loss -0.8386\n",
      "2024-12-06 08:21:37.371504: val_loss -0.37\n",
      "2024-12-06 08:21:37.371504: Pseudo dice [0.7844]\n",
      "2024-12-06 08:21:37.381502: Epoch time: 131.42 s\n",
      "2024-12-06 08:21:38.538011: \n",
      "2024-12-06 08:21:38.548010: Epoch 757\n",
      "2024-12-06 08:21:38.554752: Current learning rate: 0.0028\n",
      "2024-12-06 08:23:49.995028: train_loss -0.8336\n",
      "2024-12-06 08:23:50.002510: val_loss -0.3736\n",
      "2024-12-06 08:23:50.012508: Pseudo dice [0.7533]\n",
      "2024-12-06 08:23:50.019023: Epoch time: 131.46 s\n",
      "2024-12-06 08:23:51.351767: \n",
      "2024-12-06 08:23:51.361764: Epoch 758\n",
      "2024-12-06 08:23:51.361764: Current learning rate: 0.00279\n",
      "2024-12-06 08:26:02.615408: train_loss -0.8489\n",
      "2024-12-06 08:26:02.632129: val_loss -0.5072\n",
      "2024-12-06 08:26:02.632129: Pseudo dice [0.8379]\n",
      "2024-12-06 08:26:02.642128: Epoch time: 131.26 s\n",
      "2024-12-06 08:26:03.865356: \n",
      "2024-12-06 08:26:03.875355: Epoch 759\n",
      "2024-12-06 08:26:03.883851: Current learning rate: 0.00278\n",
      "2024-12-06 08:28:15.298122: train_loss -0.8511\n",
      "2024-12-06 08:28:15.312432: val_loss -0.5547\n",
      "2024-12-06 08:28:15.312432: Pseudo dice [0.8636]\n",
      "2024-12-06 08:28:15.312432: Epoch time: 131.43 s\n",
      "2024-12-06 08:28:16.588994: \n",
      "2024-12-06 08:28:16.595670: Epoch 760\n",
      "2024-12-06 08:28:16.605669: Current learning rate: 0.00277\n",
      "2024-12-06 08:30:27.936051: train_loss -0.8531\n",
      "2024-12-06 08:30:27.946516: val_loss -0.42\n",
      "2024-12-06 08:30:27.951517: Pseudo dice [0.6942]\n",
      "2024-12-06 08:30:27.956518: Epoch time: 131.35 s\n",
      "2024-12-06 08:30:29.102641: \n",
      "2024-12-06 08:30:29.109289: Epoch 761\n",
      "2024-12-06 08:30:29.119288: Current learning rate: 0.00276\n",
      "2024-12-06 08:32:40.451523: train_loss -0.8566\n",
      "2024-12-06 08:32:40.456377: val_loss -0.3812\n",
      "2024-12-06 08:32:40.473116: Pseudo dice [0.7825]\n",
      "2024-12-06 08:32:40.473116: Epoch time: 131.35 s\n",
      "2024-12-06 08:32:41.689696: \n",
      "2024-12-06 08:32:41.689696: Epoch 762\n",
      "2024-12-06 08:32:41.699695: Current learning rate: 0.00275\n",
      "2024-12-06 08:34:53.156512: train_loss -0.8452\n",
      "2024-12-06 08:34:53.171721: val_loss -0.1043\n",
      "2024-12-06 08:34:53.181767: Pseudo dice [0.5468]\n",
      "2024-12-06 08:34:53.191767: Epoch time: 131.47 s\n",
      "2024-12-06 08:34:54.434034: \n",
      "2024-12-06 08:34:54.444034: Epoch 763\n",
      "2024-12-06 08:34:54.454034: Current learning rate: 0.00274\n",
      "2024-12-06 08:37:05.870118: train_loss -0.8419\n",
      "2024-12-06 08:37:05.884548: val_loss -0.4437\n",
      "2024-12-06 08:37:05.893551: Pseudo dice [0.8229]\n",
      "2024-12-06 08:37:05.900508: Epoch time: 131.44 s\n",
      "2024-12-06 08:37:07.167152: \n",
      "2024-12-06 08:37:07.167152: Epoch 764\n",
      "2024-12-06 08:37:07.177151: Current learning rate: 0.00273\n",
      "2024-12-06 08:39:18.397056: train_loss -0.8466\n",
      "2024-12-06 08:39:18.397328: val_loss -0.4827\n",
      "2024-12-06 08:39:18.414025: Pseudo dice [0.7891]\n",
      "2024-12-06 08:39:18.414025: Epoch time: 131.23 s\n",
      "2024-12-06 08:39:19.783555: \n",
      "2024-12-06 08:39:19.783555: Epoch 765\n",
      "2024-12-06 08:39:19.793554: Current learning rate: 0.00272\n",
      "2024-12-06 08:41:31.229672: train_loss -0.8491\n",
      "2024-12-06 08:41:31.248171: val_loss -0.4183\n",
      "2024-12-06 08:41:31.259174: Pseudo dice [0.7828]\n",
      "2024-12-06 08:41:31.261152: Epoch time: 131.45 s\n",
      "2024-12-06 08:41:32.494280: \n",
      "2024-12-06 08:41:32.504279: Epoch 766\n",
      "2024-12-06 08:41:32.510978: Current learning rate: 0.00271\n",
      "2024-12-06 08:43:43.743529: train_loss -0.8295\n",
      "2024-12-06 08:43:43.757991: val_loss 0.1593\n",
      "2024-12-06 08:43:43.757991: Pseudo dice [0.4443]\n",
      "2024-12-06 08:43:43.767989: Epoch time: 131.25 s\n",
      "2024-12-06 08:43:44.951977: \n",
      "2024-12-06 08:43:44.958436: Epoch 767\n",
      "2024-12-06 08:43:44.958436: Current learning rate: 0.0027\n",
      "2024-12-06 08:45:56.438330: train_loss -0.8267\n",
      "2024-12-06 08:45:56.448328: val_loss -0.4095\n",
      "2024-12-06 08:45:56.455086: Pseudo dice [0.7576]\n",
      "2024-12-06 08:45:56.465085: Epoch time: 131.49 s\n",
      "2024-12-06 08:45:57.689928: \n",
      "2024-12-06 08:45:57.699433: Epoch 768\n",
      "2024-12-06 08:45:57.704675: Current learning rate: 0.00268\n",
      "2024-12-06 08:48:09.169666: train_loss -0.8456\n",
      "2024-12-06 08:48:09.185820: val_loss -0.1759\n",
      "2024-12-06 08:48:09.195323: Pseudo dice [0.6921]\n",
      "2024-12-06 08:48:09.195323: Epoch time: 131.48 s\n",
      "2024-12-06 08:48:10.461921: \n",
      "2024-12-06 08:48:10.468695: Epoch 769\n",
      "2024-12-06 08:48:10.478694: Current learning rate: 0.00267\n",
      "2024-12-06 08:50:21.758942: train_loss -0.8587\n",
      "2024-12-06 08:50:21.765718: val_loss -0.2335\n",
      "2024-12-06 08:50:21.775715: Pseudo dice [0.684]\n",
      "2024-12-06 08:50:21.784187: Epoch time: 131.3 s\n",
      "2024-12-06 08:50:23.015781: \n",
      "2024-12-06 08:50:23.025779: Epoch 770\n",
      "2024-12-06 08:50:23.032278: Current learning rate: 0.00266\n",
      "2024-12-06 08:52:34.422703: train_loss -0.8566\n",
      "2024-12-06 08:52:34.429308: val_loss -0.2475\n",
      "2024-12-06 08:52:34.439307: Pseudo dice [0.6708]\n",
      "2024-12-06 08:52:34.447600: Epoch time: 131.41 s\n",
      "2024-12-06 08:52:35.845917: \n",
      "2024-12-06 08:52:35.862571: Epoch 771\n",
      "2024-12-06 08:52:35.862571: Current learning rate: 0.00265\n",
      "2024-12-06 08:54:48.697474: train_loss -0.8614\n",
      "2024-12-06 08:54:48.697474: val_loss -0.3285\n",
      "2024-12-06 08:54:48.707476: Pseudo dice [0.7353]\n",
      "2024-12-06 08:54:48.714478: Epoch time: 132.85 s\n",
      "2024-12-06 08:54:49.897012: \n",
      "2024-12-06 08:54:49.897012: Epoch 772\n",
      "2024-12-06 08:54:49.905014: Current learning rate: 0.00264\n",
      "2024-12-06 08:57:05.602546: train_loss -0.8542\n",
      "2024-12-06 08:57:05.603546: val_loss -0.3703\n",
      "2024-12-06 08:57:05.612548: Pseudo dice [0.7405]\n",
      "2024-12-06 08:57:05.620550: Epoch time: 135.71 s\n",
      "2024-12-06 08:57:06.799817: \n",
      "2024-12-06 08:57:06.807820: Epoch 773\n",
      "2024-12-06 08:57:06.813820: Current learning rate: 0.00263\n",
      "2024-12-06 08:59:21.436678: train_loss -0.8551\n",
      "2024-12-06 08:59:21.445790: val_loss -0.5457\n",
      "2024-12-06 08:59:21.450850: Pseudo dice [0.824]\n",
      "2024-12-06 08:59:21.457299: Epoch time: 134.64 s\n",
      "2024-12-06 08:59:22.653309: \n",
      "2024-12-06 08:59:22.663306: Epoch 774\n",
      "2024-12-06 08:59:22.663306: Current learning rate: 0.00262\n",
      "2024-12-06 09:01:34.112555: train_loss -0.8509\n",
      "2024-12-06 09:01:34.117006: val_loss -0.0394\n",
      "2024-12-06 09:01:34.127005: Pseudo dice [0.4826]\n",
      "2024-12-06 09:01:34.135048: Epoch time: 131.46 s\n",
      "2024-12-06 09:01:35.409871: \n",
      "2024-12-06 09:01:35.417016: Epoch 775\n",
      "2024-12-06 09:01:35.427015: Current learning rate: 0.00261\n",
      "2024-12-06 09:03:46.713748: train_loss -0.8626\n",
      "2024-12-06 09:03:46.716474: val_loss -0.3061\n",
      "2024-12-06 09:03:46.725976: Pseudo dice [0.7123]\n",
      "2024-12-06 09:03:46.731530: Epoch time: 131.3 s\n",
      "2024-12-06 09:03:47.947357: \n",
      "2024-12-06 09:03:47.957356: Epoch 776\n",
      "2024-12-06 09:03:47.963979: Current learning rate: 0.0026\n",
      "2024-12-06 09:06:00.266685: train_loss -0.8545\n",
      "2024-12-06 09:06:00.275687: val_loss -0.297\n",
      "2024-12-06 09:06:00.281690: Pseudo dice [0.7453]\n",
      "2024-12-06 09:06:00.290691: Epoch time: 132.32 s\n",
      "2024-12-06 09:06:01.567254: \n",
      "2024-12-06 09:06:01.577707: Epoch 777\n",
      "2024-12-06 09:06:01.583708: Current learning rate: 0.00259\n",
      "2024-12-06 09:08:22.004475: train_loss -0.8396\n",
      "2024-12-06 09:08:22.016477: val_loss -0.1754\n",
      "2024-12-06 09:08:22.023479: Pseudo dice [0.6784]\n",
      "2024-12-06 09:08:22.029480: Epoch time: 140.44 s\n",
      "2024-12-06 09:08:23.416794: \n",
      "2024-12-06 09:08:23.425796: Epoch 778\n",
      "2024-12-06 09:08:23.431798: Current learning rate: 0.00258\n",
      "2024-12-06 09:10:43.385908: train_loss -0.8317\n",
      "2024-12-06 09:10:43.396910: val_loss -0.3216\n",
      "2024-12-06 09:10:43.406914: Pseudo dice [0.6597]\n",
      "2024-12-06 09:10:43.412916: Epoch time: 139.97 s\n",
      "2024-12-06 09:10:44.649194: \n",
      "2024-12-06 09:10:44.658195: Epoch 779\n",
      "2024-12-06 09:10:44.664197: Current learning rate: 0.00257\n",
      "2024-12-06 09:13:04.589636: train_loss -0.8361\n",
      "2024-12-06 09:13:04.600638: val_loss -0.2736\n",
      "2024-12-06 09:13:04.609640: Pseudo dice [0.6275]\n",
      "2024-12-06 09:13:04.614641: Epoch time: 139.94 s\n",
      "2024-12-06 09:13:05.810170: \n",
      "2024-12-06 09:13:05.819172: Epoch 780\n",
      "2024-12-06 09:13:05.825174: Current learning rate: 0.00256\n",
      "2024-12-06 09:15:24.619063: train_loss -0.8606\n",
      "2024-12-06 09:15:24.629065: val_loss -0.1589\n",
      "2024-12-06 09:15:24.640068: Pseudo dice [0.6237]\n",
      "2024-12-06 09:15:24.647070: Epoch time: 138.81 s\n",
      "2024-12-06 09:15:25.835638: \n",
      "2024-12-06 09:15:25.842639: Epoch 781\n",
      "2024-12-06 09:15:25.847641: Current learning rate: 0.00255\n",
      "2024-12-06 09:17:45.585674: train_loss -0.8461\n",
      "2024-12-06 09:17:45.596677: val_loss 0.0052\n",
      "2024-12-06 09:17:45.606679: Pseudo dice [0.3837]\n",
      "2024-12-06 09:17:45.613680: Epoch time: 139.75 s\n",
      "2024-12-06 09:17:46.824945: \n",
      "2024-12-06 09:17:46.833946: Epoch 782\n",
      "2024-12-06 09:17:46.839947: Current learning rate: 0.00254\n",
      "2024-12-06 09:20:06.838180: train_loss -0.8377\n",
      "2024-12-06 09:20:06.848182: val_loss -0.3539\n",
      "2024-12-06 09:20:06.857184: Pseudo dice [0.7423]\n",
      "2024-12-06 09:20:06.862186: Epoch time: 140.01 s\n",
      "2024-12-06 09:20:08.152477: \n",
      "2024-12-06 09:20:08.161479: Epoch 783\n",
      "2024-12-06 09:20:08.166480: Current learning rate: 0.00253\n",
      "2024-12-06 09:22:28.172904: train_loss -0.8355\n",
      "2024-12-06 09:22:28.183906: val_loss -0.4234\n",
      "2024-12-06 09:22:28.193908: Pseudo dice [0.7586]\n",
      "2024-12-06 09:22:28.200910: Epoch time: 140.02 s\n",
      "2024-12-06 09:22:29.379176: \n",
      "2024-12-06 09:22:29.388178: Epoch 784\n",
      "2024-12-06 09:22:29.394181: Current learning rate: 0.00252\n",
      "2024-12-06 09:24:49.357530: train_loss -0.8274\n",
      "2024-12-06 09:24:49.369534: val_loss -0.4637\n",
      "2024-12-06 09:24:49.377536: Pseudo dice [0.8101]\n",
      "2024-12-06 09:24:49.384538: Epoch time: 139.98 s\n",
      "2024-12-06 09:24:50.769850: \n",
      "2024-12-06 09:24:50.777853: Epoch 785\n",
      "2024-12-06 09:24:50.782854: Current learning rate: 0.00251\n",
      "2024-12-06 09:27:02.092691: train_loss -0.8489\n",
      "2024-12-06 09:27:02.093691: val_loss -0.6376\n",
      "2024-12-06 09:27:02.105694: Pseudo dice [0.8342]\n",
      "2024-12-06 09:27:02.113694: Epoch time: 131.32 s\n",
      "2024-12-06 09:27:03.286253: \n",
      "2024-12-06 09:27:03.286253: Epoch 786\n",
      "2024-12-06 09:27:03.294255: Current learning rate: 0.0025\n",
      "2024-12-06 09:29:13.059532: train_loss -0.8354\n",
      "2024-12-06 09:29:13.059532: val_loss -0.4274\n",
      "2024-12-06 09:29:13.068535: Pseudo dice [0.7711]\n",
      "2024-12-06 09:29:13.073536: Epoch time: 129.77 s\n",
      "2024-12-06 09:29:14.276807: \n",
      "2024-12-06 09:29:14.276807: Epoch 787\n",
      "2024-12-06 09:29:14.284808: Current learning rate: 0.00249\n",
      "2024-12-06 09:31:25.303152: train_loss -0.8526\n",
      "2024-12-06 09:31:25.303152: val_loss -0.4956\n",
      "2024-12-06 09:31:25.309744: Pseudo dice [0.816]\n",
      "2024-12-06 09:31:25.326477: Epoch time: 131.03 s\n",
      "2024-12-06 09:31:26.486353: \n",
      "2024-12-06 09:31:26.486353: Epoch 788\n",
      "2024-12-06 09:31:26.493017: Current learning rate: 0.00248\n",
      "2024-12-06 09:33:37.757268: train_loss -0.851\n",
      "2024-12-06 09:33:37.757268: val_loss -0.4962\n",
      "2024-12-06 09:33:37.773134: Pseudo dice [0.8342]\n",
      "2024-12-06 09:33:37.775033: Epoch time: 131.27 s\n",
      "2024-12-06 09:33:38.939790: \n",
      "2024-12-06 09:33:38.940794: Epoch 789\n",
      "2024-12-06 09:33:38.941435: Current learning rate: 0.00247\n",
      "2024-12-06 09:35:50.388806: train_loss -0.8621\n",
      "2024-12-06 09:35:50.388806: val_loss -0.4856\n",
      "2024-12-06 09:35:50.403895: Pseudo dice [0.8001]\n",
      "2024-12-06 09:35:50.403895: Epoch time: 131.45 s\n",
      "2024-12-06 09:35:51.570362: \n",
      "2024-12-06 09:35:51.570362: Epoch 790\n",
      "2024-12-06 09:35:51.587028: Current learning rate: 0.00245\n",
      "2024-12-06 09:38:03.034101: train_loss -0.8588\n",
      "2024-12-06 09:38:03.034101: val_loss -0.5904\n",
      "2024-12-06 09:38:03.050889: Pseudo dice [0.8313]\n",
      "2024-12-06 09:38:03.050889: Epoch time: 131.46 s\n",
      "2024-12-06 09:38:04.210733: \n",
      "2024-12-06 09:38:04.210733: Epoch 791\n",
      "2024-12-06 09:38:04.217307: Current learning rate: 0.00244\n",
      "2024-12-06 09:40:17.424277: train_loss -0.8564\n",
      "2024-12-06 09:40:17.424277: val_loss -0.4892\n",
      "2024-12-06 09:40:17.434279: Pseudo dice [0.8091]\n",
      "2024-12-06 09:40:17.443280: Epoch time: 133.21 s\n",
      "2024-12-06 09:40:18.813591: \n",
      "2024-12-06 09:40:18.813591: Epoch 792\n",
      "2024-12-06 09:40:18.821592: Current learning rate: 0.00243\n",
      "2024-12-06 09:42:30.432411: train_loss -0.8515\n",
      "2024-12-06 09:42:30.432411: val_loss -0.4038\n",
      "2024-12-06 09:42:30.443920: Pseudo dice [0.7122]\n",
      "2024-12-06 09:42:30.448920: Epoch time: 131.62 s\n",
      "2024-12-06 09:42:31.579367: \n",
      "2024-12-06 09:42:31.586368: Epoch 793\n",
      "2024-12-06 09:42:31.591369: Current learning rate: 0.00242\n",
      "2024-12-06 09:44:42.483497: train_loss -0.8419\n",
      "2024-12-06 09:44:42.495005: val_loss -0.2993\n",
      "2024-12-06 09:44:42.503007: Pseudo dice [0.6971]\n",
      "2024-12-06 09:44:42.509009: Epoch time: 130.91 s\n",
      "2024-12-06 09:44:43.633113: \n",
      "2024-12-06 09:44:43.640114: Epoch 794\n",
      "2024-12-06 09:44:43.646116: Current learning rate: 0.00241\n",
      "2024-12-06 09:46:53.807542: train_loss -0.8563\n",
      "2024-12-06 09:46:53.817546: val_loss -0.3283\n",
      "2024-12-06 09:46:53.825548: Pseudo dice [0.7186]\n",
      "2024-12-06 09:46:53.831549: Epoch time: 130.18 s\n",
      "2024-12-06 09:46:54.959084: \n",
      "2024-12-06 09:46:54.965085: Epoch 795\n",
      "2024-12-06 09:46:54.970086: Current learning rate: 0.0024\n",
      "2024-12-06 09:49:05.463563: train_loss -0.8321\n",
      "2024-12-06 09:49:05.475567: val_loss -0.3336\n",
      "2024-12-06 09:49:05.482073: Pseudo dice [0.8013]\n",
      "2024-12-06 09:49:05.487073: Epoch time: 130.51 s\n",
      "2024-12-06 09:49:06.628423: \n",
      "2024-12-06 09:49:06.636425: Epoch 796\n",
      "2024-12-06 09:49:06.640425: Current learning rate: 0.00239\n",
      "2024-12-06 09:51:19.342330: train_loss -0.8488\n",
      "2024-12-06 09:51:19.353428: val_loss -0.3909\n",
      "2024-12-06 09:51:19.360430: Pseudo dice [0.654]\n",
      "2024-12-06 09:51:19.365431: Epoch time: 132.71 s\n",
      "2024-12-06 09:51:20.534236: \n",
      "2024-12-06 09:51:20.542238: Epoch 797\n",
      "2024-12-06 09:51:20.548447: Current learning rate: 0.00238\n",
      "2024-12-06 09:53:35.324672: train_loss -0.8533\n",
      "2024-12-06 09:53:35.336179: val_loss -0.2235\n",
      "2024-12-06 09:53:35.345182: Pseudo dice [0.6545]\n",
      "2024-12-06 09:53:35.352183: Epoch time: 134.79 s\n",
      "2024-12-06 09:53:36.680071: \n",
      "2024-12-06 09:53:36.689073: Epoch 798\n",
      "2024-12-06 09:53:36.695074: Current learning rate: 0.00237\n",
      "2024-12-06 09:55:50.950626: train_loss -0.8497\n",
      "2024-12-06 09:55:50.958628: val_loss -0.2831\n",
      "2024-12-06 09:55:50.967630: Pseudo dice [0.571]\n",
      "2024-12-06 09:55:50.973631: Epoch time: 134.27 s\n",
      "2024-12-06 09:55:52.106138: \n",
      "2024-12-06 09:55:52.113139: Epoch 799\n",
      "2024-12-06 09:55:52.119140: Current learning rate: 0.00236\n",
      "2024-12-06 09:58:03.560920: train_loss -0.8547\n",
      "2024-12-06 09:58:03.569922: val_loss -0.3407\n",
      "2024-12-06 09:58:03.577924: Pseudo dice [0.6909]\n",
      "2024-12-06 09:58:03.584925: Epoch time: 131.46 s\n",
      "2024-12-06 09:58:04.969095: \n",
      "2024-12-06 09:58:04.977097: Epoch 800\n",
      "2024-12-06 09:58:04.982098: Current learning rate: 0.00235\n",
      "2024-12-06 10:00:18.457908: train_loss -0.8384\n",
      "2024-12-06 10:00:18.466909: val_loss 0.4385\n",
      "2024-12-06 10:00:18.475912: Pseudo dice [0.1995]\n",
      "2024-12-06 10:00:18.481912: Epoch time: 133.49 s\n",
      "2024-12-06 10:00:19.649899: \n",
      "2024-12-06 10:00:19.658901: Epoch 801\n",
      "2024-12-06 10:00:19.663903: Current learning rate: 0.00234\n",
      "2024-12-06 10:02:33.840460: train_loss -0.8478\n",
      "2024-12-06 10:02:33.847462: val_loss 0.0872\n",
      "2024-12-06 10:02:33.853464: Pseudo dice [0.454]\n",
      "2024-12-06 10:02:33.862466: Epoch time: 134.19 s\n",
      "2024-12-06 10:02:35.115599: \n",
      "2024-12-06 10:02:35.124602: Epoch 802\n",
      "2024-12-06 10:02:35.132607: Current learning rate: 0.00233\n",
      "2024-12-06 10:04:57.956059: train_loss -0.8439\n",
      "2024-12-06 10:04:57.970367: val_loss 0.2542\n",
      "2024-12-06 10:04:57.977369: Pseudo dice [0.407]\n",
      "2024-12-06 10:04:57.983371: Epoch time: 142.84 s\n",
      "2024-12-06 10:04:59.194957: \n",
      "2024-12-06 10:04:59.206960: Epoch 803\n",
      "2024-12-06 10:04:59.212962: Current learning rate: 0.00232\n",
      "2024-12-06 10:11:08.568500: train_loss -0.84\n",
      "2024-12-06 10:11:08.579515: val_loss -0.5388\n",
      "2024-12-06 10:11:08.586517: Pseudo dice [0.8216]\n",
      "2024-12-06 10:11:08.591518: Epoch time: 369.37 s\n",
      "2024-12-06 10:11:09.868329: \n",
      "2024-12-06 10:11:09.877478: Epoch 804\n",
      "2024-12-06 10:11:09.883480: Current learning rate: 0.00231\n",
      "2024-12-06 10:17:19.632584: train_loss -0.8539\n",
      "2024-12-06 10:17:19.643587: val_loss -0.4543\n",
      "2024-12-06 10:17:19.648589: Pseudo dice [0.7734]\n",
      "2024-12-06 10:17:19.654590: Epoch time: 369.77 s\n",
      "2024-12-06 10:17:21.071279: \n",
      "2024-12-06 10:17:21.079282: Epoch 805\n",
      "2024-12-06 10:17:21.086283: Current learning rate: 0.0023\n",
      "2024-12-06 10:23:29.668205: train_loss -0.8594\n",
      "2024-12-06 10:23:29.682667: val_loss -0.4678\n",
      "2024-12-06 10:23:29.690669: Pseudo dice [0.7845]\n",
      "2024-12-06 10:23:29.696671: Epoch time: 368.6 s\n",
      "2024-12-06 10:23:31.042516: \n",
      "2024-12-06 10:23:31.050518: Epoch 806\n",
      "2024-12-06 10:23:31.056520: Current learning rate: 0.00229\n",
      "2024-12-06 10:29:40.872056: train_loss -0.8553\n",
      "2024-12-06 10:29:40.880060: val_loss 0.4175\n",
      "2024-12-06 10:29:40.886062: Pseudo dice [0.2815]\n",
      "2024-12-06 10:29:40.891062: Epoch time: 369.83 s\n",
      "2024-12-06 10:29:42.069681: \n",
      "2024-12-06 10:29:42.078683: Epoch 807\n",
      "2024-12-06 10:29:42.083686: Current learning rate: 0.00228\n",
      "2024-12-06 10:35:49.752699: train_loss -0.8322\n",
      "2024-12-06 10:35:49.766702: val_loss 0.2595\n",
      "2024-12-06 10:35:49.772704: Pseudo dice [0.3055]\n",
      "2024-12-06 10:35:49.777705: Epoch time: 367.68 s\n",
      "2024-12-06 10:35:51.093481: \n",
      "2024-12-06 10:35:51.102483: Epoch 808\n",
      "2024-12-06 10:35:51.107484: Current learning rate: 0.00226\n",
      "2024-12-06 10:42:00.912152: train_loss -0.8388\n",
      "2024-12-06 10:42:00.924155: val_loss -0.4693\n",
      "2024-12-06 10:42:00.930156: Pseudo dice [0.779]\n",
      "2024-12-06 10:42:00.936157: Epoch time: 369.82 s\n",
      "2024-12-06 10:42:02.192755: \n",
      "2024-12-06 10:42:02.201758: Epoch 809\n",
      "2024-12-06 10:42:02.207759: Current learning rate: 0.00225\n",
      "2024-12-06 10:48:10.808227: train_loss -0.8527\n",
      "2024-12-06 10:48:10.808227: val_loss -0.4467\n",
      "2024-12-06 10:48:10.816229: Pseudo dice [0.8058]\n",
      "2024-12-06 10:48:10.821735: Epoch time: 368.62 s\n",
      "2024-12-06 10:48:12.039936: \n",
      "2024-12-06 10:48:12.048938: Epoch 810\n",
      "2024-12-06 10:48:12.053939: Current learning rate: 0.00224\n",
      "2024-12-06 10:51:41.052196: train_loss -0.8549\n",
      "2024-12-06 10:51:41.067199: val_loss -0.4824\n",
      "2024-12-06 10:51:41.077202: Pseudo dice [0.7714]\n",
      "2024-12-06 10:51:41.083204: Epoch time: 209.01 s\n",
      "2024-12-06 10:51:42.432096: \n",
      "2024-12-06 10:51:42.441098: Epoch 811\n",
      "2024-12-06 10:51:42.448379: Current learning rate: 0.00223\n",
      "2024-12-06 10:53:54.224927: train_loss -0.8458\n",
      "2024-12-06 10:53:54.234929: val_loss -0.3323\n",
      "2024-12-06 10:53:54.240931: Pseudo dice [0.7475]\n",
      "2024-12-06 10:53:54.247435: Epoch time: 131.79 s\n",
      "2024-12-06 10:53:55.389359: \n",
      "2024-12-06 10:53:55.396361: Epoch 812\n",
      "2024-12-06 10:53:55.401362: Current learning rate: 0.00222\n",
      "2024-12-06 10:56:06.372945: train_loss -0.8527\n",
      "2024-12-06 10:56:06.381948: val_loss -0.4137\n",
      "2024-12-06 10:56:06.388949: Pseudo dice [0.7538]\n",
      "2024-12-06 10:56:06.393950: Epoch time: 130.98 s\n",
      "2024-12-06 10:56:07.532647: \n",
      "2024-12-06 10:56:07.540649: Epoch 813\n",
      "2024-12-06 10:56:07.545650: Current learning rate: 0.00221\n",
      "2024-12-06 10:58:17.091418: train_loss -0.8377\n",
      "2024-12-06 10:58:17.101925: val_loss -0.2305\n",
      "2024-12-06 10:58:17.107925: Pseudo dice [0.6404]\n",
      "2024-12-06 10:58:17.117928: Epoch time: 129.56 s\n",
      "2024-12-06 10:58:18.255920: \n",
      "2024-12-06 10:58:18.262921: Epoch 814\n",
      "2024-12-06 10:58:18.266922: Current learning rate: 0.0022\n",
      "2024-12-06 11:00:28.113582: train_loss -0.8346\n",
      "2024-12-06 11:00:28.122583: val_loss -0.4502\n",
      "2024-12-06 11:00:28.131585: Pseudo dice [0.8033]\n",
      "2024-12-06 11:00:28.137588: Epoch time: 129.86 s\n",
      "2024-12-06 11:00:29.269916: \n",
      "2024-12-06 11:00:29.276918: Epoch 815\n",
      "2024-12-06 11:00:29.281919: Current learning rate: 0.00219\n",
      "2024-12-06 11:02:41.876747: train_loss -0.8199\n",
      "2024-12-06 11:02:41.888752: val_loss -0.5161\n",
      "2024-12-06 11:02:41.895262: Pseudo dice [0.7958]\n",
      "2024-12-06 11:02:41.901263: Epoch time: 132.61 s\n",
      "2024-12-06 11:02:43.046474: \n",
      "2024-12-06 11:02:43.054476: Epoch 816\n",
      "2024-12-06 11:02:43.060477: Current learning rate: 0.00218\n",
      "2024-12-06 11:04:54.295713: train_loss -0.8134\n",
      "2024-12-06 11:04:54.304716: val_loss -0.1981\n",
      "2024-12-06 11:04:54.310718: Pseudo dice [0.6361]\n",
      "2024-12-06 11:04:54.315719: Epoch time: 131.25 s\n",
      "2024-12-06 11:04:55.451402: \n",
      "2024-12-06 11:04:55.459402: Epoch 817\n",
      "2024-12-06 11:04:55.465404: Current learning rate: 0.00217\n",
      "2024-12-06 11:07:07.394210: train_loss -0.8338\n",
      "2024-12-06 11:07:07.404717: val_loss -0.4152\n",
      "2024-12-06 11:07:07.410718: Pseudo dice [0.6517]\n",
      "2024-12-06 11:07:07.417719: Epoch time: 131.94 s\n",
      "2024-12-06 11:07:08.741130: \n",
      "2024-12-06 11:07:08.749131: Epoch 818\n",
      "2024-12-06 11:07:08.754133: Current learning rate: 0.00216\n",
      "2024-12-06 11:09:18.383181: train_loss -0.8523\n",
      "2024-12-06 11:09:18.393182: val_loss -0.4377\n",
      "2024-12-06 11:09:18.399184: Pseudo dice [0.7582]\n",
      "2024-12-06 11:09:18.406186: Epoch time: 129.64 s\n",
      "2024-12-06 11:09:19.540023: \n",
      "2024-12-06 11:09:19.547024: Epoch 819\n",
      "2024-12-06 11:09:19.551529: Current learning rate: 0.00215\n",
      "2024-12-06 11:11:29.153068: train_loss -0.8366\n",
      "2024-12-06 11:11:29.165071: val_loss -0.4387\n",
      "2024-12-06 11:11:29.173073: Pseudo dice [0.7554]\n",
      "2024-12-06 11:11:29.178074: Epoch time: 129.61 s\n",
      "2024-12-06 11:11:30.257377: \n",
      "2024-12-06 11:11:30.265377: Epoch 820\n",
      "2024-12-06 11:11:30.270379: Current learning rate: 0.00214\n",
      "2024-12-06 11:13:39.747253: train_loss -0.8546\n",
      "2024-12-06 11:13:39.760257: val_loss -0.3773\n",
      "2024-12-06 11:13:39.770258: Pseudo dice [0.6476]\n",
      "2024-12-06 11:13:39.774260: Epoch time: 129.49 s\n",
      "2024-12-06 11:13:40.848716: \n",
      "2024-12-06 11:13:40.855848: Epoch 821\n",
      "2024-12-06 11:13:40.860938: Current learning rate: 0.00213\n",
      "2024-12-06 11:15:50.302029: train_loss -0.8557\n",
      "2024-12-06 11:15:50.315032: val_loss -0.3873\n",
      "2024-12-06 11:15:50.321034: Pseudo dice [0.6554]\n",
      "2024-12-06 11:15:50.327035: Epoch time: 129.45 s\n",
      "2024-12-06 11:15:51.405844: \n",
      "2024-12-06 11:15:51.412846: Epoch 822\n",
      "2024-12-06 11:15:51.417847: Current learning rate: 0.00212\n",
      "2024-12-06 11:18:00.931688: train_loss -0.8473\n",
      "2024-12-06 11:18:00.942195: val_loss -0.2025\n",
      "2024-12-06 11:18:00.948196: Pseudo dice [0.5621]\n",
      "2024-12-06 11:18:00.953197: Epoch time: 129.53 s\n",
      "2024-12-06 11:18:02.031117: \n",
      "2024-12-06 11:18:02.037622: Epoch 823\n",
      "2024-12-06 11:18:02.042624: Current learning rate: 0.0021\n",
      "2024-12-06 11:20:11.528931: train_loss -0.8565\n",
      "2024-12-06 11:20:11.539934: val_loss -0.3746\n",
      "2024-12-06 11:20:11.547934: Pseudo dice [0.7183]\n",
      "2024-12-06 11:20:11.553936: Epoch time: 129.5 s\n",
      "2024-12-06 11:20:12.632774: \n",
      "2024-12-06 11:20:12.639775: Epoch 824\n",
      "2024-12-06 11:20:12.645777: Current learning rate: 0.00209\n",
      "2024-12-06 11:22:22.130089: train_loss -0.8584\n",
      "2024-12-06 11:22:22.141597: val_loss -0.444\n",
      "2024-12-06 11:22:22.149598: Pseudo dice [0.7566]\n",
      "2024-12-06 11:22:22.157600: Epoch time: 129.5 s\n",
      "2024-12-06 11:22:23.418468: \n",
      "2024-12-06 11:22:23.426471: Epoch 825\n",
      "2024-12-06 11:22:23.430472: Current learning rate: 0.00208\n",
      "2024-12-06 11:24:32.965306: train_loss -0.8448\n",
      "2024-12-06 11:24:32.975308: val_loss -0.3455\n",
      "2024-12-06 11:24:32.983815: Pseudo dice [0.7115]\n",
      "2024-12-06 11:24:32.989817: Epoch time: 129.55 s\n",
      "2024-12-06 11:24:34.063126: \n",
      "2024-12-06 11:24:34.071130: Epoch 826\n",
      "2024-12-06 11:24:34.076131: Current learning rate: 0.00207\n",
      "2024-12-06 11:26:43.553412: train_loss -0.8204\n",
      "2024-12-06 11:26:43.564415: val_loss -0.4655\n",
      "2024-12-06 11:26:43.572418: Pseudo dice [0.8102]\n",
      "2024-12-06 11:26:43.578419: Epoch time: 129.49 s\n",
      "2024-12-06 11:26:44.650368: \n",
      "2024-12-06 11:26:44.657369: Epoch 827\n",
      "2024-12-06 11:26:44.662370: Current learning rate: 0.00206\n",
      "2024-12-06 11:28:54.120996: train_loss -0.8486\n",
      "2024-12-06 11:28:54.129998: val_loss -0.3894\n",
      "2024-12-06 11:28:54.140001: Pseudo dice [0.7944]\n",
      "2024-12-06 11:28:54.146001: Epoch time: 129.47 s\n",
      "2024-12-06 11:28:55.220814: \n",
      "2024-12-06 11:28:55.226815: Epoch 828\n",
      "2024-12-06 11:28:55.230816: Current learning rate: 0.00205\n",
      "2024-12-06 11:31:04.727588: train_loss -0.86\n",
      "2024-12-06 11:31:04.737589: val_loss -0.5306\n",
      "2024-12-06 11:31:04.745593: Pseudo dice [0.8344]\n",
      "2024-12-06 11:31:04.750592: Epoch time: 129.51 s\n",
      "2024-12-06 11:31:05.825480: \n",
      "2024-12-06 11:31:05.833482: Epoch 829\n",
      "2024-12-06 11:31:05.838483: Current learning rate: 0.00204\n",
      "2024-12-06 11:33:15.359020: train_loss -0.853\n",
      "2024-12-06 11:33:15.370024: val_loss -0.5219\n",
      "2024-12-06 11:33:15.378530: Pseudo dice [0.826]\n",
      "2024-12-06 11:33:15.384531: Epoch time: 129.53 s\n",
      "2024-12-06 11:33:16.457644: \n",
      "2024-12-06 11:33:16.464643: Epoch 830\n",
      "2024-12-06 11:33:16.468645: Current learning rate: 0.00203\n",
      "2024-12-06 11:35:26.212397: train_loss -0.8515\n",
      "2024-12-06 11:35:26.223903: val_loss -0.2725\n",
      "2024-12-06 11:35:26.231905: Pseudo dice [0.6133]\n",
      "2024-12-06 11:35:26.238907: Epoch time: 129.76 s\n",
      "2024-12-06 11:35:27.314779: \n",
      "2024-12-06 11:35:27.322284: Epoch 831\n",
      "2024-12-06 11:35:27.328287: Current learning rate: 0.00202\n",
      "2024-12-06 11:37:37.938344: train_loss -0.8618\n",
      "2024-12-06 11:37:37.958344: val_loss -0.3317\n",
      "2024-12-06 11:37:37.958344: Pseudo dice [0.6793]\n",
      "2024-12-06 11:37:37.968344: Epoch time: 130.62 s\n",
      "2024-12-06 11:37:39.228363: \n",
      "2024-12-06 11:37:39.238362: Epoch 832\n",
      "2024-12-06 11:37:39.238362: Current learning rate: 0.00201\n",
      "2024-12-06 11:39:48.761560: train_loss -0.8642\n",
      "2024-12-06 11:39:48.771560: val_loss -0.2557\n",
      "2024-12-06 11:39:48.781561: Pseudo dice [0.7072]\n",
      "2024-12-06 11:39:48.781561: Epoch time: 129.53 s\n",
      "2024-12-06 11:39:49.861866: \n",
      "2024-12-06 11:39:49.871866: Epoch 833\n",
      "2024-12-06 11:39:49.871866: Current learning rate: 0.002\n",
      "2024-12-06 11:41:59.412911: train_loss -0.8592\n",
      "2024-12-06 11:41:59.422912: val_loss -0.362\n",
      "2024-12-06 11:41:59.432912: Pseudo dice [0.713]\n",
      "2024-12-06 11:41:59.432912: Epoch time: 129.55 s\n",
      "2024-12-06 11:42:00.512928: \n",
      "2024-12-06 11:42:00.522927: Epoch 834\n",
      "2024-12-06 11:42:00.532929: Current learning rate: 0.00199\n",
      "2024-12-06 11:44:10.146036: train_loss -0.8454\n",
      "2024-12-06 11:44:10.166036: val_loss -0.4112\n",
      "2024-12-06 11:44:10.166036: Pseudo dice [0.7738]\n",
      "2024-12-06 11:44:10.176036: Epoch time: 129.63 s\n",
      "2024-12-06 11:44:11.256051: \n",
      "2024-12-06 11:44:11.256051: Epoch 835\n",
      "2024-12-06 11:44:11.266053: Current learning rate: 0.00198\n",
      "2024-12-06 11:46:20.807080: train_loss -0.8546\n",
      "2024-12-06 11:46:20.817080: val_loss -0.4421\n",
      "2024-12-06 11:46:20.817080: Pseudo dice [0.7658]\n",
      "2024-12-06 11:46:20.827080: Epoch time: 129.55 s\n",
      "2024-12-06 11:46:21.907625: \n",
      "2024-12-06 11:46:21.917626: Epoch 836\n",
      "2024-12-06 11:46:21.917626: Current learning rate: 0.00196\n",
      "2024-12-06 11:48:31.494129: train_loss -0.8608\n",
      "2024-12-06 11:48:31.504128: val_loss -0.3692\n",
      "2024-12-06 11:48:31.514129: Pseudo dice [0.7473]\n",
      "2024-12-06 11:48:31.514129: Epoch time: 129.59 s\n",
      "2024-12-06 11:48:32.594145: \n",
      "2024-12-06 11:48:32.604146: Epoch 837\n",
      "2024-12-06 11:48:32.604146: Current learning rate: 0.00195\n",
      "2024-12-06 11:50:42.167906: train_loss -0.8591\n",
      "2024-12-06 11:50:42.177907: val_loss -0.5111\n",
      "2024-12-06 11:50:42.177907: Pseudo dice [0.7953]\n",
      "2024-12-06 11:50:42.187907: Epoch time: 129.57 s\n",
      "2024-12-06 11:50:43.267923: \n",
      "2024-12-06 11:50:43.267923: Epoch 838\n",
      "2024-12-06 11:50:43.277922: Current learning rate: 0.00194\n",
      "2024-12-06 11:52:52.864983: train_loss -0.8619\n",
      "2024-12-06 11:52:52.884983: val_loss -0.5662\n",
      "2024-12-06 11:52:52.884983: Pseudo dice [0.8493]\n",
      "2024-12-06 11:52:52.894983: Epoch time: 129.6 s\n",
      "2024-12-06 11:52:53.975292: \n",
      "2024-12-06 11:52:53.975292: Epoch 839\n",
      "2024-12-06 11:52:53.985292: Current learning rate: 0.00193\n",
      "2024-12-06 11:55:03.541003: train_loss -0.8639\n",
      "2024-12-06 11:55:03.561004: val_loss -0.5348\n",
      "2024-12-06 11:55:03.561004: Pseudo dice [0.8544]\n",
      "2024-12-06 11:55:03.571004: Epoch time: 129.57 s\n",
      "2024-12-06 11:55:04.841935: \n",
      "2024-12-06 11:55:04.841935: Epoch 840\n",
      "2024-12-06 11:55:04.851937: Current learning rate: 0.00192\n",
      "2024-12-06 11:57:14.389304: train_loss -0.8571\n",
      "2024-12-06 11:57:14.399304: val_loss -0.4304\n",
      "2024-12-06 11:57:14.399304: Pseudo dice [0.7416]\n",
      "2024-12-06 11:57:14.409305: Epoch time: 129.56 s\n",
      "2024-12-06 11:57:15.479622: \n",
      "2024-12-06 11:57:15.489622: Epoch 841\n",
      "2024-12-06 11:57:15.489622: Current learning rate: 0.00191\n",
      "2024-12-06 11:59:25.023713: train_loss -0.867\n",
      "2024-12-06 11:59:25.033713: val_loss -0.3701\n",
      "2024-12-06 11:59:25.033713: Pseudo dice [0.726]\n",
      "2024-12-06 11:59:25.043713: Epoch time: 129.54 s\n",
      "2024-12-06 11:59:26.133730: \n",
      "2024-12-06 11:59:26.143731: Epoch 842\n",
      "2024-12-06 11:59:26.143731: Current learning rate: 0.0019\n",
      "2024-12-06 12:01:35.727354: train_loss -0.8654\n",
      "2024-12-06 12:01:35.737355: val_loss -0.062\n",
      "2024-12-06 12:01:35.747355: Pseudo dice [0.5338]\n",
      "2024-12-06 12:01:35.757354: Epoch time: 129.59 s\n",
      "2024-12-06 12:01:36.838277: \n",
      "2024-12-06 12:01:36.838277: Epoch 843\n",
      "2024-12-06 12:01:36.848277: Current learning rate: 0.00189\n",
      "2024-12-06 12:03:46.349669: train_loss -0.8622\n",
      "2024-12-06 12:03:46.359668: val_loss -0.2074\n",
      "2024-12-06 12:03:46.359668: Pseudo dice [0.6554]\n",
      "2024-12-06 12:03:46.369669: Epoch time: 129.51 s\n",
      "2024-12-06 12:03:47.449685: \n",
      "2024-12-06 12:03:47.459685: Epoch 844\n",
      "2024-12-06 12:03:47.459685: Current learning rate: 0.00188\n",
      "2024-12-06 12:05:57.025557: train_loss -0.8513\n",
      "2024-12-06 12:05:57.036681: val_loss -0.4745\n",
      "2024-12-06 12:05:57.040736: Pseudo dice [0.8021]\n",
      "2024-12-06 12:05:57.045812: Epoch time: 129.58 s\n",
      "2024-12-06 12:05:58.123267: \n",
      "2024-12-06 12:05:58.133267: Epoch 845\n",
      "2024-12-06 12:05:58.133267: Current learning rate: 0.00187\n",
      "2024-12-06 12:08:07.660017: train_loss -0.8503\n",
      "2024-12-06 12:08:07.670017: val_loss -0.3963\n",
      "2024-12-06 12:08:07.670017: Pseudo dice [0.7828]\n",
      "2024-12-06 12:08:07.680017: Epoch time: 129.54 s\n",
      "2024-12-06 12:08:08.760317: \n",
      "2024-12-06 12:08:08.770317: Epoch 846\n",
      "2024-12-06 12:08:08.770317: Current learning rate: 0.00186\n",
      "2024-12-06 12:10:18.315310: train_loss -0.856\n",
      "2024-12-06 12:10:18.325310: val_loss -0.5397\n",
      "2024-12-06 12:10:18.335310: Pseudo dice [0.8664]\n",
      "2024-12-06 12:10:18.335310: Epoch time: 129.55 s\n",
      "2024-12-06 12:10:19.595330: \n",
      "2024-12-06 12:10:19.605329: Epoch 847\n",
      "2024-12-06 12:10:19.605329: Current learning rate: 0.00185\n",
      "2024-12-06 12:12:29.190670: train_loss -0.8516\n",
      "2024-12-06 12:12:29.200671: val_loss -0.3134\n",
      "2024-12-06 12:12:29.210672: Pseudo dice [0.7411]\n",
      "2024-12-06 12:12:29.210672: Epoch time: 129.6 s\n",
      "2024-12-06 12:12:30.290688: \n",
      "2024-12-06 12:12:30.300687: Epoch 848\n",
      "2024-12-06 12:12:30.300687: Current learning rate: 0.00184\n",
      "2024-12-06 12:14:39.916081: train_loss -0.8399\n",
      "2024-12-06 12:14:39.926081: val_loss -0.3768\n",
      "2024-12-06 12:14:39.936081: Pseudo dice [0.7565]\n",
      "2024-12-06 12:14:39.946081: Epoch time: 129.63 s\n",
      "2024-12-06 12:14:41.026099: \n",
      "2024-12-06 12:14:41.026099: Epoch 849\n",
      "2024-12-06 12:14:41.036097: Current learning rate: 0.00182\n",
      "2024-12-06 12:16:50.589523: train_loss -0.8466\n",
      "2024-12-06 12:16:50.599524: val_loss -0.3197\n",
      "2024-12-06 12:16:50.609524: Pseudo dice [0.667]\n",
      "2024-12-06 12:16:50.609524: Epoch time: 129.56 s\n",
      "2024-12-06 12:16:51.940301: \n",
      "2024-12-06 12:16:51.940301: Epoch 850\n",
      "2024-12-06 12:16:51.950301: Current learning rate: 0.00181\n",
      "2024-12-06 12:19:01.496639: train_loss -0.8573\n",
      "2024-12-06 12:19:01.506639: val_loss -0.5088\n",
      "2024-12-06 12:19:01.516639: Pseudo dice [0.814]\n",
      "2024-12-06 12:19:01.516639: Epoch time: 129.56 s\n",
      "2024-12-06 12:19:02.596656: \n",
      "2024-12-06 12:19:02.606656: Epoch 851\n",
      "2024-12-06 12:19:02.606656: Current learning rate: 0.0018\n",
      "2024-12-06 12:21:12.179913: train_loss -0.8658\n",
      "2024-12-06 12:21:12.189913: val_loss -0.3488\n",
      "2024-12-06 12:21:12.199913: Pseudo dice [0.6711]\n",
      "2024-12-06 12:21:12.199913: Epoch time: 129.58 s\n",
      "2024-12-06 12:21:13.271028: \n",
      "2024-12-06 12:21:13.281028: Epoch 852\n",
      "2024-12-06 12:21:13.291028: Current learning rate: 0.00179\n",
      "2024-12-06 12:23:22.869559: train_loss -0.8666\n",
      "2024-12-06 12:23:22.879560: val_loss -0.2878\n",
      "2024-12-06 12:23:22.889560: Pseudo dice [0.7369]\n",
      "2024-12-06 12:23:22.899560: Epoch time: 129.6 s\n",
      "2024-12-06 12:23:23.969576: \n",
      "2024-12-06 12:23:23.979577: Epoch 853\n",
      "2024-12-06 12:23:23.979577: Current learning rate: 0.00178\n",
      "2024-12-06 12:25:33.556864: train_loss -0.8705\n",
      "2024-12-06 12:25:33.566863: val_loss -0.2088\n",
      "2024-12-06 12:25:33.576864: Pseudo dice [0.6182]\n",
      "2024-12-06 12:25:33.576864: Epoch time: 129.59 s\n",
      "2024-12-06 12:25:34.826882: \n",
      "2024-12-06 12:25:34.836882: Epoch 854\n",
      "2024-12-06 12:25:34.836882: Current learning rate: 0.00177\n",
      "2024-12-06 12:27:44.434245: train_loss -0.8692\n",
      "2024-12-06 12:27:44.444245: val_loss -0.4024\n",
      "2024-12-06 12:27:44.454245: Pseudo dice [0.7576]\n",
      "2024-12-06 12:27:44.454245: Epoch time: 129.61 s\n",
      "2024-12-06 12:27:45.534261: \n",
      "2024-12-06 12:27:45.544262: Epoch 855\n",
      "2024-12-06 12:27:45.544262: Current learning rate: 0.00176\n",
      "2024-12-06 12:29:55.092502: train_loss -0.8705\n",
      "2024-12-06 12:29:55.102502: val_loss -0.4174\n",
      "2024-12-06 12:29:55.112502: Pseudo dice [0.8012]\n",
      "2024-12-06 12:29:55.112502: Epoch time: 129.56 s\n",
      "2024-12-06 12:29:56.192518: \n",
      "2024-12-06 12:29:56.192518: Epoch 856\n",
      "2024-12-06 12:29:56.202518: Current learning rate: 0.00175\n",
      "2024-12-06 12:32:05.805386: train_loss -0.8618\n",
      "2024-12-06 12:32:05.815386: val_loss -0.4278\n",
      "2024-12-06 12:32:05.825386: Pseudo dice [0.759]\n",
      "2024-12-06 12:32:05.835386: Epoch time: 129.62 s\n",
      "2024-12-06 12:32:06.905401: \n",
      "2024-12-06 12:32:06.905401: Epoch 857\n",
      "2024-12-06 12:32:06.915402: Current learning rate: 0.00174\n",
      "2024-12-06 12:34:16.501461: train_loss -0.8685\n",
      "2024-12-06 12:34:16.511462: val_loss -0.412\n",
      "2024-12-06 12:34:16.521462: Pseudo dice [0.746]\n",
      "2024-12-06 12:34:16.521462: Epoch time: 129.61 s\n",
      "2024-12-06 12:34:17.591478: \n",
      "2024-12-06 12:34:17.601479: Epoch 858\n",
      "2024-12-06 12:34:17.611478: Current learning rate: 0.00173\n",
      "2024-12-06 12:36:27.215576: train_loss -0.8694\n",
      "2024-12-06 12:36:27.225576: val_loss -0.4031\n",
      "2024-12-06 12:36:27.225576: Pseudo dice [0.7165]\n",
      "2024-12-06 12:36:27.235577: Epoch time: 129.62 s\n",
      "2024-12-06 12:36:28.312111: \n",
      "2024-12-06 12:36:28.320113: Epoch 859\n",
      "2024-12-06 12:36:28.325715: Current learning rate: 0.00172\n",
      "2024-12-06 12:38:37.909150: train_loss -0.8672\n",
      "2024-12-06 12:38:37.929150: val_loss -0.3949\n",
      "2024-12-06 12:38:37.929150: Pseudo dice [0.7112]\n",
      "2024-12-06 12:38:37.939150: Epoch time: 129.6 s\n",
      "2024-12-06 12:38:39.009459: \n",
      "2024-12-06 12:38:39.019459: Epoch 860\n",
      "2024-12-06 12:38:39.019459: Current learning rate: 0.0017\n",
      "2024-12-06 12:40:48.961850: train_loss -0.8678\n",
      "2024-12-06 12:40:48.969851: val_loss -0.4622\n",
      "2024-12-06 12:40:48.975853: Pseudo dice [0.7037]\n",
      "2024-12-06 12:40:48.980853: Epoch time: 129.95 s\n",
      "2024-12-06 12:40:50.235137: \n",
      "2024-12-06 12:40:50.244139: Epoch 861\n",
      "2024-12-06 12:40:50.250140: Current learning rate: 0.00169\n",
      "2024-12-06 12:43:03.982097: train_loss -0.866\n",
      "2024-12-06 12:43:03.982097: val_loss -0.3702\n",
      "2024-12-06 12:43:03.992099: Pseudo dice [0.7845]\n",
      "2024-12-06 12:43:03.998101: Epoch time: 133.75 s\n",
      "2024-12-06 12:43:05.173367: \n",
      "2024-12-06 12:43:05.182368: Epoch 862\n",
      "2024-12-06 12:43:05.190370: Current learning rate: 0.00168\n",
      "2024-12-06 12:45:16.182976: train_loss -0.8639\n",
      "2024-12-06 12:45:16.191979: val_loss -0.1209\n",
      "2024-12-06 12:45:16.197980: Pseudo dice [0.6992]\n",
      "2024-12-06 12:45:16.202981: Epoch time: 131.01 s\n",
      "2024-12-06 12:45:17.347609: \n",
      "2024-12-06 12:45:17.357610: Epoch 863\n",
      "2024-12-06 12:45:17.363611: Current learning rate: 0.00167\n",
      "2024-12-06 12:47:30.160762: train_loss -0.8545\n",
      "2024-12-06 12:47:30.177445: val_loss -0.4036\n",
      "2024-12-06 12:47:30.187443: Pseudo dice [0.7513]\n",
      "2024-12-06 12:47:30.193833: Epoch time: 132.81 s\n",
      "2024-12-06 12:47:31.343813: \n",
      "2024-12-06 12:47:31.352809: Epoch 864\n",
      "2024-12-06 12:47:31.357811: Current learning rate: 0.00166\n",
      "2024-12-06 12:49:42.602306: train_loss -0.8717\n",
      "2024-12-06 12:49:42.607849: val_loss -0.445\n",
      "2024-12-06 12:49:42.617847: Pseudo dice [0.8055]\n",
      "2024-12-06 12:49:42.624496: Epoch time: 131.26 s\n",
      "2024-12-06 12:49:43.759567: \n",
      "2024-12-06 12:49:43.760523: Epoch 865\n",
      "2024-12-06 12:49:43.770025: Current learning rate: 0.00165\n",
      "2024-12-06 12:51:55.321743: train_loss -0.8655\n",
      "2024-12-06 12:51:55.331247: val_loss -0.2588\n",
      "2024-12-06 12:51:55.338210: Pseudo dice [0.7373]\n",
      "2024-12-06 12:51:55.348208: Epoch time: 131.56 s\n",
      "2024-12-06 12:51:56.504920: \n",
      "2024-12-06 12:51:56.514920: Epoch 866\n",
      "2024-12-06 12:51:56.514920: Current learning rate: 0.00164\n",
      "2024-12-06 12:54:07.835093: train_loss -0.8718\n",
      "2024-12-06 12:54:07.852429: val_loss -0.4256\n",
      "2024-12-06 12:54:07.852429: Pseudo dice [0.8046]\n",
      "2024-12-06 12:54:07.861932: Epoch time: 131.33 s\n",
      "2024-12-06 12:54:09.013584: \n",
      "2024-12-06 12:54:09.019134: Epoch 867\n",
      "2024-12-06 12:54:09.019134: Current learning rate: 0.00163\n",
      "2024-12-06 12:56:20.258592: train_loss -0.8714\n",
      "2024-12-06 12:56:20.265526: val_loss -0.3293\n",
      "2024-12-06 12:56:20.281944: Pseudo dice [0.7476]\n",
      "2024-12-06 12:56:20.288962: Epoch time: 131.25 s\n",
      "2024-12-06 12:56:21.398996: \n",
      "2024-12-06 12:56:21.408499: Epoch 868\n",
      "2024-12-06 12:56:21.415138: Current learning rate: 0.00162\n",
      "2024-12-06 12:58:32.822608: train_loss -0.8638\n",
      "2024-12-06 12:58:32.829086: val_loss -0.4494\n",
      "2024-12-06 12:58:32.839083: Pseudo dice [0.7692]\n",
      "2024-12-06 12:58:32.847499: Epoch time: 131.42 s\n",
      "2024-12-06 12:58:34.178777: \n",
      "2024-12-06 12:58:34.179023: Epoch 869\n",
      "2024-12-06 12:58:34.189022: Current learning rate: 0.00161\n",
      "2024-12-06 13:00:45.547630: train_loss -0.8695\n",
      "2024-12-06 13:00:45.560663: val_loss -0.4908\n",
      "2024-12-06 13:00:45.561450: Pseudo dice [0.8347]\n",
      "2024-12-06 13:00:45.576125: Epoch time: 131.38 s\n",
      "2024-12-06 13:00:46.692689: \n",
      "2024-12-06 13:00:46.692689: Epoch 870\n",
      "2024-12-06 13:00:46.702687: Current learning rate: 0.00159\n",
      "2024-12-06 13:02:58.039773: train_loss -0.8738\n",
      "2024-12-06 13:02:58.056417: val_loss -0.3606\n",
      "2024-12-06 13:02:58.056417: Pseudo dice [0.7095]\n",
      "2024-12-06 13:02:58.066415: Epoch time: 131.35 s\n",
      "2024-12-06 13:02:59.282957: \n",
      "2024-12-06 13:02:59.289722: Epoch 871\n",
      "2024-12-06 13:02:59.299721: Current learning rate: 0.00158\n",
      "2024-12-06 13:05:10.737302: train_loss -0.8683\n",
      "2024-12-06 13:05:10.753426: val_loss -0.2376\n",
      "2024-12-06 13:05:10.753426: Pseudo dice [0.6493]\n",
      "2024-12-06 13:05:10.763425: Epoch time: 131.45 s\n",
      "2024-12-06 13:05:11.869989: \n",
      "2024-12-06 13:05:11.879987: Epoch 872\n",
      "2024-12-06 13:05:11.887500: Current learning rate: 0.00157\n",
      "2024-12-06 13:07:23.177055: train_loss -0.8673\n",
      "2024-12-06 13:07:23.191680: val_loss -0.549\n",
      "2024-12-06 13:07:23.201750: Pseudo dice [0.8515]\n",
      "2024-12-06 13:07:23.201750: Epoch time: 131.31 s\n",
      "2024-12-06 13:07:24.376992: \n",
      "2024-12-06 13:07:24.385025: Epoch 873\n",
      "2024-12-06 13:07:24.385025: Current learning rate: 0.00156\n",
      "2024-12-06 13:09:35.674111: train_loss -0.8672\n",
      "2024-12-06 13:09:35.690742: val_loss -0.2644\n",
      "2024-12-06 13:09:35.699486: Pseudo dice [0.6927]\n",
      "2024-12-06 13:09:35.699486: Epoch time: 131.3 s\n",
      "2024-12-06 13:09:36.813990: \n",
      "2024-12-06 13:09:36.823989: Epoch 874\n",
      "2024-12-06 13:09:36.830634: Current learning rate: 0.00155\n",
      "2024-12-06 13:11:48.353730: train_loss -0.8659\n",
      "2024-12-06 13:11:48.361325: val_loss -0.4659\n",
      "2024-12-06 13:11:48.361325: Pseudo dice [0.8295]\n",
      "2024-12-06 13:11:48.377443: Epoch time: 131.54 s\n",
      "2024-12-06 13:11:49.545599: \n",
      "2024-12-06 13:11:49.555103: Epoch 875\n",
      "2024-12-06 13:11:49.561027: Current learning rate: 0.00154\n",
      "2024-12-06 13:14:00.801601: train_loss -0.8711\n",
      "2024-12-06 13:14:00.808382: val_loss -0.056\n",
      "2024-12-06 13:14:00.824823: Pseudo dice [0.6134]\n",
      "2024-12-06 13:14:00.824823: Epoch time: 131.26 s\n",
      "2024-12-06 13:14:02.201386: \n",
      "2024-12-06 13:14:02.208017: Epoch 876\n",
      "2024-12-06 13:14:02.208017: Current learning rate: 0.00153\n",
      "2024-12-06 13:16:13.638926: train_loss -0.8733\n",
      "2024-12-06 13:16:13.648924: val_loss -0.4232\n",
      "2024-12-06 13:16:13.656498: Pseudo dice [0.778]\n",
      "2024-12-06 13:16:13.666001: Epoch time: 131.44 s\n",
      "2024-12-06 13:16:14.788311: \n",
      "2024-12-06 13:16:14.798309: Epoch 877\n",
      "2024-12-06 13:16:14.804737: Current learning rate: 0.00152\n",
      "2024-12-06 13:18:26.095348: train_loss -0.8689\n",
      "2024-12-06 13:18:26.103599: val_loss -0.251\n",
      "2024-12-06 13:18:26.113102: Pseudo dice [0.6863]\n",
      "2024-12-06 13:18:26.118729: Epoch time: 131.31 s\n",
      "2024-12-06 13:18:27.312865: \n",
      "2024-12-06 13:18:27.318682: Epoch 878\n",
      "2024-12-06 13:18:27.328681: Current learning rate: 0.00151\n",
      "2024-12-06 13:20:38.565680: train_loss -0.8768\n",
      "2024-12-06 13:20:38.583838: val_loss -0.2797\n",
      "2024-12-06 13:20:38.583838: Pseudo dice [0.7367]\n",
      "2024-12-06 13:20:38.599051: Epoch time: 131.25 s\n",
      "2024-12-06 13:20:39.725653: \n",
      "2024-12-06 13:20:39.732346: Epoch 879\n",
      "2024-12-06 13:20:39.742344: Current learning rate: 0.00149\n",
      "2024-12-06 13:22:51.162813: train_loss -0.8685\n",
      "2024-12-06 13:22:51.172812: val_loss -0.434\n",
      "2024-12-06 13:22:51.179396: Pseudo dice [0.7438]\n",
      "2024-12-06 13:22:51.191682: Epoch time: 131.44 s\n",
      "2024-12-06 13:22:52.389432: \n",
      "2024-12-06 13:22:52.396220: Epoch 880\n",
      "2024-12-06 13:22:52.406219: Current learning rate: 0.00148\n",
      "2024-12-06 13:25:03.776489: train_loss -0.8617\n",
      "2024-12-06 13:25:03.786487: val_loss -0.3313\n",
      "2024-12-06 13:25:03.786487: Pseudo dice [0.7681]\n",
      "2024-12-06 13:25:03.793091: Epoch time: 131.39 s\n",
      "2024-12-06 13:25:04.903008: \n",
      "2024-12-06 13:25:04.909632: Epoch 881\n",
      "2024-12-06 13:25:04.909632: Current learning rate: 0.00147\n",
      "2024-12-06 13:27:16.256649: train_loss -0.8706\n",
      "2024-12-06 13:27:16.266648: val_loss -0.4552\n",
      "2024-12-06 13:27:16.273431: Pseudo dice [0.7644]\n",
      "2024-12-06 13:27:16.273431: Epoch time: 131.35 s\n",
      "2024-12-06 13:27:17.440161: \n",
      "2024-12-06 13:27:17.450158: Epoch 882\n",
      "2024-12-06 13:27:17.450158: Current learning rate: 0.00146\n",
      "2024-12-06 13:29:28.863685: train_loss -0.8709\n",
      "2024-12-06 13:29:28.872291: val_loss -0.1923\n",
      "2024-12-06 13:29:28.882290: Pseudo dice [0.6451]\n",
      "2024-12-06 13:29:28.887120: Epoch time: 131.42 s\n",
      "2024-12-06 13:29:29.986955: \n",
      "2024-12-06 13:29:29.996955: Epoch 883\n",
      "2024-12-06 13:29:30.005491: Current learning rate: 0.00145\n",
      "2024-12-06 13:31:41.244042: train_loss -0.8631\n",
      "2024-12-06 13:31:41.251591: val_loss -0.5267\n",
      "2024-12-06 13:31:41.261590: Pseudo dice [0.855]\n",
      "2024-12-06 13:31:41.268178: Epoch time: 131.26 s\n",
      "2024-12-06 13:31:42.568105: \n",
      "2024-12-06 13:31:42.568105: Epoch 884\n",
      "2024-12-06 13:31:42.578104: Current learning rate: 0.00144\n",
      "2024-12-06 13:33:53.781052: train_loss -0.8704\n",
      "2024-12-06 13:33:53.791049: val_loss -0.5734\n",
      "2024-12-06 13:33:53.797703: Pseudo dice [0.8562]\n",
      "2024-12-06 13:33:53.797703: Epoch time: 131.21 s\n",
      "2024-12-06 13:33:54.940951: \n",
      "2024-12-06 13:33:54.947602: Epoch 885\n",
      "2024-12-06 13:33:54.957601: Current learning rate: 0.00143\n",
      "2024-12-06 13:36:06.394714: train_loss -0.874\n",
      "2024-12-06 13:36:06.404712: val_loss -0.4357\n",
      "2024-12-06 13:36:06.413359: Pseudo dice [0.8658]\n",
      "2024-12-06 13:36:06.413359: Epoch time: 131.45 s\n",
      "2024-12-06 13:36:07.527958: \n",
      "2024-12-06 13:36:07.537956: Epoch 886\n",
      "2024-12-06 13:36:07.544605: Current learning rate: 0.00142\n",
      "2024-12-06 13:38:18.759454: train_loss -0.8572\n",
      "2024-12-06 13:38:18.775445: val_loss -0.2345\n",
      "2024-12-06 13:38:18.775445: Pseudo dice [0.7463]\n",
      "2024-12-06 13:38:18.784948: Epoch time: 131.23 s\n",
      "2024-12-06 13:38:19.908294: \n",
      "2024-12-06 13:38:19.918293: Epoch 887\n",
      "2024-12-06 13:38:19.925652: Current learning rate: 0.00141\n",
      "2024-12-06 13:40:31.355365: train_loss -0.8682\n",
      "2024-12-06 13:40:31.372059: val_loss -0.3582\n",
      "2024-12-06 13:40:31.382058: Pseudo dice [0.7415]\n",
      "2024-12-06 13:40:31.389417: Epoch time: 131.45 s\n",
      "2024-12-06 13:40:32.488652: \n",
      "2024-12-06 13:40:32.505278: Epoch 888\n",
      "2024-12-06 13:40:32.505278: Current learning rate: 0.00139\n",
      "2024-12-06 13:42:43.769000: train_loss -0.8709\n",
      "2024-12-06 13:42:43.786569: val_loss -0.5444\n",
      "2024-12-06 13:42:43.786569: Pseudo dice [0.7999]\n",
      "2024-12-06 13:42:43.796567: Epoch time: 131.28 s\n",
      "2024-12-06 13:42:44.903097: \n",
      "2024-12-06 13:42:44.904306: Epoch 889\n",
      "2024-12-06 13:42:44.914304: Current learning rate: 0.00138\n",
      "2024-12-06 13:44:56.189549: train_loss -0.8725\n",
      "2024-12-06 13:44:56.199437: val_loss -0.3761\n",
      "2024-12-06 13:44:56.208939: Pseudo dice [0.8034]\n",
      "2024-12-06 13:44:56.215739: Epoch time: 131.29 s\n",
      "2024-12-06 13:44:57.325966: \n",
      "2024-12-06 13:44:57.332609: Epoch 890\n",
      "2024-12-06 13:44:57.332609: Current learning rate: 0.00137\n",
      "2024-12-06 13:47:08.723069: train_loss -0.8649\n",
      "2024-12-06 13:47:08.729700: val_loss -0.4667\n",
      "2024-12-06 13:47:08.746073: Pseudo dice [0.8092]\n",
      "2024-12-06 13:47:08.746387: Epoch time: 131.41 s\n",
      "2024-12-06 13:47:10.156315: \n",
      "2024-12-06 13:47:10.164468: Epoch 891\n",
      "2024-12-06 13:47:10.164468: Current learning rate: 0.00136\n",
      "2024-12-06 13:49:21.557164: train_loss -0.8736\n",
      "2024-12-06 13:49:21.560074: val_loss -0.3859\n",
      "2024-12-06 13:49:21.570073: Pseudo dice [0.7732]\n",
      "2024-12-06 13:49:21.576716: Epoch time: 131.4 s\n",
      "2024-12-06 13:49:22.810129: \n",
      "2024-12-06 13:49:22.810129: Epoch 892\n",
      "2024-12-06 13:49:22.820127: Current learning rate: 0.00135\n",
      "2024-12-06 13:51:34.151501: train_loss -0.8732\n",
      "2024-12-06 13:51:34.157283: val_loss -0.3007\n",
      "2024-12-06 13:51:34.166787: Pseudo dice [0.7209]\n",
      "2024-12-06 13:51:34.173739: Epoch time: 131.34 s\n",
      "2024-12-06 13:51:35.390024: \n",
      "2024-12-06 13:51:35.390294: Epoch 893\n",
      "2024-12-06 13:51:35.400293: Current learning rate: 0.00134\n",
      "2024-12-06 13:53:46.867900: train_loss -0.8762\n",
      "2024-12-06 13:53:46.878228: val_loss -0.4399\n",
      "2024-12-06 13:53:46.887361: Pseudo dice [0.8347]\n",
      "2024-12-06 13:53:46.887361: Epoch time: 131.48 s\n",
      "2024-12-06 13:53:48.080634: \n",
      "2024-12-06 13:53:48.087327: Epoch 894\n",
      "2024-12-06 13:53:48.087327: Current learning rate: 0.00133\n",
      "2024-12-06 13:55:59.362764: train_loss -0.8726\n",
      "2024-12-06 13:55:59.367724: val_loss -0.5052\n",
      "2024-12-06 13:55:59.377722: Pseudo dice [0.7957]\n",
      "2024-12-06 13:55:59.389162: Epoch time: 131.29 s\n",
      "2024-12-06 13:56:00.577355: \n",
      "2024-12-06 13:56:00.586091: Epoch 895\n",
      "2024-12-06 13:56:00.592093: Current learning rate: 0.00132\n",
      "2024-12-06 13:58:11.833261: train_loss -0.8725\n",
      "2024-12-06 13:58:11.847972: val_loss -0.4281\n",
      "2024-12-06 13:58:11.857971: Pseudo dice [0.7759]\n",
      "2024-12-06 13:58:11.864716: Epoch time: 131.26 s\n",
      "2024-12-06 13:58:12.983300: \n",
      "2024-12-06 13:58:12.991302: Epoch 896\n",
      "2024-12-06 13:58:12.996303: Current learning rate: 0.0013\n",
      "2024-12-06 14:00:24.512363: train_loss -0.8738\n",
      "2024-12-06 14:00:24.513765: val_loss -0.5701\n",
      "2024-12-06 14:00:24.528340: Pseudo dice [0.8707]\n",
      "2024-12-06 14:00:24.528340: Epoch time: 131.53 s\n",
      "2024-12-06 14:00:24.538339: Yayy! New best EMA pseudo Dice: 0.787\n",
      "2024-12-06 14:00:25.978723: \n",
      "2024-12-06 14:00:25.988226: Epoch 897\n",
      "2024-12-06 14:00:25.988226: Current learning rate: 0.00129\n",
      "2024-12-06 14:02:37.291984: train_loss -0.8694\n",
      "2024-12-06 14:02:37.308611: val_loss -0.4068\n",
      "2024-12-06 14:02:37.318609: Pseudo dice [0.7729]\n",
      "2024-12-06 14:02:37.325014: Epoch time: 131.31 s\n",
      "2024-12-06 14:02:38.701931: \n",
      "2024-12-06 14:02:38.708516: Epoch 898\n",
      "2024-12-06 14:02:38.708516: Current learning rate: 0.00128\n",
      "2024-12-06 14:04:50.148808: train_loss -0.8702\n",
      "2024-12-06 14:04:50.155616: val_loss -0.5784\n",
      "2024-12-06 14:04:50.172325: Pseudo dice [0.8507]\n",
      "2024-12-06 14:04:50.172325: Epoch time: 131.45 s\n",
      "2024-12-06 14:04:50.182323: Yayy! New best EMA pseudo Dice: 0.7921\n",
      "2024-12-06 14:04:51.565511: \n",
      "2024-12-06 14:04:51.572188: Epoch 899\n",
      "2024-12-06 14:04:51.582187: Current learning rate: 0.00127\n",
      "2024-12-06 14:07:02.935909: train_loss -0.8727\n",
      "2024-12-06 14:07:02.945907: val_loss -0.4583\n",
      "2024-12-06 14:07:02.952673: Pseudo dice [0.7855]\n",
      "2024-12-06 14:07:02.962672: Epoch time: 131.37 s\n",
      "2024-12-06 14:07:04.380335: \n",
      "2024-12-06 14:07:04.385922: Epoch 900\n",
      "2024-12-06 14:07:04.395921: Current learning rate: 0.00126\n",
      "2024-12-06 14:09:15.642930: train_loss -0.8748\n",
      "2024-12-06 14:09:15.649572: val_loss -0.4924\n",
      "2024-12-06 14:09:15.666196: Pseudo dice [0.7968]\n",
      "2024-12-06 14:09:15.666196: Epoch time: 131.26 s\n",
      "2024-12-06 14:09:16.783291: \n",
      "2024-12-06 14:09:16.791337: Epoch 901\n",
      "2024-12-06 14:09:16.796338: Current learning rate: 0.00125\n",
      "2024-12-06 14:11:28.163269: train_loss -0.8757\n",
      "2024-12-06 14:11:28.173268: val_loss -0.4226\n",
      "2024-12-06 14:11:28.179913: Pseudo dice [0.7729]\n",
      "2024-12-06 14:11:28.189911: Epoch time: 131.38 s\n",
      "2024-12-06 14:11:29.313320: \n",
      "2024-12-06 14:11:29.323318: Epoch 902\n",
      "2024-12-06 14:11:29.329889: Current learning rate: 0.00124\n",
      "2024-12-06 14:13:45.883401: train_loss -0.8719\n",
      "2024-12-06 14:13:45.894404: val_loss -0.4595\n",
      "2024-12-06 14:13:45.899405: Pseudo dice [0.8024]\n",
      "2024-12-06 14:13:45.905407: Epoch time: 136.57 s\n",
      "2024-12-06 14:13:46.973648: \n",
      "2024-12-06 14:13:46.981649: Epoch 903\n",
      "2024-12-06 14:13:46.986651: Current learning rate: 0.00122\n",
      "2024-12-06 14:16:05.404022: train_loss -0.8759\n",
      "2024-12-06 14:16:05.416026: val_loss -0.5989\n",
      "2024-12-06 14:16:05.424027: Pseudo dice [0.8068]\n",
      "2024-12-06 14:16:05.430029: Epoch time: 138.43 s\n",
      "2024-12-06 14:16:05.435030: Yayy! New best EMA pseudo Dice: 0.7928\n",
      "2024-12-06 14:16:06.962801: \n",
      "2024-12-06 14:16:06.971805: Epoch 904\n",
      "2024-12-06 14:16:06.977806: Current learning rate: 0.00121\n",
      "2024-12-06 14:18:27.546293: train_loss -0.8754\n",
      "2024-12-06 14:18:27.558295: val_loss -0.3626\n",
      "2024-12-06 14:18:27.564297: Pseudo dice [0.7513]\n",
      "2024-12-06 14:18:27.573299: Epoch time: 140.58 s\n",
      "2024-12-06 14:18:28.722900: \n",
      "2024-12-06 14:18:28.731902: Epoch 905\n",
      "2024-12-06 14:18:28.737154: Current learning rate: 0.0012\n",
      "2024-12-06 14:20:49.955219: train_loss -0.8699\n",
      "2024-12-06 14:20:49.964219: val_loss -0.4777\n",
      "2024-12-06 14:20:49.971222: Pseudo dice [0.8282]\n",
      "2024-12-06 14:20:49.977224: Epoch time: 141.23 s\n",
      "2024-12-06 14:20:51.391426: \n",
      "2024-12-06 14:20:51.400428: Epoch 906\n",
      "2024-12-06 14:20:51.406429: Current learning rate: 0.00119\n",
      "2024-12-06 14:23:05.596503: train_loss -0.877\n",
      "2024-12-06 14:23:05.607506: val_loss -0.4458\n",
      "2024-12-06 14:23:05.618510: Pseudo dice [0.8401]\n",
      "2024-12-06 14:23:05.624512: Epoch time: 134.21 s\n",
      "2024-12-06 14:23:05.630513: Yayy! New best EMA pseudo Dice: 0.7974\n",
      "2024-12-06 14:23:07.143276: \n",
      "2024-12-06 14:23:07.151278: Epoch 907\n",
      "2024-12-06 14:23:07.157279: Current learning rate: 0.00118\n",
      "2024-12-06 14:25:19.898150: train_loss -0.8662\n",
      "2024-12-06 14:25:19.908153: val_loss -0.3181\n",
      "2024-12-06 14:25:19.916155: Pseudo dice [0.7672]\n",
      "2024-12-06 14:25:19.922156: Epoch time: 132.76 s\n",
      "2024-12-06 14:25:21.147506: \n",
      "2024-12-06 14:25:21.155508: Epoch 908\n",
      "2024-12-06 14:25:21.161509: Current learning rate: 0.00117\n",
      "2024-12-06 14:27:32.877828: train_loss -0.8717\n",
      "2024-12-06 14:27:32.887830: val_loss -0.2543\n",
      "2024-12-06 14:27:32.892831: Pseudo dice [0.7237]\n",
      "2024-12-06 14:27:32.897832: Epoch time: 131.73 s\n",
      "2024-12-06 14:27:34.020726: \n",
      "2024-12-06 14:27:34.028727: Epoch 909\n",
      "2024-12-06 14:27:34.034750: Current learning rate: 0.00116\n",
      "2024-12-06 14:29:45.671614: train_loss -0.8701\n",
      "2024-12-06 14:29:45.681617: val_loss -0.4761\n",
      "2024-12-06 14:29:45.691124: Pseudo dice [0.7875]\n",
      "2024-12-06 14:29:45.698125: Epoch time: 131.65 s\n",
      "2024-12-06 14:29:46.799711: \n",
      "2024-12-06 14:29:46.808712: Epoch 910\n",
      "2024-12-06 14:29:46.813712: Current learning rate: 0.00115\n",
      "2024-12-06 14:31:59.679307: train_loss -0.8736\n",
      "2024-12-06 14:31:59.691311: val_loss -0.5097\n",
      "2024-12-06 14:31:59.697311: Pseudo dice [0.8606]\n",
      "2024-12-06 14:31:59.703312: Epoch time: 132.88 s\n",
      "2024-12-06 14:32:00.777414: \n",
      "2024-12-06 14:32:00.785417: Epoch 911\n",
      "2024-12-06 14:32:00.791418: Current learning rate: 0.00113\n",
      "2024-12-06 14:34:14.784099: train_loss -0.8727\n",
      "2024-12-06 14:34:14.793150: val_loss -0.2695\n",
      "2024-12-06 14:34:14.799153: Pseudo dice [0.666]\n",
      "2024-12-06 14:34:14.804153: Epoch time: 134.01 s\n",
      "2024-12-06 14:34:15.935483: \n",
      "2024-12-06 14:34:15.943484: Epoch 912\n",
      "2024-12-06 14:34:15.949486: Current learning rate: 0.00112\n",
      "2024-12-06 14:36:28.251835: train_loss -0.8716\n",
      "2024-12-06 14:36:28.260838: val_loss -0.3419\n",
      "2024-12-06 14:36:28.267839: Pseudo dice [0.771]\n",
      "2024-12-06 14:36:28.273840: Epoch time: 132.32 s\n",
      "2024-12-06 14:36:29.528189: \n",
      "2024-12-06 14:36:29.536698: Epoch 913\n",
      "2024-12-06 14:36:29.542699: Current learning rate: 0.00111\n",
      "2024-12-06 14:38:41.859702: train_loss -0.8768\n",
      "2024-12-06 14:38:41.876288: val_loss -0.4373\n",
      "2024-12-06 14:38:41.886286: Pseudo dice [0.809]\n",
      "2024-12-06 14:38:41.894133: Epoch time: 132.33 s\n",
      "2024-12-06 14:38:43.109563: \n",
      "2024-12-06 14:38:43.119561: Epoch 914\n",
      "2024-12-06 14:38:43.126957: Current learning rate: 0.0011\n",
      "2024-12-06 14:40:54.416470: train_loss -0.8721\n",
      "2024-12-06 14:40:54.433268: val_loss -0.4138\n",
      "2024-12-06 14:40:54.440020: Pseudo dice [0.7622]\n",
      "2024-12-06 14:40:54.450018: Epoch time: 131.31 s\n",
      "2024-12-06 14:40:55.673349: \n",
      "2024-12-06 14:40:55.683347: Epoch 915\n",
      "2024-12-06 14:40:55.689658: Current learning rate: 0.00109\n",
      "2024-12-06 14:43:07.116446: train_loss -0.8685\n",
      "2024-12-06 14:43:07.120675: val_loss -0.5006\n",
      "2024-12-06 14:43:07.130178: Pseudo dice [0.85]\n",
      "2024-12-06 14:43:07.136988: Epoch time: 131.44 s\n",
      "2024-12-06 14:43:08.370365: \n",
      "2024-12-06 14:43:08.370365: Epoch 916\n",
      "2024-12-06 14:43:08.380365: Current learning rate: 0.00108\n",
      "2024-12-06 14:45:22.282019: train_loss -0.8706\n",
      "2024-12-06 14:45:22.282019: val_loss -0.5354\n",
      "2024-12-06 14:45:22.293021: Pseudo dice [0.7962]\n",
      "2024-12-06 14:45:22.299023: Epoch time: 133.92 s\n",
      "2024-12-06 14:45:23.563311: \n",
      "2024-12-06 14:45:23.563311: Epoch 917\n",
      "2024-12-06 14:45:23.572312: Current learning rate: 0.00106\n",
      "2024-12-06 14:47:35.282753: train_loss -0.8712\n",
      "2024-12-06 14:47:35.282753: val_loss -0.2438\n",
      "2024-12-06 14:47:35.297549: Pseudo dice [0.6747]\n",
      "2024-12-06 14:47:35.297549: Epoch time: 131.72 s\n",
      "2024-12-06 14:47:36.431551: \n",
      "2024-12-06 14:47:36.445184: Epoch 918\n",
      "2024-12-06 14:47:36.450660: Current learning rate: 0.00105\n",
      "2024-12-06 14:49:47.911721: train_loss -0.8679\n",
      "2024-12-06 14:49:47.927915: val_loss -0.3426\n",
      "2024-12-06 14:49:47.937913: Pseudo dice [0.7536]\n",
      "2024-12-06 14:49:47.944654: Epoch time: 131.48 s\n",
      "2024-12-06 14:49:49.054449: \n",
      "2024-12-06 14:49:49.062197: Epoch 919\n",
      "2024-12-06 14:49:49.062197: Current learning rate: 0.00104\n",
      "2024-12-06 14:52:00.263229: train_loss -0.8648\n",
      "2024-12-06 14:52:00.275668: val_loss -0.2456\n",
      "2024-12-06 14:52:00.292381: Pseudo dice [0.651]\n",
      "2024-12-06 14:52:00.302379: Epoch time: 131.22 s\n",
      "2024-12-06 14:52:01.591439: \n",
      "2024-12-06 14:52:01.601438: Epoch 920\n",
      "2024-12-06 14:52:01.609056: Current learning rate: 0.00103\n",
      "2024-12-06 14:54:13.005193: train_loss -0.8676\n",
      "2024-12-06 14:54:13.015191: val_loss 0.0726\n",
      "2024-12-06 14:54:13.031797: Pseudo dice [0.4027]\n",
      "2024-12-06 14:54:13.031797: Epoch time: 131.41 s\n",
      "2024-12-06 14:54:14.188625: \n",
      "2024-12-06 14:54:14.198623: Epoch 921\n",
      "2024-12-06 14:54:14.204875: Current learning rate: 0.00102\n",
      "2024-12-06 14:56:25.678782: train_loss -0.855\n",
      "2024-12-06 14:56:25.695511: val_loss -0.4939\n",
      "2024-12-06 14:56:25.702254: Pseudo dice [0.7962]\n",
      "2024-12-06 14:56:25.718843: Epoch time: 131.49 s\n",
      "2024-12-06 14:56:26.829652: \n",
      "2024-12-06 14:56:26.835878: Epoch 922\n",
      "2024-12-06 14:56:26.835878: Current learning rate: 0.00101\n",
      "2024-12-06 14:58:38.100801: train_loss -0.875\n",
      "2024-12-06 14:58:38.115908: val_loss -0.499\n",
      "2024-12-06 14:58:38.125907: Pseudo dice [0.8505]\n",
      "2024-12-06 14:58:38.125907: Epoch time: 131.27 s\n",
      "2024-12-06 14:58:39.359123: \n",
      "2024-12-06 14:58:39.367455: Epoch 923\n",
      "2024-12-06 14:58:39.367455: Current learning rate: 0.001\n",
      "2024-12-06 15:00:50.747669: train_loss -0.8679\n",
      "2024-12-06 15:00:50.757172: val_loss -0.3668\n",
      "2024-12-06 15:00:50.762902: Pseudo dice [0.7845]\n",
      "2024-12-06 15:00:50.762902: Epoch time: 131.39 s\n",
      "2024-12-06 15:00:51.906135: \n",
      "2024-12-06 15:00:51.912769: Epoch 924\n",
      "2024-12-06 15:00:51.922767: Current learning rate: 0.00098\n",
      "2024-12-06 15:03:03.311083: train_loss -0.8723\n",
      "2024-12-06 15:03:03.326962: val_loss -0.387\n",
      "2024-12-06 15:03:03.336464: Pseudo dice [0.8213]\n",
      "2024-12-06 15:03:03.345005: Epoch time: 131.4 s\n",
      "2024-12-06 15:03:04.494248: \n",
      "2024-12-06 15:03:04.504247: Epoch 925\n",
      "2024-12-06 15:03:04.509542: Current learning rate: 0.00097\n",
      "2024-12-06 15:05:15.857081: train_loss -0.8747\n",
      "2024-12-06 15:05:15.866584: val_loss -0.3938\n",
      "2024-12-06 15:05:15.875468: Pseudo dice [0.7569]\n",
      "2024-12-06 15:05:15.875468: Epoch time: 131.36 s\n",
      "2024-12-06 15:05:17.073192: \n",
      "2024-12-06 15:05:17.074272: Epoch 926\n",
      "2024-12-06 15:05:17.084272: Current learning rate: 0.00096\n",
      "2024-12-06 15:07:31.087162: train_loss -0.8731\n",
      "2024-12-06 15:07:31.097160: val_loss -0.3713\n",
      "2024-12-06 15:07:31.105613: Pseudo dice [0.7235]\n",
      "2024-12-06 15:07:31.120464: Epoch time: 134.02 s\n",
      "2024-12-06 15:07:32.280379: \n",
      "2024-12-06 15:07:32.288799: Epoch 927\n",
      "2024-12-06 15:07:32.288799: Current learning rate: 0.00095\n",
      "2024-12-06 15:09:43.462666: train_loss -0.8746\n",
      "2024-12-06 15:09:43.468665: val_loss -0.4888\n",
      "2024-12-06 15:09:43.487394: Pseudo dice [0.8194]\n",
      "2024-12-06 15:09:43.493394: Epoch time: 131.18 s\n",
      "2024-12-06 15:09:44.811608: \n",
      "2024-12-06 15:09:44.818858: Epoch 928\n",
      "2024-12-06 15:09:44.818858: Current learning rate: 0.00094\n",
      "2024-12-06 15:11:56.031818: train_loss -0.8741\n",
      "2024-12-06 15:11:56.047841: val_loss -0.3442\n",
      "2024-12-06 15:11:56.057840: Pseudo dice [0.7306]\n",
      "2024-12-06 15:11:56.064407: Epoch time: 131.22 s\n",
      "2024-12-06 15:11:57.241036: \n",
      "2024-12-06 15:11:57.247713: Epoch 929\n",
      "2024-12-06 15:11:57.247713: Current learning rate: 0.00092\n",
      "2024-12-06 15:14:08.711452: train_loss -0.8732\n",
      "2024-12-06 15:14:08.728152: val_loss -0.5648\n",
      "2024-12-06 15:14:08.745500: Pseudo dice [0.8754]\n",
      "2024-12-06 15:14:08.746981: Epoch time: 131.47 s\n",
      "2024-12-06 15:14:09.888035: \n",
      "2024-12-06 15:14:09.894702: Epoch 930\n",
      "2024-12-06 15:14:09.894702: Current learning rate: 0.00091\n",
      "2024-12-06 15:16:21.185113: train_loss -0.8741\n",
      "2024-12-06 15:16:21.192808: val_loss -0.4383\n",
      "2024-12-06 15:16:21.210576: Pseudo dice [0.7969]\n",
      "2024-12-06 15:16:21.210576: Epoch time: 131.3 s\n",
      "2024-12-06 15:16:22.456595: \n",
      "2024-12-06 15:16:22.458441: Epoch 931\n",
      "2024-12-06 15:16:22.467945: Current learning rate: 0.0009\n",
      "2024-12-06 15:18:33.882126: train_loss -0.8627\n",
      "2024-12-06 15:18:33.888784: val_loss -0.2994\n",
      "2024-12-06 15:18:33.898782: Pseudo dice [0.6928]\n",
      "2024-12-06 15:18:33.905423: Epoch time: 131.43 s\n",
      "2024-12-06 15:18:35.133100: \n",
      "2024-12-06 15:18:35.138712: Epoch 932\n",
      "2024-12-06 15:18:35.148711: Current learning rate: 0.00089\n",
      "2024-12-06 15:20:46.435885: train_loss -0.8734\n",
      "2024-12-06 15:20:46.445885: val_loss -0.3542\n",
      "2024-12-06 15:20:46.452441: Pseudo dice [0.7442]\n",
      "2024-12-06 15:20:46.462439: Epoch time: 131.3 s\n",
      "2024-12-06 15:20:47.619020: \n",
      "2024-12-06 15:20:47.619020: Epoch 933\n",
      "2024-12-06 15:20:47.629018: Current learning rate: 0.00088\n",
      "2024-12-06 15:22:58.842871: train_loss -0.8675\n",
      "2024-12-06 15:22:58.849390: val_loss -0.0478\n",
      "2024-12-06 15:22:58.859388: Pseudo dice [0.6258]\n",
      "2024-12-06 15:22:58.866169: Epoch time: 131.22 s\n",
      "2024-12-06 15:22:59.987448: \n",
      "2024-12-06 15:22:59.995450: Epoch 934\n",
      "2024-12-06 15:23:00.000108: Current learning rate: 0.00087\n",
      "2024-12-06 15:25:11.329756: train_loss -0.8765\n",
      "2024-12-06 15:25:11.339754: val_loss 0.1896\n",
      "2024-12-06 15:25:11.346405: Pseudo dice [0.4571]\n",
      "2024-12-06 15:25:11.346405: Epoch time: 131.34 s\n",
      "2024-12-06 15:25:12.696353: \n",
      "2024-12-06 15:25:12.713012: Epoch 935\n",
      "2024-12-06 15:25:12.713012: Current learning rate: 0.00085\n",
      "2024-12-06 15:27:24.120057: train_loss -0.8662\n",
      "2024-12-06 15:27:24.128284: val_loss -0.4566\n",
      "2024-12-06 15:27:24.144267: Pseudo dice [0.8231]\n",
      "2024-12-06 15:27:24.149266: Epoch time: 131.42 s\n",
      "2024-12-06 15:27:25.261038: \n",
      "2024-12-06 15:27:25.261038: Epoch 936\n",
      "2024-12-06 15:27:25.271037: Current learning rate: 0.00084\n",
      "2024-12-06 15:29:36.536727: train_loss -0.8701\n",
      "2024-12-06 15:29:36.540401: val_loss -0.48\n",
      "2024-12-06 15:29:36.557137: Pseudo dice [0.8031]\n",
      "2024-12-06 15:29:36.557137: Epoch time: 131.28 s\n",
      "2024-12-06 15:29:37.767957: \n",
      "2024-12-06 15:29:37.774229: Epoch 937\n",
      "2024-12-06 15:29:37.774229: Current learning rate: 0.00083\n",
      "2024-12-06 15:31:49.230851: train_loss -0.8754\n",
      "2024-12-06 15:31:49.239117: val_loss -0.5413\n",
      "2024-12-06 15:31:49.249157: Pseudo dice [0.8293]\n",
      "2024-12-06 15:31:49.254029: Epoch time: 131.47 s\n",
      "2024-12-06 15:31:50.397350: \n",
      "2024-12-06 15:31:50.407884: Epoch 938\n",
      "2024-12-06 15:31:50.412885: Current learning rate: 0.00082\n",
      "2024-12-06 15:34:01.634470: train_loss -0.8682\n",
      "2024-12-06 15:34:01.652000: val_loss -0.3021\n",
      "2024-12-06 15:34:01.661999: Pseudo dice [0.7669]\n",
      "2024-12-06 15:34:01.668175: Epoch time: 131.24 s\n",
      "2024-12-06 15:34:02.769232: \n",
      "2024-12-06 15:34:02.778735: Epoch 939\n",
      "2024-12-06 15:34:02.786187: Current learning rate: 0.00081\n",
      "2024-12-06 15:36:14.014681: train_loss -0.8804\n",
      "2024-12-06 15:36:14.031359: val_loss -0.3817\n",
      "2024-12-06 15:36:14.041357: Pseudo dice [0.7783]\n",
      "2024-12-06 15:36:14.048057: Epoch time: 131.25 s\n",
      "2024-12-06 15:36:15.174636: \n",
      "2024-12-06 15:36:15.186159: Epoch 940\n",
      "2024-12-06 15:36:15.191161: Current learning rate: 0.00079\n",
      "2024-12-06 15:38:26.612575: train_loss -0.8768\n",
      "2024-12-06 15:38:26.628370: val_loss -0.5433\n",
      "2024-12-06 15:38:26.628370: Pseudo dice [0.8442]\n",
      "2024-12-06 15:38:26.638369: Epoch time: 131.44 s\n",
      "2024-12-06 15:38:27.755811: \n",
      "2024-12-06 15:38:27.762118: Epoch 941\n",
      "2024-12-06 15:38:27.762118: Current learning rate: 0.00078\n",
      "2024-12-06 15:40:39.035338: train_loss -0.8725\n",
      "2024-12-06 15:40:39.048882: val_loss -0.442\n",
      "2024-12-06 15:40:39.054883: Pseudo dice [0.8039]\n",
      "2024-12-06 15:40:39.060858: Epoch time: 131.29 s\n",
      "2024-12-06 15:40:40.368618: \n",
      "2024-12-06 15:40:40.375288: Epoch 942\n",
      "2024-12-06 15:40:40.385288: Current learning rate: 0.00077\n",
      "2024-12-06 15:42:51.765668: train_loss -0.8745\n",
      "2024-12-06 15:42:51.774493: val_loss -0.3101\n",
      "2024-12-06 15:42:51.784492: Pseudo dice [0.7379]\n",
      "2024-12-06 15:42:51.789047: Epoch time: 131.4 s\n",
      "2024-12-06 15:42:52.905619: \n",
      "2024-12-06 15:42:52.905619: Epoch 943\n",
      "2024-12-06 15:42:52.915617: Current learning rate: 0.00076\n",
      "2024-12-06 15:45:04.219394: train_loss -0.867\n",
      "2024-12-06 15:45:04.235762: val_loss -0.3199\n",
      "2024-12-06 15:45:04.246104: Pseudo dice [0.7132]\n",
      "2024-12-06 15:45:04.252428: Epoch time: 131.32 s\n",
      "2024-12-06 15:45:05.445941: \n",
      "2024-12-06 15:45:05.452628: Epoch 944\n",
      "2024-12-06 15:45:05.452628: Current learning rate: 0.00075\n",
      "2024-12-06 15:47:16.733098: train_loss -0.8731\n",
      "2024-12-06 15:47:16.743096: val_loss -0.4317\n",
      "2024-12-06 15:47:16.749730: Pseudo dice [0.7294]\n",
      "2024-12-06 15:47:16.759729: Epoch time: 131.29 s\n",
      "2024-12-06 15:47:17.983002: \n",
      "2024-12-06 15:47:17.992003: Epoch 945\n",
      "2024-12-06 15:47:17.997004: Current learning rate: 0.00074\n",
      "2024-12-06 15:49:29.306714: train_loss -0.8729\n",
      "2024-12-06 15:49:29.313438: val_loss -0.4913\n",
      "2024-12-06 15:49:29.330066: Pseudo dice [0.7495]\n",
      "2024-12-06 15:49:29.330066: Epoch time: 131.33 s\n",
      "2024-12-06 15:49:30.557665: \n",
      "2024-12-06 15:49:30.563344: Epoch 946\n",
      "2024-12-06 15:49:30.563344: Current learning rate: 0.00072\n",
      "2024-12-06 15:51:42.010344: train_loss -0.8767\n",
      "2024-12-06 15:51:42.027080: val_loss -0.1131\n",
      "2024-12-06 15:51:42.037079: Pseudo dice [0.5609]\n",
      "2024-12-06 15:51:42.045544: Epoch time: 131.46 s\n",
      "2024-12-06 15:51:43.260333: \n",
      "2024-12-06 15:51:43.276958: Epoch 947\n",
      "2024-12-06 15:51:43.276958: Current learning rate: 0.00071\n",
      "2024-12-06 15:53:54.524017: train_loss -0.8752\n",
      "2024-12-06 15:53:54.542945: val_loss -0.3612\n",
      "2024-12-06 15:53:54.557440: Pseudo dice [0.7313]\n",
      "2024-12-06 15:53:54.557440: Epoch time: 131.26 s\n",
      "2024-12-06 15:53:55.708686: \n",
      "2024-12-06 15:53:55.718188: Epoch 948\n",
      "2024-12-06 15:53:55.723969: Current learning rate: 0.0007\n",
      "2024-12-06 15:56:07.138767: train_loss -0.8743\n",
      "2024-12-06 15:56:07.154902: val_loss -0.4129\n",
      "2024-12-06 15:56:07.164406: Pseudo dice [0.7848]\n",
      "2024-12-06 15:56:07.171077: Epoch time: 131.43 s\n",
      "2024-12-06 15:56:08.288593: \n",
      "2024-12-06 15:56:08.304056: Epoch 949\n",
      "2024-12-06 15:56:08.308611: Current learning rate: 0.00069\n",
      "2024-12-06 15:58:19.528093: train_loss -0.8755\n",
      "2024-12-06 15:58:19.534715: val_loss -0.2795\n",
      "2024-12-06 15:58:19.544713: Pseudo dice [0.7408]\n",
      "2024-12-06 15:58:19.553197: Epoch time: 131.24 s\n",
      "2024-12-06 15:58:21.253252: \n",
      "2024-12-06 15:58:21.267744: Epoch 950\n",
      "2024-12-06 15:58:21.268105: Current learning rate: 0.00067\n",
      "2024-12-06 16:00:32.465163: train_loss -0.8699\n",
      "2024-12-06 16:00:32.475162: val_loss -0.3137\n",
      "2024-12-06 16:00:32.490536: Pseudo dice [0.7134]\n",
      "2024-12-06 16:00:32.500823: Epoch time: 131.21 s\n",
      "2024-12-06 16:00:33.715755: \n",
      "2024-12-06 16:00:33.725755: Epoch 951\n",
      "2024-12-06 16:00:33.732034: Current learning rate: 0.00066\n",
      "2024-12-06 16:02:45.172000: train_loss -0.8782\n",
      "2024-12-06 16:02:45.178722: val_loss -0.3758\n",
      "2024-12-06 16:02:45.195408: Pseudo dice [0.7792]\n",
      "2024-12-06 16:02:45.195408: Epoch time: 131.46 s\n",
      "2024-12-06 16:02:46.312136: \n",
      "2024-12-06 16:02:46.322134: Epoch 952\n",
      "2024-12-06 16:02:46.322134: Current learning rate: 0.00065\n",
      "2024-12-06 16:04:57.609107: train_loss -0.8759\n",
      "2024-12-06 16:04:57.625697: val_loss -0.5362\n",
      "2024-12-06 16:04:57.635696: Pseudo dice [0.8021]\n",
      "2024-12-06 16:04:57.644175: Epoch time: 131.3 s\n",
      "2024-12-06 16:04:58.753854: \n",
      "2024-12-06 16:04:58.760436: Epoch 953\n",
      "2024-12-06 16:04:58.760436: Current learning rate: 0.00064\n",
      "2024-12-06 16:07:10.109709: train_loss -0.8742\n",
      "2024-12-06 16:07:10.122398: val_loss -0.326\n",
      "2024-12-06 16:07:10.122749: Pseudo dice [0.7424]\n",
      "2024-12-06 16:07:10.132747: Epoch time: 131.36 s\n",
      "2024-12-06 16:07:11.333506: \n",
      "2024-12-06 16:07:11.339696: Epoch 954\n",
      "2024-12-06 16:07:11.349199: Current learning rate: 0.00063\n",
      "2024-12-06 16:09:22.702816: train_loss -0.8762\n",
      "2024-12-06 16:09:22.713858: val_loss -0.3251\n",
      "2024-12-06 16:09:22.721651: Pseudo dice [0.7206]\n",
      "2024-12-06 16:09:22.731153: Epoch time: 131.37 s\n",
      "2024-12-06 16:09:23.879570: \n",
      "2024-12-06 16:09:23.887730: Epoch 955\n",
      "2024-12-06 16:09:23.897233: Current learning rate: 0.00061\n",
      "2024-12-06 16:11:35.133348: train_loss -0.8819\n",
      "2024-12-06 16:11:35.150965: val_loss -0.5329\n",
      "2024-12-06 16:11:35.160964: Pseudo dice [0.8358]\n",
      "2024-12-06 16:11:35.167372: Epoch time: 131.25 s\n",
      "2024-12-06 16:11:36.298163: \n",
      "2024-12-06 16:11:36.299894: Epoch 956\n",
      "2024-12-06 16:11:36.309397: Current learning rate: 0.0006\n",
      "2024-12-06 16:13:47.630321: train_loss -0.8758\n",
      "2024-12-06 16:13:47.640320: val_loss -0.4135\n",
      "2024-12-06 16:13:47.647065: Pseudo dice [0.7832]\n",
      "2024-12-06 16:13:47.657063: Epoch time: 131.33 s\n",
      "2024-12-06 16:13:48.956895: \n",
      "2024-12-06 16:13:48.963624: Epoch 957\n",
      "2024-12-06 16:13:48.973623: Current learning rate: 0.00059\n",
      "2024-12-06 16:16:00.445931: train_loss -0.8752\n",
      "2024-12-06 16:16:00.455929: val_loss -0.2374\n",
      "2024-12-06 16:16:00.461436: Pseudo dice [0.6581]\n",
      "2024-12-06 16:16:00.461436: Epoch time: 131.49 s\n",
      "2024-12-06 16:16:01.587211: \n",
      "2024-12-06 16:16:01.593918: Epoch 958\n",
      "2024-12-06 16:16:01.603917: Current learning rate: 0.00058\n",
      "2024-12-06 16:18:12.790976: train_loss -0.8794\n",
      "2024-12-06 16:18:12.807717: val_loss -0.315\n",
      "2024-12-06 16:18:12.807717: Pseudo dice [0.6688]\n",
      "2024-12-06 16:18:12.824342: Epoch time: 131.2 s\n",
      "2024-12-06 16:18:13.950901: \n",
      "2024-12-06 16:18:13.957556: Epoch 959\n",
      "2024-12-06 16:18:13.957556: Current learning rate: 0.00056\n",
      "2024-12-06 16:20:25.388126: train_loss -0.8773\n",
      "2024-12-06 16:20:25.404637: val_loss -0.0964\n",
      "2024-12-06 16:20:25.404637: Pseudo dice [0.6115]\n",
      "2024-12-06 16:20:25.414635: Epoch time: 131.44 s\n",
      "2024-12-06 16:20:26.639002: \n",
      "2024-12-06 16:20:26.649000: Epoch 960\n",
      "2024-12-06 16:20:26.707721: Current learning rate: 0.00055\n",
      "2024-12-06 16:22:37.961604: train_loss -0.8813\n",
      "2024-12-06 16:22:37.968295: val_loss -0.2233\n",
      "2024-12-06 16:22:37.984977: Pseudo dice [0.6483]\n",
      "2024-12-06 16:22:37.984977: Epoch time: 131.32 s\n",
      "2024-12-06 16:22:39.184935: \n",
      "2024-12-06 16:22:39.202451: Epoch 961\n",
      "2024-12-06 16:22:39.208452: Current learning rate: 0.00054\n",
      "2024-12-06 16:24:50.450694: train_loss -0.8812\n",
      "2024-12-06 16:24:50.465277: val_loss -0.3574\n",
      "2024-12-06 16:24:50.483839: Pseudo dice [0.7847]\n",
      "2024-12-06 16:24:50.488840: Epoch time: 131.27 s\n",
      "2024-12-06 16:24:51.626375: \n",
      "2024-12-06 16:24:51.631891: Epoch 962\n",
      "2024-12-06 16:24:51.641890: Current learning rate: 0.00053\n",
      "2024-12-06 16:27:03.078676: train_loss -0.8734\n",
      "2024-12-06 16:27:03.088964: val_loss -0.1443\n",
      "2024-12-06 16:27:03.088964: Pseudo dice [0.6054]\n",
      "2024-12-06 16:27:03.095615: Epoch time: 131.45 s\n",
      "2024-12-06 16:27:04.296337: \n",
      "2024-12-06 16:27:04.296780: Epoch 963\n",
      "2024-12-06 16:27:04.306778: Current learning rate: 0.00051\n",
      "2024-12-06 16:29:15.675969: train_loss -0.8752\n",
      "2024-12-06 16:29:15.685967: val_loss -0.361\n",
      "2024-12-06 16:29:15.692671: Pseudo dice [0.6909]\n",
      "2024-12-06 16:29:15.702670: Epoch time: 131.39 s\n",
      "2024-12-06 16:29:17.085929: \n",
      "2024-12-06 16:29:17.094284: Epoch 964\n",
      "2024-12-06 16:29:17.094284: Current learning rate: 0.0005\n",
      "2024-12-06 16:31:28.472919: train_loss -0.8794\n",
      "2024-12-06 16:31:28.489324: val_loss -0.3181\n",
      "2024-12-06 16:31:28.499571: Pseudo dice [0.7229]\n",
      "2024-12-06 16:31:28.507004: Epoch time: 131.39 s\n",
      "2024-12-06 16:31:29.673101: \n",
      "2024-12-06 16:31:29.683099: Epoch 965\n",
      "2024-12-06 16:31:29.683099: Current learning rate: 0.00049\n",
      "2024-12-06 16:33:41.086599: train_loss -0.8695\n",
      "2024-12-06 16:33:41.103095: val_loss -0.4247\n",
      "2024-12-06 16:33:41.109112: Pseudo dice [0.7855]\n",
      "2024-12-06 16:33:41.114113: Epoch time: 131.41 s\n",
      "2024-12-06 16:33:42.315072: \n",
      "2024-12-06 16:33:42.320910: Epoch 966\n",
      "2024-12-06 16:33:42.320910: Current learning rate: 0.00048\n",
      "2024-12-06 16:35:53.595472: train_loss -0.8731\n",
      "2024-12-06 16:35:53.602107: val_loss -0.279\n",
      "2024-12-06 16:35:53.616993: Pseudo dice [0.6535]\n",
      "2024-12-06 16:35:53.626992: Epoch time: 131.28 s\n",
      "2024-12-06 16:35:54.833530: \n",
      "2024-12-06 16:35:54.849956: Epoch 967\n",
      "2024-12-06 16:35:54.850219: Current learning rate: 0.00046\n",
      "2024-12-06 16:38:06.147360: train_loss -0.8743\n",
      "2024-12-06 16:38:06.157358: val_loss -0.3002\n",
      "2024-12-06 16:38:06.163924: Pseudo dice [0.7267]\n",
      "2024-12-06 16:38:06.173923: Epoch time: 131.31 s\n",
      "2024-12-06 16:38:07.313873: \n",
      "2024-12-06 16:38:07.323871: Epoch 968\n",
      "2024-12-06 16:38:07.330567: Current learning rate: 0.00045\n",
      "2024-12-06 16:40:18.777567: train_loss -0.8748\n",
      "2024-12-06 16:40:18.794349: val_loss -0.3501\n",
      "2024-12-06 16:40:18.810977: Pseudo dice [0.674]\n",
      "2024-12-06 16:40:18.810977: Epoch time: 131.46 s\n",
      "2024-12-06 16:40:19.977505: \n",
      "2024-12-06 16:40:19.987504: Epoch 969\n",
      "2024-12-06 16:40:19.995706: Current learning rate: 0.00044\n",
      "2024-12-06 16:42:31.235771: train_loss -0.8745\n",
      "2024-12-06 16:42:31.250141: val_loss -0.3608\n",
      "2024-12-06 16:42:31.257956: Pseudo dice [0.707]\n",
      "2024-12-06 16:42:31.257956: Epoch time: 131.26 s\n",
      "2024-12-06 16:42:32.474528: \n",
      "2024-12-06 16:42:32.474528: Epoch 970\n",
      "2024-12-06 16:42:32.484526: Current learning rate: 0.00043\n",
      "2024-12-06 16:44:43.955703: train_loss -0.8861\n",
      "2024-12-06 16:44:43.965207: val_loss -0.3024\n",
      "2024-12-06 16:44:43.971608: Pseudo dice [0.7194]\n",
      "2024-12-06 16:44:43.981606: Epoch time: 131.49 s\n",
      "2024-12-06 16:44:45.364851: \n",
      "2024-12-06 16:44:45.371532: Epoch 971\n",
      "2024-12-06 16:44:45.381531: Current learning rate: 0.00041\n",
      "2024-12-06 16:46:56.718716: train_loss -0.878\n",
      "2024-12-06 16:46:56.728714: val_loss -0.3647\n",
      "2024-12-06 16:46:56.735203: Pseudo dice [0.7237]\n",
      "2024-12-06 16:46:56.735203: Epoch time: 131.35 s\n",
      "2024-12-06 16:46:57.885370: \n",
      "2024-12-06 16:46:57.885370: Epoch 972\n",
      "2024-12-06 16:46:57.895369: Current learning rate: 0.0004\n",
      "2024-12-06 16:49:09.232309: train_loss -0.8783\n",
      "2024-12-06 16:49:09.242307: val_loss -0.5328\n",
      "2024-12-06 16:49:09.248960: Pseudo dice [0.8258]\n",
      "2024-12-06 16:49:09.258959: Epoch time: 131.35 s\n",
      "2024-12-06 16:49:10.386399: \n",
      "2024-12-06 16:49:10.394401: Epoch 973\n",
      "2024-12-06 16:49:10.398875: Current learning rate: 0.00039\n",
      "2024-12-06 16:51:21.831331: train_loss -0.8793\n",
      "2024-12-06 16:51:21.845887: val_loss -0.3987\n",
      "2024-12-06 16:51:21.855886: Pseudo dice [0.789]\n",
      "2024-12-06 16:51:21.862582: Epoch time: 131.45 s\n",
      "2024-12-06 16:51:23.039170: \n",
      "2024-12-06 16:51:23.046687: Epoch 974\n",
      "2024-12-06 16:51:23.046687: Current learning rate: 0.00037\n",
      "2024-12-06 16:53:34.469121: train_loss -0.8727\n",
      "2024-12-06 16:53:34.476250: val_loss -0.5051\n",
      "2024-12-06 16:53:34.486248: Pseudo dice [0.7831]\n",
      "2024-12-06 16:53:34.492917: Epoch time: 131.43 s\n",
      "2024-12-06 16:53:35.652683: \n",
      "2024-12-06 16:53:35.659499: Epoch 975\n",
      "2024-12-06 16:53:35.659499: Current learning rate: 0.00036\n",
      "2024-12-06 16:55:47.039884: train_loss -0.8693\n",
      "2024-12-06 16:55:47.058767: val_loss -0.4219\n",
      "2024-12-06 16:55:47.074233: Pseudo dice [0.7283]\n",
      "2024-12-06 16:55:47.074233: Epoch time: 131.39 s\n",
      "2024-12-06 16:55:48.206496: \n",
      "2024-12-06 16:55:48.216496: Epoch 976\n",
      "2024-12-06 16:55:48.223922: Current learning rate: 0.00035\n",
      "2024-12-06 16:57:59.653683: train_loss -0.8783\n",
      "2024-12-06 16:57:59.670260: val_loss -0.4022\n",
      "2024-12-06 16:57:59.680258: Pseudo dice [0.7476]\n",
      "2024-12-06 16:57:59.686929: Epoch time: 131.45 s\n",
      "2024-12-06 16:58:00.804725: \n",
      "2024-12-06 16:58:00.814724: Epoch 977\n",
      "2024-12-06 16:58:00.820171: Current learning rate: 0.00034\n",
      "2024-12-06 17:00:12.117184: train_loss -0.8786\n",
      "2024-12-06 17:00:12.133889: val_loss -0.3005\n",
      "2024-12-06 17:00:12.133889: Pseudo dice [0.7222]\n",
      "2024-12-06 17:00:12.143887: Epoch time: 131.31 s\n",
      "2024-12-06 17:00:13.533823: \n",
      "2024-12-06 17:00:13.533823: Epoch 978\n",
      "2024-12-06 17:00:13.543822: Current learning rate: 0.00032\n",
      "2024-12-06 17:02:24.808303: train_loss -0.8798\n",
      "2024-12-06 17:02:24.814164: val_loss -0.281\n",
      "2024-12-06 17:02:24.830614: Pseudo dice [0.6417]\n",
      "2024-12-06 17:02:24.830863: Epoch time: 131.28 s\n",
      "2024-12-06 17:02:25.964659: \n",
      "2024-12-06 17:02:25.974161: Epoch 979\n",
      "2024-12-06 17:02:25.980841: Current learning rate: 0.00031\n",
      "2024-12-06 17:04:37.422136: train_loss -0.8807\n",
      "2024-12-06 17:04:37.429880: val_loss -0.4941\n",
      "2024-12-06 17:04:37.444599: Pseudo dice [0.7857]\n",
      "2024-12-06 17:04:37.444599: Epoch time: 131.46 s\n",
      "2024-12-06 17:04:38.588886: \n",
      "2024-12-06 17:04:38.594837: Epoch 980\n",
      "2024-12-06 17:04:38.594837: Current learning rate: 0.0003\n",
      "2024-12-06 17:06:49.841388: train_loss -0.8788\n",
      "2024-12-06 17:06:49.851410: val_loss -0.369\n",
      "2024-12-06 17:06:49.858319: Pseudo dice [0.7138]\n",
      "2024-12-06 17:06:49.867822: Epoch time: 131.26 s\n",
      "2024-12-06 17:06:51.075560: \n",
      "2024-12-06 17:06:51.085063: Epoch 981\n",
      "2024-12-06 17:06:51.092310: Current learning rate: 0.00028\n",
      "2024-12-06 17:09:02.555214: train_loss -0.8764\n",
      "2024-12-06 17:09:02.565212: val_loss -0.2631\n",
      "2024-12-06 17:09:02.571880: Pseudo dice [0.7656]\n",
      "2024-12-06 17:09:02.581879: Epoch time: 131.48 s\n",
      "2024-12-06 17:09:03.738549: \n",
      "2024-12-06 17:09:03.748547: Epoch 982\n",
      "2024-12-06 17:09:03.755164: Current learning rate: 0.00027\n",
      "2024-12-06 17:11:15.052235: train_loss -0.8729\n",
      "2024-12-06 17:11:15.068932: val_loss -0.3486\n",
      "2024-12-06 17:11:15.068932: Pseudo dice [0.7653]\n",
      "2024-12-06 17:11:15.078931: Epoch time: 131.31 s\n",
      "2024-12-06 17:11:16.245464: \n",
      "2024-12-06 17:11:16.253568: Epoch 983\n",
      "2024-12-06 17:11:16.253568: Current learning rate: 0.00026\n",
      "2024-12-06 17:13:27.515860: train_loss -0.8783\n",
      "2024-12-06 17:13:27.532526: val_loss -0.4821\n",
      "2024-12-06 17:13:27.542526: Pseudo dice [0.8408]\n",
      "2024-12-06 17:13:27.549304: Epoch time: 131.27 s\n",
      "2024-12-06 17:13:28.675777: \n",
      "2024-12-06 17:13:28.690330: Epoch 984\n",
      "2024-12-06 17:13:28.695330: Current learning rate: 0.00024\n",
      "2024-12-06 17:15:40.098399: train_loss -0.8764\n",
      "2024-12-06 17:15:40.108397: val_loss -0.3715\n",
      "2024-12-06 17:15:40.112804: Pseudo dice [0.7564]\n",
      "2024-12-06 17:15:40.122803: Epoch time: 131.42 s\n",
      "2024-12-06 17:15:41.273633: \n",
      "2024-12-06 17:15:41.279441: Epoch 985\n",
      "2024-12-06 17:15:41.289440: Current learning rate: 0.00023\n",
      "2024-12-06 17:17:52.660080: train_loss -0.8758\n",
      "2024-12-06 17:17:52.676665: val_loss -0.3961\n",
      "2024-12-06 17:17:52.676665: Pseudo dice [0.7707]\n",
      "2024-12-06 17:17:52.686665: Epoch time: 131.39 s\n",
      "2024-12-06 17:17:54.020910: \n",
      "2024-12-06 17:17:54.026486: Epoch 986\n",
      "2024-12-06 17:17:54.026486: Current learning rate: 0.00021\n",
      "2024-12-06 17:20:05.323694: train_loss -0.8802\n",
      "2024-12-06 17:20:05.333707: val_loss -0.4798\n",
      "2024-12-06 17:20:05.340177: Pseudo dice [0.8094]\n",
      "2024-12-06 17:20:05.350176: Epoch time: 131.31 s\n",
      "2024-12-06 17:20:06.506986: \n",
      "2024-12-06 17:20:06.506986: Epoch 987\n",
      "2024-12-06 17:20:06.516984: Current learning rate: 0.0002\n",
      "2024-12-06 17:22:17.887733: train_loss -0.881\n",
      "2024-12-06 17:22:17.907746: val_loss -0.3552\n",
      "2024-12-06 17:22:17.917748: Pseudo dice [0.7076]\n",
      "2024-12-06 17:22:17.920543: Epoch time: 131.38 s\n",
      "2024-12-06 17:22:19.054209: \n",
      "2024-12-06 17:22:19.054209: Epoch 988\n",
      "2024-12-06 17:22:19.063712: Current learning rate: 0.00019\n",
      "2024-12-06 17:24:30.269263: train_loss -0.8753\n",
      "2024-12-06 17:24:30.288070: val_loss -0.4124\n",
      "2024-12-06 17:24:30.299072: Pseudo dice [0.7919]\n",
      "2024-12-06 17:24:30.300957: Epoch time: 131.22 s\n",
      "2024-12-06 17:24:31.467488: \n",
      "2024-12-06 17:24:31.467488: Epoch 989\n",
      "2024-12-06 17:24:31.477486: Current learning rate: 0.00017\n",
      "2024-12-06 17:26:42.697874: train_loss -0.8757\n",
      "2024-12-06 17:26:42.715259: val_loss -0.4242\n",
      "2024-12-06 17:26:42.716718: Pseudo dice [0.8252]\n",
      "2024-12-06 17:26:42.731274: Epoch time: 131.23 s\n",
      "2024-12-06 17:26:43.882902: \n",
      "2024-12-06 17:26:43.883452: Epoch 990\n",
      "2024-12-06 17:26:43.892956: Current learning rate: 0.00016\n",
      "2024-12-06 17:28:55.344870: train_loss -0.8773\n",
      "2024-12-06 17:28:55.354868: val_loss -0.3553\n",
      "2024-12-06 17:28:55.361508: Pseudo dice [0.7638]\n",
      "2024-12-06 17:28:55.361508: Epoch time: 131.46 s\n",
      "2024-12-06 17:28:56.577906: \n",
      "2024-12-06 17:28:56.578186: Epoch 991\n",
      "2024-12-06 17:28:56.588185: Current learning rate: 0.00014\n",
      "2024-12-06 17:31:07.875173: train_loss -0.8756\n",
      "2024-12-06 17:31:07.885172: val_loss -0.2992\n",
      "2024-12-06 17:31:07.893444: Pseudo dice [0.7431]\n",
      "2024-12-06 17:31:07.902948: Epoch time: 131.3 s\n",
      "2024-12-06 17:31:09.049657: \n",
      "2024-12-06 17:31:09.057659: Epoch 992\n",
      "2024-12-06 17:31:09.059880: Current learning rate: 0.00013\n",
      "2024-12-06 17:33:20.449961: train_loss -0.8774\n",
      "2024-12-06 17:33:20.456050: val_loss -0.4497\n",
      "2024-12-06 17:33:20.472283: Pseudo dice [0.7921]\n",
      "2024-12-06 17:33:20.472283: Epoch time: 131.4 s\n",
      "2024-12-06 17:33:21.898776: \n",
      "2024-12-06 17:33:21.906861: Epoch 993\n",
      "2024-12-06 17:33:21.906861: Current learning rate: 0.00011\n",
      "2024-12-06 17:35:33.235898: train_loss -0.8738\n",
      "2024-12-06 17:35:33.253603: val_loss -0.4762\n",
      "2024-12-06 17:35:33.263600: Pseudo dice [0.7094]\n",
      "2024-12-06 17:35:33.269924: Epoch time: 131.34 s\n",
      "2024-12-06 17:35:34.445723: \n",
      "2024-12-06 17:35:34.452480: Epoch 994\n",
      "2024-12-06 17:35:34.452480: Current learning rate: 0.0001\n",
      "2024-12-06 17:37:45.676183: train_loss -0.8695\n",
      "2024-12-06 17:37:45.689686: val_loss -0.4557\n",
      "2024-12-06 17:37:45.699226: Pseudo dice [0.778]\n",
      "2024-12-06 17:37:45.700151: Epoch time: 131.23 s\n",
      "2024-12-06 17:37:46.959491: \n",
      "2024-12-06 17:37:46.966148: Epoch 995\n",
      "2024-12-06 17:37:46.966148: Current learning rate: 8e-05\n",
      "2024-12-06 17:39:58.314110: train_loss -0.8754\n",
      "2024-12-06 17:39:58.330392: val_loss -0.4637\n",
      "2024-12-06 17:39:58.339895: Pseudo dice [0.7234]\n",
      "2024-12-06 17:39:58.346587: Epoch time: 131.35 s\n",
      "2024-12-06 17:39:59.481335: \n",
      "2024-12-06 17:39:59.490839: Epoch 996\n",
      "2024-12-06 17:39:59.496933: Current learning rate: 7e-05\n",
      "2024-12-06 17:42:10.936877: train_loss -0.8817\n",
      "2024-12-06 17:42:10.952366: val_loss -0.2768\n",
      "2024-12-06 17:42:10.960397: Pseudo dice [0.7249]\n",
      "2024-12-06 17:42:10.962265: Epoch time: 131.46 s\n",
      "2024-12-06 17:42:12.210406: \n",
      "2024-12-06 17:42:12.210406: Epoch 997\n",
      "2024-12-06 17:42:12.220403: Current learning rate: 5e-05\n",
      "2024-12-06 17:44:23.524025: train_loss -0.8743\n",
      "2024-12-06 17:44:23.540228: val_loss -0.5343\n",
      "2024-12-06 17:44:23.540537: Pseudo dice [0.756]\n",
      "2024-12-06 17:44:23.557232: Epoch time: 131.31 s\n",
      "2024-12-06 17:44:24.790447: \n",
      "2024-12-06 17:44:24.807136: Epoch 998\n",
      "2024-12-06 17:44:24.807136: Current learning rate: 4e-05\n",
      "2024-12-06 17:46:36.304605: train_loss -0.8796\n",
      "2024-12-06 17:46:36.321551: val_loss -0.5497\n",
      "2024-12-06 17:46:36.322940: Pseudo dice [0.7974]\n",
      "2024-12-06 17:46:36.332938: Epoch time: 131.51 s\n",
      "2024-12-06 17:46:37.505577: \n",
      "2024-12-06 17:46:37.515080: Epoch 999\n",
      "2024-12-06 17:46:37.521669: Current learning rate: 2e-05\n",
      "2024-12-06 17:48:48.734529: train_loss -0.8761\n",
      "2024-12-06 17:48:48.751200: val_loss -0.2262\n",
      "2024-12-06 17:48:48.751200: Pseudo dice [0.6402]\n",
      "2024-12-06 17:48:48.769562: Epoch time: 131.23 s\n",
      "2024-12-06 17:48:50.543736: Training done.\n",
      "2024-12-06 17:48:50.618270: Using splits from existing split file: D:/Liver Segmentation Meena 2024/nnUNet_blastoma_2025/nnUNet_preprocessed\\Dataset007_Blastoma\\splits_final.json\n",
      "2024-12-06 17:48:50.634976: The split file contains 5 splits.\n",
      "2024-12-06 17:48:50.634976: Desired fold for training: 4\n",
      "2024-12-06 17:48:50.651567: This split has 20 training and 4 validation cases.\n",
      "2024-12-06 17:48:50.661071: predicting volume_10\n",
      "2024-12-06 17:48:50.678129: volume_10, shape torch.Size([1, 512, 512, 512]), rank 0\n",
      "2024-12-06 17:52:33.056524: predicting volume_11\n",
      "2024-12-06 17:52:33.115482: volume_11, shape torch.Size([1, 509, 512, 512]), rank 0\n",
      "2024-12-06 17:56:13.651282: predicting volume_13\n",
      "2024-12-06 17:56:13.707570: volume_13, shape torch.Size([1, 541, 447, 447]), rank 0\n",
      "2024-12-06 17:59:19.519902: predicting volume_14\n",
      "2024-12-06 17:59:19.580107: volume_14, shape torch.Size([1, 539, 454, 454]), rank 0\n",
      "2024-12-06 18:03:59.263406: Validation complete\n",
      "2024-12-06 18:03:59.273405: Mean Validation Dice:  0.626050796159212\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "try:\n",
    "    !nnUNetv2_train 007 3d_fullres 4 -tr nnUNetTrainer\n",
    "except Exception as e:\n",
    "    print(f\"Error during training: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
